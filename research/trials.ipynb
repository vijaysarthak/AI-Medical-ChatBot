{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f3bfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fd6f151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Deployed\\\\GenAI\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2609b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf8e958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Deployed\\\\GenAI'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02ecee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26d88fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from PDF files\n",
    "def load_pdf_files(data):\n",
    "    loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2daeb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_files(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0092ff16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 0, 'page_label': '1'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              1 \\n \\n  \\n \\nAcademic Regulations'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 1, 'page_label': '2'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              2 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nRegulation No.: PU/AC-26/6/07_2025 \\n \\nResolution No. 26.6 of the 26th Meeting of the Academic Council held on \\n25/07/2025 and ratified by the Board of Management in its Meeting held on \\n28/07/2025 \\n \\n \\n              \\n \\n \\nJuly 2025 \\n \\n \\n \\n \\n \\n \\n \\n \\nAcademic Regulations'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 2, 'page_label': '3'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              3 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n[Left Blank intentionally]'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 3, 'page_label': '4'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              4 \\n \\nContents \\nPRELIMINARY ........................................................................................................................................ 5 \\n1.0    INTRODUCTION ....................................................................................................................... 6 \\n2.0    ACADEMIC CALENDAR .......................................................................................................... 7 \\n3.0    REGISTRATION ........................................................................................................................ 7 \\n4.0    MEDIUM OF INSTRUCTION AND EVALUATION .......................................................... 11 \\n5.0    COURSE CREDIT STRUCTURE .......................................................................................... 11 \\n6.0    PROGRAM REGULATIONS AND CURRICULUM (PRC) ............................................... 12 \\n7.0    ATTENDANCE REQUIREMENTS ........................................................................................ 13 \\n8.0    TEACHING, EVALUATION AND GRADING SYSTEM .................................................. 14 \\n9.0    ACADEMIC PERFORMANCE INDICES: SGPA AND CGPA ........................................ 19 \\n10.0  DISPLAY OF PERFORMANCE IN CONTINUOUS ASSESSMENTS ........................... 20 \\n11.0  DETAILED SCHEDULE OF EXAMINATIONS .................................................................. 21 \\n12.0  APPEAL FOR REVIEW OF GRADES .................................................................................. 21 \\n13.0  MAKE-UP EXAMINATIONS .................................................................................................. 22 \\n14.0  ACADEMIC PROMOTION ..................................................................................................... 23 \\n15.0  SUMMER TERM ....................................................................................................................... 24 \\n16.0  WITHDRAWAL FROM THE PROGRAM ............................................................................. 26 \\n17.0  TRANSFER OF CREDITS ...................................................................................................... 26 \\n18.0  MAXIMUM DURATION FOR THE COMPLETION OF A PROGRAM ........................... 28 \\n19.0  REQUIREMENTS FOR THE AWARD OF DEGREE ......................................................... 29 \\n20.0   PROVISIONAL DEGREE CERTIFICATE ........................................................................... 30 \\n21.0   CONVOCATION ....................................................................................................................... 30 \\n22.0   ISSUE OF DEGREE CERTIFICATE BEFORE THE CONVOCATION ......................... 30 \\n23.0  POWER TO REVISE, MODIFY AND AMEND .................................................................. 31 \\nANNEXURE A ....................................................................................................................................... 32 \\nANNEXURE B ....................................................................................................................................... 34 \\nANNEXURE C ....................................................................................................................................... 35 \\nANNEXURE D ....................................................................................................................................... 36'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 4, 'page_label': '5'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              5 \\nAcademic Regulations \\nIn exercise of the powers conferred by and in discharge of duties assigned under the relevant \\nprovision(s) of the Act and Statutes of the Presidency University, the Academic Council hereby \\nmakes the following Regulations, namely.  \\nPRELIMINARY  \\nShort Title and Commencement   \\nThese Regulations shall be called the Academic Regulations. They shall come into force with \\nimmediate effect.  \\nDefinitions  \\nIn these Regulations, unless the context otherwise requires:  \\na) “Academic Calendar” means the schedule of academic and miscellaneous events as \\napproved by the Vice Chancellor;  \\nb) “Academic Council” means the Academic Council of the University;  \\nc) “Academic Regulations” means the Academic Regulations, of the University;  \\nd) “Academic Term” means a Semester or Summer Term  \\ne) “Act” means the Presidency University Act. 2013;  \\nf) “BOG” means the Board of Governors of the University; \\ng) \"BOM” means the Board of Management of the University; \\nh) “BOE” means the Board of Examinations of the University;  \\ni) “BOS” means the Board of Studies of a particular Department/Program of Study of the \\nUniversity;  \\nj) “Basket” means a group of  Courses bundled together based on the nature/type of the \\nCourse.  \\nk) “COE” means the Controller of Examinations of the University;  \\nl) “Clause” means the duly numbered Clause, with Sub-Clauses included, if any, of these \\nRegulations;  \\nm) “Course” means a specific subject usually identified by its Course-code and Course-title, \\nwith specified credits and syllabus/course -description, a set of references, taught by \\nsome teacher(s)/course -instructor(s) to a specific class (group of students) during a \\nspecific Academic Term;  \\nn) “Course In Charge” means the teacher/faculty member responsible for developing and \\norganising the delivery of the Course; \\no) “Course Instructor” means the teacher/faculty member responsible for teaching and \\nevaluation of a Course;'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 5, 'page_label': '6'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              6 \\np) “Curriculum Structure” means the Curriculum governing a specific Degree Program \\noffered by the University, and, includes the set of Baskets of Courses along with \\nminimum credit requirements to be earned under each basket for a degree/degree with \\nspecialization/minor/honours in addition to the relevant details of the  Courses an d \\nCourse catalogues (which describes the Course content and other important information \\nabout the Course). Any specific requirements for a particular program may be brought \\ninto the Curriculum structure of the specific program and relevant approvals should  be \\ntaken from the BOS and Academic Council at that time.  \\nq) “DAC” means the Departmental Academic Committee of a concerned \\nDepartment/Program of Study of the University;  \\nr) “Dean” means the Dean/Director of the concerned School;  \\ns) “Degree Program” includes all Degree Programs;  \\nt) “Department” means the Department offering the degree Program(s)/Course(s)/School \\noffering the concerned Degree Programs/other Administrative Offices;  \\nu) “HOD” means the Head of the Department;  \\nv) “MOU” means the Memorandum of Understanding;  \\nw) “Parent Department” means the department that offers the Degree Program that a \\nstudent undergoes;  \\nx) “School” means a constituent institution of the University established for monitoring, \\nsupervising and guiding, teaching, trai ning and research activities in broadly related \\nfields of studies;  \\ny) “Section” means the duly numbered Section, with Clauses included in that Section, of \\nthese Regulations;  \\nz) “Statutes” means the Statutes of Presidency University;  \\naa) “Sub-Clause” means the duly numbered Sub-Clause of these Regulations;  \\nbb) \"Summer Term” means an additional Academic Term conducted during the summer \\nbreak;  \\ncc) “University” means Presidency University, Bengaluru; and  \\ndd) “Vice Chancellor” means the Vice Chancellor of the University.  \\n1.0 INTRODUCTION  \\n1.1 The Academic Regulations  are applicable to all existing Degree Programs of the \\nUniversity. The Academic Regulations, and any amendments made therein, shall also \\nbe applicable to new Degree , Diploma and Certificate Programs that the University \\nmay offer in the future.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 6, 'page_label': '7'}, page_content=\"Regulation No.: PU/AC-26/6/07_2025                                                                              7 \\n \\n1.2 These Regulations are in compliance with the University Grants Commission \\n(Minimum Standards of Instruction for the Grant of Undergraduate Degree and \\nPostgraduate Degree) Regulations, 2025. The specific criteria and mandatory \\nrequirements prescribed by this UGC Regulations 2025, shall be included in the \\nProgram Regulations and Curriculum (PRC) of the respective program.  \\n1.3 Further amendments  and a dditional Regulations, if any, and specific \\ncriteria/mandatory requirements prescribed by the concerned Regulatory Bodies for \\na particular Degree Program shall be included in the Program Regulations and \\nCurriculum (PRC) of the respective program.  \\n1.4 These Regulations may evolve and get amended or modified or changed through \\nappropriate approvals from the Academic Council, from time to time, and shall be \\nbinding on all concerned.  \\n1.5 The effect of periodic amendments or changes in the Academic Regulations , on the \\nstudents admitted in earlier years, shall be dealt with appropriately and carefully, to \\nensure that those students are not subjected to any unfair situation whatsoever, \\nalthough they are required to conform to these revised Academic Regulations, \\nwithout any undue favour or considerations.  \\n2.0 ACADEMIC CALENDAR  \\n2.1 The academic activities of the University are regulated by the Academic Calendar \\napproved by the Vice Chancellor and  released at the beginning of each Academic \\nYear. The Academic Calendar indicating all academic activities in chronological order, \\nshall be prepared by the Office of Dean - Academics and approved by the Vice \\nChancellor. After approval, the same shall be released by the Dean - Academics at \\nleast two weeks prior to the  commencement of the concerned academic year . It is \\nmandatory for both students and faculty to strictly adhere to the academic calendar \\nto ensure timely completion of  academic activities. Deviations , if any , under \\nunforeseen/unavoidable circumstances shall be allowed with the prior approval of the \\nVice Chancellor, and the same should be duly notified.  \\n2.2 An academic year at the University shall normally be divided into two semesters \\nconsisting of ninety (90) University working days each, known as the Odd Semester \\n(normally from August to December) and the Even Semester (normally from January \\nto May).  \\n2.3 During the summer break, i.e., (June and July), there may be an additional Academic \\nTerm known as the Summer Term. The duration of the Summer Term is around eight \\n(08) calendar weeks and shall include a minimum of thirty (30) instructional days.  \\n3.0 REGISTRATION  \\n3.1 The registration process is a fundamental aspect of the University's academic \\nframework, designed to provide a structured procedure for students to select and \\nenrol in Courses that align with program requirements and their academic goals.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 7, 'page_label': '8'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              8 \\n3.2 Registration for the relevant Academic Term  ensures timely progression in the \\nprogram by adhering to guidelines regarding Course prerequisites, necessary Courses \\nas per curriculum requirements, and the credits required for the timely completion of \\nthe minimum credit requirements for the award of the respective degree. \\n3.3 The registration at the beginning of each Semester during the prescribed period \\nannounced in the Academic Calendar and through notifications issued by the \\nUniversity to this effect, is mandatory for every student.  \\n3.4 Registration is the sole responsibility of the student. Without registration, any \\nacademic activity (Course  / Seminar / Practical / Project Work / Internship, etc.) \\nundergone by a student will not be counted towards the requirements of their Degree.  \\n3.5 The Chairperson of each Departmental Academic Committee (DAC) shall \\ncommunicate the list of approved/prescribed Courses available for registration in the \\nconcerned Academic Term to the Office of the Dean - Academics for notification. (The \\nconstitution and functions of the Departmental Academic Committee (DAC) are \\nplaced in ANNEXURE A.) \\n3.6 Upon joining the University, each student is assigned to a mentor who will counsel \\nand guide the student on matters related to academic s/registration process. Every \\nstudent after consulting her/his mentor is required to register for Courses of his/her \\nchoice from the list of proposed Courses within the time period specified for such \\nregistration as notified in the Academic Calendar or the University notification to this \\neffect.  \\n3.7 Normally, late registration is not permitted. However, considering medical exigencies, \\nspecifically hospitalization, trauma, including death of immediate family members \\n(Parents, Offspring, Siblings and Spouse) or contagious disease, a student may be \\npermitted for late registration with prior approval from the respective H oD. The \\nstudent must produce medical certificates, medical prescriptions, hospital discharge \\nreport, medical fitness report and all such releva nt documents duly attested by the \\nconcerned registered medical officer of the hospital where the concerned student was \\nhospitalized or medically treated. The student shall not be eligible for late registration \\nif she/he fails to produce authentic medical c ertificates and relevant documents in \\nsupport of the medical exigency.  \\n3.7.1 Further, in such specified cases of medical exigency (viz. hospitalization, \\ntrauma or contagious disease only), the maximum period permissible for late \\nregistration shall not exceed Eighteen (18) University working days counted \\nfrom the commencement of the semester (only Odd and Even semesters) as \\nannounced by the University. Under no circumstances shall such a student \\nbe permitted to register for the semester after the permissible period for late \\nregistration of Eighteen (18) University working days counted from the \\ncommencement of semester.  \\n3.7.2 Further, if a student has been selected/nominated by State/National/  \\nInternational Organizations/Boards to represent th e State and/or India in \\nState/National/International Competitions/Events,  as recommended by the'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 8, 'page_label': '9'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              9 \\nDepartment and approved by the Vice Chancellor, the concerned student may \\nbe permitted for late registration. The student must produce duly attested \\ndocuments and/or certificates to be eligible for the provision of late \\nregistration. The number of days for which the concerned student will be \\ngiven permission for late registration shall be approved by the Vice Chancellor \\nbased on the recommendation of the Dean of the School concerned. Further, \\nno relaxation will be given on attendance requirements, except as permissible \\nunder Clause 7.4.  \\n3.8 In case of any other reason for late registration other than the specified medical \\nexigencies outlined in Clause 3.7 above, the maximum permissible period for late \\nregistration shall not exceed FIVE (05) University working days counted from the \\nspecified date of Registration announced by the University. The  student shall pay a \\nLate Fee for late registration, as specified by the University at the commencement of \\nthe semester. Further, no relaxation whatsoever will be given on attendance \\nrequirements for late registration. Under no circumstances will such a student be \\npermitted to register for the semester after the permissible period for late registration \\nof FIVE (05) University working days counted from the specified date of Registration.  \\n3.9 Students are not permitted to re -register for Courses which t hey have already \\npassed, except under the provisions and conditions  mentioned in Clauses/Sub-\\nClauses 7.6, 8.14, 8.15.3 and 14.4 to improve their performance. \\n3.10 A student shall be permitted to register only if all of the following conditions are \\nfulfilled:  \\n3.10.1 The student has paid all specified fees to the University as per the University \\nFee Policy and payment schedule; \\n3.10.2 The student has cleared all University, Hostel, Transport and Library dues (if \\nany); \\n3.10.3 The student fulfils the yearly promotion criteria as stipulated in Section 14.0; \\nand  \\n3.10.4 The student has not been debarred from registering on any specific ground \\nby the University.  \\n3.11 Course Pre-Requisites: To register for some Courses, students may be required to \\nhave prior exposure to  or passed some specified Courses. Such Course pre-\\nrequisites shall be specified in the concerned Program Regulations and Curriculum \\n(PRC) as approved by the DAC and the BOS. If a student has secured an NP (Not \\nPermitted) Grade (Clause 8.14) due to a shortage of attendance in the pre-requisite \\nCourse(s), the student will not be permitted to register for the concerned Course(s). \\n3.12 Failure to Register and Removal from the Rolls: A student who is eligible for \\nregistration but  fails to register for the Semester within the specified dates and \\nconditions prescribed in Clauses 3.1 to 3.8, shall be removed from the rolls for the \\nconcerned semester. Consequently, the student shall not be permitted to attend \\nclasses for the concerned semester.  The student is cautioned that this will'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 9, 'page_label': '10'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              10 \\nresult in the loss of an Academic Year for the student . Such a student shall \\nbe required to discontinue the Program temporarily and shall rejoin the Program of \\nstudy by completing the Registration process in the applicable Semester of the \\nfollowing Academic Year, and shall adhere to the Academic Regulations and Program \\nRegulations and Curriculum applicable to the batch in which the student is rejoining \\nthe Program of study.  \\n3.13 Mandatory Pre -Registration ( for Elective/Specialization/Open Courses) for higher \\nsemesters: In order to facilitate proper planning of academic activities of a \\nsemester, it is essential for students to declare their intent to register for an \\nElective/Specialization/Open Course well in advance, before the actual start of the \\nconcerned Academic Term , through the process of Pre -Registration. All students \\n(other than the freshly admitted students) intending to register for the next higher \\nsemester are required to have completed the Mandatory Pre -Registration of \\nElective/Specialization/Open Course(s),  as applicable , as per the schedule/dates \\nannounced in the Academic Calendar and/or the official notifications issued  by the \\nUniversity to this effect. To facilitate this Pre -Registration process all teaching \\nDepartments/Schools shall announce the list of Courses to be offered for the next \\nhigher semester, at least four (04) University working weeks before the last day of \\nclasses in the current semester.  \\n3.14 The University reserves the right to withhold registration or to cancel the \\nregistration of any studen t who is not in compliance with the University’s \\nregulations, policies, and rules. \\n3.15 Registration for each semester must be completed in a sequential manner. Failure \\nto register for a semester will result in the loss of an academic year, as the missed \\nsemester must be completed (in the following Academic Year) before registering in \\nthe subsequent semester of the Program of study. \\n3.16 Audit a Course \\n3.16.1 Auditing a Course is a provision for a student who may opt to register for \\na Course to acquire knowledge/skills, without earning credits and grade \\npoints. \\n3.16.2 A student who desires to register to Audit a Course shall consult her/his \\nmentor and seek approval of the concerned Course Instructor. Registration \\nto Audit a Course shall only be permitted as per the criteria and guidelines \\nprescribed by the concerned Course Instructor and duly approved by the \\nconcerned Departmental Academic Committee (DAC). The student will not \\nearn credits for the Audited Course. \\n3.16.3 Auditing is not available during the Summer Term. \\n3.16.4 Audit is not permitted in Courses that involve laboratory/field/studio work, \\nor other types of practice-based instruction. \\n3.16.5 Audited Courses shall not count towards fulfilling degree requirements.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 10, 'page_label': '11'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              11 \\n4.0 MEDIUM OF INSTRUCTION AND EVALUATION  \\nEnglish shall be the medium of instruction and evaluation , except for specific Courses as \\napproved by the Academic Council.  \\n5.0 COURSE CREDIT STRUCTURE  \\nThe credit structure is used to define various types of  Courses, ensuring the appropriate \\npedagogy and methods of assessment and evaluation. The flexibility required to \\naccomplish the  Course learning objectives and outcomes can be provided for, while \\nretaining a common framework for credit allocation. More importantly, it is necessary to \\nhave a transparent, credible and robust system for the planning, delivery and evaluation \\nof each Course within the diverse programs of study offered by the University.  \\n5.1 The Credit Structure for defining and categorizing Courses follows the L-T-P-C \\n(Lecture - Tutorial- Practical - Credit) framework. Credits are assigned based on the \\nfollowing norms:  \\nLecture: One (01) contact/classroom hour per week for 15 weeks is assigned One \\n(01) Credit.  \\nTutorial: One (01) contact/classroom hour per week for 15 weeks is assigned One \\n(01) Credit  \\nPractical: Two (02) hours per week of practical/laboratory/ studio/field work and \\nother similar practice or skill development components  for 15 weeks, are assigned \\nOne (01) Credit.  \\nFor example:  \\n\\uf0b7 A Course with L-T-P structure of 3–0–0 will be assigned 3 Credits. \\n\\uf0b7 A Course with L-T-P structure of 3–1–0 will be assigned 4 Credits. \\n\\uf0b7 A Course with L-T-P structure of 3–0–2 will be assigned 4 Credits.  \\n\\uf0b7 A Course with L-T-P structure of 0–0–4 will be assigned 2 Credits.  \\n\\uf0b7 A Course with L-T-P structure of 2–0–2 will be assigned 3 Credits.  \\n\\uf0b7 A Course with L-T-P structure of 1-0-4 will be assigned 3 Credits \\nIn effect, a 3-Credit Course with structure of 3-0-0 mandatorily requires 45 hours of \\nContact/Classroom hours . Similarly, a  3-Credit Course with structure 1 -0-4 \\nmandatorily requires 15 hours of Contact/Classroom hours and 60 hours of \\nPractice/Lab hours. \\n5.2 Practical/Skill based Courses like Capstone Project, Internship, Industry Immersion, \\nInternational Immersion, Project Work, Studio, Field Visits, Dissertation, Seminar, \\nand such similar Courses  including Portfolio, Interdisciplinary Projects and Social \\nImmersion Courses, where the pedagogy does not lend itself to a typical L-T-P-C \\nstructure as defined in Clause 5.1, are assigned the number of Credits based on the \\nquantum of work/effort required to fulfil the learning objectives and outcomes'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 11, 'page_label': '12'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              12 \\nprescribed for the concerned Courses , referred to as Non -Teaching Credit Courses \\n(NTCC).  \\n5.3 A student earns credits by satisfactorily undergoing the Course evaluation. The \\ncredits associated with a Course are dependent upon the number of hours of \\ninstruction in that Course. \\n6.0 PROGRAM REGULATIONS AND CURRICULUM (PRC) \\nThe Program Regulations and Curriculum (PRC) is a set of Program specific regulations, as \\napplicable, and the Program Structure and Curriculum for the concerned Degree Program. All \\nAcademic Programs (except the Ph.D. Program) shall be governed by the respective Program \\nRegulations and Curriculum. The Program Regulations and Curriculum shall be recommended by \\nthe concerned Board of Studies for approval of the Academic Council . The program leading to \\nthe award of a Ph.D. degree  shall be governed by the Ph.D. Regulations , which shall be \\nrecommended by the Research and Innovation Council of the University for Approval of the \\nAcademic Council.   \\nThe Program Regulations and Curriculum for all Undergraduate and Postgraduate Programs shall \\ninclude details with respect to Eligibility for Admission, Program duration, mandatory minimum \\ncredit requirements for the award of the Degree, assessment and evaluation guidelines/criteria, \\nand any other regulations mandated by concerned Government Regulatory Bodies, where \\napplicable, for the specific Program of study. \\n6.1 Eligibility for Admission:  \\n6.1.1 The basic eligibility for the admission to all Programs of the University shall \\nbe as per the norms specified by the respecti ve statutory  bodies such as \\nUniversity Grants Commission (UGC), All India Council for Technical \\nEducation (AICTE), Bar Council of India (BCI), Karnataka State Higher \\nEducation Council (KSHEC) and other relevant statutory bodies.  \\n6.1.2 Lateral Entry, where applicable, i.e. admission to the second year of a \\nProgram, shall be as per the norms specified by the respective statutory  \\nbodies such as UGC, AICTE, BCI, KSHEC and other relevant statutory bodies.  \\n6.1.3 A student who seeks admission to a higher semester of a Program as a \\ntransfer from another University, must comply with the eligibility criteria \\nmentioned above in Sub-Clause 6.1.1. Further, an Equivalence Committee \\n(Refer Annexure B) shall examine the case for Transfer/Lateral Entry and \\nsubmit its report and recommendation for the approval of the Vice Chancellor \\nfor enrolment to the concerned program . The student may need to undergo \\nadditional Courses, as prescribed by the Equivalence Committee to qualify for \\nthe minimum credit requirements as prescribed by the concerned PRC for the \\naward of degree. \\n6.2 The PRC of respective Programs shall have Program Educational Objectives (PEOs), \\nProgramme Outcomes (POs), Program Specific Outcomes (PSOs), and Curriculum \\nStructure, List of Basket/Component -wise Courses along with other details such as,'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 12, 'page_label': '13'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              13 \\nL-T-P-C structure, Pre-Requisites etc. The Course catalogues for all the Courses listed \\nin the Curriculum structure shall also be part of the PRC.  \\n6.3 Assessment and Evaluation scheme: The assessment and evaluation of students in \\nall the academic programs offered in the University (except the Ph.D. program) shall \\nhave the components of assessment and weightages as recommended by the \\nrespective BoS and as approved by the Academic Council  from time to time. The \\nrelative grading framework shall be used for evaluation (Refer Clause 8.7). \\nIn order to ensure the fair and equitable assessment of learning for all Non-Teaching \\nCredit Courses (NTCC) offered in the particular Program, the method of assessment \\nshall be prescribed in the PRC. \\n6.4 The m inimum number of student registrations required  for the  Courses (except \\nNTCC) shall be defined in the PRC f or offering the  Course in the specific Academic \\nTerm. \\n7.0 ATTENDANCE REQUIREMENTS  \\n7.1 In order to maintain high standards and academic excellence, all students must \\nattend every lecture, tutorial, field work, laboratory, studio, practical classes and all \\nother such curricular sessions as prescribed by the Program Curriculum. \\n7.2 To account for approved leave of absence (for instance, representing the University \\nin State/National/International Competitions/Events/Conferences, etc.) and/or other \\ncontingencies like medical emergencies,  the attendance requirement shall be a \\nminimum of 75% of the classes actually conducted in every Course, for which the \\nstudent has registered in the concerned Academic term. \\n7.3 Further, if a student suffers serious medical exigencies of hospitalization, trauma, \\nincluding death of immediate family members (Parents, Offspring, Siblings and \\nSpouse) or contagious disease only, the concerned student may be given additional \\nrelaxation in attendance requirement (in Course(s) where there is a shortage) by the \\nVice Chancellor on the recommendations of the Dean of the School concerned. \\nHowever, under no circumstances whatsoever, shall the minimum requirement of \\nattendance be less than 65% o f the classes actually conducted in every Course the \\nstudent has registered for in the Academic Term. The student shall not be eligible for \\nthis special provision if she/he fails to produce authentic medical certificates and \\nrelevant documents (for other c ases of exemption) in support of the medical \\nexigency.  \\n7.4 Provided further that if a student has been selected/nominated by State/National/  \\nInternational Organizations/Boards to represent the State and/or India in State/  \\nNational/International Events/Competi tions, for representing the university the \\nconcerned student may be given relaxation in attendance requirement s (in the \\nCourse(s) where there is a shortage) for the concerned period of absence by the Vice \\nChancellor on the recommendations of the Dean of the School concerned.  \\n7.5 Further, where attendance requirements are prescribed by Government Regulatory \\nBodies for specific Programs, the same shall also be mandatorily adhered to without'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 13, 'page_label': '14'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              14 \\nexception. Such specific requirements, as applicable, shall be prescribed in the \\nProgram Regulations and Curriculum of the concerned Program of study. \\n7.6 Shortage of Attendance:  \\nA student with shortage of attendance (i.e., less than 75% of the classes actually \\nconducted in every Course in the concerned Academic Term as prescribed by Clause \\n7.2, and other conditions as applicable und er Clauses 7.3 to 7.5), shall not be \\npermitted to appear in the End Term Examinations of the Course(s) in which \\nthe attendance shortfall exists , irrespective of the student’s academic \\nperformance in the components of Continuous Assessments. The student shall be \\ndeclared as “NP” (Not Permitted) Grade (refer Clause 8.14), to indicate that the \\nstudent has not been permitted to appear for the End Term Examinations due to \\nshortage of attendance during the Academic Term in the concerned Course(s).  \\nFurther, a student who has shortage of attendance (received “NP” Grade) in a Course \\nin the concerned Semester, shall be eligible to re -register for the concerned Course \\nin the following Academic Term  (including Summer Term ), subject to all the \\nconditions stated in Clauses 15.4 and 15.5.  \\nThe student is cautioned that this may result in the loss of an Academic Year \\nfor the student . It is the sole responsibility of the student to ensure that she/he \\ncompletes the Course(s) in which the student has the NP Grade, and, earn the \\nminimum mandatory required credits as prescribed by the PRC of the concerned \\nprogram.  \\n8.0 TEACHING, EVALUATION AND GRADING SYSTEM  \\n8.1 Courses from the approved Program Regulations and Curriculum may be offered \\nduring any Academic Term. Each approved Course, whenever  offered in any given \\nAcademic Term, shall be conducted by the assigned Course Instructor.  \\n8.2 The Course Instructors, for all the Courses , which are  to be offered by the \\nSchool/Department during any Academic Term shall be assigned by the concerned \\nHoD/Dean of School.  (A brief of the functions and responsibilities of the Course \\nInstructor is placed in ANNEXURE C). \\n8.3 Course Plan: Course Plan is prepared for each Course offered (including Non-Teaching \\nCredit Courses (NTCC)) in a Program of study during an Academic Term. The Course \\nPlan is generally prepared by the Course In -Charge (Course IC) in consultation with \\nall Course Instructors (as applicable) of concerned Course. The Course Plan shall be \\napproved by the Departmental Academic Committee (DAC).    \\n8.3.1 The Course Plan shall clearly describe the following aspects: Course Name, \\nCourse Code, Credit Structure, Course Description, Contact Hours, Name of \\nCourse In-Charge and Course Instructor(s),  Course Outcomes, CO – PO & \\nPSO Mapping, Pre -requisites (if applicable) , Course Syllabus, Reference \\nMaterials, Schedule  of Lectures, Tutorials, Pr actical/Lab Sessions (as \\napplicable), with notes on pedagogy,  Schedule of Continuous Assessments \\nand guidelines regarding End Term Examinations (as applicable).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 14, 'page_label': '15'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              15 \\n8.3.2 The Course Plan of every Course offered in an Academic Term  of the \\nconcerned Program shall be made available to all students registered for the \\nconcerned Course. \\n8.4 The academic performance evaluation of a student in a Course shall be according to \\nthe University Letter Grading System based on the class performance distribution in \\nthe Course.  \\n8.5 Academic performance evaluation of every registered student in every Course \\nregistered by the student is carried out through various components of Assessments \\nspread across the Semester. The nature of components of Continuous Assessments \\nand the weightage given to each component of Continuous Assessments (refer Clause \\n8.8) shall be clearly defined in the Course Plan for every Course, and approved by \\nthe DAC.  \\n8.6 Format of the End-Term examination shall be specified in the Course Plan. \\n8.7 Grading is the process of rewarding the students for their overall performance in each \\nCourse. The University follows the system of Relative Grading with statistical \\napproach to classify the students based on the relative performance of the students \\nregistered in the concerned Course except in the following cases:  \\n• Non-Teaching Credit Courses (NTCC) \\n• Courses with a class strength less than 30  \\nAbsolute grading method may be adopted, where necessary with prior approval of \\nconcerned DAC. \\nGrading shall be done at the end of the Academic Term by considering the aggregate \\nperformance of the student in all components of Assessments prescribed for the \\nCourse. Letter Grades (Clause 8.10) shall be awarded to a student based on her/his \\noverall performance relative to the class performance distribution in the concerned \\nCourse. These Letter Grades  not only indicate a qualitative assessment of the \\nstudent’s performance but also carry a quantitative (numeric) equivalent called the \\nGrade Point.  \\n8.8 Assessment Components and Weightage \\nTable 8.8 Assessment Components and Weightage for different category \\nof Courses \\nNature of Course and Structure Evaluation \\nComponent Weightage \\nLecture-based Course \\nL component in the L-T-P Structure is \\npredominant (more than 1) \\n(Examples: 3-0-0; 3-0-2; 2-1-0; 2-0-2, 2-0-4 \\netc.) \\nContinuous \\nAssessments \\n50% to \\n60% \\nEnd Term \\nExamination \\n40% to \\n50% \\nLab/Practice-based Course Continuous \\nAssessments \\n75% to \\n100%'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 15, 'page_label': '16'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              16 \\nP component in the L-T-P Structure is \\npredominant \\n(Examples: 0-0-4; 1-0-4; 1-0-2; etc.) \\nEnd Term \\nExamination 0 to 25% \\nSkill based Courses like Industry Internship, \\nCapstone project, Research Dissertation, \\nIntegrative Studio, Interdisciplinary Project, \\nSummer / Short Internship, Social Engagement \\n/ Field Projects, Portfolio, and such similar Non-\\nTeaching Credit Courses, where the pedagogy \\ndoes not lend itself to a typical L-T-P structure \\nGuidelines for the assessment \\ncomponents for the various types \\nof Courses, with recommended \\nweightages, shall be specified in \\nthe concerned Program \\nRegulations and Curriculum /  \\nCourse Plans, as applicable. \\nThe exact weightages of Evaluation Components shall be clearly specified in the \\nconcerned PRC and respective Course Plan. \\nNormally, for Practice/Skill based Courses, without a defined credit structure (L –T–\\nP) [NTCC], but with assigned Credits (as defined i n Clause 5.2 of the Academic \\nRegulations), the method of evaluation shall be based only on Continuous \\nAssessments. The various components of Continuous Assessments, the distribution \\nof weightage among such components, and the method of evaluation/assessment, \\nshall be as decided and indicated in the Course Plan/PRC. The same shall be approved \\nby the respective DAC.  \\n8.9 Minimum Performance Criteria:  \\n8.9.1 Theory only Course and Lab/Practice Embedded Theory Course  \\nA student shall satisfy the following minimum performance criteria to be \\neligible to earn the credits towards the concerned Course:  \\na. A student must obtain a minimum of 30% of the total marks/weightage \\nassigned to the End Term Examinations in the concerned Course.  \\nb. The student must obtain a minimum of 40% of the AGGREGATE of the \\nmarks/weightage of the components of Continuous Assessments, Mid \\nTerm Examinations and End Term Examinations in the concerned \\nCourse.  \\n8.9.2 Lab/Practice only Course and Project Based Courses  \\nThe student must obtain a minimum of 40% of the AGGREGATE of the \\nmarks/weightage of all assessment components in the concerned Course.  \\n8.9.3 A student who fails to meet the minimum performance criteria listed above \\nin a Course shall be declared as “Fail” and given “F” Grade in the concerned \\nCourse. For theory  Courses, the student shall have to re -appear in the \\n“Make-Up Examinations” as scheduled by the University in any subsequent \\nsemester, or, re-appear in the End Term Examinations of the same Course \\nwhen it is scheduled at the end of the following Semester or Summer Term, \\nif offered. The marks obtained in the Continuous Assessments (other than \\nthe End Term Examination) shall be carried forward and be included in'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 16, 'page_label': '17'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              17 \\ncomputing the final grade, if the student se cures the minimum \\nrequirements (as per Clause 8.9.1, 8.9.2) in the “Make-Up Examinations” \\nof the concerned Course. Further, the student has an option to re -register \\nfor the  Course and clear the same in the summer term/ subsequent \\nsemester if he/she wishes to do so, provided the Course is offered. \\n8.10 Letter Grades & Grade Points: The University follows the system of Letter Grades \\nwith associated Grade Points on a scale of 10. The Letter Grades and associated \\nGrade Points along with a brief qualitative description are summarized in Table 8.10:  \\n \\nTable 8.10 Letter Grades with Grade Points and Brief Qualitative \\nDescription \\nLetter Grade Grade Point Qualitative Description \\nO 10 Outstanding \\nA+ 9 Excellent \\nA 8 Very Good \\nB+ 7 Good \\nB 6 Above Average \\nC 5 Average \\nD 4 Pass \\nF 0 Fail \\nNP 0 Not Permitted \\nS – Satisfactorily Completed \\nNC – Not Completed \\nU – Audited Satisfactorily \\nI – Incomplete \\n \\n8.11 Absolute Grading:  \\nThe Letter Grades with Marks Range for the Absolute Grading is as follows:  \\nTable 8.11 Letter Grades with Marks Range for Absolute \\nGrading \\nLetter Grade Marks range (Out of 100) \\nO >= 90 \\nA+ >= 80 but < 90 \\nA >= 70 but < 80 \\nB+ >= 60 but < 70 \\nB >= 55 but < 60 \\nC >= 50 but < 55 \\nD >= 40 but < 50 \\nF < 40'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 17, 'page_label': '18'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              18 \\n8.12 Award of the “O” (Outstanding) Grade:  \\nThe “O” grade stands for outstanding achievement, relative to the registered \\nstudents in the Course, and utmost care shall be taken in awarding of this highest \\nletter grade.  \\n8.13 Declaration of the “F” (Fail) Grade:  \\nThe “F” grade denotes failure in a Course and has “0” (Zero) Grade Points. This may \\nbe due to the following reasons:  \\n8.13.1 Failure to meet the minimum performance criteria for a Course as listed in \\nClause 8.9  \\n8.13.2 Further, if a student is absent for the End Term Examination of a Course, \\nthe student shall be declared as “Fail” and given a “F” grade in the \\nconcerned Course.  \\n8.14 Declaration of the Placeholder Grades “NP” (Not Permitted):  \\n“NP” is a grade, with “0” (Zero) Grade Points, given in the concerned Course(s) to \\nindicate that a student was not eligible to appear for the End Term Examination of \\nthe concerned Course(s) due to shortage of attendance as elaborated in Section 7.0 \\nand he /she has to re -register in the concerned  Course(s) to earn the necessary \\ncredits.  \\n8.15 Additional Grades with No Grade Points: “S”  (Satisfactorily Completed), “NC” \\n(Not-Completed) and “U” (Audited Satisfactorily) Grades:  \\n8.15.1 “S” and “NC” grades are awarded for specific mandatory Courses as \\nprescribed in the concerned PRC.  \\n8.15.2 “S” grade denotes satisfactory performance and completion of a Course , as \\nspecified in the concerned PRC. The requirements for obtaining “S” grade in \\na particular Course shall be clearly stated in the Course Plan of the concerned \\nCourse.  \\n8.15.3 “NC” grade is given for Non -Completion of Course requirements in the \\nconcerned Course and the student will have to re-register for the Course \\nuntil he/she obtains the “S” grade in the Course concerned.  \\n8.15.4 “S” and “NC” grades have no associated Grade Points and hence are not \\nincluded in the SGPA/CGPA calculations (refer Section 9.0).  \\n8.15.5 “U” grade is awarded in a  Course that a student opts to register for Audit \\n(refer to Clause 3.16) and successfully completes . It is not mandatory for \\nthe student to go through the entire regular process of evaluation for the \\nconcerned Course. However, the student must satisfy the minimum  \\nattendance requirement for securing the “U” grade, failing which, that  \\nCourse will not be listed in the Grade Card given to the concerned student \\n(refer to Clause 8.17).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 18, 'page_label': '19'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              19 \\n8.16 Additional Placeholder Grade “I” with no Grade Points:  \\n“I” (“Incomplete”) Grade is a placeholder grade which denotes “incomplete” in any \\nCourse or Courses, due conditions mentioned below  in sub -clauses 8.16.1 and \\n8.16.2. \\n8.16.1 Absence at the End Term Examination solely due medical exigencies \\nspecifically hospitalization, trauma, including death of immediate family \\nmembers (Parents, Offspring, Siblings and Spouse) or contagious disease \\nonly, and gets replaced by an appropriate regular letter grade after the \\nstudent completes the performance evaluation for the  Course(s) concerned \\nin the “Make-Up Examinations” (refer to Section 13.0).  \\n8.16.2 Malpractice case (under investigation) reported against the student in the \\nEnd Term Examination of concerned Course. The placeholder grade “I” shall \\nbe replaced with a regular grade based on recom mendations of the Unfair \\nMeans and Malpractices Committee (UMMC) (as constituted and provisioned \\nby the Examination Regulations of the University) and the subsequent \\napproval and decision of the Chairperson, BOE.  \\n8.16.3 The Course(s) in which a student has received “I” grade shall not be included \\nin the SGPA/CGPA calculations. (Refer Section 9.0).  \\n8.17 Grade Card:  \\nGrade Card is a record of a student’s performance in the Courses for which the \\nstudent has registered for in a concerned Academic Term of the Program of study.  \\nThe Grade Card shall contain the following details pertaining to the student’s \\nacademic performance:  \\n8.17.1 The List of Courses (which includes Course Name, Course Code and \\nassociated Credits) registered by the student in the concerned Academic \\nTerm.  \\n8.17.2 The Grade obtained in each of the concerned Courses.  \\n8.17.3 The SGPA and CGPA obtained by the student.  \\n8.17.4 Total credits registered and completed  in the ongoing Program of study \\nincluding the concerned Academic Term.  \\n9.0 ACADEMIC PERFORMANCE INDICES: SGPA AND CGPA  \\n9.1 The overall academic performance of a student shall be measured by two indices: \\nSGPA which is the “ Semester Grade Point Average” and CGPA which is the \\n“Cumulative Grade Point Average”.  \\n9.2 The performance of a student in a Semester is indicated by a number, Semester \\nGrade Point Average . The SGPA is the weighted average of the grade points \\nsecured in all the concerned Courses registered by the student during that Semester. \\nSGPA for a particular Semester is computed as follows:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 19, 'page_label': '20'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              20 \\n  \\nwhere:  \\nn is the number of all Courses (with Letter Grade s and Grade Points, including the \\nLetter Grades F and NP, which have zero grade points) registered by the student \\nin the Semester concerned;  \\nCk is the Credits assigned to Course k and  \\nGk is the Grade Point received by the student for the Course k.  \\n9.3 The Cumulative Grade Point Average indicates overall academic performance of \\na student in all the Courses registered up to and including the latest completed \\nsemester. CGPA is computed as follows:  \\n  \\nwhere:  \\nn is the number of all the Courses (with Letter Grades and Grade Points, including \\nthe Letter Grades F  and NP, which have zero grade points) registered by the \\nstudent up to, and including the latest completed Academic Term;  \\nCi is the Credits assigned to Course i and Gi is the Grade Point received by the student \\nfor the Course i.  \\n9.4 The SGPA and CGPA are calculated to TWO decimal places.  \\n10.0  DISPLAY OF PERFORMANCE IN CONTINUOUS ASSESSMENTS  \\n10.1 The performance of all students in the components of Continuous Assessments for \\nall Courses registered in the concerned Academic Term, shall be communicated to \\nthe students and displayed in the concerned Department/School by the respective \\nHOD/Dean.  \\n10.2 The concerned HOD/Dean shall attest and submit to the COE, a consolidated marks \\nsheet of the continuous assessment marks, where applicable,  obtained by all \\nstudents of a Program of study, in all the respective Courses registered in the \\nconcerned Academic Term, before the commencement of the End Term Examination.  \\n10.3 Answer scripts of Mid Term Examination , where applicable,  of the Course shall be \\nshown to the students for discussion, verification and corrections (if any) on pre -\\nnotified date(s) in class. \\n10.3.1 Answer books shall be shown to the students by the Faculty/Course \\nInstructor of the Department as per the schedule announced by the \\nDepartment/ School;  \\n10.3.2 Students shall be entitled to check whether all answers have been \\nevaluated and marked, and that all the marks have been correctly totalled.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 20, 'page_label': '21'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              21 \\n10.3.3 In case of Digital valuation, the portal shall be opened on specified date(s) \\nand information about the date shall be sent to students’ university email \\naddress.  \\n10.3.4 If the student finds any discrepancy, he/she shall bri ng the same into the \\nnotice of the Faculty/Course Instructor/ HOD concerned for corrections and \\nupdates \\n11.0  DETAILED SCHEDULE OF EXAMINATIONS  \\n11.1 The detailed schedule of the Mid Term and End Term Examinations , as per dates \\nindicated in the Academic Calendar, shall be prepared by the COE in consultation \\nwith the HODs/Deans of Schools and shall be announced with due approval of the \\nVice Chancellor, at least two (02) weeks before the commencement of the \\nExaminations.  \\n11.2 The regulations and guidelines pertaining to the conduct of various University \\nExaminations are prescribed in the Examination Regulations of the University.  \\n12.0  APPEAL FOR REVIEW OF GRADES \\n12.1 The University is committed to keep the entire process of  evaluation beyond \\nreproach. A mechanism for review of grades is incorporated in the evaluation system.  \\n12.2 In case of a grievance regarding the grade(s) awarded, a student shall submit an \\napplication along with the prescribed fee to the Office of the Controller of \\nExaminations for obtaining the photocopy of End Term Examination answer script(s) \\nof the Course (or Courses), within Five (05) University working days from the date \\nof the declaration of the results of the End Term Examination. No requests shall be \\nadmissible after five (05) University working days from the date of the declaration \\nof the results of the End Term Examination.  \\n12.3 A copy of the answer script(s) of the End Term Examination with marks obtained for \\neach question and evaluation scheme shall be shared to the concerned student within \\nthree (03) days from the last date of application for photocopy of answer script . If \\nthe student is not satisfied with the marks awarded, he/she shall approach Course \\nInstructor/faculty assigned by the HOD/ Dean to get the recommendation in the \\nprescribed format, and submit the application for review of grade with prescribed \\nfees, within three (03) days from receipt of photocopy of the answer script. \\n12.4 The COE shall forward the student’s request to  the concerned HoD / Dean to take \\nthe necessary steps to review the appeal. Copy of the answer script(s) with marks \\nobtained for each question and evaluation scheme shall be shared to the concerned \\nHoD / Dean, within two (2) days from the last date for app lication for review . The \\nconcerned HoD / Dean shall convene a panel consisting of the respective Course \\nInstructor / Course In-Charge and two more faculty members who are familiar with \\nthe Course concerned to review the appeal.  \\n12.5 The panel shall review the appeal and submit a report regarding the revision / \\nretention of the Grade to the CoE, within five (05) days from the date of receipt of'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 21, 'page_label': '22'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              22 \\nanswer script from CoE . The CoE shall declare the result based on the approval of \\nthe Vice Chancellor.  \\n13.0  MAKE-UP EXAMINATIONS  \\n13.1 Make-Up Examination is a provision for a student to complete a Course (or Courses) \\nin which she/he received an “F” grade (refer Section 8.0), or, was given the place \\nholder grade “I” (refer to Section 8.0) to reappear for the End Term Examination \\ncomponent of a Course (or Courses), subject to the conditions mentioned below in \\nClauses 13.2 to 13.5. Under no other circumstances, Make-Up Examinations shall be \\navailable to the student. Make-Up Examination is conducted o nly for those Courses \\nregistered in the concerned Academic Term (latest completed Semester).  \\n13.2 A student who fails to appear in the End Term Examinations, in some or all Courses, \\ndue to medical exigencies, specifically hospitalization, trauma, including death of \\nimmediate family members (Parents, Offspring, Siblings and Spouse) or a contagious \\ndisease only, and, the said student informs the HOD/Dean concerned timely (i.e., on \\nor before the last date of the said End Term Examinations), may submit a request \\nto the concerned HOD/Dean for the provision of the Make -Up Examinations in the \\nCourse(s) for which he/she could not attend the scheduled End Term Examinations.  \\n13.2.1 Provided further, the student must submit, along with the registration form \\nfor the Make -Up Examinations, medical certificates, medical prescriptions, \\nhospital di scharge summary, medical fitness report and all such relevant \\ndocuments, duly attested by the concerned registered medical officer of the \\nhospital where the concerned student was hospitalized or medically treated.  \\n13.2.2 The HOD/Dean concerned shall submit a specific report to the Chairperson, \\nBoard of Examinations (BOE) in this regard, who shall convene a special \\nmeeting of the BOE to review the student’s application. The BOE may grant \\npermission based on the veracity of the case to permit the concerned student \\nto avail the provision of Make-Up Examinations. On approval of the BOE, the \\nstudent shall submit the application form for the Make -Up Examinations to \\nthe Examination Department of the University within the duly notified dates, \\nalong with the prescribed fee for the Make -Up Examinations fixed by the \\nUniversity from time to time.  \\n13.2.3 On the basis of the student’s performance in the Make-Up Examinations and \\nconsidering the marks obtained by the student in all other Continuo us \\nAssessments as prescribed by the concerned Program Regulations and \\nCurriculum, the final letter grade awarded will replace the placeholder grade \\n“I”.  \\n13.2.4 In case the BOE rejects the application of the student for Make -Up \\nExaminations, the student shall be declared “Failed” in the concerned \\nCourse(s) and the placeholder grade “I” shall be replaced with “F” (Fail) \\ngrade in the concerned Course(s). Further, the student shall have to \\ncomplete the Course(s) as per the provisions and conditions prescribed in \\nClause 13.3.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 22, 'page_label': '23'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              23 \\n13.2.5 If the concerned student does not avail the Make -Up Examinations, or is \\nabsent for the Make-Up Examinations, the student shall be declared “Failed” \\nin the concerned Course(s) and the placeholder grade “I” shall be replaced \\nwith an “F” grade. Further, the student shall have to complete the Course(s) \\nas per the provisions and conditions prescribed in Clause 13.3.  \\n13.3 A student with “F” Grade in one or more Courses, declared under the conditions \\nstated in Section 8.0 and/or who secured “D” Grade in one or more Courses, may \\navail the benefit of the Make -Up Examinations to pass the failed Course(s) and/or \\nimprove her/his CGPA. The student shall submit the registration form for the Make -\\nUp Examinations to the Office of the Controller of Examinations of the University \\nwithin the duly notified date, along with the prescribed fee for the Make -Up \\nExaminations fixed by the University from time to time.  \\n13.3.1 Further, if the student fails in the Course(s) attempted in the Make -Up \\nExaminations, including the Course(s) where the student had earlier secured \\n“D” Grade, the student will be awarded “F” grade in the Course(s) and will \\nhave to re-appear for the Examination.  \\n13.3.2 Students appearing for Make -Up Examinations can improve only by two \\ngrade level. This means that an \"F\" grade can be improved to a \"C\" grade at \\nmost. \\n13.4 The provision of Make-Up Examinations shall not be available for practice/laboratory/ \\nskill-based Courses as described in Clause 5.2. If a student has secured an “F” Grade \\nin such a Course, the student shall complete the concerned Courses only by \\nrepeating the Courses in the Semester when they become available for registration. \\nFurther, the student is cautioned that she/he shall have to register for the concerned \\nCourse(s) only in the concerned Semester of the next Academic Year when the \\nconcerned Course(s) shall be offered, which may result in the loss of an Academ ic \\nYear for the student. It is the sole responsibility of the student to ensure that she/he \\ncompletes the Course(s) and/or earns the required credits as prescribed by the \\nconcerned Program Regulations and Curriculum.  \\n13.5 Make-Up Examinations may be scheduled at the end of each Semester. The COE \\nshall announce the schedule of the Make-Up Examinations at least two (02) calendar \\nweeks before the commencement of the Make-Up Examinations.  \\n14.0  ACADEMIC PROMOTION  \\nYearly promotion criteria of a student who is reg istered for a given Academic year to the \\nnext Year of the Program of study after the end of an Academic Year is as described below \\nin Clauses 14.1 and 14.2. The Academic Promotion is applicable only for the Undergraduate \\nPrograms. \\n14.1 A student is eligible to be promoted to the next academic year if he/ she has secured \\na CGPA of 4.00 or more at the end of the current academic year (after completion \\nof the Summer Term and/or Make-Up Examinations, as applicable).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 23, 'page_label': '24'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              24 \\n14.2 If the student has secured a CGPA of less than 4.00, they shall not be promoted to \\nthe next academic year. \\n14.3 The students who are not promoted to the next Academic year but have app ealed \\nfor review of grades  (Section 12 .0) may take provisional registration and be \\npermitted to attend classes till the review results are published. After the publication \\nof the review result, the promotion criteria stated above in Clauses 14.1 and 14.2 \\nshall be applicable. \\n14.4 A student, who is not promoted as per Clause 14.2, has the provision of improving \\nthe CGPA in the subsequent academic year by either appearing for Make-Up \\nexaminations or by re-registering in either Odd and / or Even semesters, or Summer \\nTerm of the next academic year , subject to the conditions stated in Sections 13.0 \\nand 15.0 respectively.  \\n14.5 Further, upon rejoining (Registration in the applicable Semester) , the student shall \\nadhere to the Academic Regulations and Program Regulations and Curriculum , \\napplicable to the batch in which the student is rejoining the Program of study.  \\n15.0  SUMMER TERM  \\n15.1 The Summer Term is an additional Academic Term that may be offered during the \\nsummer break, typically for about eight (08) weeks during June-July. The minimum \\nnumber of instruction days in the Summer Term shall be thirty (30) days.  \\n15.2 The Course(s) offered in the Summer Term are delivered in a shorter term of about \\n8 weeks (with a minimum of thirty instruction days). However, the total number of \\ncontact hours for these Courses are scheduled as per the Course Credit Structure. \\nThe Course Contents/Syllabus and the continuous assessments and evaluation \\npatterns for these Course(s) also remain the same as that prescribed by the \\nconcerned Course Plan.  \\n15.3 The Departments/Schools desirous of offering Courses shall announce the details of \\nthe Courses on offer for registration in the Summer Term on the dates scheduled in \\nthe Academic Calendar or dates announced through University notifications.  \\n15.4 Some Departments/Schools may offer a limited number of Courses in the Summer \\nTerm with the following special provisions, subject  to all the conditions stated in \\nClause 15.5:  \\n15.4.1 Refer Clause 7.6: A student may re -register for the concerned Course(s), \\nif offered, in which the student had received the placeholder grade “NP”, to \\ncomplete the concerned Course(s) and earn the concerned credits;  \\n15.4.2 Refer Clause 8.13: A student may re-register for the concerned Course(s), \\nif offered, in which the student had received the “F” grade (Fail) in the \\nearlier Semesters if he/she wishes to do so.  \\n15.5 A student may register for the Summer Term Course(s), subject to all the conditions \\nstated below:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 24, 'page_label': '25'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              25 \\n15.5.1 A student who wishes to register for the Summer Term must complete the \\nregistration process on or before the last date  for Registration as specified \\nin the Academic Calendar or the University Notification to this effect. No late \\nregistration shall be permitted.  \\n15.5.2 A student can register for a maximum of 12 Credits.  \\n15.5.3 Attendance requirements as prescribed in Section 7.0 shall be applicable to \\nall the students registering for Course(s) in the Summer Term.  \\n15.5.4 A student cannot request or demand for a specific Course to be offered.  \\n15.5.5 A student, who is registering for Summer Term Course(s), must submit a \\ncompleted Summer Term Registration Form, checked and verified by the \\nDean/HOD concerned, to the Office of the Controller of Examinations of the \\nUniversity. Further, where applicable, th e Summer Term Registration Form \\nwill contain the list of failed and/or lower graded Course(s) for which the \\nstudent is registering.  \\n15.5.6 The student shall remit the registration fee per Course, as prescribed by the \\nUniversity from time to time, within the date specified for payment.  \\n15.5.7 A Course that is offered in summer term may be withdrawn if the number of \\nRegistrations for the concerned Course(s) is less than TEN (10). Further, if \\nthe Course is withdrawn due to lack of the minimum number of Registrations \\nrequired (i.e., 10), the Registration Fee for the concerned Course shall be \\nrefunded to the students who had registered for the concerned Course. \\n15.5.8 Further, the student,  \\na) must have paid all the required fees and other charges including hostel \\ncharges, where applicable, for the Summer Term;  \\nb) must have cleared all University fees and Hostel dues of previous \\nSemester(s)/year(s); and,  \\nc) has not been debarred from registering on disciplinary or other grounds.  \\n15.5.9 A student can apply for the Summer Term in any of the Courses in which he/ \\nshe was declared “NP” grade in any semester preceding the Summer Term, \\nincluding the immediately preceding semester , provided that the Course is \\nbeing offered by the School. However, the student cannot demand for a \\nparticular Course which the School is not offering or for which the number of \\napplicants is below 10 as stated in Sub-Clause 15.5.7.  \\n15.5.10 A student who did not register for a regular semester (Odd or Even) shall \\nnot be permitted to register for any  Courses from that semester (for which \\nthe student did not register)  during the Summer Term. Registration in the \\nSummer Term is only applicable fo r Courses previously registered but not \\ncompleted (i.e. Course(s) in which grade given was \"NP\", “F”, or “NC”).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 25, 'page_label': '26'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              26 \\n16.0  WITHDRAWAL FROM THE PROGRAM  \\n16.1 Temporary Withdrawal:  \\nA student who has been admitted to a Degree Program of the University may be \\npermitted to withdraw temporarily, for a period of one Academic Year, on medical \\ngrounds provided:  \\n16.1.1 The student submits an application to the University, stating the reasons \\nfor withdrawal together with supporting documents and endorsement from \\nher/his parent or legal guardian;  \\n16.1.2 The University is satisfied that the student is likely to complete the \\nrequirements for the award of the Degree of the concerned Program within \\nthe specified maximum duration to complete the Program (refer Section \\n20.0).  \\n16.1.3 A student seeking temporary withdrawal shall not be entitled to a refund of \\nthe Annual Fee paid to the University for the concerned Academic Year.  \\n16.1.4 There are no outstanding dues with the De partment/School/Hostels/ \\nLibrary etc.  \\n16.1.5 Scholarship holders are bound by the appropriate rules applicable to them.  \\n16.1.6 Normally, a student will be permitted only one such temporary withdrawal \\nduring her/his tenure as a student.  \\n16.2 Rejoining the Program:  \\nA student who temporarily withdraws from the Program (Clause 16.1) and rejoins \\nthe Program in the following Academic Year, shall be governed by all the Regulations, \\nincluding the PRC, of the University and the University Fee Structure in force at the \\ntime of his/her rejoining the program.  \\n16.3 Permanent Withdrawal:  \\nThe rules pertaining to withdrawal of admission at the time of joining the University \\nare as stipulated by the Admission Rules and Fee Policy of the University.  \\nIn case of a student seeking withdrawal from the Program of study after completion \\nof one/more Academic Year(s), the rules and terms of withdrawal are as stipulated \\nin the Withdrawal from Program and Fee Refund Policy of the University.  \\nThe decision of the Vice Chancellor regarding all aspects of withdrawal of a student \\nfrom the Program of study shall be final and binding.  \\n17.0  TRANSFER OF CREDITS  \\nThe University allows students to acquire credits from other Indian or foreign institutions \\nand/or Massive Open Online Course (MOOC) platforms, subject to prior approval. These \\ncredits may be transferred and counted toward fulfilling the minimum credit requirements \\nfor the award of a degree. The process of transfer of credits is governed by the following \\nrules and guidelines:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 26, 'page_label': '27'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              27 \\n17.1 The transfer of credits shall be examined and recommended by the Equivalence \\nCommittee (Refer ANNEXURE B) and approved by the Dean - Academics. \\n17.2 Students may earn credits from other Indian or foreign Universities/Institutions with \\nwhich the University has an MOU, and that MOU shall have specific provisions, rules \\nand guidelines for transfer of credits. These transf erred credits shall be counted \\ntowards the minimum credit requirements for the award of the degree.  \\n17.3 Students may earn credits by registering for Online Courses offered by Study Web \\nof Active Learning by Young and Aspiring Minds (SWAYAM) and National Program on \\nTechnology Enhanced Learning (NPTEL), or other such recognized Bodies/ \\nUniversities/Institutions as approved by the concerned BOS and A cademic Council \\nfrom time to time. The concerned School/Parent Department shall publish/include \\nthe approved list of Courses and the rules and guidelines governing such transfer of \\ncredits of the concerned Program from time to time. The Rules and Guidelines for \\nthe transfer of credits specifically from the Online Courses conducted by SWAYAM / \\nNPTEL/ other approved MOOCs  are as stated in the following Sub-Clauses:  \\n17.3.1 A student may complete SWAYAM /NPTEL/other approved MOOC s as \\nmentioned in Clause 17.3 and transfer equivalent credits to partially or fully \\ncomplete the mandatory credit requirements of Discipline Elective Courses \\nand/or the mandatory credit requirements of Open Elective Courses  as \\nprescribed in the concerned Curriculum Structure. However, it is the sole \\nresponsibility of the  student to complete the mandatory credit \\nrequirements of the Discipline Elective Courses and the Open Elective \\nCourses as prescribed by the Curriculum Struc ture of the concerned \\nProgram.  \\n17.3.2 SWAYAM/NPTEL/ other approved MOOCs as mentioned in Clause 17.3 shall \\nbe approved by the concerned Board of Studies and placed (as Annexures) \\nin the concerned PRC.  \\n17.3.3 Parent Departments may release a list of SWAYAM /NPTEL/other approved \\nMOOCs for Pre -Registration as per schedule in the Academic Calendar or \\nthrough University Notification to this effect.  \\n17.3.4 Students may Pre-Register for the SWAYAM/NPTEL/other approved MOOCs \\nin the respective Departments and register for the same Courses as per the \\nschedule announced by respective Online Course Offering body/institute/ \\nuniversity.  \\n17.3.5 A student shall request for transfer of credits only from such approved  \\nCourses as mentioned in Sub-Clause 17.3.2 above.  \\n17.3.6 SWAYAM/NPTEL/other approved MOOC s Courses are considered for \\ntransfer of credits only if the concerned student has successfully completed \\nthe SWAYAM/NPTEL/other approved MOOC s and obtained a certificate of \\nsuccessful/satisfactory completion.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 27, 'page_label': '28'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              28 \\n17.3.7 A student who has successfully completed the approved SWAYAM /NPTEL/ \\nother approved MOOCs and wants to avail the provision of transfer of \\nequivalent credits, must submit the original Certificate of Completion, or \\nsuch similar authorized documents to the HOD concerned, with a written \\nrequest for the transfer of the equivalent credits. On verification of the \\nCertificates/Documents and approval by the HOD concerned, the Course(s) \\nand equivalent Credits shall forwarded to the COE for processing of results \\nof the concerned Academic Term.  \\n17.3.8 The credit equivalence of the SWAYAM /NPTEL/other approved MOOCs are \\nbased on Course durations and/or as recommended by the Course offering \\nbody/institute/university. The Credit Equivalence mapped to SWAYAM / \\nNPTEL approved Courses based on Course durations for transfer of credits \\nis summarised in Table shown below. The Grade will be calculated from the \\nmarks received by the Absolute Grading Table 8.11.  \\n \\nTable 17.3.8 Durations and Credit Equivalence for Transfer of \\nCredits from SWAYAM-NPTEL/ other approved MOOC Courses \\nSl. \\nNo. Course Duration Credit Equivalence \\n1 4 Weeks 1 Credit \\n2 8 Weeks 2 Credits \\n3 12 Weeks 3 Credits \\n \\n17.3.9 The maximum permissible number of credits that a student may request \\nfor credit transfer from MOO Cs shall not exceed 20% of the mandatory \\nminimum credit requirements specified by the concerned Program \\nRegulations and Curriculum for the award of the concerned Degree. \\n17.3.10 The University shall not reimburse any fees/expense; a student may incur \\nfor the SWAYAM/NPTEL/other approved MOOCs.  \\n17.4 The maximum number of credits that can be transferred by a student shall be limited to \\nforty percent (40%) of the mandatory minimum credit requirements specified by the \\nconcerned Program Regulations and Curriculum for the award of  the concerned  \\nDegree. However, the grades obtained in the  Courses transferred from other \\nInstitutions/MOOCs, as mentioned in this Section (17.0), shall not be included in the \\ncalculation of the CGPA. \\n18.0 MAXIMUM DURATION FOR THE COMPLETION OF A PROGRAM  \\n18.1 A student who for whatever reason is not able to complete the Program within the \\nnormal period or the minimum duration  (number of years)  prescribed for the \\nProgram, may be allowed a period of two years beyond the normal period to \\ncomplete the mandatory minimum credits requirement as prescribed by the \\nconcerned Program Regulations and Curriculum. In general , the permissible'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 28, 'page_label': '29'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              29 \\nmaximum duration (number of years) for completion of Program is ‘N’ + 2 years, \\nwhere ‘N’ stands for the normal or minimum duration  (number of years)  for \\ncompletion of the concerned Program as prescribed by the concerned Program \\nRegulations and Curriculum. \\n18.2 The time taken by the student to improve Grades/CGPA, and in case of temporary \\nwithdrawal/re-joining (Refer to Clause 16.1), shall be counted in the permissible \\nmaximum duration for completion of a Program. \\n18.3 In exceptional circumstances, such as temporary withdrawal for medical exigencies \\nwhere there is a prolonged hospitalization and/or treatment, as certified through \\nhospital/medical records, women students requiring extended maternity break  \\n(certified by registered medical practitioner) ,   and, outstanding sportspersons  \\nrepresenting the University/State/India  requiring extended time to participate in \\nNational/International sports events, a further extension of one  (01) year may be \\ngranted on the approval of the Academic Council.  \\n18.4 The enrolment of the student who fails to complete the mandatory requirements for \\nthe award of the concerned Degree (refer Section 19.0) in the prescribed maximum \\nduration (Sub-Clauses 18.1 and 18.2) , shall stand terminated and no Degree shall \\nbe awarded.  \\n19.0 REQUIREMENTS FOR THE AWARD OF DEGREE  \\n19.1 The award of the Degree shall be recommended by the Board of Examinations and \\napproved by the Academic Council and Board of Management of the University.  \\n19.2 A student shall be declared to be eligible for the award of the concerned Degree if \\nshe/he:  \\n19.2.1 Fulfilled the Minimum Credit Requirements and all other mandatory \\nrequirements as prescribed by the concerned Program Regulation s and \\nCurriculum (PRC) for the award of the concerned Degree;  \\n19.2.2 For Undergraduate Programs : Secured a minimum CGPA of 4.50 in the \\nconcerned Program at the end of the Semester/Academic Term in which \\nshe/he completes all the requirements for  the award of the Degree as \\nspecified in Sub-Clause 19.2.1;  \\n19.2.3 For Postgraduate Programs : Secured a minimum CGPA of 5.00 in the \\nconcerned Program at the end of the Semester/Academic Term in which \\nshe/he completes all the requirements for the award of t he Degree as \\nspecified in Sub-Clause 19.2.1;  \\n19.2.4 No dues to the University, Departments, Hostels, Library, and any other such \\nCenters/ Departments of the University; and  \\n19.2.5 No disciplinary action is pending against her/him.  \\n19.3 Award of Class:  \\nThe award of Class in a Degree shall be based on the CGPA in the concerned Program \\nat the end of the Semester/Academic Term in which the student completes all the'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 29, 'page_label': '30'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              30 \\nrequirements for the award of the Degree. In case a student has earned more credits \\nthan the required minimum as prescribed by the concerned Curriculum Struct ures, \\nthe higher CGPA, as applicable, considering the Credits and Grades corresponding to \\nthe mandatory minimum credit requirements as prescribed by the concerned \\nCurriculum Structure, for the award of the concerned Degree shall be considered for \\nthe award of Class.  \\nClasses shall be awarded as per the following scale:  \\n19.3.1 First Class with Distinction: CGPA of 8.00 and above  \\n19.3.2 First Class: CGPA from 6.50 to 7.99  \\n19.3.3 Second Class (for Postgraduate Programs): CGPA of 5.00 to 6.49  \\n19.3.4 Second Class (for Undergraduate Programs): CGPA of 4.50 to 6.49  \\n20.0  PROVISIONAL DEGREE CERTIFICATE  \\nOn completion of the requirements for the award of the Degree as prescribed in Section \\n19.0, the student may apply for a Provisional Degree Certificate  in the prescribed \\napplication form, along with the prescribed Fee notified by the University from time to \\ntime, to the Controller of Examinations of the University.  \\nOn verification of the eligibility criteria prescribed in Clause 19.2, the Controller of \\nExaminations shall issue the Provisional Degree Certificate to the concerned student, to \\nthe effect that the concerned student has fulfilled all the requirements for the award of \\nthe Degree in the concerned Program, and that, the Degree shall be conferred on the \\nconcerned student at the next Convocation of the University.  \\n21.0  CONVOCATION  \\nThe Convocation of the University shall be held annually as per the Convocation \\nRegulations of the University. The University shall announce the date for the Convocation \\nand call for applications from eligible students to register for the Convocation. The duly \\ncompleted application form along with the prescribed Convocation Fee must be submitted \\nby the student to the University within the specified date announced by the University.  \\nDegrees shall be awarded in person at the Convocation for the students who have \\ngraduated during the preceding Academic Year. Degrees shall be awarded in absentia to \\nsuch students who are unable to attend the Convocation.  \\n22.0  ISSUE OF DEGREE CERTIFICATE BEFORE THE CONVOCATION  \\nIn exceptional circumstances where a student requires the Degree Certificate before the \\ndate of the Convocation, for purposes of higher education or employment where the \\nconcerned University/Organization where the concerned student has secured/seeking \\nadmission/employment requires that the concerned stude nt must produce the Degree \\nCertificate, the concerned student may submit an application to the University, along \\nwith the prescribed Fee and all the supporting documents.  \\nThe Vice Chancellor shall consider the merit of the application and submit her/his \\nrecommendation to the Chancellor for the issue of the Degree Certificate, or otherwise.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 30, 'page_label': '31'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              31 \\nThe decision of the Chancellor shall be final and binding. On the approval of the \\nChancellor, the Degree Certificate shall be issued to the concerned student.  \\nThe minimum time taken to process and issue the Degree Certificate shall be two (02) \\ncalendar months from the date of receipt of the request for the issue of the Degree \\nCertificate.  \\n23.0 POWER TO REVISE, MODIFY AND AMEND  \\nNotwithstanding anything contained in the above Regulations:  \\n23.1 The Academic Council has the right to revise, amend or modify any of the above \\nRegulations from time to time, and shall be binding on all stakeholders concerned, \\nincluding the Students, Faculty, Staff, Departments, Schools and University \\nAuthorities.  \\n23.2 In case of a dispute, the decision of the Academic Council shall be final and binding.  \\n23.3 In case of difficulty in application of any of the Clauses of the Regulations specified \\nabove, the Chancellor shall have the powers to amend/modify/remove the difficulty \\nin the relevant Regulation.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 31, 'page_label': '32'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              32 \\nANNEXURE A \\nDEPARTMENTAL ACADEMIC COMMITTEE (DAC) \\na) “Department” refers to the School/Department offering Degree Programs  \\nb) There shall be at least one DAC for every School/Department that is involved in teaching \\nDegree Programs.  \\nc) However, each program can also have a separate DAC.  The HoD/Dean is authorized to ta ke \\ndecisions to this effect.  \\nd) The Respective School Dean  shall notify the concerned DAC as per the following \\nconstitution:  \\nMembers Designation Remarks \\nChairperson \\nDean/Associate Dean/Assistant Dean of \\nconcerned School/Head of the Department/ \\nHOD In Charge of the Program \\nEx Officio \\nMembers (Five) \\nfrom within the \\nSchool/Department \\nThree (03) Faculty Members representation \\nfrom Senior Professors/Senior Faculty and  \\nTwo (02) Assistant Professors \\nAppointed by \\nChairman, DAC \\nMember (One) Senior Faculty member from another \\nSchool/Department of the University \\nNominated by \\nDean \\n(Academics) \\nMember Secretary Faculty member from the School/ \\nDepartment \\nAppointed by the \\nChairman, DAC \\nTenure of the DAC is for one academic year \\n \\ne) The Chairperson may co-opt and/or invite more members, if necessary.  \\nf) Functions:  \\ni. To monitor the conduct of the respective Programs of study of the Department/School.  \\nii. To ensure academic standard and excellence of the respective Programs offered by the \\nDepartment/School.  \\niii. To consolidate the Registration List of the students and communicate to Course \\nInstructor, the Academic Office and Examination Department of the University.  \\niv. To review and approve the Course Plan (with Session Plan) submitted by the Faculty/ \\nCourse Instructor/Instructor In-Charge for each Course and forward the collated Course \\nPlan of each Program to the Dean - Academics.  \\nv. To ensure that at least two Class Committee (Refer Annexure D) meetings are conducted \\nduring the Semester and act upon the Resolutions passed by Class Committee(s).  \\nvi. To arrange to obtain the Student Feedback for every Course, once during the middle of \\nthe Semester and one at the end of each Semester, and to submit the consolidated report \\nof such feedback to the Dean - Academics.  \\nvii. To conduct at least two DAC meetings each Semester and a copy of the Resolutions of \\nthe DAC Meeting shall be communicated to the Dean - Academics, and a record of the \\nsame to be maintained in the Department/School.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 32, 'page_label': '33'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              33 \\nviii. To Plan the curriculum and syllabus changes based on various stakeholders (Faculty, \\nStudents, Alumni and Industry) feedback and suggestions. The complied suggestions \\nfrom DAC will be presented before the BOS for further discussions and follow up actions. \\nix. To implement the resolutions of the BOS for the upcoming batches and semesters.  \\nx. Any other responsibility or function assigned by the Dean (Academics).'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 33, 'page_label': '34'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              34 \\nANNEXURE B \\nEQUIVALENCE COMMITTEE \\nEquivalence refers to the process of evaluating and recognizing academic credits earned by \\nstudents from other institutions. The purpose of equivalence is to facilitate academic mobility \\nwhile maintaining the integrity and quality of the degree programs. It ensures that the Courses, \\ncredits, and learning outcomes align with the academic standards and program requirements of \\nthe University. This process applies to both credit transfers from other recognized institutions \\nand the acceptance of students transferring into the University. \\nEquivalence Committee shall have the following constitution: \\n1. Chairperson – Dean/Director of the Concerned School \\n2. Members – Two Professor(s)/Associate Professor (s) from the Concerned Program \\n3. Convenor – Head of the Department \\nResponsibilities: \\n\\uf0b7 Equivalence Committee shall examine the case for Transfer/Lateral Entry admissions and \\nsubmit its report and recommendation for the approval of the Vice Chancellor for \\nenrolment to the concerned program. \\n\\uf0b7 Equivalence  \\n\\uf0b7 Committee shall examine the Credit Transfer from other Indian/Foreign Institutions and \\nsubmit its report and recommendation for the approval of the Dean – Academics.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 34, 'page_label': '35'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              35 \\nANNEXURE C \\nCourse Instructor/Course In-Charge \\n \\nA Course Instructor for each Course on offer in a given Academic Term shall be assigned by \\nHoD/Dean/Director of School and approved by the Departmental Academic Committee. \\nIf a Course needs to be assigned to more than one class of students (due to a large number \\nregistered for the concerned Course) and if more than one Course Instructor needs to be \\nassigned to teach this Course, the HoD shall assign a Course In -Charge (who must be a \\nCourse Instructor for at least one class taking this Course) to coordinate with other Course \\nInstructors to facilitate the delivery of Course Plan in a consistent manner and also to ensure the \\nevaluation scheme and grading is conducted in a proper and consistent manner. \\nFunctions/Responsibilities (Highlights) \\nThe Course Instructor shall: \\na. follow all the Regulations related to teaching of a Course and evaluation of students; \\nb. be responsible for all the records (i.e., Course registration, assessment/answer \\nbooks, attendance, etc.) of the students registered for the Course; \\nc. shall conduct classes as prescribed in the Academic Calendar and as per the \\nteaching assignment time-table; \\nd. shall arrange to distribute a Course Plan and the evaluation plan together with the \\nCourse Outcomes, background materials to all the students within the first week of \\neach Semester; \\ne. prepare an evaluation plan showing details of how the student’s performance will \\nbe evaluated in the Course; \\nf. document the students’ performance and announce/declare such details as stipulated; \\ng. report to the HoD on a periodic (monthly) basis, the potential cases of poor \\nacademic performance (Slow Learners)  as well as those of low attendance, that \\nwould possibly result in a ‘F’ or ‘NP’ grade at the end of the Semester. \\nThe Course In-Charge shall co-ordinate the above functions/responsibilities with the other \\nassigned Course Instructors regularly as decided by their concerned HoD.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013', 'creator': 'Microsoft® Word 2013', 'creationdate': '2025-08-02T09:51:56+05:30', 'author': 'shilpa mehta', 'moddate': '2025-08-02T09:51:56+05:30', 'source': 'data\\\\College-Rule.pdf', 'total_pages': 36, 'page': 35, 'page_label': '36'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              36 \\n \\nANNEXURE D \\nCLASS COMMITTEE \\na) Every Class of the Degree Program (for example, 1st Year of a Program, Section A, etc., as \\napplicable) shall have a Class Committee, consisting of Faculty members and Students.  \\nb) The HOD/Program Head of the School/Department concerned shall notify the concerned Class \\nCommittee as per the following constitution:  \\nMembers Designation Remarks \\nChairperson Senior Faculty \\nMember of the Parent/ \\nTeaching Department, \\nassociated with the Class \\nMembers (Faculty) All Course Instructors of that \\nClass  \\nMembers \\n(Students: at least \\nSix) \\nStudents representing the Class \\nChosen by the students \\namongst themselves, but \\nonly those whose \\nMember Secretary Class Coordinator of the Class Appointed by the Dean of \\nthe School concerned \\nTenure of the Class Committee is for the Semester concerned. \\nAll members must attend the Class Committee Meeting. \\nc) Functions:  \\ni. The basic responsibility of the Class Committee is to review the progress of the \\nclasses/Courses, to discuss problems concerning the conduct of the classes and \\ncontinuous assessments as per the Course Plan and recommend remedial measures, \\nwhere necessary.  \\nii. Each Class Committee will communicate its recommendations to the Chairperson, DAC \\nof the Parent/Teaching Department/School.  \\niii. There shall be at least two Class Committee meetings every Semester, the first one \\nbefore midterm Examinations and the second one at least two weeks before the last \\ninstruction day of the semester  \\niv. However, additional Class Committee meetings may be convened as decided by the \\nChairperson, DAC.  \\nv. The Resolutions of each Class Committee meeting shall be recorded and submitted to the \\nHOD/Dean of the Parent Department/School, and, a copy shall be submitted to the Dean \\n(Academics).  \\nvi. Any appropriate responsibility or function assigned by the Chairman of the DAC.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-01-21T10:10:37+05:30', 'author': 'Ахил Кумар', 'moddate': '2025-01-21T10:10:37+05:30', 'source': 'data\\\\courses.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1'}, page_content='PU\\nUU \\nINSTITUTIONAL  INFORMATION  \\n \\n \\n \\n \\n \\n \\n \\n  \\nEnhance your degree with \\nExchange and Study Abroad \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\nName of the Institution Presidency University (PU) \\nPostal Address \\nThe Office of International Affairs \\nPresidency University, Itgalpur Rajanakunte, \\nYelahanka, Bengaluru, Karnataka 560064 \\nWebpage www.presidencyuniversity.in  \\nTelephone Number +91 80 2309 3500 \\n \\nInternational Office Contact \\nDr Sivaperumal S \\nDirector of International Affairs \\ndirector-\\ninternational.relations@presidencyuniversity.in  \\nStudent Exchange Website Presidency_InternationalAffairs-Student_Exchange \\nFact sheet \\nInbound Mobility Students \\n2025-26'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-01-21T10:10:37+05:30', 'author': 'Ахил Кумар', 'moddate': '2025-01-21T10:10:37+05:30', 'source': 'data\\\\courses.pdf', 'total_pages': 12, 'page': 1, 'page_label': '2'}, page_content='Bangalore is a cosmopolitan city in India, known for its thriving IT industry and \\ninnovation hub. It is often referred to as the Silicon Valley of India. Bangalore city is \\nhome to many multinational companies, startups, research institutes, NGOs, etc. \\nthat provide internships and placements to students. Bengaluru will soothe you with \\nits pleasant weather throughout the year.  \\nBangalore is home to several prestigious universities and colleges that offer \\nundergraduate and postgraduate courses in a wide range of fields, including arts, \\nscience, commerce, law, management, and engineering.  \\nBangalore has a vibrant campus life that provides students with opportunities for \\nlearning, networking, cultural exchange, and extracurricular activities. The city is \\nalso known for its rich cultural heritage and attractions such as garde ns, parks, \\ntemples, and museums.  \\nCompared to other metro cities in India, Bangalore has a low cost of living and a \\npleasant climate throughout the year. It is well -connected by road, rail, and air to \\nother parts of the country and the world.  \\nBangalore is listed as the top 10 fastest growing cities in the world, the economy of \\nthis city is an important part of the economy of India.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-01-21T10:10:37+05:30', 'author': 'Ахил Кумар', 'moddate': '2025-01-21T10:10:37+05:30', 'source': 'data\\\\courses.pdf', 'total_pages': 12, 'page': 2, 'page_label': '3'}, page_content='BENGALURU \\nBENGALUR  U, KARNA  TAKA,  INDIA  \\nSTUDE  NT MI GRATION  TREND  \\n46 . 55 % \\nSAME CITY \\n \\n6. 90% \\nSAME STATE \\n46 . 55 % \\nNATIONAL \\n \\nWHY  BENGALURU?  ( RANKED  ORDER)  \\n Good  We ath  \\n Sa fe t y \\n \\n  Soc  ial  Life  \\n \\n I n f r a s t r u c t u r e \\n Employability  \\n \\n  University Life \\n  Reputation  Public     \\n Transport \\n \\nNight Life \\nBest Student Cities, Bengaluru \\nwas ranked as India’s best \\nstudent city, while ranking 114 \\nglobally'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-01-21T10:10:37+05:30', 'author': 'Ахил Кумар', 'moddate': '2025-01-21T10:10:37+05:30', 'source': 'data\\\\courses.pdf', 'total_pages': 12, 'page': 3, 'page_label': '4'}, page_content='Welcome Mid of August \\nSemester begins End of August \\nClasses end Mid of January \\nIncluding exams \\n \\nWelcome Mid of January \\nSemester begins Beginning of February \\nClasses end End of June \\nIncluding exams \\n \\nACADEMIC  CALENDAR  2025 -26 \\nSemester one* (Odd/Fall semester) Semester two* (Even/Spring semester) \\n \\n \\n* Confirmed dates will be indicated on the individual acceptance/visa letter. \\nSTUDY  ABROAD/EXCHANGE  APPLICATION  AND ADMISSION  \\nApplication documents (in English): \\n▪ Completed application form \\n▪ Academic transcripts of record (official, stamped and signed by home institution) \\n▪ Passport copy (valid for a minimum of six months beyond the date of intended \\ndeparture from India)  \\n▪ All non-native English speaking applicants must provide proof of English language \\nability or a letter from the home university certifying applicant proficiency \\n▪ Proof of international health insurance \\n \\nINSTRUCTION OF NOMINATION \\nStudents must be nominated by their home institution’s Advisor/Coordinator. Once \\napproved by the home institution, students’ nomination should be sent via email by \\nthe Advisor/Coordinator to the respective region in charge officers stated below \\nwith the following information. \\n• First Name \\n• Last Name \\n• Class Level \\n• Date of Birth \\n• Email ID \\n• Program of Study \\n \\n \\nAfter home institution nomination the prospective exchange students are requested to \\nsend the completed application form with required documents to:  \\nMs. Sai Prasanna \\noia4@presidencyuniversity.in \\n+91 97317 42211'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-01-21T10:10:37+05:30', 'author': 'Ахил Кумар', 'moddate': '2025-01-21T10:10:37+05:30', 'source': 'data\\\\courses.pdf', 'total_pages': 12, 'page': 4, 'page_label': '5'}, page_content='Nomination deadlines Application deadlines* Semester \\n \\n20 March 2025 \\n \\n30 March 2025 \\nOne semester (odd/Fall \\nsemester) for August 2025 \\nentry \\nTwo semester (odd and even \\nsemester) for August 2025 \\nentry \\n20 September 2025 30 September 2025 One semester (even/Spring \\nsemester) for February 2026 \\nentry \\n \\n*We cannot guarantee consideration of applications submitted after the above \\ndeadlines, although we will try to consider every application where possible. \\nFEES  \\nAs an Incoming exchange student,  you will pay tuition fees to your  home institution \\nbased on their fee  requirements. However, exchange students shall pay for things \\nsuch as books and equipment, health insurance, local excursion , accommodation, \\nflight, and a student visa. \\n \\nACCOMMODATION  \\nAs soon as you have been accepted a course (s) offered from us, you can request \\nfor off -campus accommodation and Presidency University will facilitate incoming \\nstudents in finding accommodation  close to the campus , approximately 7 -10 kms. \\nStudents are advised to apply for accommodation as soon as possible after  \\naccepting an offer letter; so, you have accommodation arranged before your arrival \\nin Bangalore, India.  \\nNote: The university will provide a bus service for all incoming exchange students \\nfrom partner universities so that they can commute to and from campus. \\n \\nResidence Facilities: \\n▪ Twin sharing bedroom (Euro 300 approx. per month) \\n▪ Furnished with beds, wardrobes, study tables chairs, bookshelves \\n▪ Fan \\n▪ Common bathroom toilet \\n▪ Wi-Fi'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-01-21T10:10:37+05:30', 'author': 'Ахил Кумар', 'moddate': '2025-01-21T10:10:37+05:30', 'source': 'data\\\\courses.pdf', 'total_pages': 12, 'page': 5, 'page_label': '6'}, page_content='AVAILABLE  PROGRAMMES  \\nInternational students are required to take a full-time study load from below schools: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\nComputer Science & Engineering \\n \\n▪ B.Tech. - Computer Science and Engineering \\n▪ B.Tech. - Computer Science and Engineering \\n(Artificial Intelligence & Machine Learning) \\n▪ B.Tech. - Computer Science and Engineering \\n(Data Science) \\n▪ B.Tech. - Computer Science and Engineering \\n(Cyber Security) \\n▪ B.Tech. - Computer Science and Engineering \\n(Block chain) \\n▪ B.Tech. - Computer Science and Engineering \\n(Internet of Things) \\n▪ B.Tech. - Computer Science and Technology \\n(Big Data) \\n▪ B.Tech. - Computer Science and Technology \\n(DevOps) \\n▪ B.Tech. - Computer Science and Technology \\n[Spl. in Artificial Intelligence & Machine \\nLearning] \\n▪ B.Tech. - Computer Engineering [Spl. in \\nArtificial Intelligence & Machine Learning] \\n▪ B.Tech. - Computer Science and Information \\nTechnology \\n▪ B.Tech. - Computer Science and Engineering \\n(Networks) \\n▪ B.Tech. - Information Science and Engineering \\n[Spl. in Artificial Intelligence & Robotics] \\n▪ B.Tech. - Information Science and Technology \\n[Spl. in Artificial Intelligence & Data Science] \\n▪ M.Tech. - Artificial Intelligence \\n▪ M.Tech. - Data Science \\nEngineering \\n \\n▪ B.Tech. - Civil Engineering \\n▪ B.Tech. - Electrical & Electronics Engineering \\n▪ B.Tech. - Electronics and Communication \\nEngineering \\n▪ B.Tech. - Mechanical Engineering \\n▪ B.Tech. - Mechanical Engineering [Spl in \\nMechatronics] \\n▪ B.Tech. - Petroleum Engineering \\n▪ B.Tech. – VLSI \\n▪ M.Tech. - Embedded Systems & VLSI \\n▪ M.Tech. - Building & Construction Technology \\n▪ M.Tech. - Product Design and Development \\nCommerce, Economics & Management \\n \\n▪ Bachelor of Business Administration (BBA) \\n▪ BBA (Digital Marketing) \\n▪ BBA (Business Analytics) \\n▪ BBA (Aviation Management) \\n▪ B. Com – (Professional) – (Spl. In Banking and \\nFinance) \\n▪ B.Com – (Professional) – (Spl. In Corporate \\nAccounting and Taxation) \\n▪ B.Com – (Hons.) – (Spl. In Business Analytics) \\n▪ B.Sc. – Economics  \\n▪ Master of Business Administration (MBA) \\n▪ MBA (Business Analytics) \\n▪ MBA (Digital Marketing) \\n▪ MBA (Banking & Finance Management) \\n▪ MBA (Marketing & Finance) \\n \\nMedia Studies \\n \\n▪ BA (Journalism and Mass Communication) \\n \\nInformation Science \\n \\n▪ Bachelor of Computer Application (BCA) \\n▪ BCA Data Science \\n▪ BCA Artificial Intelligence & Machine Learning \\n▪ Master’s in Computer Applications (MCA) \\nDesign \\n \\n▪ B. Des – Product Design \\n▪ B. Des – Communication Design \\n▪ B. Des – Space Design [Interior Design] \\n▪ B. Des – Fashion Design \\n▪ B. Des – Game Design \\n▪ B.Sc. Multimedia (VFX, SFX & Gaming) \\n \\n *All the programmes at Presidency University are completely taught in English'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-01-21T10:10:37+05:30', 'author': 'Ахил Кумар', 'moddate': '2025-01-21T10:10:37+05:30', 'source': 'data\\\\courses.pdf', 'total_pages': 12, 'page': 6, 'page_label': '7'}, page_content='CHOOSING MODULES/COURSES  \\nYou may take courses across multiple faculties (subject to availability, no guarantees \\nmay be given) as long as your course choices are approved by your home university  \\nand meet your degree requirements.  Most courses are open to Incoming Exchange \\nstudents. However, some have prerequisites or require permission from the relevant \\nfaculty or school before you can enroll in them. Students to enroll prior to their arrival \\nat Presidency University. However, courses need t o be finalized within one week of \\nstart of   the class. All the programmes/courses are taught completely in English.  \\nACADEMIC WORKLOAD  \\nExchange students can take a workload of 12 to 20 credits. The minimum \\nworkload is 12 credits  and maximum would be 20 credits.  It may be considered on \\nthe request of the home university on reducing the workload. \\nPU 01 credit = U.S. 01 credit. \\nPU 01 credit is 15 teaching contact hours (study period, project, assignments, and \\nexamination period is excluded) \\nATTENDANCE REQUIREMENTS  \\nA student must have a minimum of 75%  attendance of the classes actually \\nconducted in that academic term, for which course(s) the student has registered for \\nin the academic term, will be permitted to write the final examination. \\nGRADING SYSTEM \\nGrade Grade Point Marks range  \\n(out of 100) Qualitative Description \\nO 10 >= 90 Outstanding \\nA+ 9 >= 85 but < 90 Excellent \\nA 8 >= 80 but < 85 Very Good \\nB+ 7 >= 75 but < 80 Good \\nB 6 >= 70 but < 75 Above Average \\nC 5 >= 60 but < 70 Average \\nD 4 >= 50 but < 60 Pass \\nF 0 < 50 Fail'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-01-21T10:10:37+05:30', 'author': 'Ахил Кумар', 'moddate': '2025-01-21T10:10:37+05:30', 'source': 'data\\\\courses.pdf', 'total_pages': 12, 'page': 7, 'page_label': '8'}, page_content='TRANSCRIPTS  \\nAll credit-bearing exchange students will be issued with a transcript detailing their  \\nmodules and final grades at the end of the semester, once the exam results have  \\nbeen finalized. Transcript’s will be mailed directly to the home university. \\n \\nWHEN SHOULD YOU ARRIVE  \\nYou should arrive at least 7  days prior to the commencement of the term. Late \\narrival may be accepted under certain conditions such as health or travel/diplomatic \\nrestrictions.  \\nVISA  AND IMMIGRATION  REQUIREMENTS  \\nAll international students applying to study in India must have a valid student visa \\n(before travelling to India) unless they have an alternative visa that enables them \\nto study  in India . If you are granted a student visa, you must comply with all \\nstudent visa conditions. For all visa enquiries and applications, please contact your \\nlocal Indian Embassy/High Commission/Consulate General of India . The visa must \\nbe valid for the orientation days before the start of the semester. Find more details \\nby visiting https://www.mea.gov.in/    \\nINSURANCE  \\nAll international students  are required to acquire a  health insurance from their  \\nhome country before their  departure. The insurance  should cover for medical  and \\nevacuation expenses abroad due to accident or  sickness for the entire  duration of \\nexchange at the host country. \\nFOREIGN REGIONAL REGISTRATION OFFICES  (FRRO)  \\nForeigner visiting India on Student Visa(S) is required to get himself / herself \\nregistered with concerned FRRO, within 14 days of his/her first arrival, irrespective \\nof the duration of his / her stay. FORM –S (Foreign Students Information System) is \\nused to capture information about foreign nationals admitted in Indian educational \\ninstitutions. Follow the FRRO link for more details.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-01-21T10:10:37+05:30', 'author': 'Ахил Кумар', 'moddate': '2025-01-21T10:10:37+05:30', 'source': 'data\\\\courses.pdf', 'total_pages': 12, 'page': 8, 'page_label': '9'}, page_content='CURRENT  ESTIMATED  COST  OF LIVING * \\nAccording to the study in India, the average cost of living in India (Bangalore) for  \\nstudents is € 140 (A student can experience a comfortable stay for a month). \\nLiving costs will vary depending on lifestyle but it is generally inexpensive to live in  \\nBangalore than other Indian cities, such as Mumbai or Delhi. Here is a breakdown of \\nsome general expenses for you to consider when preparing your finances (click for  \\nmore details): \\n \\nGeneral Expenses Approximate cost \\nAccommodation (off campus) \\nPlease check with the office of International Affairs whether certain items are  \\nincluded e.g. bedding, kitchen utensils, etc., and whether you would be required \\nto pay a deposit as well as made an advance payment. \\n \\n€ 250 (per month) \\nGroceries € 65 (per month) \\nMeal (affordable restaurant) € 2-5 \\nTransport € 30 (per week) \\nWi-Fi € 4-12 (per month) \\nMobile telephone (depends on usage) € 8 (per month) \\nWater € 0.60 per liter \\nCourse related costs: books/stationery/photocopying/binding € 10 (per month) \\n*Please note: The above costs are estimated and subject to each student’s \\nindividual lifestyle - personal expenses and spending habits. \\nSERVICES and SUPPORT \\nStudying overseas is a rewarding opportunity to broaden your experience and \\noutlook, but it can also be challenging. PU provides the support you need to \\ndevelop academic and professional skills, feel confident in your study and maintain \\nyour wellbeing. \\nPU INTERNATIONAL OFFICE \\nThe PU International team offers you advice and support during the application \\nprocess and throughout your studies at PU. Our student advisers/Mentors can assist \\nwith general enquiries, and will keep you up to - date with important news and \\nevents around PU via emails.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-01-21T10:10:37+05:30', 'author': 'Ахил Кумар', 'moddate': '2025-01-21T10:10:37+05:30', 'source': 'data\\\\courses.pdf', 'total_pages': 12, 'page': 9, 'page_label': '10'}, page_content='SAFETY AND SECURITY \\nPU fosters a safe and secure environment for students, staff and visitors, with 24 -\\nhour security assistance on and around campus. This includes accessible security \\nofficers, regular patrols, and closed-circuit television cameras. \\nARRIVAL TIPS \\nStudents to arrive in Bangalore 7 days prior to start of the formal classes so as to \\nfinalize the courses and to settle in their accommodation. \\nPU International Office offers a complimentary airport shuttle service from \\nBengaluru International Airport to PU for exchange students who arrive 7 days \\nbefore Orientation begins.  Exchange students need to provide their flights details \\nand visa for arrange the pick service from the Bengaluru Airport. \\nGENERAL SUPPORT SERVICES \\nPU provides a wide range of on-campus services for students, including: \\n• Medical services \\n• Counselling services \\n• Accessibility services for students with a disability or ongoing medical \\ncondition \\n• Wi-Fi facility throughout campus \\n• Library services \\n• Sports facilities \\n• Student welfare services \\n• Canteen facilities \\n• PU Buddy \\n• ATM'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-01-21T10:10:37+05:30', 'author': 'Ахил Кумар', 'moddate': '2025-01-21T10:10:37+05:30', 'source': 'data\\\\courses.pdf', 'total_pages': 12, 'page': 10, 'page_label': '11'}, page_content='HOW TO APPLY \\n \\n1. Choose  your  \\nprogramme  \\nAre  you  applying  as a Student  Exchange/  Study  Abroad  \\n \\n2. Check  your  eligibility  Check that you meet the entry requirements for your \\nprogram.  \\n \\n3. Discuss  your  study  \\noptions with your home \\nuniversity  \\nConsult  with  your  home  university  to understand  the \\napplication  and  credit  requirements  of studying  abroad.  \\nIf you are from PU exchange partner university, you’  ll also \\nneed home university approval to participate in the \\nexchange.  \\n4. Choose your courses \\n- 12 or 18 credit points  \\nReview the information in this guide and select the \\nappropriate study plan for  your  program in PU.  \\n \\n \\n \\n5. Apply  at PU \\nExchange  Programme  \\n\\uf0a8 Ensure your home university confirms your \\nnomination to PU first.  \\n\\uf0a8 Submit the f i l led  application form  with academic \\ntranscripts along with essential supporting  \\ndocuments  as requested  on the  application  form . \\n6. Apply for PU off -campus \\naccommodation  \\n \\nYou will receive an acknowledgement of your application  \\n \\n \\n7. Offer letter and study \\nplan  \\nPU will  assess  your  application.  I f you  are  successful,  \\nPU will  email  your  offer  Letter  after  receiving  the \\nconfirmation for accommodation and administrative \\ncharges.  \\nYou  can  start  to prepare  your  study  plan.  The  average  \\ntimeframe  to process  applications  is two  to three  weeks.  \\n8. Acceptance  and \\nconfirmation  of \\nenrolment  \\nYou must formally accept your offer and, PU will also  \\npre - enroll  you  in your  preferred, approved subjects.  \\n \\n \\n9. Apply  for a student  \\nvisa  \\nApply for a student visa. Once your student visa has  \\nbeen approved, you should  finalize your travel  \\narrangements and insurance. You must obtain an Indian \\nstudent  visa  before  you  can  commence study in India.  \\n \\n10. Pre - arrival  \\nPU will send you pre - arrival information regarding \\naccommodation, airport reception and  orientation \\nactivities.  \\n \\n \\n \\n11. Arrival  and  \\nOrientation  \\nArrive in Bangalore, India and attend PU Orientation, \\nwhich  is compulsory for  all  exchange students.  Our  \\ncomprehensive Orientation programs include information \\nsessions  and  social  activities,  to help  you  get  to know  \\nPU and meet other new and experienced students. You \\nwill also be able to finalize your enrolment and receive \\nyour student ID card.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2025-01-21T10:10:37+05:30', 'author': 'Ахил Кумар', 'moddate': '2025-01-21T10:10:37+05:30', 'source': 'data\\\\courses.pdf', 'total_pages': 12, 'page': 11, 'page_label': '12'}, page_content='Phone: +91 80 2309 3500  \\nEmail: ir_office@presidencyuniversity.in \\nWeb: https://presidencyuniversity.in  \\n \\nPlease note that this factsheet is subject to change \\nLast update: January 2025'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 0, 'page_label': 'C1'}, page_content=''),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 1, 'page_label': 'C2'}, page_content=''),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 2, 'page_label': 'i'}, page_content='“Cutting through the clutter, Martin Musiol explains generative AI with \\ngreat insight and clarity. The reader is left with a clear understanding of the \\ntechnology, without the need to master complex mathematics or code. A must \\nread for those who want to understand the future.”\\n—  Rens ter Weijde, Chairman & CEO of KIMO.AI\\n“ An illuminating guide through the evolving landscape of generative AI and \\nAGI, this book masterfully demystifies complex concepts, making them acces-\\nsible to all and ignites the imagination about the boundless possibilities of \\nthe future.”\\n—  David Foster, author of Generative Deep Learning, Partner at \\nApplied Data Science Partners\\n“This book is a must-read for anyone wanting to improve their understand-\\ning of where AI has come from, where it stands today, and, importantly, \\nwhere it is heading. The advent of AGI and ASI is too important not to \\nunderstand, and Martin meticulously explains many potential outcomes \\nwith a factual and unbiased perspective.”\\n—  Roy Bhasin (Zeneca), author, entrepreneur,  \\nangel investor\\n“Highly recommended. Musiol deeply and expertly demonstrates how to \\nnavigate the complex, exhilarating, and essential landscape of generative AI.”\\n—  Katie King, published author,  \\nCEO of AI in Business\\n“Generative AI by Martin Musiol offers a comprehensive overview of the \\nGenAI technology and skillfully demystifies complex concepts of this trans-\\nformative AI.”\\n—  Sheamus McGovern, entrepreneur, investor, Founder & CEO Open \\nData Science\\nPraise for Generative AI'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 3, 'page_label': 'ii'}, page_content='“Martin, my esteemed former colleague and an AI expert, has authored this \\ncrucial book designed for anyone seeking to enhance their knowledge of gen-\\nerative AI, autonomous AI agents, and AGI. From complex subjects to com-\\npelling and easily comprehensible, this book is invaluable for business \\napplications and everyday life.”\\n—  Martin Weis, Country Head Switzerland & Global Co-Lead AI, \\nAnalytics & Automation at Infosys Consulting\\n“Martin’s book masterfully encapsulates the transformative power of AI and \\nprovides great foundational knowledge for innovators and builders to explore \\nthe industry further.”\\n—  Anton Volovyk, Co-CEO Reface  \\n(GenAI app, 250m downloads, backed by a16z)\\n“This book is akin to a comprehensive playbook, detailing strategies and \\nrules for navigating the complex field of AI, much like a coach laying out a \\nwinning game plan. It masterfully presents the evolutionary stages, key \\nplayers beyond ChatGPT, foundational technologies, and practical guidance, \\nequipping readers to effectively ’play’ and excel in the dynamic and competi-\\ntive arena of AI.”\\n—  Dr. Harald Gunia, Leader for Applied Artificial  \\nIntelligence Europe at Infosys Consulting\\n“Martin Musiol’s book on generative AI provides a compelling narrative \\nthat unveils the meticulous evolution of this groundbreaking technology. \\nFrom the quiet simmering of its inception, to the carefully curated recipe of \\ntechnological advancements that propelled it to unprecedented heights, \\nMusiol carefully peels back the layers, revealing the pivotal factors that \\nshaped the rise of generative AI.”\\n—  Matteo Penzo, Co-Founder & CEO of zicklearn.com\\n“Martin’s book offers deep insights and a comprehensive overview that \\nmakes this complex subject accessible to all readers.”\\n—  Prof. Dr. Patrick Glauner\\n“This book is a must-read for anyone like me captivated by artificial intel-\\nligence’s present and future implications.”\\n—  Catherine Adenle, Senior Director, Global Employer Brand,  \\nElsevier, top\\xa022 AI and tech influencer'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 4, 'page_label': 'iii'}, page_content='Generative AI\\nNavigating the Course to the Artificial \\nGeneral Intelligence Future\\nMartin Musiol'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 5, 'page_label': 'iv'}, page_content='Copyright © 2024 by John Wiley & Sons, Inc. All rights reserved.\\nPublished by John Wiley & Sons, Inc., Hoboken, New Jersey.\\nPublished simultaneously in Canada and the United Kingdom.\\nISBNs: 9781394205912 (Hardback), 9781394205950 (ePDF), 9781394205943 (ePub)\\nNo part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form \\nor by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as \\npermitted under Section\\xa0107 or 108 of the 1976 United States Copyright Act, without either the prior \\nwritten permission of the Publisher, or authorization through payment of the appropriate per-copy \\nfee to the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-\\n8400, fax (978) 750-4470, or on the web at www.copyright.com. Requests to the Publisher for \\npermission should be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River \\nStreet, Hoboken, NJ 07030, (201) 748-6011, fax (201) 748-6008, or online at www.wiley.com/go/\\npermission.\\nTrademarks: WILEY and the Wiley logo are trademarks or registered trademarks of John Wiley & \\nSons, Inc. and/or its affiliates, in the United States and other countries, and may not be used without \\nwritten permission. All other trademarks are the property of their respective owners. John Wiley & \\nSons, Inc. is not associated with any product or vendor mentioned in this book.\\nLimit of Liability/Disclaimer of Warranty: While the publisher and author have used their best \\nefforts in preparing this book, they make no representations or warranties with respect to the accuracy \\nor completeness of the contents of this book and specifically disclaim any implied warranties of mer-\\nchantability or fitness for a particular purpose. No warranty may be created or extended by sales rep-\\nresentatives or written sales materials. The advice and strategies contained herein may not be suitable \\nfor your situation. Y ou should consult with a professional where appropriate. Further, readers should \\nbe aware that websites listed in this work may have changed or disappeared between when this work \\nwas written and when it is read. Neither the publisher nor author shall be liable for any loss of profit \\nor any other commercial damages, including but not limited to special, incidental, consequential, or \\nother damages. Generative AI tools were used by the author to research ideas for this book; however, \\nthe writing and finished text of the book are completely the work of the author and the Wiley editorial \\nstaff.\\nFor general information on our other products and services or for technical support, please contact \\nour Customer Care Department within the United States at (800) 762-2974, outside the United States \\nat (317) 572-3993 or fax (317) 572-4002.\\nWiley also publishes its books in a variety of electronic formats. Some content that appears in print \\nmay not be available in electronic formats. For more information about Wiley products, visit our web \\nsite at www.wiley.com.\\nLibrary of Congress Control Number: 2023951020\\nCover image: © undefined/Getty Images\\nCover design: Wiley'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 6, 'page_label': 'v'}, page_content='T o my parents, who have always supported me, and to my grandma \\nHelena, whose wise words continue to echo in my ears, guiding me \\nthrough life. I will be forever grateful for the deep love I have received \\nfrom you, and rest assured, I feel the same for you. A truth perhaps \\nnot spoken enough, yet profoundly felt.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 7, 'page_label': 'vi'}, page_content=''),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 8, 'page_label': 'vii'}, page_content='Introduction ix\\nChapter 1 AI in a Nutshell 1\\nChapter 2 Innovative Approaches for\\xa0High-Quality  \\nData Generation 23\\nChapter 3 Generative AI’s Broad  Spectrum of  \\nApplications 119\\nChapter 4 Generative AI’s Exponential Growth 219\\nChapter 5 Ethical Concerns and Social Implications  \\nof Generative AI 285\\nChapter 6 Artificial General  Intelligence in\\xa0Sight 337\\nAcknowledgments 405\\nAbout the\\xa0Author 407\\nIndex  409\\xa0\\nContents\\nvii'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 9, 'page_label': 'viii'}, page_content=''),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 10, 'page_label': 'ix'}, page_content='ix\\nI\\nn the realm of technology, epochs of transformation are often \\nignited by the spark of human imagination, fused with the \\nfinesse of engineering artistry. We stand at the precipice of such \\nan epoch, where the realms of generative AI unfurl into the once \\nuncharted territories of artificial general intelligence (AGI). I am \\nboth thrilled and humbled to be your guide on this thrilling \\nexpedition into the future, a journey that begins with the pages \\nof this book.\\nThe technological zeitgeist of our times is one of exponential \\nprogress. A mere glimpse into the recent past reveals the embry-\\nonic stages of generative AI, yet, within a fleeting span, advance-\\nments like ChatGPT have marked a point of no return. This \\ncrescendo of innovation is not confined to textual realms alone \\nbut spans across images, videos, 3D objects, datasets, virtual real-\\nities, code, music, and sound generation, each stride accelerating \\nour pace toward the enigmatic horizon of AGI. The rapid matu-\\nration and adoption of generative AI outshine the evolutionary \\narcs of many preceding technologies.\\nIt was during the cusp of this book’s creation that the concept \\nof autonomous AI agents morphed into a tangible reality, cour -\\ntesy of emerging open source frameworks. Now, a subscription \\naway, the first AI agents are at our beck and call. This swift pro-\\ngression, magnifying the efficiency of AI model development, \\nIntroduction'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 11, 'page_label': 'x'}, page_content='x IntroductIon\\nunderscores the urgency and the timeliness of delving into the \\ndiscourse this book intends to foster. As you traverse through its \\nchapters, you’ll realize we are merely at the dawn of an exhilarat-\\ning technological epoch with a vast expanse yet to be unveiled.\\nWho should venture into this exploration? Whether you’re a \\ntechnology aficionado, a student with a zest for the unknown,  \\na policymaker, or someone who’s merely curious, this book beck-\\nons. No prior acquaintance with AI or machine learning is \\nrequired; your curiosity is the sole ticket to this expedition. As we \\ncommence, we’ll demystify the essence of AI, its lexicon, and its \\nmetamorphosis over time. With each page, we’ll delve deeper, yet \\nthe narrative is crafted to foster an understanding, irrespective of \\nyour prior knowledge. By the narrative’s end, your imagination \\nwill be aflame with the boundless possibilities that the future holds.\\nThe narrative arc of this book has been meticulously crafted \\nto offer an understanding yet a profound insight into generative \\nAI and its trajectory toward AGI. Our expedition begins with the \\nrudiments of AI, tracing its evolution and the brilliant minds that \\npropelled it forward. As we delve into the heart of generative AI, \\nwe’ll explore its broad spectrum of applications, unraveling \\npotential startup ideas and pathways to venture into this domain. \\nThe discussion will then transcend into the convergence of \\ndiverse technological realms, each advancing exponentially \\ntoward a shared zenith. Ethical and social considerations, indis-\\npensable to this discourse, will be deliberated upon before we \\nventure into the realms of AGI, humanoid and semi- humanoid \\nrobotics, and beyond. Through the annals of my experience, \\nincluding my tenure as the generative AI lead for EMEA at Info-\\nsys Consulting, we’ll traverse through real- world scenarios, \\nalbeit veiled for confidentiality, offering a pragmatic lens to envi-\\nsion the theoretical discourse.\\nWhat sets this narrative apart is not merely the content, but \\nthe vantage point from which it is observed. My journey, from'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 12, 'page_label': 'xi'}, page_content='Introduction xi\\nadvocating generative AI since 2016, founding GenerativeAI.net \\nin 2018, to now sharing a platform with luminaries at the AI \\nSpeaker Agency, has been nothing short of exhilarating. It’s \\nthrough the crucible of real- world implementations and contin-\\nuous discourse with global thought leaders that the insights \\nwithin this book have been honed. Our conversations, a conflu-\\nence of diverse perspectives, have enriched the narrative, making \\nit a crucible of collective wisdom.\\nA treasure trove of knowledge awaits to equip you to navi-\\ngate the complex yet exhilarating landscape of generative AI and \\nAGI. The ethos of this narrative is to empower you to become a \\n10X more effective human, to harness the tools that propel you \\nforward, and should a spark of an idea ignite within, to pursue it \\nwith vigor. Things can be figured out along the way, especially in \\nthis era equipped with generative AI tools. Remember, AI in itself \\nwon’t replace us, but those wielding AI effectively certainly will \\nhave an edge.\\nIn the words of British physicist David Deutsch, our civiliza-\\ntion thrives on technological growth, and it’s our prerogative to \\nstrive for a better future. This book is a stepping stone toward \\nthat endeavor, and I invite you to step into the future, one page \\nat a time.\\nHow to\\xa0Contact the\\xa0Publisher\\nIf you believe you’ve found a mistake in this book, please bring it \\nto our attention. At John Wiley & Sons, we understand how \\nimportant it is to provide our customers with accurate content, \\nbut even with our best efforts an error may occur.\\nIn order to submit your possible errata, please email it to our \\nCustomer Service T eam at wileysupport@wiley.com with the \\nsubject line “Possible Book Errata Submission.”'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 13, 'page_label': 'xii'}, page_content='xii IntroductIon\\nHow to\\xa0Contact the\\xa0Author\\nI appreciate your input and questions about this book! Feel free \\nto contact me at the following:\\nMartin Musiol’s email: generativeai.net@gmail.com\\nMartin’s LinkedIn profile: www.linkedin.com/in/martinmusiol1\\nGenerativeAI.net’s web page: https://generativeai.net'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 14, 'page_label': '1'}, page_content='1\\nN\\no other field of technology has such inconsistent jargon as \\nartificial intelligence (AI). From mainstream media to tech \\ninfluencers to research scientists, each layer of media has con-\\ntributed to that confusion. In order of their degree of contribu-\\ntion and frequency, I observed mainstream media simplifying \\nand misusing terms consistently, tech influencers misunderstand-\\ning the tech in- depth, and even some research scientists over- \\ncomplicating their model findings with fancy terms. By no means \\ndo I intend to criticize research scientists. They are the backbone \\nof everything discussed in this book. Their work offers solutions \\nto a plethora of problems, making AI the umbrella term for \\nalmost every intelligent problem. However, its interdisciplinary \\nnature, the rapid advancements in this space, and AI’s general \\ncomplexity make it already difficult to gain a clear understanding \\nof this field. I am convinced that consistent and clear language \\nwould help to understand this topic area.\\n1\\nCHAPTER\\nAI in a Nutshell'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 15, 'page_label': '2'}, page_content='2 GENERATIVE AI\\nWe can see two broad classes in AI: generative AI, the subject \\nof this book, and discriminative AI. The latter is the traditional \\nand better- known part of AI. Before delving into both AI classes, \\nlet’s take a moment to understand the broader picture of AI, \\nmachine learning (ML), deep learning (DL), and the process of \\ntraining models, to avoid getting ahead of ourselves.\\nWhat Is AI?\\nEven though AI includes a broad spectrum of intelligent code, \\nthe term is often incorrectly used. Figure\\xa01.1 shows how AI, ML, \\nand DL are related. ML, a part of AI, learns from data. DL, a \\ndeeper part of ML, uses layered setups to solve tougher prob-\\nlems. Non- self- learning programs like expert systems don’t learn \\nfrom data, unlike ML and DL. We’ll explore these more next.\\nHow AI Trains Complex Tasks\\nAI can perform tasks ranging from predefined expert answers, \\nalso known as expert systems, to tasks that require human- level \\nintelligence. Think about recognizing speech and images, \\nAI\\nNon-Self-\\nLearning\\nAlgorithms\\nSelf-Learning\\nAlgorithms\\nML\\nDL\\nFIGURE\\xa01.1 The relationship between AI, ML, and DL'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 16, 'page_label': '3'}, page_content='AI in a Nutshell 3\\nunderstanding natural language processing (NLP), making \\nsophisticated decisions, and solving complex problems. For tasks \\nlike this, the AI has to train on a respective dataset until it is able \\nto perform the desired activity as well as possible. This self- \\nlearning part of AI is referred to as machine learning (ML). \\nBecause most of the interesting applications are happening \\nthrough machine learning in one way or another, and to keep it \\nsimple, we use AI and ML interchangeably.\\nT o make it tangible, we are designing an AI system that rates \\nthe cuteness of cats from 5 (absolutely adorable) to 1 (repulsively \\ninelegant). The ideal dataset would consist of pictures of cute \\nkittens, normal cats, and those half- naked grumpy cats from the \\nInternet. Further, for classifying pictures in a case like this, we \\nwould need labeled data, meaning a realistic rating of the cats. \\nThe model comes to life through three essential steps: training, \\nvalidation, and evaluation.\\nIn training, the model looks at each picture, rates it, com-\\npares it with the actually labeled cuteness of the cat, and adjusts \\nthe model’s trainable parameters for a more accurate rating next \\ntime— much like a human learns by strengthening the connec-\\ntions between neurons in the brain. Figure\\xa01.2 and Figure\\xa01.3 \\nillustrate training and prediction, respectively.\\nThroughout the training process, the model needs to make \\nsure training goes in the right direction— the validation step. In \\nvalidation, the model checks the progress of the training against \\nseparate validation data. As an analogy, when we acquire a skill \\nlike solving mathematical problems, it makes sense to test it in \\ndedicated math exams.\\nAfter training has been successfully completed and respective \\naccuracy goals have been reached, the model enters the predic-\\ntion or evaluation mode. The trainable parameters are not being \\nadjusted anymore, and the model is ready to rate all the cats in \\nthe world.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 17, 'page_label': '4'}, page_content='4 GENERATIVE AI\\nIt is typical for a model in production mode that the accuracy \\ngets worse over time. The reason for this could be that the real- \\nworld data changed. Maybe we are only looking at kittens and \\nthey are all cute compared to our training data. Retraining the \\nmodel, whenever accuracy decreases or by scheduling retraining \\nperiodically, tackles the problem of a discrepancy between the \\ndata distribution of training data and evaluation data.\\nPerhaps you have a sense already that training AI models \\nrequires much more computing power than they need in  \\nprediction mode. T o adjust its trainable parameters, often referred \\nto as weights, we need to calculate the grade of adjustment care-\\nfully. This happens through a famous model function called \\nAI Model in Prediction\\nAI Model\\nImage Cute = 5\\nFIGURE\\xa01.3 Prediction mode in a supervised ML model.\\nImage1\\nAI Model in Training (2 Steps)\\nAI Model - Training prediction, get error\\nLabel\\nAI Model - Use error to update weights (Bach propagation)\\nError\\nCute = 5 Cute = 5\\nCute = 4\\nError\\n2\\nFIGURE\\xa01.2 In supervised training of a ML model, two main steps are \\ninvolved: predict the training data point, then update the trainable \\nparameters meaningfully based on the prediction’s accuracy.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 18, 'page_label': '5'}, page_content='AI in a Nutshell 5\\nbackpropagation. It entails the backward propagation of prediction \\nerrors— the learning from making mistakes in the training pro-\\ncess. The errors are turned back to respective weights for improve-\\nment. This means that we go forward to predict a data point and \\nbackward to adjust the weights. In prediction mode, however, we \\ndon’t adjust the weights anymore, but just go forward and predict. \\nThe function that has been trained through the training data is \\nbeing applied, which is comparatively cheap.\\nUnsupervised Learning\\nWhen ML models reach a certain complexity by having many \\ncomputing stages, called layers, we enter the realm of deep learn-\\ning (DL). Most of the cutting- edge applications are at least  \\npartially drawing their algorithms from DL. Algorithms are step- \\nby- step instructions for solving problems or performing tasks.\\nThe preceding example of rating the cuteness of a cat was \\nsimplified drastically and didn’t tell the whole story. A relevant \\naddition to this is that as we train on labeled cat pictures, with \\nthe label being the cuteness of the cats, we call this supervised \\nmachine learning. With labels, we provide guidance or feedback \\nto the learning process in a supervised fashion.\\nThe counterpart for supervised ML is called unsupervised \\nmachine learning. The main difference between them is that in \\nunsupervised ML the training data is not labeled. The algorithms \\nought to find patterns in the data by themselves.\\nFor example, imagine you have a dataset of customer pur -\\nchases at a grocery store, with information about the type of \\nproduct, the price, and the time of day. In AI these attributes are \\ncalled features. Y ou could use an unsupervised clustering algo-\\nrithm to group similar purchases together based on these fea-\\ntures. This could help the store better understand customer \\nbuying habits and preferences. The algorithm might identify'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 19, 'page_label': '6'}, page_content='6 GENERATIVE AI\\nthat some customers tend to buy a lot of fresh produce and dairy \\nproducts together, whereas others tend to purchase more pro-\\ncessed foods and snacks. This information could be used to cre-\\nate targeted marketing campaigns or to optimize store layout \\nand product placement.\\nComparing the performance of unsupervised learning appli-\\ncations to that of supervised learning applications is akin to con-\\ntrasting boats with cars— they represent distinct methodologies \\nfor addressing fundamentally diverse problems. Nevertheless, \\nthere are several reasons why we reached success years faster \\nwith supervised than with unsupervised learning methods.\\nIn supervised learning, the model is given a training dataset \\nthat already includes correct answers through labels. Under -\\nstandably, this helpful information supports model learning. It \\nalso accurately outlines the AI model’s intended objective. The \\nmodel knows precisely what it is trying to achieve. Evaluating \\nthe model’s performance is simpler than it is in unsupervised \\nmachine learning, as accuracy and other metrics can be easily \\ncalculated. These metrics help in understanding how well the \\nmodel is performing.\\nWith this information, a variety of actions can be taken to \\nenhance the model’s learning process and ultimately improve its \\nperformance in achieving the desired outcomes.\\nUnsupervised models face the challenge of identifying data \\npatterns autonomously, which is often due to the absence of \\napparent patterns or a multitude of ways to group available data.\\nGenerative AI a Decade Later\\nGenerative AI predominantly employs unsupervised learning. \\nCrafting complex images, sounds, or texts that resemble reason-\\nable outputs, like an adorable cat, is a challenging task compared \\nto evaluating existing options. This is primarily due to the \\nabsence of explicit labels or instructions.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 20, 'page_label': '7'}, page_content='AI in a Nutshell 7\\nT wo main reasons explain why generative AI is taking off \\nroughly a decade after discriminative AI. First, generative AI is \\nmostly based on unsupervised learning, which is inherently more \\nchallenging. Second, generating intricate outputs in a coherent \\nmanner is much more complex than simply choosing between \\nalternatives. As a result, generative AI’s development has been \\nslower, but its potential applications are now visible.\\nBetween supervised and unsupervised learning, there are \\nplenty of hybrid approaches. We could go arbitrarily deep into \\nthe knick- knacks of these ML approaches, but because we want \\nto focus on generative AI, it is better to leave it at that. If you \\nwant to dive deeper into the technicalities, I recommend the \\nbook Deep Learning (Adaptive Computation and Machine Learn-\\ning series), by Ian Goodfellow, Y oshua Bengio, and Aaron Cour-\\nville (MIT Press, 2016), which covers ML and DL in great detail, \\nlaying the theoretical generative AI foundation. It is regarded as \\nthe best book in the space, which isn’t surprising, given the \\nauthors. I will come back to those gentlemen later.\\nThe AI landscape is vast and ever- expanding. In this book, I \\nstrike a balance between simplifying concepts for clarity and \\nproviding sufficient detail to capture the essence of recent AI \\nadvancements. T o understand what generative AI is and its value \\nproposition, we first have to understand the traditional part of \\nAI, called discriminative AI.\\nWhat Is Discriminative AI?\\nDiscriminative AI models made headlines long before large lan-\\nguage models (LLMs) like ChatGPT by OpenAI and image gen-\\neration models like stable diffusion by Stability AI entered the \\nstage. Since the term “artificial intelligence” was coined by John \\nMcCarthy in 1955, discriminative models have yielded great \\nresults, especially in the past 15 years.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 21, 'page_label': '8'}, page_content='8 GENERATIVE AI\\nDiscriminative AI focuses on algorithms that learn to tell \\napart different data classes. They recognize patterns and features \\nunique to each class, aiming to link input features with labels for \\nthe output. This way, they can effectively classify instances into \\npredefined groups, making it easier to distinguish one class from \\nanother. Discriminative AI has found numerous applications in \\nvarious domains, including NLP , recommendations, and com-\\nputer vision.\\nIn the field of NLP , discriminative AI is used to classify text \\ndata into different categories, such as sentiment analysis or topic \\nclassification. In the domain of recommendations, discriminative \\nAI is used to predict user preferences and make personalized \\nproduct recommendations. In computer vision, discriminative \\nAI is used to recognize objects and classify images based on their \\ncontent. The applications of discriminative AI are vast and \\ndiverse, and its impact on various industries is immense.\\nLooking at existing applications, discriminative AI generally \\nhas five main tasks: classification, regression, clustering, dimen-\\nsionality reduction, and reinforcement learning. They are not \\ncrucial to be able to follow the book’s thread, but it helps to \\nunderstand them conceptually because then the term “discrimi-\\nnative” and what it means in the context of AI becomes apparent. \\nPut simply, in one way or another, this part of AI is deciding, \\nselecting, distinguishing, or differentiating on data or a prob-\\nlem at hand.\\nClassification\\nThe objective of classification is to accurately predict the class of \\nnew inputs based on prior training with labeled examples  \\n(Figure\\xa0 1.4). This supervised learning process uses training \\nexamples accompanied by their respective class labels.\\nFor instance, consider unlocking your phone with facial rec-\\nognition. Y ou initially show your face from various angles,'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 22, 'page_label': '9'}, page_content='AI in a Nutshell 9\\nallowing the classifier model to learn your appearance. Advanced \\nface recognition systems, like the iPhone’s FaceID, quickly iden-\\ntify you due to their extensive pretraining and incorporation of \\nbiometric information to deterministically classify users. In \\nessence, the model or system of models assesses your face and \\ndiscriminates whether you belong to the “person with access \\nrights” or “person without access rights” class.\\nClassification has driven breakthroughs in diverse applica-\\ntions, including image classification, sentiment analysis, disease \\ndiagnosis, and spam filtering. These applications typically involve \\nmultiple processing steps and rely on deep learning techniques.\\nRegression\\nA regression model in AI is designed to predict numerical values \\nfor new inputs based on data it has learned from a given problem. \\nIn this case, the output is not a class label but a continuous value. \\nFor example, imagine you want to buy a 100- square- meter apart-\\nment with a balcony in Munich, Germany. A real estate agent pre-\\nsents three similar apartments, priced at 2\\xa0million, 2.5\\xa0million, and \\n2.7\\xa0million euros.\\nY ou have three options: the naive approach, where you \\nassume these three properties represent the market; the informed \\napproach, where you estimate market prices by researching mul-\\ntiple offers; or the data science approach, which involves build-\\ning a machine learning model to determine a fair price by \\nAI Model\\nImage\\nAccess\\nNo access\\nFIGURE\\xa01.4 In ML, the concept of classification involves assigning data \\nto one of a finite set of categories.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 23, 'page_label': '10'}, page_content='10 GENERATIVE AI\\nanalyzing all available properties in the market with their \\nprice tags.\\nA well- trained regression model will give you a market- based \\nand rational price, as it takes into account all the characteristics \\nof apartments in the market (Figure\\xa0 1.5), helping you make a \\nmore informed decision. By recommending a price, the model \\ninherently has a discriminative nature.\\nClustering\\nAs the name suggests, this application field in AI clusters data \\npoints. Be they people, groceries, or songs, based on a similarity \\nmeasure, these items are grouped. By the way, you are being clus-\\ntered all the time. For example, Internet ads are targeted to your \\ndigital persona, including your sex, age, IP address (which repre-\\nsents your location), and all other data ad- providing companies \\nhave collected about you. T o cement it, if you use a web page that \\nrecommends songs like Spotify, movies like Netflix, and prod-\\nucts like Amazon to you, then you have been clustered. In the \\nsuccess of big tech companies like those mentioned previously, \\nclustering algorithms have played a crucial role, as they are the \\nbackbone of every recommendation engine.\\nHouse\\nBalcony\\n67 m2\\n...\\nPrice\\nAI Model\\nHouse Instances\\n2 Million\\nLearnt Regression\\nm2\\nBalcony yes/no\\n67\\n1 Million\\nFIGURE\\xa01.5 In regression, data like house details go into the ML model, \\nwhich then predicts its price based on these features.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 24, 'page_label': '11'}, page_content='AI in a Nutshell 11\\nIn clustering tasks, the data comes without labels. For \\ninstance, there are no labels on our heads indicating “prefers Ben \\n& Jerry’s Chubby Hubby.” Clustering models must identify pat-\\nterns and groups autonomously, making it an unsupervised learn-\\ning task. Moreover, the process of assigning items or personas to \\nclusters is a decision- making aspect of discriminative AI.  \\nFigure\\xa0 1.6 illustrates the conceptual operation of a clustering \\nmodel. By analyzing other people’s behavior, it infers that indi-\\nviduals who purchase butter and milk might also prefer cereals. \\nAdding soda to the mix increases the likelihood of a preference \\nfor Ben & Jerry’s Chubby Hubby.\\nDimensionality Reduction\\nDimensionality reduction is not an application field of AI that is \\ndiscussed much in mainstream media. It is rather research- heavy \\nand often a means to achieve something greater, more efficiently.\\nIts primary purpose is to reduce low-information data, mainly \\nmaking machine learning applications as effective as possible. By \\n“low- information data,” I mean data that contains little to no \\nmeaningful insights to solve a problem. See Figure\\xa0 1.7 for a  \\nvisual representation.\\nShopping List:\\n- Milk\\n- Butter\\n- Flour\\nButter\\nAI Model\\nRecommend\\nB & J Chubby\\nHubby\\nMilk\\nOther groceries\\nLikes pizza\\nLikes cereals\\nLikes Ben & Jerry’s\\nChubby Hubby\\nFIGURE\\xa01.6 Clustering model identifying buying patterns'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 25, 'page_label': '12'}, page_content='12 GENERATIVE AI\\nImagine that you have an extensive recipe book with hun-\\ndreds of recipes. Each recipe has several ingredients, and some of \\nthem are similar. For example, many recipes might call for salt, \\npepper, and olive oil. If you were to list all the ingredients used \\nin the book, it would be a long list with many similar items.\\nNow imagine that you want to make a simpler version of the \\nrecipe book that is easy to use on a daily basis. One way to do this \\nis to group similar ingredients. For example, you could create a \\ncategory called “seasonings” that includes salt, pepper, and other \\nspices used in the recipes. Y ou could also create a category called \\n“cooking oils” that contains olive oil, vegetable oil, and so forth.\\nIn the world of data science, the same thing happens. We \\nmight have a large dataset with many different features, and we \\nwant to simplify it to make it easier to work with. Dimensionality \\nreduction techniques help us to do this by finding a way to rep-\\nresent the data with fewer features while still preserving essential \\ninformation. They make it easier to analyze data, build models, \\nor visualize data more understandably.\\nNaturally, the data is not labeled, and we don’t know up \\nfront which features carry relevant information. In an unsuper -\\nvised manner, the models must learn to distinguish what low-  \\ninformation data can be modified or truncated and how. The \\nmodels must decide or discriminate, indicating that we are in \\ndiscriminative AI.\\nDataset\\nMany features\\nAI Model\\nDataset\\nFew features\\nX\\nY\\nZ\\nY\\nY\\nX\\nZ\\nFIGURE\\xa01.7 Dimensionality reduction'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 26, 'page_label': '13'}, page_content='AI in a Nutshell 13\\nReinforcement Learning\\nReinforcement learning (RL) models, typically called agents, \\nlearn from positive or negative consequences that their actions \\nyield in real- world or virtual environments. A positive conse-\\nquence is a reward, and a negative consequence is a punishment. \\nIn Figure\\xa01.8, the agent executes an action in a virtual/physical \\nenvironment, altering the environment (even if minimally), and \\nreceives a reward or penalty based on its stated goal. During the \\ntraining phase of the RL model, initial emphasis is on explora-\\ntion to identify available paths (e.g., for warehouse navigation), \\ngradually shifting to an exploitation phase for efficient goal \\nachievement (or technically, maximizing rewards), as indicated in \\nFigure\\xa01.9.\\nVirtual environments encompass a wide range of applica-\\ntions, from simulations for practicing real- world maneuvers to \\ngaming experiences, and even stock market environments for \\ntrading agents. In gaming, AI has demonstrated remarkable \\nsuper- human abilities, excelling in games such as Super Mario. \\nWhen an RL agent acts in a real- world environment, it is prob-\\nably a robot in a warehouse or Boston Dynamics’s Atlas perform-\\ning ninja moves. The agents acquire the ability to determine the \\noptimal action in a given situation, positioning them as a compo-\\nnent of discriminative AI.\\nAgent\\nAction\\nNew state of environment\\nReward/\\npunishment\\nVirtual/\\nphysical\\nenvironment\\nFIGURE\\xa01.8 Technical workings of reinforcement learning models'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 27, 'page_label': '14'}, page_content='14 GENERATIVE AI\\nReinforcement learning has many exciting aspects, one of \\nwhich is forming great synergies with generative AI. It was of lit-\\ntle public interest for decades until its turning point in 2016, \\nwhen AlphaGo by Google’s DeepMind won a series of Go \\nmatches against the former world champion Lee Sedol. Go is a \\ncomplex Chinese board game with a 19×19 grid, and thus it has \\n10^172 possible moves. For comparison, there are 10^82 atoms \\nin the universe. RL not only plays complex games exceptionally \\nwell but also delivers on a variety of tasks, ranging from autono-\\nmous vehicles to energy management in buildings. More on the \\npowerful collaboration between RL and generative AI later.\\nAdditionally, RL is helping to advance our understanding of \\nthe learning process itself, leading to new insights into how intel-\\nligence works and how it can be developed and applied.\\nWhat Is Generative AI?\\nSo far we have talked about discriminative AI, which can decide, \\ndistinguish, or discriminate between different options or con-\\ntinuous values.\\nGenerative AI, however, is fundamentally different. It has the \\nability to generate all kinds of data and content. By learning the \\npatterns and characteristics of given datasets, generative AI \\nLearn First\\nData Collection/Sample Learning\\nExplore/Learn Exploit/Earn\\nTime\\nFIGURE\\xa01.9 Exploration versus exploitation in RL training over time'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 28, 'page_label': '15'}, page_content='AI in a Nutshell 15\\nmodels can create new data samples that are similar to the \\noriginal data.\\nRecent advancements, such as the mind- blowing creations of \\nMidjourney’s image generation, the steps of video generation \\nlike Meta’s Make- A- Video, and the conversational abilities of \\nChatGPT , have completely altered the way we view AI. It is a \\nfascinating field that revolutionizes the way we create products \\nand interact with data.\\nGenerally speaking, generative AI models can perform three \\ntasks, each with a unique and exciting set of applications.\\nData Generation\\nFirst, and it is the most obvious one, that they can generate all \\nkinds of data, including images, videos, 3D objects, music, voice, \\nother types of audio, and also text—like book summaries, poems, \\nand movie scripts. By learning the patterns and characteristics of \\ngiven data, generative AI models can create new data samples \\nthat are similar in style and content to the original.\\nData Transformation\\nThe second task of generative AI is to perform data transforma-\\ntions. This means transforming existing data samples to create \\nnew variations of them. T ransformations can reveal new insights \\nand create appealing outputs for various applications. For exam-\\nple, you can transform winter pictures into summer pictures or \\nday pictures into night pictures. T ranslating an image from one \\ndomain (for example, summer) into another (winter) is called a \\ndomain transfer. Image style transformation involves taking an \\nimage, such as a photograph of your garden, and maintaining the \\ncontent (i.e., the garden) while altering its appearance to resem-\\nble the artistic style of, say, Monet’s paintings. This process,'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 29, 'page_label': '16'}, page_content='16 GENERATIVE AI\\nknown as style transfer, is not limited to visual content like photos \\nand videos but can also be applied to other data types like music, \\ntext, speech, and more. The essence of style transfer lies in pre-\\nserving the original content while imbuing it with a distinct and \\nrecognizable, often artistic, flair.\\nStyle transfer is more than just a delightful tool; it possesses \\nthe potential to significantly improve datasets for broader appli-\\ncations. For example, researchers from Korea and Switzerland \\nhave independently investigated the use of style transfer tech-\\nniques to augment the segmentation of cancer cells in medical \\nimages using machine learning. This method, dubbed contextual \\nstyle transfer, relies on the seamless integration of style- transferred \\ninstances within the overall image, ensuring a smooth and cohe-\\nsive appearance— something that generative adversarial net-\\nworks (GANs) are able to perform. In a fascinating study, Nvidia \\nshowcased a remarkable improvement in segmentation perfor -\\nmance by incorporating synthetic data into the training set. This \\nintegration led to a leap from 64 percent to 82 percent in accu-\\nracy simply by augmenting the dataset, without modifying the \\nmachine learning pipeline in any way.\\nData Enrichment\\nAs already indicated with style transfer, the third task of genera-\\ntive AI is to enrich datasets to improve machine learning models \\nultimately. This involves generating new data samples similar to \\nthe original dataset to increase its size and diversity. By doing so, \\ngenerative AI can help to improve the accuracy and robustness of \\nmachine learning models.\\nImagine we want to build a computer vision model that uses \\nML techniques to classify whether rare cancer cells are benign or \\nmalignant. As we are looking at a rare cancer type, it will be a \\nsmall dataset to train on. In real- world scenarios, privacy issues \\nare another data- diminishing factor. However, our neural net is'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 30, 'page_label': '17'}, page_content='AI in a Nutshell 17\\ndata- hungry and we can’t get the most out of its power, landing \\nat 64 percent classification accuracy. Through generative AI, rare \\ncancer images can be generated to create a larger and more \\ndiverse training dataset for improved detection performance.\\nOverall, the capabilities of generative AI are truly remarka-\\nble, and the potential applications are vast and varied. AI limits \\nare being pushed every day, not only by research but also by for- \\nprofit companies. This is especially true of generative AI.\\nIf we zoom out further, we see that the overall concept of \\ngenerative AI is even simpler. Models generate data based on \\nsome input. The complexity of the input can vary a lot. It could \\nrange from simple tasks, such as transforming a single digit like \\n6\\xa0into a handwritten image, to complex endeavors like applying \\ndomain transformations to a video.\\nUnder the\\xa0Radar No More: Picking Up\\xa0Speed\\nWhat we often observe, especially in AI, is that a new tech \\napproach has early roots, but has been in stealth mode for a cou-\\nple of decades. Once sufficient advancements transpire in a \\nrelated tech domain, the dormant technology awakens, deliver -\\ning substantial value in real- world applications. This is recog-\\nnized as technological convergence.\\nDeep Learning Tech Convergence with GPUs The advent \\nof deep learning, the underlying technology propelling fields \\nsuch as computer vision and robotics, traces its roots back to \\n1967, when the first neural network, the multilayer perceptron, \\nwas conceived and introduced by two prominent Soviet scien-\\ntists, Ivakhnenko and Lapa.1 For numerous decades deep learn-\\ning struggled to yield tangible business value and real- world \\n1A. G. Ivakhnenko and Valentin Grigor’evich Lapa,\\xa0 Cybernetics and Forecasting T echniques, American Elsevier \\nPublishing Company, 1967.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 31, 'page_label': '18'}, page_content='18 GENERATIVE AI\\napplications. However, a transformative moment arrived with \\nthe emergence of graphics processing units (GPUs) at the onset \\nof the 21st century.\\nGPUs first became popular in the gaming industry. In the \\nlate 1990s and early 2000s, video games became increasingly \\ncomplex and required more processing power to render high- \\nquality graphics and animations.\\nIn the 1990s, GPUs were initially developed with the pri-\\nmary aim of providing specialized processing for intricate 3D \\ngraphics and rendering in video games and other computer \\napplications. Firms such as 3DFX, ATI, and Nvidia spearheaded \\nthese advancements. The early 2000s witnessed another signifi-\\ncant development for GPUs: the introduction of parallel pro-\\ncessing, enabling multiple calculations to be executed \\nsimultaneously.\\nThis ability to compute large amounts of data breathed new \\nlife into deep learning, allowing it to gain traction and experi-\\nence a surge in research popularity. Leveraging GPUs’ enhanced \\ncapabilities, researchers and practitioners accelerated deep learn-\\ning’s potential, sparking a multitude of practical applications. \\nT oday, it’s unimaginable to train a robust machine learning or \\ndeep learning model without the assistance of GPUs.\\nDeep learning has reaped the benefits of other advancements \\nas well. The Internet’s growth and technological innovations \\nprovided abundant data for training models, while committed \\nresearchers and research, in general, led to numerous break-\\nthroughs in deep neural networks. This progress extends from \\nconvolutional neural networks achieving remarkable feats in \\nimage recognition to recurrent neural networks demonstrating \\nadvanced NLP capabilities. It’s not just the researchers who are \\npassionate about the subject; capital allocators and profit- driven \\ncompanies have also invested heavily in the field.\\nIncidentally, it’s worth mentioning that we are now seeing, \\nand will likely keep seeing, a similar rise in interest in generative'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 32, 'page_label': '19'}, page_content='AI in a Nutshell 19\\nAI. The growth of other areas, especially discriminative AI and \\ncomputational power, along with the increasing amount of data, \\nwere crucial for generative models to evolve in the background.\\nT oday, we see billions being invested in generative AI pro-\\njects aimed at tackling a wide range of business and non- business \\napplications, as long as people can imagine it. This growing focus \\non generative AI promises to bring even more transformative \\nadvancements in the near future, building on the foundation \\nestablished by previous AI breakthroughs.\\nIn today’s attention economy, capturing the focus of individ-\\nuals has become increasingly challenging, as attention itself is a \\nscarce and valuable resource. The widespread adoption of the \\nInternet, social media, and other digital technologies has led to \\nan overwhelming influx of information and stimuli, all compet-\\ning for our limited attention. Consequently, only groundbreak-\\ning technologies can truly stand out and capture the spotlight. \\nFor a long time, generative AI remained relatively obscure in this \\ncompetitive landscape. However, recent advances and remarka-\\nble achievements have now propelled generative AI into promi-\\nnence, showcasing its immense potential and securing its place at \\nthe forefront of technological innovation.\\nGenerative AI’s Early Impact Generative AI is still quite new, \\nbut its future effects are expected to be amazing, going beyond \\nwhat we’ve seen so far. Its influence can be noticed in many areas, \\nbut it has mainly made a difference in three sectors: creative \\nindustries, gaming, and natural language processing.\\nCreative Industries Generative AI has made a lasting impact on \\ncreative fields like art. This technology enables artists to create \\nunique and inventive digital artworks. By studying patterns and \\nstyles in existing art, music, and fashion, AI algorithms can pro-\\nduce new content that matches market trends and engages'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 33, 'page_label': '20'}, page_content='20 GENERATIVE AI\\naudiences. In the world of music, these algorithms can generate \\noriginal tracks or remix current ones, opening up fresh possibili-\\nties for both producers and artists.\\nThe integration of generative AI has led to new business \\nmodels in the creative industry, such as selling exclusive digital \\nart or creating customized products using AI- generated designs. \\nThis growth has occurred alongside a technological convergence \\nbetween AI and the rapidly expanding cryptocurrency landscape.\\nIn the last eight years, the cryptocurrency world has seen \\nincredible progress, with numerous coins quickly making some \\npeople wealthy and leaving others financially devastated. Decen-\\ntralized finance and institutional adoption have drawn significant \\ninterest. However, the most far- reaching impact may come from \\nnon- fungible tokens (NFT s).\\nNFT s allow artists and creators to produce unique, verifiable \\ndigital assets, leading to a growing demand for imaginative, high- \\nquality AI- generated art. While not the sole driving force behind \\nadvancements in image generation, the NFT market has undeni-\\nably accelerated progress in this area.\\nGaming Industry The gaming industry has experienced a sig-\\nnificant transformation due to generative AI, which has opened \\nup possibilities for a variety of new game content, such as levels, \\ncharacters, 3D objects, scenarios, and even entire quests. A nota-\\nble example is Microsoft’s Flight Simulator, which partnered \\nwith Blackshark.ai to generate a photorealistic, three- dimensional \\nworld from two- dimensional satellite images, covering the \\nwhole Earth.\\nThe popularity of open- world concepts in gaming has \\nencouraged many companies to adopt AI- generated content. \\nImagine AI algorithms that study player behavior and dynami-\\ncally modify game difficulty or generate new content on the spot,'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 34, 'page_label': '21'}, page_content='AI in a Nutshell 21\\nleading to personalized and engaging gaming experiences. Con-\\nsider the potential of giving non- player characters (NPCs) AI- \\ndriven language models for more captivating and immersive \\ninteractions. These advancements could make returning to the \\nreal world a challenge.\\nBy using generative AI to create in- game items and environ-\\nments more efficiently, gaming companies can allocate more \\ntime and resources to concentrate on core aspects, ensuring the \\nproduction of intriguing and original content. The future of \\ngaming, fueled by generative AI, is set to be an exciting and \\nimmersive adventure for players.\\nNatural Language Processing The third impact vertical is not a \\nsingle industry per se but rather many industries.\\nGenerative AI can be used to generate new content such as \\ntext, summaries, or translations. Large language models are at \\nthe forefront of generative AI applications, with widespread \\nimpacts across various industries. LLMs can improve operational \\nefficiencies by automating repetitive internal processes and \\naccelerating innovation through customer feedback analysis, \\ninsights, and market research. These models can also improve \\ncustomer experiences with concise answers and summaries avail-\\nable 24/7. The potential for managing knowledge is perhaps one \\nof the most significant aspects of AI systems; organizations with \\nspecialized knowledge can offer their expertise in a tailored and \\nconcise manner to end users. T ake the Mayo Clinic, for instance. \\nSpecializing in patient care, research, and education, the Mayo \\nClinic has amassed a wealth of data on medical conditions and \\ntreatments, such as patient records, research studies, and medical \\nimaging data. They could create chatbots and virtual assistants \\nthat harness this data to provide expert guidance and advice to \\npatients. By integrating these AI- driven tools into the Mayo'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 35, 'page_label': '22'}, page_content='22 GENERATIVE AI\\nClinic’s website or mobile app, patients could access expert med-\\nical advice from anywhere around the globe.\\nLanguage models don’t just generate language, but also code, \\nmusic, poetry, stories, jokes, captions, summaries, translations, \\nrecommendations, and much more. The fields will further \\nbroaden, with LLMs providing innovative solutions for busi-\\nnesses and society.\\nGenerative AI is immensely exciting as it will undoubtedly \\nrevolutionize how we create, consume, and process content \\nacross all aspects of our lives. As the technology develops, we can \\nexpect further paradigm shifts, leading to groundbreaking \\nadvancements in industries worldwide.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 36, 'page_label': '23'}, page_content='23\\nT\\nhe present and future of generative AI are significantly more \\nexhilarating than the developments of previous decades. As \\nwe consider the key milestones in AI’s evolution, we’ll highlight \\nthe features that have informed modern advancements in the \\nfield. Pioneering approaches have been crucial for the high-quality  \\ndata generation we witness today, leading to a paradigm shift in \\nartificial intelligence. This shift has transformed the way we pro-\\nduce and consume content and, consequently, the way humanity \\nprogresses.\\n2\\nCHAPTER\\nInnovative Approaches \\nfor\\xa0High-Quality Data \\nGeneration'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 37, 'page_label': '24'}, page_content='24 GENERATIVE AI\\nWhy Generative Models?\\nWhat makes generative models so special? How do they differ \\nfrom others? T o fairly answer these questions, we must ultimately \\ndelve into the innovative thought processes behind their crea-\\ntion. While avoiding overly technical details, we’ll examine how \\ndevelopers thought outside the box to devise sophisticated, intel-\\nligent, and novel methods for generating data from scratch.\\nExplaining generative model concepts can quickly become \\ntoo scientific and perplexing. However, their fundamental idea is \\nrelatively simple to grasp. Consider an example of handwritten \\ndigits from the renowned MNIST (Modified National Institute \\nof Standards and T echnology) dataset. A discriminative model’s \\ntask might be to discern if an image of a handwritten digit is 0, 1, \\n2, 3, 4, 5, 6, 7, 8, or 9. For simplicity, let’s focus only on 0s and 1s. \\nConceptually, a discriminative model seeks to differentiate digits \\nby constructing a boundary in the data space. (Imagine the data \\nspace as a canvas where each data point represents a digit, and \\nthe boundary is like an invisible line that divides the different \\ncategories.) This boundary, representing the decision-making \\nprocess of the discriminative AI model, separates the 0s and 1s.\\nIf the model accurately establishes this boundary, it can dis-\\ntinguish the digits without explicitly identifying the exact loca-\\ntions of instances in the data space. In this context, achieving a \\nreasonably accurate separation between categories might be suf-\\nficient for the model to perform its classification task effectively.\\nDiscriminative models look at where 0s and 1s are located  \\nin the data space and use this information to find the best way  \\nto separate them. The term conditional probability refers to the \\nlikelihood of an instance being a 0 or 1 based on its features. By \\nunderstanding these probabilities, the models can tell apart  \\nnew instances, distinguishing between 0s and 1s, as shown in \\nFigure\\xa02.1.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 38, 'page_label': '25'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 25\\nIn contrast, generative models study the training data. As \\nthey train on the data, they see what the data looks like and how \\nits features are distributed. They then try to generate data— 1s \\nand 0s, in this case as shown in Figure\\xa02.2— that fall close to the \\nreal counterparts in the data space. Concrete, a generator model, \\nwould generate 1s that look similar to other 1s in the training \\ndata, and 0s that look similar to the 0s in the training data. This \\nis what in the literature is meant by “modeling the distribution \\nthroughout the data space.”\\nAgain, from this point of view it is not sufficient to roughly \\nunderstand the data to replicate it; it must be understood precisely. \\n• Discriminative Model\\nx p(y|x)\\n1\\n/\\n0\\n0 y = 0\\ny = 1\\nFIGURE\\xa02.1 Representation of a discriminative model, showing how it \\ndistinguishes between two classes (y = 0 and y = 1) given input exam-\\nples, choosing between the two options based on what model (the \\ndotted line) has been trained on.\\n• Generative Model\\nx p(x, y)\\ny = 0\\ny = 1\\n1\\n/\\n0\\n0\\nFIGURE\\xa0 2.2 Representation of a generative model, highlighting the \\njoint probabilities p(x, y). Data samples are drawn based on input fea-\\ntures: 1s are sourced from the joint probability distribution, whereas \\n0s stem from their specific probability within this specific model.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 39, 'page_label': '26'}, page_content='26 GENERATIVE AI\\nGiven the training data distribution, the models have to learn how \\nto connect the output data distribution to it— jointly. They cap-\\nture the joint probability, which makes them probabilistic. Their \\noutput is typically happening based on the probability of the pos-\\nsible outputs. And this is how you generate new data.\\nThe underlying concept is basically that simple idea, and it is \\nremarkable how good the different models have become. The \\noutput quality has jumped significantly because they are succes-\\nsively getting better at mapping both distributions correctly. A \\nmuch-underestimated benefit of generative models is their abil-\\nity to cope with unlabeled data. They not only identify the under-\\nlying structure of the unlabeled data but can represent it. The \\nfirst step is already nontrivial, and conventional artificial intelli-\\ngence struggles with it.\\nThe potential of generative AI is incredibly exciting and is \\nbased on this simple technical idea of mapping input and output \\ndistributions. However, as simple as the idea is, the execution is \\nmuch harder. Research scientists, data scientists, and other very \\nsmart folks had to be creative in the process of developing these \\nalgorithms. From neural networks trying to fool each other, to \\niteratively adding noise and denoising images, to extended atten-\\ntion mechanisms, achieving breakthroughs goes hand in hand \\nwith breaking out from normal AI architectures. This is what has \\nenabled truly special AI models.\\nFrom Birth to\\xa0Maturity: Tracing the\\xa0 \\nDevelopment of\\xa0Generative Models\\nCurrently, we are at a point where a lot of the tech hasn’t been \\ndefined yet. However, some tech approaches have made a perma-\\nnent mark in the evolution of generative AI and AI as a whole. \\nThis section considers some of those approaches.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 40, 'page_label': '27'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 27\\nELIZA\\nIt is 1966. The Vietnam War intensified as the United States \\nlaunched Operation Rolling Thunder, a sustained bombing cam-\\npaign against North Vietnam, and the Chinese Cultural Revolu-\\ntion began, marking the start of a decade of political upheaval \\nand social unrest in China.\\nA small group of computer scientists is standing in the IT lab \\n2.3.5 at MIT in Boston, Massachusetts, where Associate Profes-\\nsor Dr. Joseph Weizenbaum is about to reveal something ground-\\nbreaking: a chatbot named ELIZA, designed to imitate a \\npsychotherapist’s conversational style (Figure\\xa02.3). The audience \\nis stunned. ELIZA analyzes human input and generates responses \\nthat seem like they’re coming from a real person. Weizenbaum \\nexplains how ELIZA ’s algorithm works: First it identifies pat-\\nterns, then generates a response using predefined templates and \\nrules. For example, if the input includes the word “mother,” \\nELIZA might respond with “T ell me more about your family.” \\nThe responses are usually in the form of a question or statement \\ndesigned to encourage further conversation.\\nAfter initial reservations, something extraordinary is happen-\\ning, as the scientists are opening up to this machine, sharing their \\ndeepest thoughts and emotions. ELIZA ’s ability to connect with \\npeople on a human level is simply astonishing. The demo ends \\nand ELIZA has opened the door to a new world of possibilities, \\nwhere machines and humans can communicate in ways never \\nthought possible.\\nCould machines one day communicate with humans in a nat-\\nural, conversational way? What kind of impact would this have \\non society?\\nIt is officially agreed that ELIZA is the first chatbot that prop-\\nerly imitates conversations. ELIZA wasn’t the first bot that \\nexisted, but the first with the ripple effect in research. The first'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 41, 'page_label': '28'}, page_content='28 GENERATIVE AI\\ntrials of bots date back to 1950. The field was too primitive to use \\nthe term chatbot, as there was no chat happening. 1950 was also \\nthe year Alan T uring proposed a test for describing machine intel-\\nligence. He titled his work “Computing Machinery and Intelli-\\ngence.” He wrote that if a machine can trick humans into thinking \\nit is human, then it has intelligence— the so-called Turing test. \\nT oday we have a much more refined idea of the T uring test, as we \\nare experiencing the performance of large language models \\n(LLMs) like ChatGPT . We see in detail what language models \\nare good at and where they lack skills, making it easy for us to \\nreveal them as nonhuman. Even though Alan T uring was decades \\nahead of his time, he wouldn’t have a way to imagine this. How-\\never, ELIZA was not good enough to pass the T uring test.\\nBy no means is Alan T uring an insignificant figure. Widely \\nregarded as the father of modern computing, T uring is best \\nknown for his work during World War II at Bletchley Park, the \\nFIGURE\\xa02.3 A conversation with the ELIZA chatbot.\\nSource: Wikimedia Commons / Public Domain'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 42, 'page_label': '29'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 29\\ncodebreaking center established to decipher German messages. \\nThere, he led a team of codebreakers who cracked the Nazi \\nEnigma code, an accomplishment believed to have shortened the \\nwar by several years. Indeed, his name graces the T uring Award, \\noften referred to as the Nobel Prize for computing.\\nThe year 1955\\xa0 marked another pivotal moment in the  \\nevolution of AI, as the term “artificial intelligence” was coined  \\nby another heavyweight computer scientist, John McCarthy.  \\nAn American computer scientist, McCarthy co-authored the \\ngroundbreaking document that introduced the term artificial \\nintelligence (AI) alongside Marvin Minsky, Nathaniel Rochester, \\nand Claude E. Shannon on August 31, 1955. McCarthy described \\na field of study centered on creating machines capable of execut-\\ning tasks typically requiring human intelligence, such as reason-\\ning, learning, and problem-solving. As a testament to his immense \\ncontributions to the theory and practice of AI and the develop-\\nment of the programming language Lisp, McCarthy was hon-\\nored with the T uring Award in 1971. Indeed, Lisp holds a special \\nplace in AI history as it was specifically designed to support sym-\\nbolic processing— a cornerstone concept in artificial intelligence.\\nSymbolic processing is when a program uses words, num-\\nbers, and other symbols to do things that generally require \\nhuman thinking. Just like how we use letters and numbers to \\nwrite words and sentences, computers use symbols to represent \\ninformation and then use special rules to do things with that \\ninformation.\\nLisp was widely used in the development of expert systems \\nand other AI applications, not only because of its symbolic pro-\\ncessing but also because it is a high-level programming language. \\nThis means it uses syntax that is closer to natural language, and \\noften includes features like variables, functions, and control \\nstructures that allow programmers to write complex programs \\nmore easily. For example, Python, Java, C++, and Ruby are'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 43, 'page_label': '30'}, page_content='30 GENERATIVE AI\\nhigh-level programming languages, whereas machine code and \\nassembly code are low-level. T rying to read it the first time is a \\nsure way into headache land.\\nIn the field of AI, there was a lot happening in the 1940s and \\n’50s. Another result of the momentum in AI research is the mul-\\ntilayer perceptron first implemented in 1957 by Frank Rosen-\\nblatt. Inspired by the human brain and built on top of McCulloch \\nand Pitts’s theoretical invention of the perceptron in 1943, the \\nmultilayer perceptron (MLP) paved the way for neural networks. \\nIt has one input layer, a few in layers, and an output layer of \\ninterconnected nodes called neurons. Each layer is a step that \\nprocesses the output of the previous layer to gradually build up a \\nmore complex representation of the input data. The MLP is \\ntrained in an iterative fashion via, for example, backpropagation, \\nwhich adjusts the weights and biases of the neurons to minimize \\nthe difference between the network’s output and the desired out-\\nput, as described in Chapter\\xa01, “AI in a Nutshell.”\\nSo far, all set for AI takeoff. However, winter was coming. An \\nAI winter to be precise. T o be even more precise, an AI ice age, as \\nit spanned the late 1970s and early 1980s. It was triggered by a \\ncombination of factors, including unrealistic expectations about \\nthe capabilities of AI systems, a lack of progress in the develop-\\nment of AI technologies, and a reduction in government funding \\nfor AI research. In addition, some AI researchers were skeptical \\nof the dominant approaches to AI at the time, resulting in no \\nconfidence, no developments, and no money.\\nAnd, as if this were not enough, there was a second AI winter \\nfollowing in the late 1980s and early 1990s, with no ground-\\nbreaking achievements in between the winters. Both AI winters \\nwere caused by a similar combination of factors; plus, there was \\na shift in research funding toward other areas, such as the Inter-\\nnet and biotechnology. In addition, there was a growing percep-\\ntion among some researchers that AI was overhyped and that'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 44, 'page_label': '31'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 31\\nprogress in AI was unlikely without significant breakthroughs in \\nareas such as natural language processing (NLP) and knowledge \\nrepresentation.\\nDuring this low point of AI, a then nameless research scien-\\ntist proposed a very interesting idea that carried a lot of weight \\nin the development of AI. The convolutional neural network \\n(CNN) was first proposed by Yann LeCun and his team in 1989. \\nTheir convolutional layers are conceptually scanning images and \\nmaking sense of them. Over multiple layers, they abstract detailed \\nimages. For example, the first convolution identifies straight \\nlines. In the second convolution, these lines can become curves. \\nIn the third convolution layer, curves become eyes, whereas other \\nlayers represent ears and a nose. In the final layer, based on all \\nthe facial features, the decision is clear. It’s a Chihuahua! LeCun \\nand his colleagues developed the first practical implementation \\nof CNNs, which was used for handwritten digit recognition and \\nachieved state-of-the-art performance on benchmark datasets. \\nAmong all deep learning architecture, CNNs has had probably \\nthe most industry impact since then. The vast majority of com-\\nputer vision (CV) applications are based on CNNs. Like the per-\\nceptron, CNNs  proved to be a crucial step in the evolution of AI \\nand generative AI later on.\\nBoltzmann\\xa0Machines\\nBack to generative AI. The first significant machine learning \\narchitecture, which is an important precursor to later models, \\nwas the Boltzmann machine, which was introduced in the 1980s \\nas a neural network that could learn and generate data from a \\nprobability distribution. For this, the data distribution needs to \\nbe stable, which means that there is a low degree of variability. \\nThis helps the Boltzmann machines to learn and represent'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 45, 'page_label': '32'}, page_content='32 GENERATIVE AI\\ncomplex patterns. If the data is unstable, the generated samples \\ngenerated by the Boltzmann machine are inaccurate or incon-\\nsistent, and the training is generally inefficient. The way a Boltz-\\nmann machine generates data is close to modern generative \\nAI models.\\nIn Boltzmann machines there are hidden, invisible neurons \\nthat take binary states, either at 1 or 0, “on” or “off   ” (Figure\\xa02.4). \\nT o generate a new data sample, the network is initialized with \\nrandom values for the visible units, and then a series of alternat-\\ning Gibbs sampling steps are performed. In Gibbs sampling, the \\nnodes in the Boltzmann machine are updated one at a time, while \\nkeeping the other nodes fixed. The probability of a node being \\n“on” or “off   ” is determined by the current state of the other \\nnodes in the network. This process is repeated many times, \\nresulting in a sample from the probability distribution of the \\nBoltzmann machine. By generating many such samples, the \\nmodel can learn the underlying distribution of the input data. \\nGibbs sampling is an iterative process that gradually improves \\nthe quality of the samples, allowing the model to converge on a \\nstable distribution. The final state of the visible units represents \\na new data sample that has been generated by the Boltzmann \\nmachine. This process can be repeated to generate multiple new \\nsamples from the learned probability distribution. Even though \\nBoltzmann machines have the capabilities to generate data, in \\nthe early days of these machines they were primarily used as a \\ntool for exploring the properties of complex systems, rather than \\nfor generating data.\\nThe standard Boltzmann machine was a blueprint for other \\nneural network architectures that have contributed to the evolu-\\ntion of modern generative AI. But before we shed light on that, \\nanother headline has dominated the news about AI for quite \\nsome time.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 46, 'page_label': '33'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 33\\nDeep Blue\\nIn 1997, the world watched in awe as a chess-playing computer \\nnamed Deep Blue (Figure\\xa02.5), created by IBM, faced off against \\nthe reigning world chess champion, Garry Kasparov (Figure\\xa02.6). \\nThis was the first time in history that a machine had challenged \\na human being at the game of chess on such a grand stage.\\nThere was much speculation as to whether a machine could \\never defeat a human being in a game as complex and strategic as \\nchess. Many believed that Kasparov, widely regarded as one of \\nthe greatest chess players of all time, would easily defeat Deep \\nBlue and prove once and for all that machines could never truly \\nrival human intelligence.\\nHowever, as the match progressed, it became clear that Deep \\nBlue was a formidable opponent. The computer, which had been \\nspecially programmed to play chess using advanced algorithms \\nand machine learning techniques, was able to analyze millions of \\nHidden Nodes\\nVisible Nodes\\nFIGURE\\xa02.4 Boltzmann machine concept'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 47, 'page_label': '34'}, page_content='34 GENERATIVE AI\\npossible moves per second and make decisions based on complex \\npatterns and strategies.\\nDespite his best efforts, Kasparov was unable to outmaneu-\\nver the machine, and in the end, Deep Blue emerged victorious. \\nThe result was a stunning upset, and it sent shockwaves through-\\nout the world of chess, artificial intelligence, and the world.\\nThe match between Deep Blue and Kasparov marked a turn-\\ning point in the history of AI, capturing the imagination of the \\nFIGURE\\xa02.5 Deep Blue, a computer similar to this one, defeated chess \\nworld champion\\xa0Garry Kasparov in May 1997.\\nSource: James the photographer / Wikimedia Commons / CC BY 2.0.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 48, 'page_label': '35'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 35\\nworld and sparking a new era of innovation and discovery. It was \\na moment that would be remembered for years to come, and it \\nlaid the foundation for a future in which machines and humans \\nwould continue to push the limits of what is possible.\\nEven though Deep Blue’s victory over Kasparov was per -\\nceived as an excellent case for AI that unlocked interest and fund-\\ning, I see it more as a case for computational power. The \\nunderlying machine learning algorithms of Deep Blue were not \\nrevolutionary; rather, it was Deep Blue’s power to process all \\npossible moves and choose the best. However, sometimes it’s not \\nabout technical truth, but perception.\\nRestricted Boltzmann Machines\\nIn 2006 Geoffrey Hinton and his team developed a variant of \\nBoltzmann machines as a solution to the problem of inefficient \\nFIGURE\\xa02.6 Garry Kasparov.\\nSource: S.M.S.I., Inc / Wikimedia Commons / CC BY-SA 3.0.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 49, 'page_label': '36'}, page_content='36 GENERATIVE AI\\ntraining— restricted Boltzmann machines (RBMs). RBMs restrict \\nthe connections between neurons to only occur between visible \\nneurons and hidden neurons (Figure\\xa02.7). Visible neurons repre-\\nsent the input data, whereas hidden neurons represent the fea-\\ntures that RBMs learn to represent the input data. This restriction \\nmakes RBMs computationally more efficient and easier to train. \\nOn a conceptual level, the Boltzmann machine and the restricted \\nBoltzmann machine aren’t significantly different. Nevertheless, \\nthere’s a gap of 24 years between their development. Back then, \\ndevising the restricted Boltzmann machine algorithm might not \\nhave been straightforward, and in reality, its intricacies run \\ndeeper than one might initially realize.\\nOnce the RBM is trained, it can be used for a variety of tasks \\nin discriminative AI and generative AI, such as classification, \\nregression, or generating new data samples.\\nSo, media attention has been captured, but on the algorithm \\nsite, there was still a lot to be done. While in the conventional \\npart of AI a lot of progress has happened, especially with neural \\nnetworks, generative AI hasn’t enjoy much attention.\\nThey were only a few research scientists who were popular -\\nizing and promoting generative models like Boltzmann machines \\nVisible units\\nHidden units\\nFIGURE\\xa02.7 Concept of restricted Boltzmann machines.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 50, 'page_label': '37'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 37\\nand others. Yann LeCun was one of them and Geoffrey Hinton \\nwas another.\\nLike LeCun, Hinton is regarded as one of the AI superstars. \\nIn 1978 he was awarded a PhD in AI. T oday he is a professor at \\nthe University of T oronto and a researcher at Google Brain. He \\nis considered to be one of the fathers of deep learning, as he \\ntogether with other colleagues developed the backpropagation \\nalgorithm for training neural networks. He won numerous \\nawards for his work before he also received the prestigious T uring \\nAward in 2018. On Yann LeCun’s fun stuff page, he shares some \\nGeoffrey Hinton facts. One of them: “Geoff Hinton goes directly \\nto third Bayes”— a nerdy joke that refers to Bayes’ theorem, a \\nmathematical formula that calculates the probability of an event \\nbased on prior knowledge or information. It took me three nights \\nuntil I laughed.\\nHinton had a huge interest in Boltzmann machines. How-\\never, Boltzmann machines have a problem known as the sign \\nproblem, which makes it difficult to perform efficient learning due \\nto the sign of the weights in the neural network that the machine \\nis made of. Updating the weights, which is the learning, includes \\nthe product of the weights of the neurons. This product can be \\npositive or negative, leading to cancellation effects that make the \\nlearning process slow and inefficient.\\nDeep Belief Networks\\nIn 2006, Geoffrey Hinton and his colleagues, building on the \\nadvancements of RBMs, introduced the concept of deep belief \\nnetworks (DBNs). They stacked multiple RBMs or other unsu-\\npervised learning models to create a more powerful and efficient \\narchitecture.\\nThe deep in DBNs comes from stacking multiple layers of \\nRBMs, with each layer learning a more abstract representation'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 51, 'page_label': '38'}, page_content='38 GENERATIVE AI\\nof the input data (Figure\\xa0 2.8). The training process of DBNs \\ntypically involves unsupervised pretraining using layer-wise \\ntraining, followed by supervised fine-tuning using backpropaga-\\ntion. This made DBNs effective in unsupervised feature extrac-\\ntion, as the layers learned to capture increasingly abstract features \\nfrom the input data. For example, when applied to image recog-\\nnition, DBNs could identify edges and textures in the lower lay-\\ners and more complex shapes and objects in the higher layers.\\nDBNs found applications in various fields such as image  \\nrecognition, NLP , and speech recognition. They marked a signifi-\\ncant difference from RBMs in that they learned hierarchical rep-\\nresentations with higher layers, capturing more abstract features, \\nwhereas RBMs only learned a single layer of features. Additionally, \\nDBNs employed backpropagation during the fine-tuning phase, \\nwhereas RBMs were solely unsupervised learning models.\\nInput\\nlayer\\nHidden\\nlayer 1\\nHidden\\nlayer 2\\nHidden\\nlayer 3\\nOutput\\nlayer\\nRBM 3\\nRBM 2\\nSource: Peltarion.com\\nRBM 1\\nFIGURE\\xa02.8 A deep belief network.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 52, 'page_label': '39'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 39\\nInterestingly, DBNs played a crucial role in the resurgence of \\ndeep learning research in the mid-2000s. They were among the \\nfirst models to demonstrate the effectiveness of unsupervised \\npretraining for deep architectures. The introduction of DBNs \\nsparked renewed interest in the field of deep learning, leading to \\na wave of innovation and groundbreaking discoveries. Speaking \\nto fellow data scientists, this seems to be forgotten.\\nDeep Boltzmann Machines\\nThe journey of generative AI took yet another significant turn in \\n2009\\xa0 when Ruslan Salakhutdinov and Geoffrey Hinton intro-\\nduced deep Boltzmann machines (DBMs). DBMs were another \\nleap forward in generative AI, as they further enhanced the capa-\\nbilities of generative models.\\nDBMs, similar to DBNs, are hierarchical generative models \\nmade up of multiple layers of unsupervised networks, allowing \\nthem to model complex, high-dimensional data. They’re created \\nby stacking multiple RBMs, with each layer learning an increas-\\ningly abstract representation of the input data.\\nT raining DBMs is done using a two-step process: layer-wise \\npretraining, which involves training each layer of RBMs indepen-\\ndently, followed by fine-tuning using methods like contrastive \\ndivergence or persistent contrastive divergence. Contrastive diver-\\ngence is an optimization algorithm that minimizes the difference \\nbetween the input data distribution and the distribution learned \\nby the model, while persistent contrastive divergence maintains a \\nset of persistent samples that are updated throughout the training \\nprocess, making it more efficient.\\nDBMs have found applications across various fields, such as \\nimage recognition, NLP , and speech recognition, thanks to their \\nability to model complex data structures and learn abstract  \\nfeatures.\\nIn terms of architecture, both DBMs and DBNs stack multi-\\nple RBMs, but DBMs have undirected connections between all'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 53, 'page_label': '40'}, page_content='40 GENERATIVE AI\\nlayers, whereas DBNs have directed connections between layers, \\nexcept for the top two layers, which have undirected connections.\\nThe generative process in DBMs and DBNs also differs. In \\nDBNs, the process is top-down, starting from the highest layer \\nand moving downward. For example, in image recognition, a \\nDBN might start with the high-level concept of an object and \\nwork its way down to the details. In contrast, DBMs sample from \\nthe joint probability distribution between visible and hidden \\nunits, allowing them to generate new data samples by taking into \\naccount the complex relationships between different features.\\nThe introduction of DBMs contributed to the growing inter-\\nest in the unsupervised learning and generative models that have \\ncontinued to shape the field of AI. This further highlights the \\nextraordinary impact of Hinton’s work and dedication to the \\nfield of AI, which has propelled generative models and deep \\nlearning to new heights.\\nAutoencoders\\nAs the field of AI continued to evolve, researchers explored new \\nand innovative ways to leverage the power of neural networks. \\nOne such development was the emergence of autoencoders \\n(AEs), a unique type of artificial neural network designed for \\nunsupervised learning tasks. Autoencoders caught the attention \\nof the AI community for their ability to learn efficient represen-\\ntations of data, as well as their potential to transform the land-\\nscape of generative AI.\\nThe structure of autoencoders consists of two main parts: an \\nencoder, which compresses input data into a lower-dimensional \\nlatent representation, and a decoder, which reconstructs the \\noriginal data from the latent representation (Figure\\xa0 2.9). For \\nexample, imagine an autoencoder trained to process images of \\nhandwritten digits. The encoder could compress the input image'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 54, 'page_label': '41'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 41\\ninto a compact numeric representation, while the decoder would \\nattempt to generate an image resembling the original input based \\non this compressed representation.\\nAutoencoders aim to minimize the difference between the \\ninput data and the reconstructed output, usually by optimizing a \\nloss function like mean squared error or cross-entropy. In our \\nhandwritten digit example, the autoencoder would seek to mini-\\nmize the differences between the original input image and the \\nreconstructed image produced by the decoder, thereby learning \\nthe most efficient way to represent and reconstruct the data.\\nAutoencoders have found a variety of practical applications, \\nsuch as denoising, anomaly detection, and data compression. In \\ndenoising, an autoencoder can be trained to remove noise from \\nimages, effectively “cleaning” them up. For anomaly detection, \\nautoencoders can be employed to identify unusual patterns  \\nin data, such as detecting fraudulent credit card transactions. In \\ndata compression, autoencoders can be used to reduce the size  \\nof data files while still maintaining their essential information.\\nCode\\nInput Output\\nredoceDredocnE\\nFIGURE\\xa02.9 The autoencoder architecture.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 55, 'page_label': '42'}, page_content='42 GENERATIVE AI\\nWith the advent of deep learning, more complex, multilay-\\nered autoencoders have emerged, enabling the learning of intri-\\ncate data representations. These deep autoencoders are capable \\nof capturing hierarchical relationships within the data, leading to \\neven more powerful applications.\\nOne notable use of autoencoders is in visualizing high-\\ndimensional data in lower-dimensional spaces, allowing for eas-\\nier interpretation and analysis of complex datasets. For instance, \\na deep autoencoder could be utilized to reduce the dimensions of \\na dataset containing gene expression data, making it possible for \\nresearchers to visualize and understand the relationships between \\ndifferent genes more easily.\\nThe history of autoencoders spans several decades, with their \\napplication in generative AI truly taking off in the 2010s, primar-\\nily due to advancements in deep learning. Autoencoders have \\ninspired other powerful generative models, such as variational \\nautoencoders (VAEs), which have been applied to generate new \\nimages, text, and other data types by sampling from the learned \\nlatent space. This development marked a significant leap in the \\nevolution of AI, opening up new possibilities for the future of \\nmachine learning and artificial intelligence.\\nVariational Autoencoders\\nIn 2013, the world of generative AI saw a significant advance-\\nment by the introduction of VAEs by Kingma and Welling in \\ntheir paper “Auto-Encoding Variational Bayes.”1 VAEs are built \\non the foundation laid by autoencoders, which are neural net-\\nworks that learn to encode input data into a lower-dimensional \\nrepresentation and then decode it back to the original input. \\n1Diederik Kingma and Max Welling, “Auto-Encoding Variational Bytes,” arXiv, December 10, 2022, https://\\narxiv.org/pdf/1312.6114.pdf'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 56, 'page_label': '43'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 43\\nAutoencoders played a key role in the development of VAEs by \\nproviding a foundation for unsupervised learning and dimen-\\nsionality reduction.\\nUnlike traditional autoencoders, VAEs introduced a proba-\\nbilistic framework, modeling the input data using a continuous \\nprobability distribution. This enabled more diverse and realistic \\nsample generation, a significant milestone in the evolution of \\ngenerative AI. VAEs consist of two main components: an encoder, \\nwhich maps input data to a latent space, and a decoder, which \\nreconstructs the input data from the latent space (Figure\\xa02.10).\\nVariational inference played a crucial role in the success of \\nVAEs, as it was used to approximate the true posterior distribu-\\ntion of the latent variables, enabling efficient learning and sam-\\npling. For the first time, true generative capabilities were \\nunlocked, allowing AI models to generate new images by inter -\\npolating between existing data points in the latent space, such as \\ncreating entirely new faces by blending features of existing faces.\\nVAEs found applications across various fields, such as image \\ngeneration, text generation, drug discovery, and anomaly detec-\\ntion. For instance, VAEs have been used to generate realistic 3D \\nInput Output\\nEncoder Decoder\\nCode\\n/uni03BC\\n/uni03C3\\n/uni03F5\\nFIGURE\\xa02.10 The variational autoencoder architecture.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 57, 'page_label': '44'}, page_content='44 GENERATIVE AI\\nmodels of molecules for drug discovery, accelerating the process \\nof finding new treatments for diseases.\\nWomen in Generative AI History\\nBorn in various eras, numerous exceptional women have left \\ntheir mark on the broader field of AI. Ada Lovelace, Grace  \\nHopper, Elaine Rich, and Daphne Koller are just a few who have \\nmade substantial contributions. However, pinpointing outstand-\\ning women who specifically impacted early generative AI is chal-\\nlenging due to the historical gender imbalance in the field. \\nNevertheless, several women have made remarkable contribu-\\ntions to AI areas indirectly connected to generative AI or laid the \\ngroundwork for the development of generative AI techniques.\\nFor instance, Pamela McCorduck, an author and AI histo-\\nrian, chronicled the history of AI in her influential book Machines \\nWho Think, published in 1979. She provided valuable insights \\ninto the evolution of generative AI over the years. Cognitive psy-\\nchologist Eleanor Rosch, active in the 1970s, developed proto-\\ntype theory, which asserts that human categorization is based on \\nprototypical examples rather than strict rules. Rosch’s work indi-\\nrectly impacted the development of generative AI, as her insights \\non human cognition informed AI model structure and data gen-\\neration methods.\\nCynthia Breazeal’s research, primarily focused on social \\nrobotics during the late 1990s and early 2000s, laid the ground-\\nwork for AI systems generating human-like responses and behav-\\niors. By creating robots capable of interacting and communicating \\nwith humans, such as Kismet, Breazeal made an indirect yet sig-\\nnificant contribution to the generative AI domain.\\nIn 2009, Fei-Fei Li co-developed ImageNet, a large-scale \\nimage database crucial for advancing deep learning. Although \\nthe modern generative AI era, marked by advancements like'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 58, 'page_label': '45'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 45\\ngenerative adversarial networks (GANs), began around 2014, \\nLi’s work on ImageNet facilitated these advancements by sup-\\nplying the necessary data and infrastructure for training deep \\nlearning models.\\nIt is essential to acknowledge the historical gender imbalance \\nin the field of AI and promote increased diversity and inclusion \\nin AI research moving forward. While there are many official \\nfemale contributors, numerous unofficial ones have gone unmen-\\ntioned for their contributions in the past. By recognizing and \\ncelebrating these women, we can work toward a more equitable \\nfuture in AI research, ultimately leading to more diverse perspec-\\ntives and innovative solutions in the realm of generative AI.\\nGANs: The Era of Modern Generative AI Begins\\nIn 2014, just a year after the variational autoencoder caught the \\nattention of the AI community, a 27-year-old research scientist \\nnamed Ian Goodfellow revolutionized the AI landscape. Along \\nwith his team, Goodfellow developed a groundbreaking approach \\ncalled generative adversarial networks (GANs), ushering in a \\nnew era of modern generative AI. This innovative technique took \\nthe AI world by storm, but it didn’t come without its challenges.\\nGoodfellow’s exceptional mind and relentless determination \\npropelled him to the forefront of AI research. Beginning his aca-\\ndemic journey at Stanford University, he earned his bachelor’s \\nand master’s degrees in computer science under the guidance of \\nAndrew Ng, a renowned AI expert and cofounder of Coursera. \\nGoodfellow later pursued his PhD in machine learning at the \\nUniversité de Montréal, supervised by Y oshua Bengio, a pioneer \\nin deep learning, and Aaron Courville, an esteemed AI researcher.\\nGoodfellow was surrounded by top-tier mentors, and his \\ncareer trajectory was nothing short of extraordinary. Alongside \\nBengio and Courville, he co-authored the MIT textbook Deep'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 59, 'page_label': '46'}, page_content='46 GENERATIVE AI\\nLearning, which quickly became a staple resource in the field. His \\nnumerous accolades include being named one of MIT T echnology \\nReview’s 35\\xa0Innovators Under 35.\\nGoodfellow’s career took him to prestigious institutions like \\nGoogle Brain, OpenAI, Google Research, and Apple, where he \\nserved as a director of machine learning in the Special Projects \\nGroup. However, he never shied away from standing up for his \\nprinciples. In April 2022, Goodfellow resigned from his lucrative \\nposition at Apple to protest the company’s in-person work \\nrequirements for employees. His next step took him to Google \\nDeepMind as a research scientist, demonstrating his unwavering \\npassion for AI research.\\nHow GANs Work\\nSo, how do GANs work? In a two-step process involving training \\nand production, the crux of the magic unfolds during  \\nthe training phase. The brilliance of GANs lies in their dual- \\ncomponent structure, comprising a generator that meticulously \\ncrafts new data samples and a discriminator that determines the \\nauthenticity of said samples. T o create images, for instance, the \\ngenerator employs a deconvolutional neural network, transform-\\ning noise into data samples, whereas the discriminator relies on a \\nconvolutional neural network to classify images as genuine or \\ngenerated (Figure\\xa02.11).\\nThe essence of adversarial training involves the generator \\nattempting to deceive the discriminator with lifelike creations, \\nwhile the discriminator strives to differentiate between the \\nauthentic and the artificial. Should the generated data be detected \\nas such, the generator must update its trainable parameters; like-\\nwise, if the generated data is not detected, the same process occurs \\nfor the discriminator. This dynamic propels both components'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 60, 'page_label': '47'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 47\\nto improve until they reach the Nash equilibrium— a point  \\nwhere neither can gain an advantage by changing their strategy. \\nReaching Nash equilibrium is a necessary condition for good \\nperformance.\\nAfter training, the generator, now at its peak performance, is \\nfrozen and subsequently employed for generating the respective \\ndata. With the ability to produce highly realistic and intricate \\ndata samples, such as images, text, and audio, GANs have sparked \\na revolution in numerous fields, ranging from art and design to \\nscientific research and beyond. The true potential of generative \\nmodels and their capacity to transform our interactions with \\ntechnology has been unveiled.\\nThe applications of GANs are astoundingly diverse, with \\nuses such as\\n• Generating strikingly realistic images of faces, animals, and  \\nobjects\\n• Image-to-image translation, morphing simple sketches into \\nvibrant masterpieces\\n• Super-resolution, rejuvenating low-quality images by enhanc-\\ning their resolution\\nReal\\nFake\\nReal-world\\nImages\\nLatent\\nVariable\\nLOSSDiscriminator\\nGenerator\\nSample\\nSample\\nFIGURE\\xa02.11 The generative adversarial network architecture.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 61, 'page_label': '48'}, page_content='48 GENERATIVE AI\\n• Data augmentation, producing additional training samples \\nfor machine learning models\\n• Style transfer, which imbues one image with the artistic \\nessence of another image\\nWith GANs, the landscape of AI, and even other fields, like \\nphysics, are continually evolving, opening up a world of endless \\npossibilities.\\nGAN Challenges\\nThe inception of GANs was no small feat. The groundbreaking \\nconcept of pitting two networks against each other not only rev-\\nolutionized deep learning but also introduced a host of new chal-\\nlenges. The delicate balance of power between these networks \\nhinges on factors such as hyperparameters, architecture, and \\ntraining methods. If any one of these elements is off kilter, one \\nnetwork may overpower the other, resulting in training stagna-\\ntion due to insufficiently differentiated feedback.\\nNavigating the complexities of GANs also involves address-\\ning issues like mode collapse, vanishing gradients, and internal \\ncovariate shifts. In simple terms, mode collapse occurs when the \\ngenerator becomes fixated on producing a limited variety of out-\\nputs, hindering its ability to generate diverse samples. Vanishing \\ngradients, on the other hand, refer to the dwindling gradients \\nthat arise during backpropagation, making it difficult for the net-\\nworks to learn effectively. Lastly, internal covariate shifts pertain \\nto the inconsistencies in the distribution of layer inputs during \\ntraining, which can hamper the overall learning process.\\nSince 2014, the landscape of GAN variations has expanded \\nexponentially, now approaching nearly 9,300\\xa0iterations, each tai-\\nlored to tackle a specific challenge. Although newer GAN models'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 62, 'page_label': '49'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 49\\nhave grown more sophisticated, the initial breakthrough was made \\npossible by the efforts of Ian Goodfellow and his colleagues.\\nGoodfellow’s dedication and expertise laid the foundation \\nfor a transformative technology that has since become a corner-\\nstone of AI. As GANs continue to influence the future of artifi-\\ncial intelligence, Goodfellow’s remarkable career serves as a \\npowerful reminder of the potential unleashed through determi-\\nnation, collaboration, and innovation.\\nFrom Pixels to Perfection: The Evolution of AI \\nImage Generation\\nAs a visually compelling field, it’s no wonder that AI image gen-\\neration has garnered widespread attention. The rapid progress, \\ncombined with the ease of grasping its potential, makes the gen-\\nerative AI story captivating to tell.\\nT o achieve what was once deemed unattainable, generative AI \\nimage generation demanded remarkable algorithms and innova-\\ntive technical ideas. The secret sauce that AI needed to generate \\nexceptional images emerged from the evolution of autoencoders, \\nGANs, and diffusion models.\\nInitially, autoencoders demonstrated prowess in reconstruct-\\ning images. However, as deterministic models, they lacked true \\nimage generation capabilities. Deterministic, in this context, \\nmeans that given the same input data, an autoencoder will con-\\nsistently produce the same output.\\nThe introduction of the variational component in the form \\nof variational autoencoders marked a turning point for these \\nmodels, granting them genuine generative potential. With vari-\\national autoencoders, AI began to yield promising results in gen-\\nerating images and faces. Y et, it was the arrival of GANs that \\npropelled image generation quality to new heights.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 63, 'page_label': '50'}, page_content='50 GENERATIVE AI\\nGANs for Image Generation\\nGANs have emerged as a formidable force in the realm of image \\ngeneration. As they learn the distribution of a given dataset, their \\nflexibility allows them to generate a wide array of images, from \\nrealistic photographs and abstract art to depictions of nonexist-\\nent objects or creatures. However, their architecture, which sug-\\ngests parallel data generation, is not traditionally suited for \\nsequential data generation, such as text.\\nT o bridge this gap, images and their captions can be com-\\nbined in their respective vector embeddings. Vector embeddings \\nare representations of images or pieces of text as a vector of num-\\nbers, capturing the semantic meaning of the input in a compact \\nand useful form for downstream machine learning tasks. By inte-\\ngrating text and image representations through vector embed-\\ndings during GAN training, the image generation process \\nbecomes steerable via text. This groundbreaking functionality \\nenables the seamless fusion of images and styles.\\nOne of the remarkable attributes of GANs is their ability to \\ngenerate images without labeled training data, as they inherently \\nunderstand the original data distribution. Additionally, GANs \\ncan be trained progressively, commencing with low-resolution \\nimages and gradually enhancing resolution over time. This \\napproach ensures that the generator learns to create increasingly \\ndetailed and realistic images as training advances.\\nThe surge of research interest in GANs has sparked numer-\\nous innovations. Here are some notable examples:\\n• In 2016 and 2017, Wasserstein GAN (WGAN) and progres-\\nsive growing of GANs (ProGAN) enhanced GAN training \\nstability, allowing for the generation of higher-resolution \\nimages with improved quality.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 64, 'page_label': '51'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 51\\n• In 2018, BigGAN pushed the boundaries of GAN-generated  \\nimage quality and resolution, creating high-fidelity images \\nup to 512×512 pixels in size, boasting more realistic and \\ndiverse content.\\n• Between 2019 and 2021, StyleGAN emerged as a state-of-\\nthe-art image generator, providing fine-grained control over \\nstyle and content. This enabled impressive results in face \\ngeneration and other domains.\\nCLIP\\nWhile GANs have made substantial progress in generating \\nimages based on textual descriptions, they occasionally yield \\nresults that lack consistency with the text or the desired level of \\ncontrol. In January 2021, OpenAI introduced an innovative neu-\\nral network model called CLIP (Contrastive Language-Image \\nPre-T raining) to bridge this gap.\\nCLIP , bridging the gap between NLP and CV , is pretrained \\non a vast dataset of over 400\\xa0million image-text pairs. With an \\nobjective to create a joint representation of images and text, it \\nuses contrastive pretraining to distinguish between similar and \\ndissimilar pairs. This approach helps CLIP relate relevant text to \\nimages, even when the text doesn’t directly describe the visual \\ncontent. In a subsequent step, the model encodes images and text \\ninto a shared space through an image encoder and a text trans-\\nformer. The goal is to amplify the similarity of genuine image-\\ntext pairs and reduce it for mismatched pairs, thereby boosting \\nits efficiency. Figure\\xa02.12 shows the three main steps of its train-\\ning process. The ability of CLIP to comprehend the meaning of \\na text in relation to images has unlocked new possibilities for \\nfusing NLP and CV .'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 65, 'page_label': '52'}, page_content='52 GENERATIVE AI\\nAs a powerful tool for tasks requiring an understanding of \\nthe relationship between text and images, CLIP surpasses GANs \\nfor several reasons:\\n• CLIP allows for more fine-grained control over image gen-\\neration, enabling users to specify desired attributes such as \\ncolor or orientation.\\n• CLIP can work with multiple modalities, including images, \\ntext, and audio, paving the way for more intricate and \\nnuanced generation tasks.\\n• CLIP has demonstrated excellent generalization to unseen \\ndata, meaning it can generate high-quality images consistent \\nwith textual descriptions, even when the images are not seen \\nduring training.\\nThe impact of CLIP on the AI community has been immense. \\nInfluencing other models like DALL-E and Stable Diffusion, \\nCLIP has spurred research in text-to-image models and popu-\\nlarized the contrastive pretraining method.\\nImage 1 Image\\nCLIP\\nText\\nEmbed image\\nand text\\nCompare the\\nembeddings\\nPrediction Label\\n1\\n(Similar)\\n1\\n(Similar)\\n0\\n(Not similar)\\n0\\n(Not similar)\\nCaption 1\\nUpdate the\\nmodels321\\nImage\\nembedding\\nText\\nembedding\\nFIGURE\\xa02.12 Training of CLIP.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 66, 'page_label': '53'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 53\\nDALL-E 2\\nBolstered by the success of CLIP and the advancements it has \\nspurred in the field of AI, research scientists have continued to \\npush the boundaries of what’s possible in a text-to-image genera-\\ntion. One such breakthrough, which has captured the world’s \\nattention, is OpenAI’s DALL-E 2.\\nOpenAI’s DALL-E 2\\xa0 was the talk of the town in summer \\n2022, setting the tech world abuzz with its jaw-dropping image \\ngeneration capabilities. A nearly solved problem, DALL-E 2 \\ngenerates astoundingly realistic images at higher resolutions, \\nadeptly blending concepts, attributes, and styles. It can manipu-\\nlate and rearrange objects within images, and is a maestro at \\nplacing design elements in innovative compositions.\\nDALL-E 2’s finesse lies in its ability to inpaint and outpaint \\nimages, generate variations, and transform aspects of images \\nusing text. Inpainting involves filling in missing or corrupted \\nparts of an image using surrounding information, whereas out-\\npainting, also known as image extrapolation, extends the content of \\nan image beyond its original boundaries.\\nOnce a nonprofit organization, OpenAI was established in \\n2015\\xa0with the noble objective of developing AI for the benefit of \\nhumanity. However, in 2018, the company made a controversial \\nshift to a for-profit model, raising concerns about conflicts of \\ninterest and the potential undermining of its original mission.\\nNowadays, OpenAI isn’t as open as it used to be. No longer \\nopen sourcing their models, the organization discloses only \\nselect information, which means we can discuss the models only \\nfrom a secondhand perspective.\\nT o understand DALL-E 2, picture a skilled artist who listens \\nto your description, captures the concept, and then produces a \\ndetailed, realistic image based on your vision. This wondrous'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 67, 'page_label': '54'}, page_content='54 GENERATIVE AI\\ntechnology is built on two key innovations: CLIP , which we’ve \\ntouched upon before, and diffusion, which we’ll delve into shortly.\\nIn a nutshell, DALL-E 2 uses CLIP encoders to map inputs \\nto an embedding within a shared concept space, where matching \\npairs are mapped to nearby points and mismatching pairs are \\nmapped to distant ones. The diffusion model, which they call \\nGLIDE by the way, is trained to undo the steps of a fixed corrup-\\ntion or noising process, reversing the corruption or denoising \\nand regenerating erased information. More on this in a moment.\\nDALL-E 2’s prowess is showcased through a two-stage pro-\\ncess: First, the prior model generates a CLIP image embedding \\nfrom the given caption, capturing the gist of the image. Next, the \\ndiffusion model (unCLIP) generates the actual image from the \\nembedding, filling in the details.\\nThe advantages of this two-stage sampling process are evi-\\ndent: it prioritizes high-level semantics, making images more \\nmeaningful to humans, and allows for text-based transformations \\nusing CLIP’s multimodal embedding space. In the summer of \\n2022\\xa0DALL-E 2\\xa0was, without a doubt, a testament to the poten-\\ntial of generative AI and a harbinger of even greater advancements.\\nDiffusion Models\\nAs all of this evolves at a rapid pace, the open source ethos pro-\\npelling its growth has enabled both researchers and hobbyists \\nalike to explore and develop the capabilities of diffusion models.\\nJune 2021\\xa0marked a pivotal moment for image generation, as \\na publication emerged, revealing that diffusion models had sur -\\npassed GANs in their capabilities. This revelation piqued my \\ninterest and brought the potential of diffusion models into focus \\nfor the first time. Fast-forward 10\\xa0months, and OpenAI’s DALL-2,  \\nan image generation model based on the diffusion principle, has'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 68, 'page_label': '55'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 55\\ntaken the world by storm, producing premium images that have \\nleft many astounded.\\nIn August 2022, another significant development in the field \\nof AI made headlines: Stability AI released Stable Diffusion, a \\nmodel capable of achieving outputs on par with DALL-E 2.  \\nT aking a different approach from its counterparts, Stability AI \\nastonished the tech community by open sourcing the model \\nalmost immediately. This model has been made accessible to all, \\nrunnable within a Python Notebook and on the Hugging Face \\nplatform. Hugging Face, a hub for sharing pretrained models, \\ndatasets, and demos of machine learning projects, promotes open \\nsource contributions and fosters a collaborative environment for \\nAI enthusiasts.\\nStability AI, under the leadership of CEO and founder Emad \\nMostaque, distinguishes itself by open sourcing AI technology— a \\nrarity among the few companies equipped with the resources and \\ntalent to develop it. Their mission is to democratize access to AI \\ntechnology and prevent its monopolization by major tech players.  \\nBeyond Stable Diffusion, they are working on projects such as \\nHarmonai, which focuses on open source generative audio tools, \\nand OpenBioML, a venture into the intersection of machine \\nlearning and biology. A vast and dedicated community has rallied \\nbehind Stability AI’s vision.\\nMostaque and his team are steadfast in their commitment to \\ncreating tools that empower individuals and grant them agency, \\na pursuit they believe can lead to a happier world and drive posi-\\ntive change. Stability AI, a well-capitalized startup, has garnered \\nfunding from Mostaque’s personal fortune, a $100\\xa0million invest-\\nment led by Coatue, and has plans to monetize by concentrating \\non specific domains, such as Bollywood.\\nDespite the general trend of keeping AI technology closed \\nsource— exemplified by OpenAI, ironically enough— it is both \\nrefreshing and challenging to see a company like Stability AI'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 69, 'page_label': '56'}, page_content='56 GENERATIVE AI\\nopen source its models. This strategy comes at the cost of relin-\\nquishing much of their competitive advantage, as anyone can \\ndownload a stable diffusion model, run it on some GPUs on-\\npremises or in the cloud, fine-tune it, and obtain a remarkable \\nimage generation model without paying Stability AI a single penny.\\nStable Diffusion Tech\\nDiffusion models stand at the forefront of innovation. What sets \\nthem apart is their unique methodology: introducing noise to \\nlearn the art of denoising, thereby unraveling the secrets of gen-\\nerating images. The results are nothing short of enchanting!\\nAs previously mentioned, the crux of the diffusion model lies \\nin its ability to add and remove noise from images. Picture this: \\nDuring the forward diffusion phase, noise is added to the image, \\nakin to static interference on a television screen. In the reverse \\ndiffusion stage the noise is eliminated, gradually revealing the \\nimage beneath the static. However, the pure diffusion model is \\nhampered by its sluggishness, especially when dealing with a \\nlarge number of diffusion steps or sizable images, as there are \\nsimply too many pixels to process.\\nEnter stable diffusion, a swifter alternative. This technique \\noperates within the latent space, which is essentially a compressed \\nversion of the image, much like a smaller, condensed file. This fam-\\nily of models is known as latent diffusion models. T o create the latent \\nspace, an autoencoder is employed, acting as a simplified version of \\nthe variational autoencoder mentioned earlier. The autoencoder’s \\nencoder compresses the image into lower-dimensional data, similar \\nto zipping a file, whereas the decoder decompresses the latent data \\nback into an image, akin to unzipping a file.\\nOne of the most remarkable features of stable diffusion is its \\nability to generate images from text prompts in a highly impressive'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 70, 'page_label': '57'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 57\\nmanner. The diffusion model is adapted to accept conditioning \\ninputs, comparable to modifying a recipe based on a special request. \\nT ext inputs are transformed into embeddings (vectors) using a lan-\\nguage model, reminiscent of the process employed by CLIP .\\nFor inquisitive minds yearning to delve into stable diffusion, \\nlook no further than GitHub, where the code is easily accessible. \\nAdditionally, a web application has been thoughtfully designed \\nto offer a hands-on experience with this revolutionary model.\\nMidjourney\\nMidjourney is an AI image-generation company that has taken \\nthe world by storm. Its latest creation, Version 5, is renowned for \\ngenerating images of unparalleled quality, spanning from  \\nphotorealistic to a wide array of artistic and nonartistic styles. \\nHailed as the epitome of AI-generated artistry, Midjourney’s \\nimages are so remarkably lifelike that they have earned the title \\nof being “indistinguishable” from real photographs.\\nHowever, this near-perfect level of realism has raised eye-\\nbrows among AI art enthusiasts. Some have dubbed Midjour -\\nney’s creations as “creepy” and “too perfect.” The groundbreaking \\nimprovements in Version 5\\xa0include incredibly realistic skin tex-\\ntures, impeccably detailed facial features, cinematic lighting \\neffects, and striking reflections, glares, and shadows. The model \\nalso boasts more expressive angles or overviews of a scene, and— \\nperhaps most importantly— human hands now consistently dis-\\nplay the correct number of fingers.\\nAccessible through a Discord bot command, Midjourney’s \\nplatform was still in open beta as of December 2023. The com-\\npany’s trailblazing team, led by founder David Holz, has a track \\nrecord of releasing new and improved model versions every few \\nmonths. With a keen eye for innovation and a commitment to'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 71, 'page_label': '58'}, page_content='58 GENERATIVE AI\\nconsistent progress, Midjourney has already achieved profitabil-\\nity. Artists worldwide employ the platform for rapid prototyping \\nof artistic concepts, while the advertising industry reaps the ben-\\nefits of quickly creating original content.\\nNevertheless, Midjourney remains vigilant about the images \\ngenerated by its platform. In a fascinating turn of events, the \\ncompany made headlines in March 2023\\xa0when it preemptively \\nblocked the generation of images depicting Xi Jinping. This \\nmove was taken to prevent potential censorship by the Chinese \\ngovernment. Holz said that “the ability for people in China to \\nuse this tech is more important than your ability to gener -\\nate satire.”2\\nThe enigmatic team behind Midjourney has kept their train-\\ning techniques under wraps. However, it’s very likely that they \\nmight use methods similar to stable diffusion, as its approach is \\nknown in detail. As AI-generated artistry evolves, the interplay of \\nideas and techniques among pioneers like Midjourney fuels pro-\\ngress and sparks anticipation for future revelations.\\nThe Importance of\\xa0Training Data\\nT raining data reigns supreme as the vital cornerstone of AI image \\ngeneration model performance. T ext-to-image models necessi-\\ntate sizable datasets, often procured by scouring the web for \\nimage-text pairs. However, this method bears inherent limita-\\ntions and biases, including toxic language, nudity, violence, and \\nharmful social stereotypes.\\nFor those desiring elite model performance and possessing \\nample budgets, the LAION-400M dataset is the gold standard. \\nSourced from Common Crawl web data, it amasses an impressive \\n2Christopher McFadden, “Midjourney will no longer let you generate images of Xi Jinping,” Interesting Engi-\\nneering, April 3, 2023, https://interestingengineering.com/culture/midjourney- bans- xi- jinping- images'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 72, 'page_label': '59'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 59\\n413\\xa0million image-text pairs tailored for top-tier models. T o ensure \\nsafety, filters can be applied to regulate output, and models can be \\nretrained on custom datasets to minimize biases for specific use \\ncases. The operations are fueled by donations and public research \\ngrants. The team comprises 15\\xa0 members, although it remains \\nuncertain if all are engaged full-time.\\nMeanwhile, smaller AI image generation models like Craiyon— \\nalso known as DALL-E mini— trained on a mere 30\\xa0million images, \\nproduce fewer photorealistic images compared to their larger \\ncounterparts like stable diffusion. Here, strategic partnerships play \\na pivotal role, providing invaluable training data inaccessible to \\nothers. For instance, OpenAI’s strategic partnership with Shutter-\\nstock was instrumental in DALL-E’s development. Shutterstock is \\na marketplace for high-quality, royalty-free photographs, vectors, \\nillustrations, videos, motion graphics, and music.\\nAnother interesting dataset that merits attention is ImageNet.  \\nThis extensive image database is organized following the Word-\\nNet hierarchy, which, as of now, is confined to nouns. Each node \\nwithin this hierarchy is illustrated by hundreds, even thousands, \\nof images. The data is available at no cost to researchers for non-\\ncommercial purposes and comprises an impressive 14,197,122 \\nimages along with 21,841 synsets indexed. “Synsets” is short for \\n“synonym sets,” which are groups of words that mean the same \\nthing. In ImageNet, each synset is linked to a bunch of images \\nthat show the same thing. Conceived as a large-scale visual data-\\nbase, the ImageNet project is designed for use in the field of \\nvisual object recognition software research.\\nThough Midjourney remains tight-lipped about the datasets \\nutilized in training its model, whispers within the insider com-\\nmunity suggest that copyrighted artists’ work may have been \\nincluded. Despite the lack of official confirmation, Midjourney’s'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 73, 'page_label': '60'}, page_content='60 GENERATIVE AI\\nperformance speaks volumes. Key speculations that stand out \\ninclude the following:\\n• Midjourney enhances prompts pregeneration and applies post-\\nprocessing to the image, resulting in its distinctive aesthetic.\\n• A carefully trained classifier model may evaluate and filter \\ngenerated content.\\n• Midjourney’s output is somewhat limited in terms of style, as \\nthey understand what works and what doesn’t.\\n• Most crucially, they meticulously curate their data, retaining \\nonly the most exquisite images— a testament to their unwa-\\nvering commitment to quality.\\nAs the tale of Midjourney continues to unfold, the world \\neagerly anticipates the next chapter in the company’s enigmatic \\njourney, as well as the innovations and revelations that are yet \\nto emerge.\\nAutoregression\\nGoogle is another significant player in the realm of generative \\nAI. Among their most notable models are the image generation \\nmodels Imagen and Parti. Imagen, a latent diffusion model, \\nshowcases Google’s expertise in diffusion models. Parti offers an \\nimpressive performance through a different approach to image \\ngeneration— autoregression. Although this method is sequential \\nrather than parallel, it is worth delving into autoregressive mod-\\nels for image generation. As you shall see, they play a crucial role \\nin this field.\\nEnter Parti, Google’s answer to DALL-E 2, which began  \\nwith the publication of “Scaling Autoregressive Models for'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 74, 'page_label': '61'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 61\\nContent-Rich T ext-to-Image Generation.”3 Parti addresses text-\\nto-image generation as a sequence-to-sequence modeling prob-\\nlem, taking advantage of advances in LLMs. Employing  \\nthe Vision-T ransformer-based VQGAN (ViT-VQGAN) image \\ntokenizer, Parti encodes images as sequences of discrete tokens, \\nenabling the reconstruction of high-quality, visually diverse images. \\nThe result is state-of-the-art zero-shot and fine-tuned FID  \\n(Fréchet inception distance) scores on MS-COCO\\xa0 (Microsoft \\nCommon Objects in Context), with the model proving effective \\nacross a broad range of categories and difficulty aspects, as demon-\\nstrated in the Localized Narratives and PartiPrompts bench-\\nmark analysis.\\nIn essence, zero-shot refers to a model’s ability to perform a \\ntask without prior training or examples specific to that task. It \\nhighlights a model’s capacity to generalize and apply learned \\nknowledge from one context to another without the need for \\nadditional fine-tuning.\\nFID is a commonly used metric for evaluating the quality of \\ngenerated images. Picture it as a ruler measuring the distance \\nbetween two distributions of features extracted from real and \\ngenerated images. Lower FID scores signify that the generated \\nimages more closely resemble the real ones, thus indicating \\nhigher quality.\\nMS COCO is an extensive image recognition, segmenta-\\ntion, and captioning dataset, boasting over 330,000 images and \\nmore than 2.5\\xa0million object instances labeled with object cat-\\negories, instance segmentation, and dense captioning. Its \\nimportance in image generation research cannot be overstated, \\nas it provides a widely used benchmark dataset for assessing \\nthe quality and diversity of generated images. Numerous state-\\nof-the-art image generation models are evaluated using  \\n3Jiahui Yu et\\xa0al. “Scaling Autoregressive Models for Content-Rich T ext-to-Image Generation,” arXiv, June 22, \\n2022, https://arxiv.org/pdf/2206.10789.pdf'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 75, 'page_label': '62'}, page_content='62 GENERATIVE AI\\nthe MS COCO dataset, and high scores on this benchmark \\nstrongly indicate the performance and generalization ability of \\nthe model.\\nAutoregressive models are undoubtedly innovative, achiev-\\ning remarkable results in both parallel and sequential data gen-\\neration. While they may have been underestimated in the past, \\nthey have brought about significant advancements in AI and \\ncould lead to further breakthroughs in the field. Perhaps their \\ntrue potential lies in supporting video generation and other  \\nyet-to-be-discovered applications in the realm of generative AI.\\nThe Future of AI Image Generation\\nAs the modern generative AI era unfolds, a plethora of models \\nhave emerged, including stable diffusion, Midjourney, DALL-E \\n2, Craiyon, Parti, Imagen, and others such as Night Café,  \\nArtbreeder, DeepAI, StarryAI, WOMBO Dream, and Bria \\n(which is targeted for business-to-business [B2B])— and even \\nearlier models like Google’s Deep Dream Generator. This pro-\\nliferation heralds a future teeming with mind-blowing technol-\\nogy. Improvements, innovations, trends, new paradigms, issues, \\nadoption, and applications of generative AI will persist and evolve \\nin the years to come, with AI image generators creating 2D, 3D, \\nand even 4D images based on text.\\nSimply put, 4D images represent changes over time— a \\nsequence of three-dimensional images depicting a transforming \\nobject or scene. Achievable through video capture, 3D modeling, \\nanimation, and machine learning, 4D images hold immense \\npotential. For instance, generative AI could revolutionize medi-\\ncal diagnostics by transforming X-rays and CT scans into realis-\\ntic, interactive images, allowing doctors, for example, to examine \\na broken rib from various angles.\\nAs generative AI platforms become increasingly prevalent, \\nimage generation as a standard functionality seems inevitable.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 76, 'page_label': '63'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 63\\nEmad Mostaque’s theory posits that most image generation \\ncompanies will eventually converge in terms of AI capabilities. \\nHowever, this may not necessarily be true, as consistently excep-\\ntional personnel are required to push these hard tech boundaries, \\nand the diverse landscape of generative AI allows for countless \\nturns on the highway of innovation. Consider use case–specific \\nAI image generation: one focusing on training data for self-driving  \\ncars, another on medical imaging. Ultimately, this diversity \\nhinges on the training data each company obtains and potentially  \\ngenerates.\\nAssuming AI image generation models do eventually reach \\nsimilar capabilities and qualities in a profitable manner, compa-\\nnies must explore what’s next. In this innovative, competitive \\nspace with high expectations set by capital allocators, models will \\nlikely evolve into more capable, multimodal systems, eventually \\nculminating in artificial general intelligence. More on this fasci-\\nnating prospect will be explored later in the book.\\nLastly, generative AI companies must be nimble in pivoting \\ntheir strategies, even after expending significant energy on a par-\\nticular tech approach. As witnessed in AI image generation, many \\ncompanies initially doubled down on GANs, tweaking and refin-\\ning them to fit narrow use cases. However, the open source release \\nof stable diffusion— with its superior performance— prompted an \\nimmediate shift in strategy. In this ever-evolving landscape, adapt-\\nability and resilience are the hallmarks of success, as generative AI \\ncontinues to forge new frontiers in the world of technology.\\nA Crucial Tech Disruption: Text Generation\\nIn the realm of AI data generation, two primary streams have \\nemerged, each with its own unique capabilities: image generation, \\nwhich exemplifies parallel data generation, and text generation, \\nrepresentative of sequential data generation. These two distinct'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 77, 'page_label': '64'}, page_content='64 GENERATIVE AI\\nstreams complement one another, paving the way for AI’s versatile \\napplications in various domains.\\nT ext generation models, being intrinsically adept at handling \\nsequential data, excel in generating not only written text but also \\nother forms of sequential data, such as code, music, voice, and \\nother auditory elements. Furthermore, they can generate time-\\nseries data, encompassing synthetic sensor data to enhance data-\\nsets, stock market data, and much more. A few examples include \\ncomposing original music pieces, simulating stock market trends, \\nand even generating realistic human speech, all thanks to the \\ninherent sequential nature of these models.\\nAs you delve further into this chapter, you will witness the \\ninnovative spirit of research scientists who achieved groundbreak-\\ning results. This creative triumph is best exemplified by the launch \\nof ChatGPT on November 22, 2022. Since then, LLMs have \\ntranscended mere hype, offering tangible value for businesses and \\nindividuals alike. My experience with GenerativeAI.net is a testa-\\nment to this, as I consult companies on leveraging language mod-\\nels for tailored applications, and as a leader at Infosys Consulting, \\nI guide teams in implementing this revolutionary technology, \\naccumulating an impressive array of client success stories and cre-\\ndentials. Our work with these organizations extends beyond sim-\\nple implementation; we help them harness the power of generative \\nAI to transform into AI-first companies.\\nAutoregression Models\\nIn the fascinating realm of text generation models, an overarch-\\ning player emerges: the autoregressive model. Whenever a model \\nuses a sequence of words or other sequences to predict the  \\nensuing words, we are witnessing the prowess of autoregression. \\nWhile this mechanism is not exclusive to text generation, it  \\ndominates the field. As we traverse through the landscape of text'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 78, 'page_label': '65'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 65\\ngeneration, note that all models presented, except for rule-based \\nsystems and GANs, are autoregressive. However, we shall main-\\ntain our chronological approach.\\nOur journey takes us back to the early 20th century, when the \\nBritish statistician Yule first introduced autoregression models, \\nalso known as autoregressive models. These statistical marvels \\nutilize past values of a time series to forecast future values. When \\napplied to text generation, autoregression models astutely pre-\\ndict the next word or token, basing their deductions on the con-\\ntext of the preceding words in the sequence.\\nAutoregression models come in various orders, ranging from \\nthe elementary first-order model, AR(1), to more intricate vari-\\nants. AR(1) predicts the value of the time series at time ‘t’ by \\nrelying on its value at time ‘t-1’. Meanwhile, the more sophisti-\\ncated AR(p) models predict the time-series value at time ‘t’ by \\nconsidering values at times ‘t-1’, ‘t-2’, and so forth, up to ‘t-p’.\\nWhile these models are traditionally grounded in statistical \\nmethods, they have evolved to adapt to neural network architec-\\ntures such as recurrent neural networks (RNNs) and transform-\\ners. This adaptation has enabled them to capture more complex \\ndependencies, thus generating text that is not only coherent but \\nalso imbued with semantic meaning. The autoregressive model’s \\njourney from its inception to its modern adaptations reflects the \\never-evolving nature of AI, a testament to human ingenuity and \\nour drive to understand the intricacies of language.\\nMarkov Chains\\nBorn in Russia, Andrey Markov was a prodigious mathemati-\\ncian who, in 1906, introduced the world to Markov chains. His \\ngroundbreaking paper laid the foundation for the study of sto-\\nchastic processes, particularly those now called Markov chains. \\nAlthough they were far removed from text generation at the \\ntime, their potential in this area would soon be recognized.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 79, 'page_label': '66'}, page_content='66 GENERATIVE AI\\nFast-forward to 1948\\xa0when Claude Shannon, an illustrious \\nmathematician and electrical engineer who later helped to coin \\nthe term artificial intelligence, presented a paper demonstrating \\nthe use of Markov chains in text generation. Shannon’s innova-\\ntive Markov chain model generated English text that echoed the \\nstyle and structure of natural English sentences. The model was \\ntrained on a corpus of text data, and it crafted new sentences by \\npredicting the next word based on the previous word.\\nMarkov chains, a type of statistical model, depict sequences \\nof events in which each event’s probability depends solely on the \\nstate of the system during the previous time step, not on earlier \\nevents. T o generate new text, Markov chains predict the next \\nword in a sequence based on the probability of each word, given \\nthe previous word. By training the model on a corpus of text \\ndata, the probabilities of each word given the previous word are \\nestimated. With an initial seed word or phrase, the model gener-\\nates new text by predicting the next word using the probability \\ndistribution and incorporating it into the sequence. Figure\\xa02.13 \\nshows an example.\\nChristmas Wish\\nClique\\n0.10\\n1.00\\n1.00\\n1.00 1.00\\n1.00 1.00\\n0.33\\n0.33\\n0.33\\n1.00\\n0.25\\n0.75\\n0.10\\n0.10\\n0.10\\n0.10\\n0.20\\n0.30\\nCold\\nColonyThe\\nCom\\nClient\\nColor\\nHeart\\nList\\nPurple\\nof\\na\\nCourage\\nLove:\\nKiller\\nStoryJacey’s\\nFIGURE\\xa02.13 A probability diagram of a Markov chain for text genera-\\ntion. Each node represents a state (word or sequence of words), and \\neach edge represents the transition probability from one state to \\nanother, as determined from the training text.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 80, 'page_label': '67'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 67\\nAlthough Markov chains offer simplicity and computational \\nefficiency in text generation, their limitations lie in capturing long-\\nterm dependencies and generating coherent, semantically mean-\\ningful text. As such, Markov chains often serve as a baseline model \\nfor text generation tasks, whereas more advanced applications rely \\non sophisticated models like recurrent neural networks and \\n transformer-based models. Thus, Markov chains, while founda-\\ntional, represent just one stepping stone in the ever-evolving jour-\\nney of AI, as we strive to decode the complexities of language.\\nRule-Based Text Generation\\nPioneered in the 1980s, rule-based systems for text generation \\nmarked another significant milestone in text generation. These \\nsystems harnessed the collective knowledge of researchers and \\ndevelopers from various disciplines, including computer science \\nand linguistics. By employing sets of rules and handcrafted \\nknowledge, rule-based systems generated text with structure, \\ncontent, and style that adhered to linguistic principles.\\nIn essence, rule-based systems generate text by following \\nhandcrafted rules based on linguistic knowledge, such as gram-\\nmar rules and semantic relationships between words. For \\ninstance, the rules might dictate that a weather report should \\nbegin with a general statement about the overall weather condi-\\ntions, followed by specific details about temperature, precipita-\\ntion, and wind.\\nThese rule-based systems have been used for various applica-\\ntions, including weather reports, financial reports, and medical \\nreports. They remain relevant even today in specific domains \\nthat require standardized text output. For example, rule-based \\nsystems have been employed to generate personalized medical \\nreports for patients, summarizing their symptoms, diagnoses, \\nand treatment plans in a clear, concise manner. The quality of the \\ngenerated text is contingent on the quality and accuracy of the'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 81, 'page_label': '68'}, page_content='68 GENERATIVE AI\\nrules, which demand considerable domain expertise and manual \\neffort to develop.\\nAlthough rule-based systems have their merits, they are \\ninherently limited in generating novel or creative text. Their \\nstrength lies in producing standardized or formulaic text,  \\nwhere adherence to linguistic rules and conventions is of para-\\nmount importance. Consequently, rule-based systems, much like \\nMarkov chains, form an essential part of the ever-evolving AI \\njourney, as we endeavor to unravel the complexities of language \\nand craft increasingly sophisticated text generation models.\\nRecurrent Neural Networks\\nBuilding upon the foundations laid by rule-based systems and \\nMarkov chains, recurrent neural networks (RNNs) emerged in \\nthe early 1980s, thanks to the pioneering work of John Hopfield \\nand David Rumelhart. Both Hopfield and Rumelhart were lead-\\ning figures in the realm of AI, with Hopfield renowned for his \\ncontributions to neural networks and Rumelhart for his work on \\nparallel distributed processing— a great team fit.\\nRNNs are a type of neural network designed to process \\nsequential data by maintaining an internal state that captures the \\ncontext of previous inputs. In text generation tasks, RNNs com-\\nmonly predict the next word or token based on the context of \\npreceding words in the sequence. By processing the input \\nsequence one token at a time and updating its internal state at \\neach step based on the input token and the previous state, RNNs \\neffectively encapsulate a summary of prior inputs. This internal \\nstate is instrumental in predicting the next output. Figure\\xa02.14 \\nillustrates an unrolled RNN, and Figure\\xa0 2.15 showcases the \\ndeceptively simple mechanics of a standard RNN unit. A layer is \\nquite straightforward.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 82, 'page_label': '69'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 69\\nRNNs have found widespread applications in natural lan-\\nguage processing, including language translation, dialogue gen-\\neration, and sentiment analysis.\\nHowever, RNNs are not without their limitations. They \\noften grapple with the vanishing gradient problem, which hin-\\nders their ability to capture long-term dependencies, akin to \\nlong-term memory. This issue can lead to degraded performance, \\nrendering RNNs impractical for large-scale applications. T o \\naddress this challenge, researchers have developed variants of \\nRNNs, such as long short-term memory (LSTM) networks and \\ngated recurrent units (GRUs). Both LSTMs and GRUs excel at \\ncapturing long-term dependencies, enabling the generation of \\nmore coherent and semantically meaningful text.\\nA\\nX2X1X0Xt Input\\nOutput\\nXt...\\n=A AAA\\n0t 00 01 02 0t\\nFIGURE\\xa02.14 A recurrent neural network unrolled.\\nXt-1 Xt+1Xt\\nAA\\nOutput\\nInput\\nOt-1 Ot+1Ot\\ntanh\\nFIGURE\\xa02.15 A standard RNN unit.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 83, 'page_label': '70'}, page_content='70 GENERATIVE AI\\nLSTMs typically outperform GRUs, making them the pre-\\nferred choice for many applications. As a result, we will bypass \\nGRUs and delve directly into LSTMs, looking at their capabili-\\nties and potential.\\nLong Short-Term Memory Networks\\nLong short-term memory (LSTM) networks first appeared on \\nthe AI scene in 1997, thanks to the innovative work of Sepp \\nHochreiter and Jürgen Schmidhuber, two researchers known for \\ntheir expertise in neural networks and deep learning. T oday, they \\ncontinue to be influential in the AI research community; Schmid-\\nhuber is the scientific director of the Dalle Molle Institute for \\nArtificial Intelligence Research in Switzerland.\\nAs previously mentioned, LSTMs are a specialized type of \\nRNN designed to tackle the vanishing gradient problem, which \\nplagues traditional RNNs in capturing long-term dependencies \\nwithin sequential data. While they outshine earlier models, \\nLSTMs are overshadowed by the more recent transformer archi-\\ntecture, which boasts unparalleled attention mechanisms.\\nLSTMs manage to maintain a cell state that selectively adds \\nor removes information, allowing the network to remember or \\nforget details over extended input sequences. This feat is accom-\\nplished through a system of gates that regulate the flow of infor-\\nmation into and out of the cell state. Figure\\xa0 2.16 depicts the \\ndetailed workings of an LSTM unit.\\nSince their inception, LSTMs have been employed in a vast \\narray of applications, such as machine translation, text classifica-\\ntion, and sentiment analysis. In text generation tasks, LSTMs \\nhave proven especially effective, generating coherent and seman-\\ntically meaningful text with fewer errors than earlier models.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 84, 'page_label': '71'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 71\\nLSTMs have been broadly adopted within the tech industry, \\nwith numerous companies utilizing them for natural language \\nprocessing applications. Google, for instance, has used LSTMs \\nin products like Google T ranslate and Google Assistant for lan-\\nguage translation and speech recognition. However, it is worth \\nnoting that more recently, LSTMs have been largely superseded \\nby more advanced systems, such as neural machine translation \\n(NMT). NMT specializes in language translation, with the neu-\\nral network being trained on vast corpora of parallel sentences to \\nlearn the relationships between words and phrases in source and \\ntarget languages.\\nOther areas where LSTMs have been the go-to AI model \\ninclude chatbot development, language modeling for speech rec-\\nognition, and speech synthesis. All in all, LSTMs have been an \\ninstrumental tool in natural language processing and have left a \\nlasting impact on the field since their introduction.\\nOutput\\ncurrent\\nOt\\nOt\\nOutput\\ncurrent\\nCurrent\\ncell state;\\nupdated\\n“memory”\\nCt\\nit\\n/uni03C3/uni03C3\\n×\\n×\\n+\\nft\\nOt\\nCtˆ\\nCt–1\\nXt\\nPrevious\\ncell state\\n“memory”\\nCandidate for\\ncell update\\nUpdated cell state\\nto help determine\\nnew hidden state\\nInput gate:\\nHow much emphasis do\\nwe give the new input info?\\nForget gate [0–1]: How much info\\nfrom previous output do we forget?\\nOutput gate: What info\\nshould the hidden\\nstate carry to the next state?\\nPrevious\\noutput Input\\n×\\ntanh\\ntanh\\n/uni03C3Ot-1\\nFIGURE\\xa02.16 An LSTM unit'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 85, 'page_label': '72'}, page_content='72 GENERATIVE AI\\nN-Gram Models\\nDelving into the annals of computer science and language mod-\\neling, one might find that the specific origins of n-gram models \\nremain shrouded in mystery. Nevertheless, it is widely acknowl-\\nedged that these models experienced a resurgence in popularity \\nduring the mid-2000s. Exhibiting a simplicity that is both elegant \\nand efficient, n-gram models operate by counting the frequency \\nof word sequences in a corpus of text and estimating their prob-\\nabilities. The models’ computational efficiency renders them an \\nattractive option for implementation in large-scale applications.\\nY et, like all things, n-gram models do have shortcomings. \\nChief among these are their inability to capture long-term \\ndependencies in text and their susceptibility to data sparsity and \\noverfitting. Despite these limitations, the models have been \\nemployed in an array of applications, ranging from voice assis-\\ntants like Siri, Alexa, and Cortana to keyword extraction, topic \\nmodeling, and sentiment analysis.\\nHowever, as the sands of time have shifted and more advanced \\nmodels have emerged, the once-prevalent n-gram models have \\ngradually receded into the background. Nonetheless, their \\nimpact on the development of natural language processing \\nshould not be understated, and they will forever remain an \\nimportant milestone in the rich tapestry of AI history.\\nSeq2Seq\\nVenturing deeper into the labyrinth of AI text generation, we \\narrive at the ingenious development of sequence-to-sequence \\n(Seq2Seq) models. Much like an architect who carefully con-\\nstructs a sturdy frame around the building’s core, Seq2Seq mod-\\nels ingeniously harness the power of other AI text generation \\nmodels, elevating them to a new level of sophistication and \\nefficiency.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 86, 'page_label': '73'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 73\\nThe foundations of the Seq2Seq model were laid in 2014\\xa0in \\na paper titled “Sequence to Sequence Learning with Neural \\nNetworks” by a group of trailblazing researchers from Google, \\nincluding Ilya Sutskever, Oriol Vinyals, and Quoc V . Le.4 As an \\nintriguing aside, Ilya Sutskever cofounded OpenAI and serves as \\nits chief scientist.\\nSeq2Seq models consist of two recurrent neural networks \\n(RNNs)— LSTMs and GRUs— working in tandem as an encoder \\nnetwork and a decoder network. With applications ranging from \\nmachine translation and text summarization to speech recogni-\\ntion, Seq2Seq models operate by using the encoder to transform \\nan input sequence into a fixed-size vector representation, aptly \\ndubbed the context vector. This vector serves as a concise sum-\\nmary of the input sequence, providing the foundation on which \\nthe decoder generates an output sequence (the text generation \\ncomponent). The training process hinges on minimizing a loss \\nfunction that quantifies the disparity between the predicted out-\\nput sequence and the ground truth.\\nAs with any great invention, there is always room for improve-\\nment. Enter the attention mechanism, introduced by Dzmitry \\nBahdanau, KyungHyun Cho, and Y oshua Bengio in 2015, which \\nbestowed upon the decoder the ability to focus on different seg-\\nments of the input sequence at varying time steps. This break-\\nthrough significantly enhanced the model’s context awareness. \\nT o distill this concept into its simplest form, imagine the decod-\\ner’s initial limitation: A single hidden state vector at the end of \\nthe encoder proved insufficient. The attention mechanism’s \\nsolution was elegant and effective; it provided as many hidden \\nstate vectors as there were instances in the input sequence, ena-\\nbling the decoder to process information with greater finesse and \\nprecision.\\n4Ilya Sutskever, Oriol Vinyals, and Quoc V . Le, “Sequence to Sequence Learning with Neural Networks,” Neu-\\nrIPS Proceedings, accessed November 27, 2023, https://proceedings.neurips.cc/paper/2014/file/a14ac55a4f \\n27472c5d894ec1c3c743d2- Paper.pdf'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 87, 'page_label': '74'}, page_content='74 GENERATIVE AI\\nIt becomes apparent that Seq2Seq models’ applications are \\nvast and varied. One such prominent application, which I touched \\nupon earlier, is Google T ranslate. Seq2Seq models are not limited \\nto LSTMs but can incorporate them, enabling the translation of \\none sequence or sentence in one language to another sequence \\nor sentence in a different language. Refer to Figure\\xa02.17 for a \\nzoomed-out view of the architecture of Seq2Seq models.\\nGoogle’s innovative streak does not end with translation. \\nThe tech giant has also harnessed the power of Seq2Seq models \\nto enhance the accuracy of speech recognition in Google Assis-\\ntant, among other applications. Meanwhile, chatbots and con-\\nversational agents have benefited greatly from Seq2Seq models, \\nwhich, when trained on a vast corpus of conversational data, gen-\\nerate responses that are more contextually appropriate and \\nnatural-sounding.\\nGoogle is not alone in recognizing the potential of Seq2Seq \\nmodels. Other tech behemoths, including Facebook, Microsoft, \\nand Amazon, have incorporated these models into their products \\nand services. However, Google has undoubtedly been a key driv-\\ning force in the development and popularization of Seq2Seq \\nmodels, with Google Brain hosting numerous leading research-\\ners in the field.\\nHe\\nEncoder\\nEmbed\\nloved to eat .\\nNULL\\nSoftmax\\nDecoderS\\nEr liebte zu essen\\nEr liebtez u essen .\\nFIGURE\\xa02.17 The big picture perspective of a Seq2Seq model.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 88, 'page_label': '75'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 75\\nComparing Seq2Seq models with their AI counterparts, \\nLSTMs excel at capturing long-term dependencies, while n-gram \\nmodels are faster to train but lack the ability to capture context as \\neffectively. Seq2Seq models, as a kind of meta-model, are specifi-\\ncally designed for sequence-to-sequence mapping tasks and can \\ngenerate more natural-sounding output. However, they require \\nmore data and fine-tuning.\\nThe Amazon AlexaTM 20B, a moderate-sized (20 billion \\nparameter) Seq2Seq language model, is likely the most powerful \\nSeq2Seq model to date. It outperforms the much larger GPT-3\\xa0in \\nlanguage translation and summarization, achieving state-of-the-\\nart performance in few-shot-learning tasks across all Flores- \\n101\\xa0language pairs. Despite its impressive capabilities, its release \\nin August 2022 did not cause the same stir in the AI community \\nas OpenAI’s ChatGPT did three months later. The reason behind \\nthis disparity in impact lies in the output quality: AlexaTM 20B’s \\noutput was not as impressive as ChatGPT’s. The intriguing  \\nreasons behind this discrepancy shall be unveiled later.\\nGANs for Text Generation\\nBefore delving into transformers, the cornerstone of state-of-\\nthe-art language generation models like GPT , let’s pause to take \\na look at GANs in text generation.\\nT o recapitulate, GANs for text generation operate in a fasci-\\nnating dance of deception and detection. The generator model \\nconcocts realistic text samples, aiming to dupe the discriminator \\nmodel into believing the text is genuine. Simultaneously, the dis-\\ncriminator model hones its ability to discern between authentic \\nand fabricated text samples. Through this iterative process, both \\nmodels evolve, refining their skills based on feedback from one  \\nanother.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 89, 'page_label': '76'}, page_content='76 GENERATIVE AI\\nSeveral GAN architectures have emerged specifically for text \\ngeneration, such as SeqGAN, MaliGAN, and T extGAN. Examin-\\ning T extGAN as a representative example offers valuable insights \\ninto the process of generating sequential data using GANs. T o \\nbetter grasp its inner workings, we must first address the unique \\nchallenges posed by the text’s discrete nature, which hinders the \\ndirect application of gradients from the discriminator to the gen-\\nerator. T extGAN adapts to these challenges in several ways:\\n• It converts both real and fake sentences into high-dimensional  \\nlatent feature distributions, transforming the discrete text \\nproblem into a continuous space. In layman’s terms, it maps \\nthe text onto a spectrum, smoothing out the rough edges \\nand making it more amenable to analysis.\\n• T extGAN employs a kernelized discrepancy metric called \\nreproducing kernel Hilbert space (RKHS) to gauge the dis-\\nparity between real and fake text samples. Simply put, it \\nmeasures the “distance” between the two, enabling the gen-\\nerator to better understand how to produce realistic text.\\nT o render the generator differentiable, T extGAN utilizes a \\nsoft-argmax operator and additional techniques like initializa-\\ntion strategies and discretization approximations. In essence, \\nT extGAN modifies the traditional GAN framework, overcoming \\nthe hurdles of text generation and producing more plausible and \\ncoherent text samples.\\nHowever, GANs’ potential for text generation is not without \\nlimitations. They can suffer from mode collapse, reducing the \\ngenerator model’s output range and stifling sentence variety. \\nFurthermore, GANs may generate nonsensical or irrelevant text \\nand can be difficult to train and optimize due to an unstable \\ntraining process.\\nIn the grand scheme of text generation, GANs are unlikely to \\nplay a pivotal role in the future.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 90, 'page_label': '77'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 77\\nAttention\\xa0– Transformer\\xa0– Self-Attention\\nThe intriguing tale of attention mechanisms in deep learning \\nunfurled with the publication of a seminal paper in 2016 titled \\n“Neural Machine T ranslation by Jointly Learning to Align and \\nT ranslate,”5 by Dzmitry Bahdanau, KyungHyun Cho, and Y oshua \\nBengio. Within the dense text of their paper, they introduced the \\nworld to the concept of the attention mechanism— an innovative \\nsolution to the problem of long-range dependencies in Seq2Seq \\nmodels. Imagine reading a lengthy novel with countless charac-\\nters and plotlines. The attention mechanism is akin to a well-\\nplaced bookmark, enabling you to keep track of important details \\nand navigate the narrative more efficiently. In the context of \\nSeq2Seq models, Bahdanau, Cho, and Bengio’s attention mecha-\\nnism operates like this literary bookmark, allowing the model to \\nfocus on different parts of the input sequence while generating \\nthe output, thereby attenuating the issue of long-range depend-\\nencies. This novel approach drastically enhanced the perfor -\\nmance of neural machine translation systems, setting a new path \\nfor future exploration in the field.\\nFast-forward to 2017, a year marked by another monumental \\nstride in AI research— a groundbreaking paper titled “Attention \\nIs All Y ou Need,” by Ashish Vaswani and his fellow researchers at \\nGoogle Brain and Google Research. 6 The paper proposed the \\ninnovative transformer architecture, making attention mecha-\\nnism its central pillar. In a way, it’s like shifting from a traditional \\nbook to an e-reader that allows you to highlight and annotate  \\nthe most crucial parts of the text. The attention mechanism in \\nthese models enables focusing on specific parts of the input to \\nmake accurate predictions, much like highlighting pivotal points \\nin a text.\\n5Dzmitry Bahdanau, KyungHyun Cho, and Y oshua Bengio, “Neural Machine T ranslation by Jointly Learning \\nto Align and T ranslate,” arXiv, May 19, 2016, https://arxiv.org/pdf/1409.0473.pdf\\n6Ashish Vaswani et\\xa0al. “Attention Is All Y ou Need,” NeurIPS Proceedings, accessed November 27, 2023, https://\\nproceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa- Paper.pdf'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 91, 'page_label': '78'}, page_content='78 GENERATIVE AI\\nSelf-attention, a specific variant of attention mechanism \\nemployed in the transformer architecture, functions somewhat \\nlike a photographic memory— it captures relationships between \\ndifferent parts of the input sequence, irrespective of their dis-\\ntance. This mechanism allows the model to “remember” infor -\\nmation from far-flung parts of the sequence and use that \\ninformation to create a better output.\\nA key advantage of the transformer architecture was its  \\nability to process input sequences in parallel, rather than sequen-\\ntially. It’s a bit like reading multiple chapters of a book simultane-\\nously without losing the narrative thread. This meant improved \\nefficiency and scalability, which in turn led to a rise in the popu-\\nlarity and application of transformer models.\\nSubsequently, transformers took the AI world by storm, rap-\\nidly emerging as the state-of-the-art architecture for an array of \\nNLP tasks, including machine translation, text summarization, \\nand language modeling. They outclassed existing RNN-based \\nmodels, as they effectively address the issues of long-range \\ndependencies, a problem that LSTM and RNN models grappled \\nwith. It’s like upgrading from an old typewriter to a modern \\ncomputer— the core concept remains the same, but the capabili-\\nties are vastly expanded.\\nTech Triumphs in\\xa0Text Generation\\nSince the advent of the self-attention mechanism, we have wit-\\nnessed an effusion of diverse LLMs, each bringing unique fea-\\ntures to the table. Among the most notable are OpenAI’s GPT \\nseries, Google’s BERT , T ransformer-XL from Google Brain, \\nFacebook’s BART , and T5 from Google Research. Subsequent \\nchapters will delve deeper into the intricacies of these different \\nmodels. However, for now, let’s focus on some key technical'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 92, 'page_label': '79'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 79\\naspects like tokenization, models being probabilistic, training, \\nfine-tuning, prompting, scaling laws, reinforcement learning \\nfrom human feedback (RLHF), emergent abilities, and more. \\nThese, in essence, form the backbone of these models, acting as \\nthe nuts and bolts that piece together the entire machinery of AI.\\nTokenization for LLMs\\nT okenization, in the context of language models, is akin to the \\nprocess of linguistic dissection. It involves the fragmentation of \\ninput and output texts into smaller, manageable units known as \\ntokens. These tokens could be as minute as characters, as standard \\nas words, or as nuanced as subwords and symbols. This process is \\nnot merely an act of division, but a means to a greater end. \\nT okenization is instrumental in enabling AI models to grapple \\nwith the diversity and complexity of human language, encom-\\npassing different vocabularies, languages, and formats. Moreo-\\nver, it allows for a significant reduction in computational and \\nmemory costs, thus boosting the efficiency of these models.\\nThe act of tokenization, however, is not a one-size-fits-all \\napproach. There are different methods of tokenization, such as \\nrule-based, statistical, or neural. The choice of method is deter -\\nmined by the complexity and variability of the texts being han-\\ndled. Rule-based methods, for instance, rely on predetermined \\nrules to tokenize text, whereas statistical methods look for com-\\nmon patterns and frequencies in the text. Neural methods, on \\nthe other hand, leverage the power of neural networks to under-\\nstand and segment text.\\nAmong these methods, OpenAI, the creator of this very \\nmodel you’re interacting with, has opted for a subword tokeniza-\\ntion method known as byte-pair encoding (BPE) for its GPT-based \\nmodels. BPE operates akin to a keen-eyed linguist, identifying \\nand merging the most frequently occurring pairs of characters or'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 93, 'page_label': '80'}, page_content='80 GENERATIVE AI\\nbytes into a single token. It’s important to note that the number \\nof tokens or the size of the vocabulary is not a constant across all \\nmodels; it varies, much like the models themselves.\\nT okenization inevitably impacts the amount of data and the \\nnumber of calculations a model is required to process. It’s a sim-\\nple equation: The more tokens a model has to juggle, the greater \\nthe demand on memory and computational resources. Conse-\\nquently, the cost of running a model is intrinsically linked to the \\ntokenization method employed, the size of the vocabulary, as \\nwell as the length and complexity of the input and output texts.\\nAs of February 2023, OpenAI’s Davinci model cost $0.06 per \\n1,000 tokens. T o illustrate, generating a summary for a 2,500-\\nword article, roughly 3,125 tokens, costs about $0.19. For a \\nbook-length text, the price rises to approximately $7.50. Scaling \\nup to an industrial operation, such as producing 100 books a day, \\ndaily costs hit $750, monthly around $22,500, and annually about \\n$270,000— only for tokenization, prediction excluded, and train-\\ning is a totally different topic. These estimates vary with factors \\nlike text length, complexity, and potential volume usage agree-\\nments. As impressive as AI models are, it’s important to under -\\nstand the underlying costs associated with their operation.\\nOutput Probability\\nLanguage models such as GPT , short for Generative Pre-trained \\nT ransformer, fundamentally operate as probabilistic models. A \\nprobabilistic model is a distinctive design that assigns probabili-\\nties to myriad possible outcomes.\\nT o delve deeper, we must turn our attention to the trans-\\nformer architecture, the underlying framework on which  \\nGPT and other LLMs are built. Herein lies the significance of \\nprobability.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 94, 'page_label': '81'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 81\\nAt its core, the principal duty of transformer-based language \\nmodels like GPT is to forecast the subsequent word or token in \\na sequence. Given a certain input, the model computes a proba-\\nbility distribution spanning the entire vocabulary for the follow-\\ning word. T ypically, the word boasting the highest probability is \\nchosen as the predicted outcome. Imagine feeding the model a \\nsequence such as “The cat is on the”; it then calculates the prob-\\nabilities for all conceivable succeeding words and may conclude \\nthat “roof   ” bears the highest probability. This process can be sig-\\nnificantly adjusted through the art of prompt engineering, an \\nintriguing topic that I’ll cover in more detail later in this chapter.\\nThis fundamental principle extends to entire sequences as \\nwell. The model is capable of computing the joint probability of \\na series of words by breaking it down into conditional probabili-\\nties. This clever mathematical maneuver is carried out using the \\nchain rule of probability, enabling the model to churn out sen-\\ntences that are not only coherent but also contextually appropriate.\\nDuring the training phase, the model tweaks its parameters \\nin a bid to maximize the likelihood of the training data. This \\nprocess, known as maximum likelihood estimation (MLE), entails \\nadjusting the model’s internal learnable parameters— weights \\nand biases— to ensure that the probabilities assigned to the actual \\nsucceeding words in the training data are as high as possible.\\nFinally, during the generation of new text, sampling methods \\nsuch as beam search, nucleus sampling, or top-k sampling lever-\\nage the probability distribution over the subsequent word to \\nproduce diverse and captivating outputs. While beam search \\nconsiders multiple possible sequences simultaneously and keeps \\nthe top few, nucleus sampling selects from a core group of most \\nlikely words, and top-k sampling chooses from the top ‘k’ prob-\\nable words. With that we make sure that instead of always opting \\nfor the word with the highest probability— a strategy that can'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 95, 'page_label': '82'}, page_content='82 GENERATIVE AI\\nlead to monotonous and deterministic text— the model might \\nsample from the distribution, resulting in more varied and crea-\\ntive outputs.\\nThus, while the cost of running such models may seem steep \\nat first glance, understanding the intricate play of probabilities in \\ngenerating coherent, creative, and contextually appropriate text \\nreveals the true value of these advanced AI systems.\\nPretraining LLMs\\nAs we journey through the world of LLMs, we find ourselves \\nencountering various stages of their training process. The initial \\ntraining phase— often referred to as pre-training— is where our \\nfocus now lies (Figure\\xa02.18).\\nWhen considering pre-training in the context of LLMs, two \\nbroad strategies stand out. The first approach, known as autore-\\ngressive training, is akin to predicting the next word in a sentence. \\nPre-training LLMs\\nPrompt Engineering\\nFine-tuning\\nRLHF\\n1\\n2\\n3\\nMust\\noptional\\nSpecific and quality\\ndataset needed\\nCarefully constructed\\nprompts needed\\nUsed to further\\nimprove the weights\\nGeneralSpecific\\nFIGURE\\xa02.18 The different stages of receiving a desired LLM output.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 96, 'page_label': '83'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 83\\nFor instance, given the phrase “I like to eat,” the model’s task is \\nto predict what comes next— perhaps “ice cream.”\\nThe second pre-training approach is called masked training. \\nHere, parts of the sentence are obscured or “masked,” and the \\nmodel must predict the missing elements. For instance, given  \\n“I like to [MASK] [MASK] cream,” the model would need to fill \\nin the gaps, possibly with “eat ice.”\\nIn addition to these primary pre-training tasks, there are aux-\\niliary ones that further refine the model. For instance, the next \\nsentence prediction (NSP) task requires the model to predict \\nwhether pairs of sentences appear consecutively in the training \\ncorpus. This aids in honing the model’s understanding of narra-\\ntive flow and coherence.\\nThe objective of all this training is to minimize a specific loss \\nfunction, often the average negative log-likelihood per token, \\notherwise known as cross-entropy loss. Think of it as a scoring sys-\\ntem: It measures how well the model’s predictions align with the \\nactual outcomes. If the model predicts “cake” when the sentence \\nis “I like to eat ice cream,” the cross-entropy loss will be high, \\nsignaling the model to adjust its internal parameters.\\nAnother concept that comes into play during training is regu-\\nlarization loss. It’s akin to a guiding hand that prevents the model \\nfrom overfitting or memorizing the training data. However, this \\nis typically applied during training and not considered during \\ntesting and evaluation.\\nThe scale of training datasets for LLMs is astoundingly large. \\nEarly LLMs, like GPT-1, cut their teeth on datasets such as Book-\\nCorpus, boasting a hefty 985\\xa0million words. BERT , another early \\nmodel, trained on a combination of BookCorpus and English \\nWikipedia, amassing a total of 3.3 billion words. With time, the \\nsize of these training corpora ballooned, reaching up to a stagger-\\ning trillions of tokens.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 97, 'page_label': '84'}, page_content='84 GENERATIVE AI\\nThere’s no denying that the computational cost of training \\nLLMs is high. But there is a silver lining. Over the years, thanks \\nto technology advancements and economies of scale, these costs \\nhave been steadily decreasing. Moore’s Law, despite being dec-\\nades old, still holds relevance in this context. It postulates that \\nthe number of transistors on a microchip doubles approximately \\nevery two years, which in turn drives down computing costs.\\nConsider this: The cost of training a 1.5 billion parameter \\nLLM in 2019\\xa0 was around $1.6\\xa0 million. Fast-forward to 2023, \\nand you could train a model with four times as many parame-\\nters— 6 billion— for the same price.\\nShifting our focus to larger models, GPT-3, which carries \\n175 billion trainable parameters, created a noteworthy shift in \\nthe cost landscape. The actual figure remains undisclosed by its \\nprogenitor, OpenAI, but estimates range between $5\\xa0million and \\n$12\\xa0million. As we leap forward to GPT-4, the details of its size \\nare still under wraps, yet the speculated costs of training such a \\nmodel oscillate between a hefty $100\\xa0million and $200\\xa0million. \\nThe path forward in AI is a costly one indeed, but given the vast \\npotential, it remains a worthy exploration.\\nFinally, it’s worth noting the cost difference between training \\nand inference (or using the model to make predictions) in  \\ntransformer-based LLMs. T raining costs about six floating point \\noperations (FLOPs) per parameter for each token, whereas infer-\\nence costs significantly less— just one or two FLOPs per param-\\neter per token. This roughly equates to a 4.5 to 1 ratio, making \\ninference more economical, whereas pre-training is the necessary  \\ninitial investment.\\nFine-tuning LLMs\\nT urning our attention to the next pivotal element of our AI jour-\\nney, we encounter the concept of fine-tuning language models. \\nThis process is akin to chiseling a masterful statue out of a crude'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 98, 'page_label': '85'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 85\\nslab of marble. Initially, pre-trained language models are exposed \\nto large, diverse corpora, absorbing language patterns and a \\nsomewhat profound understanding of the world and learning to \\nconstruct coherent text. This, however, is just the beginning.\\nWhen we engage in the fine-tuning process, the preexisting \\nparameters of our pre-trained model serve as our foundation. \\nSubsequent training is carried out on task-specific data, which \\nmight be annotated to illustrate the desired behavior or output \\nfor a specific task. Like a versatile tool, fine-tuning can be applied \\nto the entire neural network or just a subset of layers. Imagine \\nlocking some layers in place, their learning stalled, while others \\nadapt and evolve.\\nThis finely honed focus allows the language model to imbibe \\ntask-specific characteristics, vocabulary, and subtleties integral to \\nthe target application. The outcome? More precise, contextually \\nrelevant responses and heightened performance on niche NLP \\ntasks such as textual question answering within a corpus of com-\\nplex jargon, such as contracts and other legal documents.\\nA recurring theme in my myriad interactions at conferences \\nand dialogues with other thought leaders suggests a veering \\ntoward smaller, task-specific AI models. Echoing this sentiment \\nis Sam Altman, the CEO of OpenAI. Altman foresees an immi-\\nnent halt to the expansion of LLMs. His focus rests on augment-\\ning capability rather than simply inflating parameter count. If \\nsubstantial improvements can be attained via lesser parameters \\nor through an amalgamation of smaller models, so be it. There \\nare, after all, finite datacenters that companies like OpenAI can \\nconstruct— a limit to their pace of construction as well as financial  \\nrestrictions.\\nWhile full fine-tuning offers improved results, it’s not as \\nmuch as pre-training, a resource-intensive endeavor that’s sus-\\nceptible to overfitting. A fascinating piece of ongoing research \\nthat caught my attention was published in Nature under the title \\n“Parameter-Efficient Fine-T uning of Large-Scale Pre-T rained'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 99, 'page_label': '86'}, page_content='86 GENERATIVE AI\\nLanguage Models” by Ning Ding et\\xa0al.7, who propose a strategic \\nbalance between performance and efficiency when fine-tuning \\nlarge-scale pre-trained language models.\\nThey present an innovative method christened delta tuning, \\nwhich adjusts the pre-trained model by adding or tweaking a \\nsmall number of parameters. The striking results: delta-tuning \\nmethods have exhibited similar or even superior performance to \\nconventional fine-tuning methods while employing a mere \\n10–20 percent of the original parameters. The inherent prowess \\nof fine-tuning large-scale models, coupled with the resourceful-\\nness of delta tuning, paints an exhilarating picture of the poten-\\ntial locked within AI.\\nPrompt Engineering\\nNavigating the maze of AI innovations, one cannot help but \\nnotice the understated role of prompt engineering. This meth-\\nodology involves meticulously crafting or sculpting the prompts \\nor directions given to a generative model. The idea is to manipu-\\nlate the model’s output by molding the input information and \\ncontext. Certain keywords, phrases, or even the layout can be \\nwielded strategically to steer the model’s responses. The over -\\narching objective is to trigger a desired behavioral outcome, \\nheighten precision, or command the output style. It is no sur -\\nprise then that prompt engineering has come to be a trusted ally \\nin optimizing the performance of generative AI models for speci-\\nfied tasks. It also serves as a robust tool to counter biases and \\nfoster fairness in the produced output.\\nThe importance of prompt engineering is hard to overstate. \\nIt holds the potential to completely redefine the manner in which \\nwe interact with AI. By incorporating the best practices of \\n7Ning Ding et\\xa0al., “ Parameter-Efficient Fine-T uning of Large-Scale Pre-T rained Language Models,” Natural \\nMachine Intelligence, 5, 220–235 (2023), www.nature.com/articles/s42256- 023- 00626- 4'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 100, 'page_label': '87'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 87\\ncommunication between humans and machines, prompt engi-\\nneering allows machines to accurately interpret human instruc-\\ntions and provide valuable responses. Not only does it underscore \\na science in its own right, but it also has significant implications \\nfor the future job market.\\nWhile most of the scientific exploration of prompting is cen-\\ntered around language models, owing to their versatility in han-\\ndling text, it is important to note that image generation prompting \\nalso offers a wealth of techniques and guidelines.\\nChain-of-Thought (CoT) Prompting One of the more nota-\\nble advancements in the world of prompting is chain-of-thought \\n(CoT) prompting. Coined by researchers at Google in 2022, \\nCoT prompting enhances the reasoning ability of LLMs by \\nmaking them generate intermediate steps that lead to the final \\nanswer of a multistep problem. This methodology shows \\nmarked improvements with larger and more powerful language \\nmodels and can be fine-tuned on CoT reasoning datasets.\\nFew-Shot and Zero-Shot Prompting CoT reasoning can be \\ntriggered using two primary methods: few-shot prompting \\nand zero-shot prompting. Few-shot prompting (Figure\\xa02.19) \\nemploys at least one example of a question paired with  \\nappropriate human-written CoT reasoning, whereas zero-\\nshot prompting (Figure\\xa0 2.20) could be as uncomplicated as \\nappending “Let’s think step by step” to the prompt.\\nSelf-Consistency Prompting In our pursuit of improved \\nCoT reasoning for more complex problems, we come across \\nthe technique of self-consistency prompting. This method \\nentails supplying the AI model with multiple reasoning paths \\nor diverse perspectives, after which the most consistent and \\ncoherent answer among the generated responses is selected \\n(Figure\\xa02.21). Not only does self-consistency prompting help'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 101, 'page_label': '88'}, page_content='88 GENERATIVE AI\\ndiminish biases in the AI’s responses, but it also propels  \\nthe model to consider various viewpoints before reaching a \\nconclusion.\\nFIGURE\\xa02.19 Few-shot prompting.\\nSource: OpenAI\\nFIGURE\\xa02.20 Zero-shot prompting.\\nSource: OpenAI'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 102, 'page_label': '89'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 89\\nKnowledge Prompting Another significant tool in our prompt-\\ning toolkit is knowledge prompting. This technique involves \\nfeeding the AI model with extra information or knowledge to \\nenhance its performance on specific tasks. Such information, \\nwhich might provide context or background, can be embedded \\ninto the input prompt to assist the model in better understand-\\ning the task at hand. Knowledge prompting proves particularly \\nuseful for complex tasks requiring a deeper comprehension of \\nthe subject matter. However, it is of utmost importance to \\nmeticulously design and optimize prompts for specific use cases \\nto ensure optimal performance.\\nFIGURE\\xa02.21 Self-consistency prompting: same question asked multi-\\nple times, resulting in same answer.\\nSource: OpenAI'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 103, 'page_label': '90'}, page_content='90 GENERATIVE AI\\nKnowledge prompting isn’t haphazard; it follows a defined \\nprocess (Figure\\xa02.22). This begins with identifying the task or \\nproblem and understanding the AI model’s existing knowledge \\nto spot any gaps. Next, external knowledge sources are identified \\nand integrated, enhancing the model’s understanding. The \\nresultant knowledge-rich prompts are then refined to optimize \\ntask-specific performance. Following this, the AI’s output is eval-\\nuated, assessing the effectiveness of the prompts. The evaluation \\nprovides invaluable insights for further iterative improvements, \\nbeginning again from the first step, if required. This process \\nensures knowledge prompting serves as a robust tool to elevate \\nAI performance on complex tasks, each iteration bringing us \\ncloser to creating optimized knowledge prompts.\\nDirectional Stimulus Prompting In 2023, Li and his team \\nintroduced a novel prompting technique, directional stimulus \\nprompting, aiming to enhance the guidance provided to LLMs \\nin generating desired summaries. The process involves train-\\ning a manageable policy language model (LM) to generate a \\nstimulus or hint, marking an increasing trend in the use of \\nreinforcement learning (RL) to optimize LLMs. Figure\\xa02.23 \\noffers a comparative view of directional stimulus prompting \\nagainst conventional prompting. Notably, the policy LM, kept \\ncompact for convenience, is fine-tuned to generate hints that \\nefficiently navigate a black-box, frozen LLM toward the \\ndesired output.\\nKnowledge 1\\nKnowledge 2\\n...\\nKnowledge\\nGeneration AnswerKnowledge\\nIntegrationQuestion\\nFIGURE\\xa02.22 Generated knowledge prompting structure.\\nSource: https://arxiv.org/pdf/2110.08387.pdf'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 104, 'page_label': '91'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 91\\nReAct (Reason + Act) Prompting T aking things a notch \\nhigher, ReAct prompting merges reasoning and action tasks to \\namplify the capabilities of LLMs. The ReAct method inter -\\nleaves reasoning traces and task-specific actions to enhance the \\ndecision-making and comprehension abilities of LLMs. This \\napproach refines the model’s capacity to formulate action plans, \\nhandle exceptions, and source more information from external \\navenues. The prompts featured in ReAct are comprehensive \\nand multifaceted. They encompass few-shot task-solving trajec-\\ntories, which involve solutions that emerge after only seeing a \\nfew examples of a problem. Additionally, they also contain \\nhuman-written reasoning traces, providing insight into the \\nthought processes that led to certain conclusions or decisions. \\nFurthermore, the prompts detail specific actions taken and the \\nsubsequent environmental responses that arise due to these \\nactions, offering a clear picture of cause-and-effect relationships \\nin various scenarios. Outperforming the existing baselines in \\ndiverse tasks, ReAct demonstrates improved performance, \\nhuman interpretability, and trustworthiness. This will be espe-\\ncially important for robots.\\nFIGURE\\xa02.23 Directional stimulus prompting.\\nSource: https://arxiv.org/pdf/2302.11520.pdf'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 105, 'page_label': '92'}, page_content='92 GENERATIVE AI\\nFigure\\xa02.24 depicts the “ReAct” (Reason + Act) method. In \\nthis approach, “Act” signifies the decisions or actions undertaken \\nby the agent, while “Obs” stands for observations, highlighting \\nthe consequences or results of the said actions.\\nIt is important to acknowledge that prompting does have pit-\\nfalls. For instance, it opens the door to vulnerabilities and poten-\\ntially malicious use. An AI model can be exploited through \\nprompt injection— a technique that coerces a language model, \\nwhich is usually trained to follow human-given instructions, to \\ncomply with the instructions of a malicious user. The prompt \\ninjection can happen when instructions and data are mashed \\ntogether, rendering it challenging for the underlying system to \\ndifferentiate between the two.\\nAs we journey further into the world of AI, it is essential to \\napproach these innovations with an understanding of their \\npotential, but also their associated risks.\\nFIGURE\\xa02.24 ReAct prompting.\\nSource:\\xa02022 https://arxiv.org/pdf/2210.03629.pdf'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 106, 'page_label': '93'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 93\\nLLMs Until ChatGPT\\nThe release of GPT-2\\xa0in 2019 still stands out in my mind. OpenAI \\nmade an unprecedented move by initially withholding the full \\nmodel due to concerns about its potential misuse. Their decision \\nsparked extensive discussions about the responsible development \\nof AI and the delicate balance between harnessing benefits and \\nmitigating risks. OpenAI’s stance left me pondering— was this \\nsimply a marketing ploy, or did GPT-2 truly possess capabilities \\nthat warranted such caution?\\nGPT-2\\xa0 was more than a mere upgrade to its predecessor, \\nGPT . It was a quantum leap in terms of scale, boasting over 10 \\ntimes the parameters— with a mind-boggling count of 1.5 billion \\ntrainable parameters. T rained on an extensive dataset of 8\\xa0mil-\\nlion web pages, GPT-2 flexed its muscles by demonstrating a \\nbroad array of capabilities, including the generation of synthetic \\ntext samples of unprecedented quality.\\nSince the advent of GPT-2, countless LLMs have been \\ndeveloped, each with its own unique strengths. However, a few \\nLLMs have distinguished themselves from the crowd, demand-\\ning special mention.\\nJust over a year after the release of GPT-2, OpenAI unveiled \\nGPT-3\\xa0 in June 2020. This new iteration made GPT-2\\xa0 look \\nalmost modest in comparison, sporting not 10 times, but over \\n100 times the trainable parameters, amounting to a staggering \\n175 billion. Such a scale was unrivaled at the time of its release. \\nThis beast of a model was trained on roughly 570\\xa0GB of Internet \\ntext, and the results spoke for themselves. GPT-3\\xa0marked a sig-\\nnificant leap in language generation quality and has been \\nemployed in a variety of applications, including the generation of \\ncode snippets, regular expressions, and even Microsoft Excel \\nfunctions from simple text descriptions. Owing to its advanced \\ncapabilities, OpenAI opted to keep GPT-3 under wraps, grant-\\ning access only to a select few, and never open sourcing it.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 107, 'page_label': '94'}, page_content='94 GENERATIVE AI\\nReflecting on the landscape of LLMs in late 2020, the scene \\nwas not entirely monopolized by OpenAI. Google was also mak-\\ning waves with its research contributions. They introduced  \\nmodels such as the T ext-to-T ext T ransfer T ransformer (T5) and  \\nT ransformer-XL, which both had substantial impacts on the field. \\nThe T5 stood out with its unified, text-to-text framework, revolu-\\ntionizing how various NLP tasks were approached, whereas the \\nT ransformer-XL excelled in handling longer sequences of text, \\nproving its mettle in language modeling and text generation tasks. \\nDespite OpenAI’s dominance, it’s clear that other players, like \\nGoogle, have also played a significant part in shaping the pro-\\ngress of LLMs.\\nIn June 2021, Google introduced a model known as LaMDA. \\nThis LLM had 137 billion trainable parameters and was trained \\non an extensive dataset comprising 1.56 trillion words. LaMDA \\nwas not open source, but it was designed with a unique goal in \\nmind: to facilitate free-flowing conversations on a broad range of \\ntopics. This capability made LaMDA intriguing, as it suggested a \\nmove toward more naturalistic, dynamic human-computer \\ninteractions.\\nNot necessarily to facilitate natural conversations but rather \\ncode generation, OpenAI released Codex later in the same year. \\nThis model had fewer trainable parameters than LaMDA— 12 \\nbillion in total— but it was fine-tuned for a very specific task: \\nprogramming applications. Codex was trained on a vast array of \\nprogramming languages sourced from 54\\xa0million GitHub repos-\\nitories, making it a significant development in the realm of cod-\\ning automation. Like LaMDA, Codex was not made open source, \\nfurther illustrating the growing trend of proprietary LLMs.\\nGoogle made further strides in 2022\\xa0 with the release of \\nLaMDA 2. Unfortunately, not much is known about this model’s \\nspecifications due to Google’s decision to keep the details under'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 108, 'page_label': '95'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 95\\nwraps. This secrecy might seem unusual, but it is likely a strate-\\ngic move designed to maintain a competitive edge in the rapidly \\nevolving field of AI.\\nThe close of 2022 saw the arrival of Galactica, an LLM by \\nMeta. With 120 billion trainable parameters, Galactica was \\ntrained on 48\\xa0million examples taken from an assortment of sci-\\nentific articles, websites, textbooks, lecture notes, and encyclope-\\ndias. This model was not only open source but also specifically \\ndesigned to aid scientists in simplifying their research and accel-\\nerating the writing of scientific literature. Despite these ambi-\\ntious goals, Galactica received substantial criticism for generating \\nnonsensical and inaccurate information, as it was very good at \\nconfidently hallucinating facts and results. In response to this \\nbacklash, Meta removed the public demo after just three days \\nand temporarily halted the project. While the model remains \\naccessible to researchers interested in working with it or repli-\\ncating its results, this incident underscored the challenges that \\neven the most advanced AI can face.\\nDespite these exciting developments, we saw that even by the \\nend of 2023, LLMs had yet to make a truly transformational \\nimpact. The promise of these technologies is immense, but their \\npractical applications continue to evolve, often in unexpected \\nways. It’s clear that the journey of LLMs is far from over and \\ntheir potential to reshape our world remains largely untapped.\\nLLM Scaling Laws\\nThe advent of LLMs has brought forth a profound shift, akin to \\nthe tectonic movements shaping the landscape of a planet, subtly \\nyet inexorably altering the contours of the field. Among the \\nforces driving these changes, none are perhaps as influential as \\nthe phenomenon known as scaling laws.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 109, 'page_label': '96'}, page_content='96 GENERATIVE AI\\nScaling laws, in essence, delineate the relationship between \\nthe size of a model— its number of parameters— and the amount \\nof data it requires for optimal performance. Among these laws, a \\nset of findings known as the Chinchilla scaling laws, unearthed by \\nDeepMind in 2022, has proven especially instrumental in guid-\\ning the development of language models.\\nThe Chinchilla scaling laws assert that an optimal LLM \\nrequires approximately 20 text tokens per parameter. Compared to \\nthe earlier Kaplan scaling laws, which served as the guiding star for \\nOpenAI’s GPT-3 and suggested a requirement of 1.7 text tokens \\nper parameter, the Chinchilla laws signal a massive leap in data \\ndemands. For instance, to align GPT-3\\xa0with the Chinchilla laws, \\nthe model would either need to be pared down to 15 billion param-\\neters, using its original 300 billion tokens, or inflate its dataset to a \\nwhopping 3.5 trillion tokens, maintaining its original 175 billion \\nparameters. This implies an 11-fold surge in data requirements.\\nThe reach of the Chinchilla scaling laws extends to models of \\ngargantuan proportions, those measured in trillions of parame-\\nters and trained on petabytes of text data— a quantity equivalent \\nto quadrillions of text tokens. However, the quest to feed such \\ntitanic models presents a herculean challenge. As the number of \\nparameters begins to outstrip the number of unique published \\nbooks, sourcing sufficient data becomes an increasingly complex \\nendeavor. Privacy concerns, issues related to sensitive data, and \\nthe emerging trend of companies charging for data scraping \\nfrom platforms rich in user-generated content, such as Reddit \\nand Quora, all contribute to the complexity of this landscape.\\nPredictions for the year 2023 and beyond suggest a contin-\\nued adherence to the Chinchilla scaling laws among LLMs. \\nNevertheless, the area of data optimization and efficient data use \\nduring training remains a hotbed of research, with new discover-\\nies anticipated on the horizon.\\nFigure\\xa02.25 illustrates the dataset sizes necessary to conform \\nto the principles of Chinchilla data optimization across a range'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 110, 'page_label': '97'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 97\\nof model sizes. Alongside, it provides a concise summary of the \\nexisting models, capturing their tokens-to-parameters ratios.\\nT wo central conclusions can be drawn from this. First, \\nmerely ballooning the size of models in the coming years will \\nnot suffice. The need for a significantly larger pool of data and \\nthe development of smaller, more specialized models that excel \\nin specific tasks will become paramount. Prompt designing and \\nspecific datasets will play a critical role in enhancing perfor -\\nmance. Second, it is projected that the generation of data will \\nsee an exponential increase. According to IDC, the compound \\nannual growth rate of new data creation from 2020 to 2025 is \\nforecast at 23 percent, resulting in approximately 175 zetta-\\nbytes of new data. Coupled with increasingly affordable com-\\nputing resources, this will permit the expansion of model sizes \\nin a balanced manner.\\nChatGPT\\nDrawing upon the successful launch of ChatGPT on November \\n30, 2022, built atop the impressive framework of GPT-3.5, the \\nAI world experienced a monumental event. This was not merely \\nFIGURE\\xa02.25 Chinchilla scaling in table.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 111, 'page_label': '98'}, page_content='98 GENERATIVE AI\\nthe introduction of yet another AI model, but a revolution that \\nswept across the globe. With over 1\\xa0million users within its first \\nfive days, and a staggering 100\\xa0 million just two months post-\\nlaunch, the application became an unparalleled success. By Janu-\\nary 2023, the count of visits had skyrocketed to about 590\\xa0million.\\nThis global embracement wasn’t happenstance but rather a \\nmeticulously curated triumph. The brilliance of ChatGPT lies in \\nits sheer versatility, transforming words into a vast array of out-\\nputs, from articles, essays, and jokes, to job applications and \\npoetry. Its utility expanded across various sectors, aiding in draft-\\ning emails, writing code, creating written content, tutoring, \\ntranslating languages, and even simulating characters for video \\ngames. Its ability to generate human-like responses, coupled with \\nits versatility and precision, set it apart in the AI industry, making \\nit a vanguard of its time.\\nPropelled by the resounding success of ChatGPT , OpenAI \\nheld an enviable position in the AI industry, a first-mover advan-\\ntage that was not to be taken lightly. The substantial usage pro-\\nvided invaluable insights and feedback, instrumental in refining \\nand honing the chatbot’s responses.\\nHowever, the journey of ChatGPT was not without its share \\nof criticism. The potential for malicious use loomed large, with \\nconcerns over malware creation and phishing. The AI, in its \\nenormous capacity, also grappled with issues of potential copy-\\nright infringement, generating content that could be similar or \\nidentical to existing copyrighted material. Ethical concerns like \\nracism, sexism, and other biases also formed part of the discourse. \\nMoreover, the AI’s occasional inaccuracy, or “hallucinating,” led \\nto erroneous answers, including failures in basic math and logic \\nquestions.\\nY et, OpenAI’s resolve remained unshaken, grounded in its \\nmission to ensure that artificial general intelligence serves all of'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 112, 'page_label': '99'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 99\\nhumanity. It was a vision that acted as a beacon, illuminating the \\npath toward the development of more refined, responsible, and \\nbeneficial AI applications.\\nThis was clearly evident with the initial launch of ChatGPT . \\nWhile it wasn’t fully at the AGI level, the AI showcased  \\nan unprecedented level of complexity and understanding. It  \\nwas far from a simple mimic, merely echoing back predetermined \\nresponses.\\nT ransitioning toward the more practical aspects of its design, \\nChatGPT demonstrated a conscientious approach. It was hard-\\nwired to abstain from generating inappropriate content, showcasing \\nOpenAI’s commitment to ethical AI development. Further more, \\nthe model was designed with a knowledge cutoff in September \\n2021, creating a well-defined boundary to its awareness of world \\nevents beyond this date.\\nThe power of ChatGPT was continually enhanced through \\nan iterative system of upgrades and improvements, fueled by user \\nfeedback. This is known as reinforcement learning from human \\nfeedback (RLHF).\\nReinforcement Learning from\\xa0Human Feedback\\nThe concept of RLHF unfolded as a significant milestone in the \\nsphere of AI development. This technique, which marries rein-\\nforcement learning with human feedback, is essentially used to \\ntrain a “reward model.” Launched by OpenAI in the early days of \\n2020, it pioneered the use of human feedback to directly shape \\nthe reward function to optimize an agent’s policy using rein-\\nforcement learning. The approach involves a dynamic update of \\nthe model’s parameters based on the feedback received from \\nhumans, thus introducing a unique interactive element into the \\nlearning process.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 113, 'page_label': '100'}, page_content='100 GENERATIVE AI\\nThis innovative approach found its applications in various \\ndomains of natural language processing, such as conversational \\nagents, text summarization, and natural language understanding, \\nmaking the process of AI communication more refined and effec-\\ntive. ChatGPT , an exemplar of this advanced technique, was fine-\\ntuned using a combination of supervised learning and RLHF . A \\ncohort of human trainers was actively involved, providing crucial \\nfeedback on the model’s performance and ranking different model-\\ngenerated outputs based on their quality or correctness.\\nThis feedback was then transformed into a reward signal for \\nreinforcement learning, following which the model was fine-\\ntuned using proximal policy optimization (PPO) or similar algo-\\nrithms. PPO is an optimization technique used in reinforcement \\nlearning that helps to improve the policy (or decision-making \\nprocess) of an AI model while ensuring that the changes made \\ndon’t deviate too much from the previous policy. This ensures a \\nbalance between exploration and exploitation, allowing the \\nmodel to learn effectively without taking undue risks.\\nThis unique feedback collection and refinement process, \\nwhich is repeated iteratively, stimulates continuous improvement \\nin ChatGPT’s performance. RLHF offers several advantages in \\nthe development of AI systems, including improved performance, \\nadaptability, reduced biases, continuous improvement, and \\nenhanced safety. However, like any other process, it comes with its \\nown set of challenges, such as scalability, ambiguity and subjectiv-\\nity in human feedback, and long-term value alignment. There is a \\npotential for models to output harmful or factually inaccurate text \\nwithout any uncertainty. This puts into perspective the need for \\ncontinuous monitoring and refinement of such models to prevent \\nthe dissemination of misleading or harmful information. There is \\na pressing need for further research to gain a better understanding \\nof RLHF , improve its performance, and address these hurdles.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 114, 'page_label': '101'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 101\\nThis transformative approach is not limited to language mod-\\nels alone. It has also found applications in other areas, such as the \\ndevelopment of video game bots. Noteworthy examples of RLHF-\\ntrained language models include OpenAI’s ChatGPT and its pre-\\ndecessor InstructGPT , as well as DeepMind’s Sparrow. Sparrow, a \\nchatbot equipped with 70 billion trainable parameters, adheres to \\nthe Chinchilla scaling laws and is trained accordingly. However, its \\napplication appears to be largely confined to the realm of videos, \\ngiven its closed source nature.\\nIn the grand scheme of things, RLHF has emerged as an out-\\nof-the-box approach in AI training that has proven pivotal in the \\ndevelopment of advanced LLMs. It is a testament to the impor -\\ntance of investing in further research and development of tech-\\nniques like RLHF to ensure the creation of AI systems that are \\nnot only powerful but also aligned with human values and \\nexpectations.\\nEvaluation of\\xa0Large Language Models\\nThe evaluation of LLMs is a critical aspect of AI development. It \\nprovides a measure of the model’s performance, accuracy, and \\nreliability, which are essential for ensuring the quality of the AI’s \\noutput and its suitability for various applications.\\nLLMs can be assessed using benchmark datasets, which pro-\\nvide scores that serve as numerical indicators for comparison \\nacross different models. However, it’s important to note that the \\nperformance of these models is often influenced by minor imple-\\nmentation details. Consequently, it can be challenging to expect \\nresults from one codebase to transfer directly to another.\\nT o address these issues, several approaches have been pro-\\nposed. EleutherAI, a nonprofit AI research lab known for its \\nwork on models like GPT-Neo and GPT-J, has introduced the'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 115, 'page_label': '102'}, page_content='102 GENERATIVE AI\\nLM Evaluation Harness. This unifying framework allows any \\ncausal language model to be tested on the same exact inputs and \\ncodebase. This not only provides a ground-truth location for \\nevaluating new LLMs but also saves practitioners time imple-\\nmenting few-shot evaluations repeatedly, ensuring that their \\nresults can be compared against.\\nAnother intriguing approach is the evaluation of LLMs with \\nLLMs. This method involves comparing and ranking the results \\nagainst a baseline or other LLMs, providing valuable insights \\ninto the relative strengths and weaknesses of each model.\\nPerplexity, a commonly used measure of a language model’s \\nperformance, is another approach. It gauges how well a model \\npredicts the contents of a dataset. In simple terms, a model with \\nlower perplexity has a higher likelihood of accurately predicting \\nthe dataset’s content, making it a valuable tool for evaluating  \\nLLMs.\\nT ask-specific datasets and benchmarks have also been devel-\\noped to evaluate the capabilities of language models on more \\nspecific downstream tasks. These tests may evaluate a variety of \\ncapabilities, including general knowledge, common sense rea-\\nsoning, and mathematical problem-solving.\\nQuestion-answering datasets, which consist of pairs of  \\nquestions and correct answers, are another version of this. A \\nquestion-answering task is considered “open book” if the model’s \\nprompt includes text from which the expected answer can be \\nderived; otherwise, the task is considered “closed book,” and the \\nmodel must draw on knowledge retained during training.\\nT ext completion is another form of evaluation, where the \\nmodel selects the most likely word or sentence to complete a \\nprompt. Composite benchmarks, such as GLUE, SuperGLUE, \\nMMLU, BIG-bench, and HELM, combine a diversity of differ-\\nent evaluation datasets and tasks.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 116, 'page_label': '103'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 103\\nThere are also adversarially constructed evaluations, which \\nfocus on particular problems on which extant language models \\nseem to have unusually poor performance compared to humans. \\nExamples include the T ruthfulQA dataset and the Swag and its \\nsuccessor, HellaSwag.\\nHowever, the rapid pace of improvement of LLMs presents \\nchallenges in evaluation. Due to the swift saturation of existing \\nbenchmarks by state-of-the-art models, which often exceed the \\nperformance of human annotators, there is a continuous need to \\nreplace or augment the benchmark with more challenging tasks. \\nThis highlights the dynamic nature of AI development and the \\nneed for ongoing refinement in evaluation methods.\\nIt’s undeniable that the development of large AI models has \\nseeped into the strategic consciousness of numerous companies. \\nEntities such as Stanford, OpenAI, DeepMind, and Hugging Face \\ncome to mind when contemplating organizations that are stead-\\nfast in their pursuit to comprehend, enhance, and detoxify LLMs. \\nThese strides are more than mere indications of the prowess of \\nthese entities; they signify promising leaps toward the responsible \\nusage of these potent tools. Some selected observations:\\n• Stanford University has reported that LLMs can generate \\nhigh-quality legal content and predict court decisions with \\nreasonable accuracy. They are committed to studying these \\nissues and developing guidelines for the responsible \\nuse of LLMs.\\n• OpenAI is actively working on techniques to make LLMs \\nrefuse inappropriate requests. They are also investing in \\nresearch aimed at reducing harmful and untruthful outputs \\nfrom these models.\\n• DeepMind has pointed out the limitations of current detoxi-\\nfication methods, such as the risk of overgeneralization and'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 117, 'page_label': '104'}, page_content='104 GENERATIVE AI\\nthe difficulty in defining what constitutes harmful content. \\nThey are committed to further research in this area to \\nimprove the safety and fairness of LLMs.\\n• Hugging Face employs a combination of crowd-sourcing \\nand expert review to assess the fairness and inclusivity of \\ntheir models. They are also in the process of developing \\ntools that would allow users to customize the behavior of \\ntheir models.\\n• The increasing capabilities of LLMs in various fields, includ-\\ning science and law, suggest a future where these models \\ncould significantly accelerate research and development in \\nthese areas.\\n• The focus on benchmarking and evaluation methods indi-\\ncates a future where the performance and behavior of LLMs \\nare more transparent and accountable.\\nGPT-4\\nGPT-4, stepping up from the legacy of GPT-3.5, is a robust, \\nmultimodal model that surpasses previous versions in nearly \\nevery aspect. Its superior performance is undeniably impressive, \\nbut what truly sets it apart are the additional functionalities it \\nintroduces.\\nOne of the most striking features of GPT-4 is its creativity. \\nIt’s more creative and collaborative than ever before. Whether \\nit’s composing songs, writing screenplays, or learning a user’s \\nwriting style, GPT-4 can generate, edit, and iterate on creative \\nand technical writing tasks with a level of finesse that is truly \\nremarkable.\\nAnother significant advancement is in the area of extended \\noutputs and context inputs. GPT-4 is capable of accepting long \\ncontextual input information. It can handle up to 32,000 tokens, \\nwhich is roughly equivalent to 43,000\\xa0words, or about half of a'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 118, 'page_label': '105'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 105\\n270-page book. This capability opens up a world of possibilities \\nfor more complex and nuanced interactions with the model.\\nMultimodality in AI and GPT-4’s Multimodal Advancement\\nIn the realm of AI, the term multimodal refers to models that can \\nprocess more than one type of input, such as text, images, audio, \\nand video. GPT-4 takes a significant leap in this direction by \\naccepting images as input and generating captions, classifica-\\ntions, and analyses with meticulous detail. See, for example,  \\nFigure\\xa02.26. The implications of this are profound, as it opens \\nup a new frontier for AI applications, from content moderation \\nand targeted advertising to more nuanced interactions with \\nAI models.\\nFIGURE\\xa02.26 The multimodal capabilities of GPT-4 allow it to compre-\\nhend the content of an image. Moreover, it possesses a sufficient \\nunderstanding of the world to recognize when the events depicted in \\nthe image are out of the ordinary.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 119, 'page_label': '106'}, page_content='106 GENERATIVE AI\\nThe idea of multimodality extends beyond text and images. \\nIt encompasses audio and video streams, and even data from \\ndevices measuring physiological parameters such as heart rate or \\nblood sugar levels. In essence, any mode of data could be relevant \\nto an AI model, depending on the use case. This multimodal \\ncapability can significantly enhance the capabilities and applica-\\ntions of AI models.\\nConsider a social media post, for instance. A multimodal AI \\ncould analyze both the text and images in the post to understand its \\ncontent more fully. This could be used in content moderation, sen-\\ntiment analysis, or targeted advertising. Similarly, in e-commerce, a \\nmultimodal AI could analyze both product descriptions and cus-\\ntomer reviews to make more accurate product recommendations.\\nThe potential applications are not limited to these examples. \\nIn healthcare, a multimodal AI could analyze both medical imag-\\ning data and patient records to assist in diagnosis or treatment \\nplanning. In the realm of autonomous vehicles, a multimodal AI \\ncould process data from various sensors, such as cameras, radar, \\nand lidar, to navigate safely. The possibilities are vast, and the \\nopportunities for startups and companies are immense. The sky is \\nindeed the limit!\\nWhile the concept of multimodality is not new, OpenAI has \\nmanaged to make it work well, though there is still room for \\nimprovement. Other notable contributions in this field include \\nthe Multimodal-CoT model with 738\\xa0million trainable parame-\\nters, released by Amazon Science in February 2023. This open \\nsource model garnered attention for its strong performance on \\nvarious multimodal tasks, incorporating both language (text) and \\nvision (images), for now, into a two-stage framework.\\nAmazon Science, a division of Amazon, is at the forefront of \\nresearch and innovation in various fields, including machine \\nlearning, robotics, operations research, and cloud computing. \\nTheir goal is to apply cutting-edge scientific research to create'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 120, 'page_label': '107'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 107\\nnew technologies, improve services, and enhance the customer \\nexperience. They have made significant strides in multimodal \\nresearch, as evidenced by their contributions.\\nIn one paper, Amazon Science trained a model that used vis-\\nual information to ground speech recognition in videos. The \\nmodel improved word error rate (WER) performance by up to \\n18 percent over subword prediction models, and incorporating \\nvisual information further improved performance.8\\nIn another paper, they addressed the problem of learning \\nproduct similarity for real-world data from the Amazon catalog. \\nThe model used the image as the primary source of information, \\nwith the title helping the model focus on relevant regions in the \\nimage. The model achieved up to a 10 percent improvement in \\nprecision compared to state-of-the-art multimodal benchmarks \\nand effectively scaled across multiple product categories.9\\nThe release of GPT-4, with its multimodal capabilities, is a \\nsignificant milestone. Although not the first to implement these \\nfeatures, OpenAI, much like Apple, has a knack for delivering \\noutstanding capabilities when they do. The demo of GPT-4\\xa0was \\nunparalleled, leveraging its unmatched text generation capabili-\\nties to set a new standard in the field of AI. This is just the begin-\\nning, and the future holds even more exciting possibilities.\\nEmergent Capabilities of GPT-4\\nThe grand reveal of GPT-4\\xa0was more than a spectacle; it was a \\ntestament to a significant leap in AI capabilities. These capabili-\\nties, known as emergent abilities, were not explicitly programmed \\nbut surfaced during the training process. As we delve into the \\n8Georgios Paraskevopoulus et\\xa0al. “Multiresolution and Multimodal Speech Recognition with T ransformers,” \\nAmazon Science, 2020, www.amazon.science/publications/multiresolution- and- multimodal- speech- recognition-  \\nwith- transformers\\n9Nilotpal Das et\\xa0 al. “MAPS: Multimodal Attention for Product Similarity,” Amazon Science, 2022, www \\n.amazon.science/publications/maps- multimodal- attention- for- product- similarity'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 121, 'page_label': '108'}, page_content='108 GENERATIVE AI\\nremarkable capabilities of GPT-4, let’s first explore the concept \\nof emergent abilities, a pivotal element in our journey toward \\nartificial general intelligence (AGI).\\nEmergent abilities in AI are like unexpected gifts. They are \\nskills or capabilities that aren’t directly coded into the system but \\nemerge, almost magically, as the system learns and processes \\ninformation. These abilities surface as the large language models \\n(LLMs) are scaled up, without any specific training or architec-\\ntural modifications for these tasks. They appear in rapid and \\nunpredictable ways, demonstrating the power of LLMs to learn \\nand adapt simply by observing natural language, and visual input \\nin some cases.\\nThese abilities are the result of the system’s capacity to com-\\nbine and extrapolate from simpler learned behaviors or rules, \\nwhich it has gleaned from the data it was trained on. Essentially, \\nemergent abilities are unexpected skills that the system develops \\norganically through its learning process.\\nExamples of these abilities are diverse and impressive. They \\ninclude answering questions, summarizing passages, guessing a \\nmovie from an emoji sequence, and performing multistep rea-\\nsoning. LLMs can also understand the sentiment or emotion \\nconveyed in a piece of text, generate original stories, screenplays, \\nor even poetry, and check the veracity of a statement by cross-\\nreferencing it with the information they were trained on. Other \\nnotable abilities include advanced empathy modeling, real-time \\ntranslation, cultural understanding, ethical decision-making \\nguidance, historical analysis, and performing arithmetic.\\nOpenAI tested GPT-4’s capabilities using simulated real-\\nworld exams. The model’s performance on various benchmarks, \\nincluding exams designed for humans, was nothing short of \\nastounding. It’s important to note that GPT-4\\xa0wasn’t specifically \\ntrained for these exams. It had only seen a minority of the'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 122, 'page_label': '109'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 109\\nproblems during training. Y et, the results were representative, \\nand they were impressive.\\nFor instance, GPT-4 didn’t just pass the notoriously complex \\nUniform\\xa0Bar Exam; it scored in the top\\xa010 percent of test takers. \\nSimilarly, it exceeded the passing score on the United States \\nMedical Licensing Examination (USMLE) by over 20 points, \\noutperforming not only earlier general-purpose models but also \\nmodels specifically fine-tuned on medical knowledge. In the \\nrealm of mathematics, GPT-4 scored a 4 out of 5 on the Advanced \\nPlacement Calculus BC exam, a significant improvement over \\nChatGPT’s (GPT-3.5) score of 1 (see Figure\\xa02.27).\\nHowever, GPT-4’s performance was not flawless. It strug-\\ngled with the advanced LeetCode exam, a test that prepares \\ndevelopers for technical interviews, especially for those aiming \\nFIGURE\\xa02.27 GPT-4 of simulated exams. Additional visual information \\nhelps the model to perform better on the exams.\\nSource: OpenAI / https://openai.com/research/gpt-4.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 123, 'page_label': '110'}, page_content='110 GENERATIVE AI\\nto join the ranks of the MAANG (Meta, Amazon, Apple, Netflix, \\nGoogle). This serves as a reminder that while AI has come a long \\nway, there are still areas where it struggles.\\nInterestingly, one such area is abstract creativity. Despite its \\nremarkable capabilities, GPT-4\\xa0has been noted to be “incapable \\nof abstract creativity.” This suggests that there are still facets of \\nhuman intelligence where we outshine our AI counterparts. It’s a \\nhumbling reminder that while we continue to push the bounda-\\nries of AI, there’s still much to learn and explore.\\nGPT-4 also exhibits steerability, the ability to change its per-\\nsonality and behavior based on user prompts (Figure\\xa02.28). This \\nallows for a more personalized and engaging interaction. Rather \\nthan the classic ChatGPT personality with a fixed verbosity, \\ntone, and style, you can now prescribe their AI’s style and task by \\ndescribing those directions in the “system” message.\\nThese system messages, along with contextual information \\nand other parameters like a goal, tone, and so forth, are opening \\nup new marketplaces where people can buy and sell effective \\nprompts, prompt patterns, and meta prompts. This is an exciting \\ndevelopment, as it opens up a whole new world of possibilities \\nfor customization and personalization of AI systems. It’s like hav-\\ning your own personal AI assistant that can be tailored to your \\nspecific needs and preferences. The future of AI is not just about \\nmore powerful models, but also about more personalized and \\nuser-friendly experiences.\\nOther Large Models and Specific Models\\nThe year 2023\\xa0marked a significant surge in the number of capable \\nAI models. Companies such as Berkeley, Stability AI, EleutherAI, \\nT ogether, Microsoft, and NVIDIA, to name a few, unveiled their \\nmodels. Each of these models was designed with a specific objective \\nin mind, from providing medical reasoning to supporting coding.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 124, 'page_label': '111'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 111\\nThese models, both small and large, have demonstrated their value \\nin various ways. T o illustrate this, consider Stanford’s Alpaca and \\nBloombergGPT .\\nStanford’s Alpaca is a fascinating example of an instruction-\\nfollowing language model. It was fine-tuned from Meta’s LLaMA \\n7B model, which itself was trained on 52,000 instruction-  \\nfollowing demonstrations generated using OpenAI’s GPT-3.5. \\nThis process of one model fine-tuning another exemplifies the \\npotential of diverse data sources in AI development.\\nFIGURE\\xa02.28 Steerability example of GPT-4 as a Socratic tutor.\\nSource: OpenAI / https://openai.com/research/gpt-4.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 125, 'page_label': '112'}, page_content='112 GENERATIVE AI\\nThe instruction-following demonstrations were generated \\nusing the self-instruct method. This involved using 175 human-\\nwritten instruction-output pairs from the self-instruct seed set. \\nIn simpler terms, this means that the model was trained using a \\nset of instructions and their corresponding outputs, which were \\nprovided by humans. This method allowed the model to learn \\nhow to follow instructions and generate appropriate outputs.\\nOne of the most striking aspects of Alpaca is its cost- \\neffectiveness. The generation pipeline was simplified, and the \\ncost was significantly reduced. This resulted in 52,000 unique \\ninstructions and corresponding outputs, costing less than $500 \\nusing the OpenAI API. Fine-tuning a LLaMA 7B model took \\nonly threes hours on eight 80\\xa0GB A100s, costing less than $100 \\non most cloud compute providers. Figure\\xa02.29 shows the Alpaca \\nmodel development process.\\nDespite its size, Alpaca exhibits many behaviors similar to \\nthose of OpenAI’s GPT-3.5, making it surprisingly powerful and \\nLLaMA 7BText-davinci-003\\n175 Self-\\nInstruct\\nseed tasks\\nModified Self-instruct\\nInstruction Generation\\nSupervised\\nFinetuning \\nInstruction: Brainstorm a list of\\npossible NewYear’s resolutions.\\nOutput:\\n- Lose weight\\n- Exercise more\\n- Eat healthier \\nAlpaca 7B 52K\\nInstruction-following\\nexamples \\nExample seed task\\nInstruction: Brainstorm creative\\nideas for designing a conference\\nroom.\\nOutput:\\ncomponents, such as moveable\\n... incorporating flexible\\nwalls and furniture ...\\nExample Generated task\\nFIGURE\\xa02.29 The Alpaca model development process: starting with a \\nseed set of human-written instructions, expanding it using text-\\ndavinci-003, and fine-tuning the LLaMA models using Hugging Face’s \\ntraining framework.\\nSource: https://crfm.stanford.edu/2023/03/13/alpaca.html. (a) OpenAI and (b) Meta.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 126, 'page_label': '113'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 113\\neasy to reproduce. However, it still exhibits some of the classic \\nlimitations of instruction-following models, such as toxicity, hal-\\nlucinations, or stereotypes.\\nThe researchers behind Alpaca believe that releasing the train-\\ning recipe, data, model weights, and training code incurs minimal \\nfurther risk, given the simplicity of the recipe. They see this as a \\nsignificant step toward reproducible science. However, it’s impor-\\ntant to note that Alpaca is intended only for academic research, \\nand any commercial use is prohibited.\\nMoving on to BloombergGPT , this model was developed by \\nBloomberg and has been specifically trained on a wide range of \\nfinancial data. It is a 50 billion-parameter LLM that is purpose-\\nbuilt from scratch for finance. BloombergGPT can evaluate \\nfinancial data in real time, including market data, breaking news, \\nfinancial research, and advanced analytics. It can perform tasks \\nsuch as sentiment analysis, news classification, and question-\\nanswering, among others.\\nBloombergGPT is designed to enhance Bloomberg’s current \\nfinancial NLP capabilities and open up fresh possibilities for \\norganizing the enormous amounts of data available on the \\nBloomberg T erminal. For those unfamiliar, the Bloomberg T er-\\nminal is a computer software system provided by Bloomberg L.P . \\nthat enables professionals in finance and other industries to \\naccess Bloomberg’s professional services, including real-time \\nfinancial data, news feeds, and messages, and also to place trades.\\nThe model is trained on Bloomberg’s extensive archive of \\nfinancial data, which has been meticulously collected and curated \\nover 40 years. This makes BloombergGPT unique as it is trained \\non highly specific financial data, which is expected to make it \\nmore effective for financial NLP tasks. However, Bloomberg-\\nGPT is only accessible within Bloomberg and will be used to \\nprocess large amounts of data on Bloomberg T erminal.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 127, 'page_label': '114'}, page_content='114 GENERATIVE AI\\nThe release of BloombergGPT is part of a trend of companies \\ndeveloping their own LLMs, tailored to their specific needs and \\ndata. This trend is not just a passing fad, but a significant shift in \\nthe AI landscape. Many companies have already announced their \\ninterest in following suit, indicating that the future of AI is not just \\nabout more powerful models, but also about more personalized \\nand user-friendly experiences.\\nApplications of\\xa0Specific Language Models\\nLet’s consider a few more sectors where these models could be \\nand in fact are leveraged to great effect.\\nIn the realm of healthcare, hospitals and healthcare providers \\ncould develop a language model trained on medical literature \\nand patient data (while respecting privacy laws) to assist doctors \\nin diagnosing diseases or suggesting treatments. Imagine a  \\n“MayoClinicGPT” that could interpret patient symptoms and \\nmedical history, suggest potential diagnoses, and even generate \\npatient-friendly explanations of complex medical conditions. \\nThis is not a far-fetched idea. K Health, for instance, has devel-\\noped an AI-driven platform that uses anonymized health data to \\nprovide personalized medical information.\\nIn the legal sector, law firms might create a language model \\ntrained on legal texts and case law to assist in legal research or \\ndrafting legal documents. A “LegalGPT” could help lawyers to \\nquickly find relevant case law, draft legal documents, and even \\npredict the outcome of legal cases based on historical data. Har-\\nvey AI, a UK-based company, has developed an AI model for the \\nlegal sector that uses AI to automate legal processes, making it \\neasier for lawyers to manage their workloads and focus on more \\ncomplex tasks, utilizing their core competencies.\\nEducation is another sector ripe for AI intervention. Educa-\\ntional institutions or e-learning platforms could create a language \\nmodel trained on educational content to provide personalized'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 128, 'page_label': '115'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 115\\nlearning experiences. Khan Academy, for instance, has partnered \\nwith OpenAI to create an AI model for education. This model, \\n“Khanmigo,” is designed to provide personalized learning experi-\\nences, making education more accessible and effective.\\nIn the retail sector, e-commerce companies might develop a \\nlanguage model trained on product descriptions and customer \\nreviews to improve product recommendations or customer ser -\\nvice. An “AmazonGPT” could be used to generate accurate prod-\\nuct recommendations, answer customer queries, and even predict \\nfuture shopping trends.\\nInsurance companies could develop a language model trained \\non insurance claims and policy data to streamline the claims pro-\\ncess and provide personalized policy recommendations. For exam-\\nple, a “StateFarmGPT” could be used to interpret insurance \\nclaims, suggest policy adjustments, and even generate customer-\\nfriendly explanations of complex insurance terms. MetLife, for \\ninstance, is using AI to streamline the claims process and provide \\npersonalized policy recommendations.\\nIn the real estate sector, firms might create a language model \\ntrained on property listings and market data to assist in property \\nvaluation or predicting market trends. A “ZillowGPT” could \\nhelp real estate agents to quickly find comparable properties, \\nestimate property values, and even predict future real estate mar-\\nket trends. Skyline AI, a real estate investment technology com-\\npany, uses AI to enhance the property investment process.\\nT ravel agencies and hospitality companies could develop a \\nlanguage model trained on travel guides and customer reviews to \\nprovide personalized travel recommendations. Allora, a travel \\ntechnology company, has developed an AI-driven platform for \\nthe hospitality industry that uses customer reviews and travel \\nguides to provide personalized travel recommendations.\\nIn the media and entertainment sector, companies could cre-\\nate a language model trained on scripts, reviews, and audience \\ndata to assist in content creation and audience targeting. A'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 129, 'page_label': '116'}, page_content='116 GENERATIVE AI\\n“NetflixGPT” could be used to suggest plot ideas, predict audi-\\nence preferences, and even generate promotional content.\\nConsider the telecommunications sector. Here, AI models \\ncould be a game changer. Imagine a “VerizonGPT ,” trained on \\nnetwork data and customer feedback, working tirelessly to \\nenhance network performance and customer service. It could \\npredict network issues before they occur, suggest improvements, \\nand even demystify complex telecom terms for customers. This \\nisn’t just speculation— McKinsey reports that AI is already trans-\\nforming telco service operations, with models predicting net-\\nwork issues, recommending improvements, and simplifying \\ncomplex telecom jargon.\\nIn the energy sector, companies might develop a language \\nmodel trained on energy usage data and research to improve \\nenergy efficiency and develop new energy solutions. An “Exxon-\\nMobilGPT” could be used to analyze energy usage trends, sug-\\ngest energy-saving measures, and even predict future energy  \\ntrends.\\nThink food and beverages, and imagine the transformative \\npower of AI. Envision a “CocaColaGPT ,” an AI model trained \\non a rich blend of recipe data and customer reviews. It’s stirring \\nup new beverage ideas, responding to customer queries with \\nease, and even forecasting the next big trends in food and bever-\\nages. This isn’t a futuristic dream— it’s already happening. For \\nexample, McCormick & Company is using AI to create an excit-\\ning array of new flavors and food products.\\nPharmaceutical companies could develop a language model \\ntrained on medical research and clinical trial data to assist in drug \\ndiscovery and development. A “PfizerGPT” could be used to \\ninterpret research findings, suggest potential drug candidates, \\nand even generate patient-friendly explanations of complex \\nmedical research.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 130, 'page_label': '117'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 117\\nPicture the aerospace industry, where AI could take flight in \\na big way. Companies could harness a language model like, for \\nexample, “SpaceXGPT ,” trained on aerospace engineering data \\nand research, to turbocharge the design and development of air-\\ncraft and spacecraft. This AI co-pilot could assist engineers in \\nswiftly locating pertinent research, sparking innovative design \\nideas, and even forecasting the trajectory of aerospace projects \\nbased on historical data.\\nThe potential for AI model applications across industries is \\ninfinite. Y et, it’s worth noting that some of the strategies I’ve dis-\\ncussed are already being implemented by ChatGPT plug-ins. \\nWe can anticipate not just a tenfold increase in productivity, but \\nalso a tenfold enhancement in experience. The horizon of AI \\nholds promise for even more thrilling advancements in the \\nyears to come.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 131, 'page_label': '118'}, page_content=''),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 132, 'page_label': '119'}, page_content='119\\nT\\nhis chapter offers a concise exploration of generative AI’s \\ndiverse applications, highlighting how the technology is \\nreshaping industries from music to 3D object generation. The \\nconcept of “finding the untapped” is an observed strategy for \\nuncovering and leveraging gen AI’s vast potential.\\nFoundational and Specialized AI Models, and \\nthe Question of Open Source vs. Closed Source\\nJust as the Internet has become a fundamental part of the opera-\\ntions of most companies, we are witnessing a similar transition \\nwith AI. We are still in the early stages of this transition, and \\nthere is a vast landscape of opportunities for those venturing into \\n3\\nCHAPTER\\nGenerative AI’s Broad \\n Spectrum of Applications'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 133, 'page_label': '120'}, page_content='120 GENERATIVE AI\\nthis field and making progress in it. Established companies like \\nIBM and Microsoft have shifted their focus to AI over time, and \\nnew companies and startups are emerging with AI at the core of \\ntheir products. For instance, Rain Neuromorphics is building \\nartificial brains to make AI radically cheaper, aiming to enable \\nubiquitous advanced AI and power fully autonomous artificial \\ngeneral intelligence (AGI). Allganize, on the other hand, is revo-\\nlutionizing enterprise productivity with its AI document under -\\nstanding platform, Alli. Adept is building an ML model that can \\ninteract with everything on your computer, aiming to build an AI \\nteammate for everyone.\\nThe direction is clear: an AI-driven future, not only in indus-\\ntry but also in society. There is, however, another important \\nobservation to make. We can roughly separate AI adoption into \\ntwo waves, or shock waves, looking at the pace of it. The first \\nwave consists of model-maker companies, and the second wave \\nconsists of startups and companies with innovative approaches \\nthat use the models of the model-makers to build niche products. \\nThese companies, perhaps already niche somewhere, are paving \\nthe way for society to experience the power of AI.\\nFirst Wave of the Generative AI Adoption: Model-Makers\\nThe first wave of AI adoption is characterized by the rise of \\nmodel-maker companies. These are exceptional companies with \\nexceptional talent. They require substantial funding, as training \\nAI models can cost millions, and they need the knowledge to \\nbuild these models. Interestingly, these model-maker companies \\noften don’t have large teams of thousands of engineers and com-\\nputer scientists. Instead, they tend to operate with smaller, more \\nfocused, and highly talented teams. This approach seems to fos-\\nter innovation and efficiency, allowing these companies to make \\nsignificant strides in AI development with a lean team structure.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 134, 'page_label': '121'}, page_content='Generative AI’s Broad  Spectrum of Applications 121\\nOpenAI, for instance, has raised more than $11 billion in \\nfunding over four rounds. Most of this funding is used for train-\\ning their models. Despite having a relatively small team of \\nroughly 375 employees, they have achieved significantly more \\nthan companies with thousands of research scientists. This still is \\na mystery to me. Y es, they have a few hundred contractors, but \\nthe core team and capabilities are within OpenAI. They have \\nbeen pioneering research on the path to AGI and transforming \\nwork and creativity with AI. They have introduced products like \\nthe ChatGPT app for iOS or plug-ins for ChatGPT and are \\ncontinuously making strides in AI research and safety.\\nAnthropic AI In the midst of the COVID pandemic in 2021, a \\nnew player emerged on the AI scene. Anthropic, founded by for-\\nmer senior members of OpenAI, including siblings Daniela \\nAmodei and Dario Amodei (who served as OpenAI’s vice presi-\\ndent of research), burst onto the scene with a clear and compel-\\nling mission. They aimed to build large-scale AI systems that are \\nsteerable, interpretable, and robust.\\nAnthropic, a company that started from scratch, has raised \\na staggering $1.5 billion in funding, catapulting it to a valuation \\nof almost $5 billion. This meteoric rise is a testament to the \\ntransformative potential of AI and the faith investors have in \\nAnthropic’s vision and capabilities. As you might expect, they \\nare now in a phase of rapid expansion, hiring talent to join their \\n“small but growing” team.\\nAnthropic’s focus is on AI safety and alignment with human \\nvalues, a crucial aspect of AI development that cannot be over -\\nstated. They envision a future where AI’s impact could be on par \\nwith the industrial and scientific revolutions, a future where rapid \\nAI progress leads to transformative AI systems. T o prepare for \\nthis future, they are pursuing a variety of research directions,'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 135, 'page_label': '122'}, page_content='122 GENERATIVE AI\\nall aimed at better understanding, evaluating, and aligning \\nAI systems.\\nTheir approach is empirical, heavily relying on evidence and \\nreal-world observations. This grounded approach allows them to \\nnavigate the complex landscape of AI development with a clear \\nvision and a firm grasp on reality. What sets them apart is their \\nunique approach to AI safety research. They take a “portfolio \\napproach,” preparing for a wide range of scenarios, from the \\nmost optimistic to the most pessimistic, regarding the safety and \\ncontrol of advanced AI systems.\\nAnthropic’s unique approach to ensuring AI safety is a topic \\nwe’ll revisit in a later chapter, specifically when we explore the \\nethical side of generative AI. Their story is representative of the \\nexciting and dynamic nature of the AI field, where new players \\ncan emerge and make significant strides in a short span of time.\\nGoogle DeepMind In the dynamic landscape of AI, Google \\nDeepMind stands as a beacon of innovation. Acquired by Google \\nin 2014 for a staggering $500\\xa0 million dollars, DeepMind has \\ngrown into a powerhouse of AI development. The acquisition, \\nfor which Facebook had initially been in negotiations, has proven \\nto be a lucrative deal for Google, as DeepMind has been at the \\nforefront of numerous groundbreaking advancements in the \\nfield of AI.\\nDeepMind’s prowess lies in its innovative approach to AI, par-\\nticularly in the areas of deep learning and reinforcement learning. \\nThe company has developed AI systems capable of learning and \\nmastering complex tasks autonomously, demonstrating its com-\\nmitment to creating systems that can adapt and evolve.\\nHowever, the achievement that truly shook the world of AI \\nwas Google’s AlphaGo’s historic victory over Go champion Lee'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 136, 'page_label': '123'}, page_content='Generative AI’s Broad  Spectrum of Applications 123\\nSedol. This victory was significant because Go had previously \\nbeen regarded as a hard problem in machine learning that was \\nexpected to be out of reach for the technology of the time. Alpha-\\nGo’s victory not only demonstrated the capabilities of AI but also \\nmarked a turning point in the perception of AI’s potential.\\nDeepMind’s mission is to “solve intelligence” and create AGI, \\na type of AI that can understand, learn, and apply its knowledge \\nto a wide variety of tasks, much like a human brain. Their \\napproach is unique in that it focuses on creating systems that can \\nlearn and adapt autonomously. They combine two promising \\nareas of research— deep neural networks and reinforcement \\nlearning algorithms— to create AI systems that can apply their \\nlearning from one domain to a new domain.\\nOne of DeepMind’s most significant achievements is Alpha-\\nFold, an AI system that has been recognized as a solution to the \\n50-year-old grand challenge in biology known as the protein- \\nfolding problem. This breakthrough demonstrates the impact AI \\ncan have on scientific discovery and its potential to dramatically \\naccelerate progress in some of the most fundamental fields that \\nexplain and shape our world.\\nSecond Wave of AI Adoption: AI Model Wrapper Companies\\nAs we delve deeper into the realm of AI, we encounter a diverse \\narray of entities known as model-makers. These are the master -\\nminds behind large-scale machine learning models trained on a \\nbroad spectrum of Internet data. These models serve as a base— a \\nfoundation, if you will— for myriad downstream tasks. Their \\nsize and the vastness of their training data endow them with a \\ngeneral understanding of human language, making them incred-\\nibly versatile and useful across a multitude of applications.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 137, 'page_label': '124'}, page_content='124 GENERATIVE AI\\nModel-making powerhouses include Facebook AI Research \\n(FAIR), Baidu Research, NVIDIA AI Research, and Stability AI, \\nin addition to the previously mentioned OpenAI, Anthropic, and \\nGoogle DeepMind. Each organization has made significant \\nstrides in the development and application of foundation models. \\nAdept AI, a company with a keen focus on crafting useful general \\nintelligence, also stands out in this field. Even conglomerates like \\nLG from Korea have dedicated research departments working \\non these models. The list is extensive and continues to grow, \\nreflecting the increasing importance and influence of foundation \\nmodels in the field of AI.\\nThe second wave of the generative AI impact has given rise \\nto a multitude of startups and a handful of established compa-\\nnies. They harness the power of foundation models to tailor \\nsolutions to specific needs, as indicated in Figure\\xa03.1. The ripple \\neffects of this wave are far-reaching and diverse. Advancements \\nin text generation have revolutionized copywriting, customer \\nrelations, knowledge, and research. In the realm of audio, we’ve \\nseen innovations in music generation, speech generation, and \\nother sounds. Image generation has seen significant strides in \\ninfluencing design and marketing. Code generation and devel-\\nopment applications have also seen advancements. Video genera-\\ntion, synthetic data generation, and even the gaming and design \\nindustry have been revolutionized with the creation of 3D assets \\nand worlds, characters, and NPCs. Legal, tax advisory, and health \\nsolutions have also been influenced. AI model management has \\nseen advancements in fine-tuning, prompt management, and \\ndesigning, optimization, monitoring, and storage.\\nBetween March and May 2023, thousands of companies were \\nfounded. The first wave of generative AI was fundamentally \\nimportant, and the second wave is equally crucial in capturing \\nthat value. Goldman Sachs suggests that generative AI could \\ndrive a 7 percent (or almost $7 trillion) increase in global GDP'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 138, 'page_label': '125'}, page_content='Generative AI’s Broad  Spectrum of Applications 125\\nover 10 years. Other research estimates that the global artificial \\nintelligence market, which includes generative AI, is expected to \\nreach $1,811.75 billion by 2030, expanding at a compound annual \\ngrowth rate (CAGR)— a measure of the average yearly growth \\nrate over a specified period— of 37.3 percent from 2023 to 2030. \\nThe generative AI market\\xa0alone is expected to reach $38.8 bil-\\nlion by 2026. While different sources suggest different figures,  \\nI am much more optimistic, as I anticipate a tenfold increase  \\nin productivity, after some adoption, and hopefully a diminished \\nreluctance to use it.\\nMicrosoft’s AI Dominance\\nWhile the primary aim of this chapter is to explore the expansive \\npanorama of generative AI and its far-reaching implications, \\nwe’ll momentarily pause our examination of the application \\nData\\nText\\nImages\\nSpeech\\nStructured\\nData\\n3D Signals\\nTraining Foundation\\nModel\\nAdaptation\\nTasks\\nQuestion\\n Answering\\nSentiment\\n   Analysis\\nInformation\\nExtraction\\nImage\\nCaptioning\\nObject\\nRecognition\\nInstruction\\nFollowing\\nFIGURE\\xa03.1 From foundation models to serving specific tasks.\\nSource: “On the Opportunities and Risks of Foundation Models,” Stanford University'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 139, 'page_label': '126'}, page_content='126 GENERATIVE AI\\nfields and their innovative approaches. There’s an undercurrent, \\na less apparent yet significant power struggle, that merits our \\nattention. It’s the clash of titans: Microsoft versus Google. This \\nconfrontation is worth noting as we stand at a pivotal juncture, a \\nmoment that will determine who will seize the reins of global AI \\ndominance.\\nMicrosoft has been making strategic moves to assert its lead-\\nership in the global AI landscape. One of their notable initiatives \\nis that they have ramped up their efforts in the development and \\ndeployment of specialized supercomputing systems. These sys-\\ntems are designed to accelerate OpenAI’s groundbreaking inde-\\npendent AI research, and they also continue to enhance Azure’s \\nleading AI infrastructure to aid customers in building and deploy-\\ning their AI applications on a global scale.\\nAnother significant step taken by Microsoft is their partner -\\nship with OpenAI. Initially investing in OpenAI, Microsoft has \\nextended its partnership through a multiyear, multibillion-dollar \\ninvestment. This partnership aims to accelerate AI breakthroughs \\nand ensure these benefits are broadly shared with the world. The \\nagreement extends their ongoing collaboration across AI super -\\ncomputing and research and enables both parties to indepen-\\ndently commercialize the resulting advanced AI technologies.\\nMicrosoft has also been deploying OpenAI’s models across \\nits consumer and enterprise products and introduced new cate-\\ngories of digital experiences built on OpenAI’s technology. This \\nincludes Microsoft’s Azure OpenAI Service, which empowers \\ndevelopers to build cutting-edge AI applications through direct \\naccess to OpenAI models backed by Azure’s trusted, enterprise-\\ngrade capabilities and AI-optimized infrastructure and tools.\\nAs OpenAI’s exclusive cloud provider, Azure powers all  \\nOpenAI workloads across research, products, and API services. \\nThis exclusive partnership has been a strategic move for'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 140, 'page_label': '127'}, page_content='Generative AI’s Broad  Spectrum of Applications 127\\nMicrosoft, reinforcing its commitment to AI and its position as a \\nglobal leader in the field.\\nIn a significant development, OpenAI’s GPT-4 technology, \\nwhich was designed to be the underlying engine that powers \\nchatbots and all sorts of other systems, has been integrated into \\nMicrosoft’s Bing search engine. This integration showcases the \\npractical application of advanced AI technologies in everyday \\ndigital experiences.\\nGoogle’s AI Dominance\\nGoogle, from its inception, has been a beacon of AI innovation. \\nHowever, Microsoft’s strides with OpenAI have started to chal-\\nlenge this position significantly. In response, Google has been \\nfocusing on building an answer to ChatGPT . Let’s examine the \\nsteps Google has taken to maintain its position in this competi-\\ntive landscape.\\nGoogle Cloud offers a suite of AI and machine learning (ML) \\nservices that businesses can use to build, deploy, and scale AI \\nmodels. These services include Atoll, AI Platform, and AI Build-\\ning Blocks. Google Cloud also provides industry-specific AI \\nsolutions, such as Contact Center AI and Document AI.\\nGoogle’s 2014 acquisition of DeepMind, a leading AI research \\nlab, has led to significant advancements in AI research and devel-\\nopment. More recently, Google acquired Anthropic AI, a startup \\nfocused on building large-scale models that are understandable \\nand interpretable. This acquisition further strengthens Google’s \\nAI capabilities.\\nIn an effort to consolidate its AI research and development \\nefforts, Google merged its two main AI research groups, Google \\nBrain and DeepMind. This strategic move has streamlined \\nGoogle’s AI research, allowing for more focused and efficient \\ndevelopment.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 141, 'page_label': '128'}, page_content='128 GENERATIVE AI\\nGoogle announced an ambitious project to develop a single \\nAI language model that supports the world’s “1,000\\xa0most spoken \\nlanguages.” This initiative aims to bring various AI functionali-\\nties to languages that are poorly represented in online spaces and \\nAI training datasets, thereby promoting inclusivity and diver -\\nsity in AI.\\nGoogle has also developed Bard, a conversational generative \\nAI chatbot, as a direct response to the rise of OpenAI’s Chat-\\nGPT . Bard, initially based on the LaMDA family of large lan-\\nguage models (LLMs) and later on PaLM, an LLM also developed \\nby Google, was released in a limited capacity in March 2023.\\nGoogle’s Bard In the wake of OpenAI’s ChatGPT , Google \\nintroduced Bard, a conversational AI chatbot. Bard was initially \\nbuilt on the LaMDA family of LLMs but was later upgraded to \\nthe more powerful PaLM LLM. The development of Bard was \\na reaction to the success of ChatGPT , which had gained world-\\nwide attention and was seen as a potential threat to Google \\nSearch. This led to emergency meetings involving Google  \\nco-founders Larry Page and Sergey Brin, where they discussed \\nGoogle’s response to ChatGPT .\\nBefore Bard, Google had already developed LaMDA, a pro-\\ntotype LLM. However, it had not been released to the public due \\nto concerns about reputational risk. In January 2023, Google \\nemployees were instructed to accelerate progress on a ChatGPT \\ncompetitor, intensively testing “Apprentice Bard” and other \\nchatbots. Bard was announced on February 6, 2023, and was first \\nrolled out to a select group of 10,000 “trusted testers,” who rig-\\norously tested its capabilities.\\nThe technology was developed under the codename “Atlas,” \\nwith the name “Bard” chosen to reflect the creative nature of'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 142, 'page_label': '129'}, page_content='Generative AI’s Broad  Spectrum of Applications 129\\nthe algorithm. The announcement of Bard was seen as a \\nresponse to Microsoft’s planned event to unveil its partnership \\nwith OpenAI to integrate ChatGPT into its Bing search engine. \\nHowever, after a poorly received livestream showcasing Bard, \\nGoogle’s stock fell 8 percent, equivalent to a $100 billion loss in \\nmarket value.\\nDespite criticism from Google employees and concerns \\nabout safety and ethics, Google executives decided to proceed \\nwith the launch of Bard. Bard was launched as a stand-alone web \\napplication, with users prompted to submit feedback on the use-\\nfulness of each answer. However, the launch was not without \\ncontroversy. Google researcher Jacob Devlin resigned from the \\ncompany after claiming that Bard had surreptitiously leveraged \\ndata from ChatGPT , an allegation that Google denied.\\nBard was later upgraded to be based on PaLM, a newer and \\nmore powerful LLM from Google, and gained the ability to assist \\nin coding. The Pathways Language Model (PaLM), a 540 billion–\\nparameter, densely activated T ransformer language model, was \\ntrained on 6144 TPU v4 chips using Pathways, a new ML system \\nthat enables highly efficient training across multiple TPU Pods. \\nGoogle custom-developed its own tensor processing units \\n(TPUs), which are application-specific integrated circuits (ASICs) \\nused to accelerate ML workloads. TPUs are designed to handle \\nmassive matrix operations used in neural networks at fast speeds.\\nPaLM surpassed average human performance on the BIG-\\nbench benchmark, a collaborative benchmark openly developed \\nby GitHub that was intended to probe LLMs and extrapolate \\ntheir future capabilities. BIG-bench includes more than 200 \\ntasks summarized by keyword and task name. PaLM showed \\nstrong results on tasks such as logical inference.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 143, 'page_label': '130'}, page_content='130 GENERATIVE AI\\nPaLM is part of Google’s vision to enable a single AI system \\nto generalize across thousands or millions of tasks, to understand \\ndifferent types of data, and to do so with remarkable efficiency. It \\nhas set new state-of-the-art records on English-only natural lan-\\nguage processing (NLP) tasks and competitive performance on \\nmultilingual tasks. The team behind PaLM has noted areas for \\nimprovement, such as the model being too large for its compute \\nbudget and the fact that encoder-decoder models fine-tune better.\\nGoogle is working to integrate Bard into its ChromeOS \\noperating system and Pixel devices. Bard received mixed reviews \\nupon its initial release, with some critics finding it faster than \\nChatGPT and Bing, but others criticizing its uninteresting and \\nsometimes inaccurate responses. Despite these criticisms, Google \\ncontinues to improve Bard, with recent updates adding improved \\nmath and logic capabilities.\\nThe journey of Bard has been a rollercoaster ride, with its \\nshare of highs and lows. From its inception as a response to \\nChatGPT to the controversies surrounding its launch and the \\nsubsequent improvements and upgrades, Bard has been a testa-\\nment to Google’s commitment to advancing AI technology. \\nDespite the initial setbacks, Google has continued to refine and \\nenhance Bard, demonstrating its dedication to creating a chatbot \\nthat can effectively interact with and assist users.\\nThe development of Bard and PaLM also highlights Google’s \\nefforts to promote inclusivity and diversity in AI. Despite the exist-\\nence of over 7,000\\xa0languages worldwide, the Internet represents \\nonly a fraction of these. Google Search supports 348\\xa0languages, \\nFacebook recognizes 120, and LinkedIn only 24. This disparity \\ncreates a barrier to information access for many people, not only \\ndue to a lack of technology but also because their language is \\nunderrepresented online. Google’s Bard and PaLM, part of a'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 144, 'page_label': '131'}, page_content='Generative AI’s Broad  Spectrum of Applications 131\\nproject to support the world’s “1,000\\xa0most spoken languages,” aim \\nto address this issue, promoting inclusivity and diversity in AI. \\nThis endeavor could significantly contribute to making the Inter-\\nnet a more inclusive space.\\nChatGPT vs. Bard Performance\\nThe intense competition between Google’s Bard and OpenAI’s \\nChatGPT has sparked much debate. Each chatbot possesses dis-\\ntinct strengths and weaknesses, and their performance fluctuates \\ndepending on the task at hand.\\nWhen it comes to summarizing long-form content, Chat-\\nGPT has an edge over Bard. It provides a more detailed sum-\\nmary, whereas Bard’s summary tends to be terse and conveys less \\ninformation. In the realm of coding, both models have their \\nshortcomings. However, ChatGPT has shown a quicker ability \\nto iterate to a correct version of a Python function. As for craft-\\ning a customized tweet, both models perform adequately, but \\nChatGPT’s response tends to exceed the character limit, neces-\\nsitating edits.\\nIn terms of mimicking natural language and facilitating open-\\nended conversations, Bard outshines ChatGPT . Bard’s responses \\nare designed to be ultra-authentic, mimicking human speech. \\nHowever, some responses have been found to be less than authen-\\ntic, indicating room for improvement. One of Bard’s significant \\nadvantages is its capability to draw responses from the Internet in \\nreal time, while ChatGPT relies on a dataset that only goes up \\nuntil late 2021. This changes if one is enabled to use plug-ins or \\nthe ChatGPT Browser, which is gradually being released to \\nthe public.\\nWhen it comes to user-friendliness and interface, Bard takes \\nthe lead with a more visually appealing interface and formatted'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 145, 'page_label': '132'}, page_content='132 GENERATIVE AI\\ntext that’s easier to scan. It also allows users to edit their ques-\\ntions after they ask them, enhancing the user experience. How-\\never, in the area of text processing, such as summarization and \\nparagraph writing, ChatGPT outperforms Bard, making it ideal \\nfor applications that require these capabilities.\\nIn terms of cost, access to ChatGPT is limited and comes at \\na price, whereas Bard is free for all.\\nChatGPT leads in text generation, with Microsoft/OpenAI \\nand Google’s models rapidly evolving, reshaping conversational \\nAI. Amidst this, Elon Musk’s xAI’s Grok, with unique data access \\nto X/T witter, challenges their dominance, indicating a dynamic  \\nfuture.\\nGenerative AI Platforms\\nAs we traverse the landscape of generative AI applications, a \\nmore fundamental question arises: What new generative  \\nAI platforms are emerging, and who will be their proprietors? A \\nmultitude of platforms are sprouting up, each with unique offer-\\nings. For instance, Selas AI provides plug-and-play services to \\nleverage state-of-the-art text-to-anything features for businesses, \\noffering a full-stack solution to build products. Another platform, \\nAspen AI, offers a no-code platform for building AI-powered \\nweb apps, allowing users to configure AI models and deploy their \\napplications in minutes.\\nIn the midst of this technological evolution, we are witness-\\ning a shift from a software-centric world to an AI-centric one. \\nGenerative AI platforms are becoming the new infrastructure for \\ndigital products and services, replacing traditional software. This \\ntransformation is not merely a change in the tools we use but a \\nfundamental shift in how we approach the creation and delivery \\nof digital services.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 146, 'page_label': '133'}, page_content='Generative AI’s Broad  Spectrum of Applications 133\\nHowever, this shift does present challenges. Some, like the \\ninvestment firm Andreesen Horowitz, argue that the control of \\ngenerative AI platforms, including the respective data therein, by \\na few large tech companies could lead to a concentration of \\npower and a lack of competition. While the point of dominance \\nis valid, I believe that there have never been so many opportuni-\\nties for everyone in a tech revolution like this one. There  \\nare so many angles and ideas to deploy that this dominant posi-\\ntion, while influential, does not necessarily stifle competition or \\ninnovation.\\nIn fact, we are also witnessing a completely new open and \\ncollaborative approach to AI development, arguing that this \\nwould lead to more innovation and better outcomes for society. \\n(Chapter\\xa04, “Generative AI’s Exponential Growth,” explores the \\nopen source activities happening on this front.)\\nNow, let’s turn our attention to the existing layers of the tech \\nlandscape (Figure\\xa03.2). The first layer is hardware, which includes \\nGPUs, TPUs, servers, and accelerator chips optimized for model \\ntraining and inference workloads. These components form the \\nphysical infrastructure that powers AI technologies. The second \\nlayer is the cloud platforms, such as Google Cloud, AWS from \\nAmazon, and Azure. These platforms build a virtual layer on top \\nof the hardware, providing scalable computing resources and a \\nrange of services for developing, deploying, and managing AI \\napplications.\\nIn the tech chain, we have large foundation models that are \\nexpensively trained on vast data. These foundation models are \\nthen customized, fine-tuned, or prompt-designed for specific use \\ncases. This process leads to the development of end-to-end apps, \\nwhich are end user–facing applications with proprietary models. \\nA good example of an end-to-end app is ActiveChat.AI, a  \\nplatform that uses AI to automate customer service and sales \\nprocesses.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 147, 'page_label': '134'}, page_content='134 GENERATIVE AI\\nOn the other hand, we observe the separation of foundation \\nmodels and downstream customization. Here, we distinguish \\nbetween closed and open source. Closed source foundation mod-\\nels, like OpenAI’s GPT-4, are large-scale, pretrained models \\nexposed to downstream apps via APIs, which are paid. The open \\nsource variant uses openly available foundation models like Sta-\\nble Diffusion or StableLM from Stability AI. These models are \\noften released as trained weights and hosted on model hubs, like \\nHugging Face and Replicate, which share and host models.\\nApps\\nApps\\nEnd-to-End Apps\\nClosed Source\\nFoundation Models\\nModel Hubs\\nCloud Platforms\\nCompute Hardware\\nOpen Source\\nFoundation Models\\nUsers Models\\nInfrastructure\\nExamples: Jasper, Github Copilot\\nExamples: Hugging Face, Replicate\\nExamples: Stable Diffusion (Stability)\\nExamples: AWS, GCP, Azure, Coreweave\\nExamples: GPUs (NVIDIA), TPUs (Google)\\nExamples: GPT-3\\n(OpenAI)\\nExamples: Midjourney,\\nRunway\\nEnd user–facing B2B and B2C applications\\nwithout proprietary models\\nPlatforms to share and host models\\nModels released as trained weights\\nCompute hardware exposed to developers in a cloud deployment model\\nAccelerator chips optimized for model training and inference workloads\\nLarge-scale, pre-\\ntrained models\\nexposed via APIs\\nEnd user–facing\\napplications with\\nproprietary models\\nFIGURE\\xa03.2 Preliminary generative AI tech stack.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 148, 'page_label': '135'}, page_content='Generative AI’s Broad  Spectrum of Applications 135\\nThe closed source and open source foundation models ena-\\nble downstream applications via APIs. The apps are end user–\\nfacing B2B and B2C applications without proprietary models. \\nExamples here include Jasper, an AI-powered assistant that  \\nhelps manage and automate digital marketing tasks, and GitHub  \\nCopilot, a tool that suggests code snippets as developers type, \\neffectively acting as an AI pair programmer.\\nThis platform landscape, as I see it, will consolidate even fur-\\nther. One emerging element in this big-picture perspective is \\nautonomous agents. These are systems capable of autonomous, \\npurposeful action in the real world. They sense and act autono-\\nmously in their environment, realizing a set of goals or tasks for \\nwhich they are designed. We will discuss autonomous agents in \\nmore detail later, and time will tell how they will shape the AI \\nlandscape.\\nOpen Source Models\\nOpen source models, such as StableLM and GPT-NeoX-20B, \\nare a cornerstone of the AI landscape. They are software or AI \\nmodels whose source code is made available to the public, allow-\\ning anyone to view, use, modify, and distribute the project’s \\nsource code. This openness fosters a collaborative environment \\nwhere developers from around the globe can contribute to the \\ncode, leading to a diverse range of perspectives and expertise that \\ncan enhance the quality and functionality of the model.\\nFor instance, GPT-NeoX-20B, developed by EleutherAI, is a \\n20 billion–parameter autoregressive language model trained on the \\nPile using the GPT-NeoX library. Its architecture closely resembles \\nthat of GPT-3. The model was trained on a multitude of English-\\nlanguage texts, reflecting its general-purpose nature. The model’s \\nsource code is available on Hugging Face, the platform that hosts \\nand shares models, allowing anyone to study and modify it.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 149, 'page_label': '136'}, page_content='136 GENERATIVE AI\\nOpen source models like these promote transparency and \\naccountability, as anyone can inspect the code for bugs, errors, or \\nbiases. They also serve as a great learning resource for individu-\\nals and organizations looking to understand or get started with \\nAI, as they can study and modify existing models. The open \\nnature of these models encourages innovation, as developers can \\nbuild upon existing models to create new solutions.\\nHowever, it’s important to note that training large AI models \\ncan be expensive, and this cost can be prohibitive for some devel-\\nopers or organizations. Moreover, because open source models \\nare publicly available, they can be misused by malicious actors. \\nDespite these challenges, the benefits of open source models in \\npromoting transparency, fostering innovation, and serving as a \\nlearning resource make them a vital part of the AI landscape.\\nClosed Source Models\\nClosed source models, unlike their open source counterparts, are \\nproprietary software or AI models whose source code is not dis-\\nclosed to the public. The code is owned, controlled, and main-\\ntained by a specific individual, team, or organization.\\nA prime example of a closed source model is GPT-4, devel-\\noped by OpenAI. GPT-4, the successor to GPT-3, is OpenAI’s \\nmost advanced system, producing safer and more useful responses. \\nIt can solve complex problems with greater accuracy, thanks to \\nits broader general knowledge and problem-solving abilities. \\nGPT-4 is more creative and collaborative than ever before, capa-\\nble of generating, editing, and iterating with users on creative \\nand technical writing tasks. However, the source code of GPT-4 \\nis not publicly available, making it a closed source model.\\nThese models are typically commercial products developed \\nby businesses for profit. They can provide a competitive advan-\\ntage to the company that developed them. For instance, GPT-4'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 150, 'page_label': '137'}, page_content='Generative AI’s Broad  Spectrum of Applications 137\\ndeepens the conversation on Duolingo, transforms visual acces-\\nsibility on Be My Eyes, and streamlines the user experience and \\ncombats fraud on Stripe.\\nOne of the benefits of closed source models is that they \\noften come with customer support and regular updates. This \\ncan be a boon for users who are not tech-savvy or do not have \\nthe resources to maintain and update the software themselves. \\nHowever, the lack of transparency can lead to concerns about \\nbias, fairness, and privacy. Users have to trust the provider that \\nthe software is performing as it should, without any hid-\\nden issues.\\nA significant concern with closed source models is that they \\ncan lead to a concentration of power, as only a few entities have \\ncontrol over the most advanced AI models. For instance, OpenAI \\nhas exclusive control over its source code and usage.\\nOpenAI’s Founding Story\\nThe story of OpenAI’s inception is a captivating narrative, \\nmarked by unexpected twists and high-stakes decisions. It all \\nbegan amidst the acquisition talks between DeepMind and \\nGoogle. Elon Musk implored DeepMind’s leaders, including \\nDemis Hassabis, not to sell. Musk’s concern was rooted in the \\npotential dominance of a commercial entity like Google in the \\nAI landscape.\\nAfter DeepMind’s eventual sale to Google, Musk, along  \\nwith a group of influential figures such as Sam Altman, Greg \\nBrockman, Reid Hoffman, Jessica Livingston, and Peter Thiel, \\nand organizations including Amazon Web Services (AWS), Info-\\nsys, and YC Research, announced the formation of OpenAI in \\nDecember 2015. They pledged over a billion dollars to the ven-\\nture, promising to freely collaborate with other institutions and \\nresearchers by making their research open to the public.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 151, 'page_label': '138'}, page_content='138 GENERATIVE AI\\nHowever, by early 2018 Musk felt that OpenAI had fallen \\nsignificantly behind Google. He proposed taking control of \\nOpenAI and running it himself, a proposal that was rejected by \\nthe other founders. Following this, Musk distanced himself from \\nOpenAI and withdrew a substantial planned donation. His depar-\\nture was publicly attributed to a conflict of interest, as T esla was \\ndeveloping its own AI for autonomous driving, which would be \\ncompeting for talent with OpenAI.\\nIn the same year, Sam Altman, who also ran the influential \\nstartup accelerator Y Combinator, stepped in and added the title \\nof president to his role at OpenAI. Musk stepped down from \\nOpenAI’s board of directors. In the fall of 2018, OpenAI made a \\nsignificant decision to pivot toward T ransformer models, which \\nrequired feeding vast amounts of data to train the AI, a \\ncostly endeavor.\\nOn March 11, 2019, OpenAI announced it was transitioning \\ninto a for-profit entity to raise enough capital to fund the com-\\nputing power necessary to pursue the most ambitious AI models. \\nThis marked a significant shift from OpenAI’s original mission, \\nleading some to refer to the organization as “ClosedAI,” a term \\ncoined by Jason Calacanis. In 2019, OpenAI secured $1 billion \\nfrom Microsoft, which provided not just funding but also infra-\\nstructure know-how. T ogether, they built a supercomputer to \\ntrain massive models that eventually led to the creation of Chat-\\nGPT and DALL-E.\\nBy November 2022, when ChatGPT launched, OpenAI \\ninstantly became the hottest new tech startup, forcing Google to \\nscramble to keep up. However, in December 2022, Musk pulled \\nOpenAI’s access to the T witter “fire hose” of data— a contract \\nthat was signed before Musk acquired T witter.\\nIn 2023, Musk expressed his confusion and frustration over \\nOpenAI’s transformation from a nonprofit to a for-profit entity \\n(Figure\\xa03.3). In a surprising turn of events, Musk has founded  \\na new AI company called X.AI, which aims to compete with'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 152, 'page_label': '139'}, page_content='Generative AI’s Broad  Spectrum of Applications 139\\nOpenAI in the artificial intelligence industry. X.AI is reportedly \\nplanning to adopt an open source approach, a stark contrast to \\nOpenAI’s recent shift. Musk is the sole listed director of the com-\\npany, which was incorporated in Nevada. X.AI has authorized \\nthe sale of 100\\xa0million shares for its privately held business. Musk \\nhas been actively recruiting researchers to establish a rival effort \\nto OpenAI, marking yet another intriguing chapter in the evolv-\\ning narrative of the AI industry.\\nNo Moat Leakage Letter at Google\\nIn 2019, OpenAI underwent a significant transformation, shift-\\ning from a nonprofit to a for-profit entity. The leaders of  \\nOpenAI justified this move as a necessary measure to secure the \\nfunding needed for the creation of advanced AI models. How-\\never, after extensive research and numerous conversations with \\nthought leaders at conferences and interviews, it becomes \\nincreasingly clear that this transition may not have been as cru-\\ncial as it was portrayed.\\nOpenAI’s shift toward a for-profit model has sparked a debate \\nabout the future of AI model development and research. The \\nopen source approach, in my opinion, holds immense potential. \\nIt could secure a top-notch, if not pole position, in the AI land-\\nscape. The future of open source AI models could be as vibrant, \\ncollaborative, and impactful as the React community is today. \\nReact, an open source, frontend JavaScript library for building \\nFIGURE\\xa03.3 Tweet from Elon Musk about OpenAI turning from a non-\\nprofit to a for-profit company.\\nSource: X Corp.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 153, 'page_label': '140'}, page_content='140 GENERATIVE AI\\nuser interfaces or UI components, is maintained by Meta (for -\\nmerly Facebook) and a community of individual developers and \\ncompanies.\\nEven within Google, this topic is a subject of ongoing discus-\\nsion. A leaked document from a Google researcher recently sur-\\nfaced, shared by an anonymous individual on a public Discord \\nserver. The document, titled “We Have No Moat, and Neither \\nDoes OpenAI,” provides an insightful analysis of the competitive \\nlandscape of AI, with a particular focus on Google and OpenAI.\\nThe document suggests that open source AI will outperform \\nboth Google and OpenAI. It highlights several advancements in \\nopen source AI, such as running foundation models on a Pixel 6, \\nscalable personal AI, and unrestricted release of art models. \\nWhile closed source models still hold a slight edge in terms of \\nquality, the gap is closing quickly. Open source models are faster, \\nmore customizable, more private, and more capable. The docu-\\nment asserts that Google has no secret sauce and should learn \\nfrom and collaborate with others outside Google. It also suggests \\nthat people will not pay for a restricted model when free, unre-\\nstricted alternatives are comparable in quality. I find myself in \\nagreement with this sentiment. A few months of difference in \\ndevelopment doesn’t make a significant difference.\\nThe document further highlights the rapid innovation in the \\nopen source community, particularly after the leak of Meta’s \\nLLaMA model. The community quickly developed variants with \\ninstruction tuning, quantization, quality improvements, human \\nevaluations, multimodality, and so forth. The document discusses \\nthe recent successes of open source AI, particularly in image gen-\\neration and language model fine-tuning. It suggests that Google \\ncould benefit from paying more attention to these innovations.\\nInterestingly, the document also suggests that OpenAI is \\nmaking the same mistakes as Google in their posture relative to \\nopen source, and their ability to maintain an edge is necessarily'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 154, 'page_label': '141'}, page_content='Generative AI’s Broad  Spectrum of Applications 141\\nin question. It proposes that Google should establish itself as a \\nleader in the open source community, even if it means taking \\nsome uncomfortable steps, like publishing the model weights.\\nThe future of AI model development and research seems to \\nbe leaning toward the open source approach. The rapid advance-\\nments in open source AI, coupled with the closing gap in quality \\nbetween proprietary and open source models, suggest that the \\nopen source approach could be the key to unlocking the full \\npotential of AI.\\nGenerating Revenue with\\xa0Open Source Models\\nThe question of how a for-profit company can differentiate itself \\nwhile open sourcing its expensively trained AI models is indeed a \\npertinent one. How can such a company generate revenue? The \\nanswer may seem counterintuitive at first, but open sourcing an \\nAI model can be a strategic decision that opens up several ave-\\nnues for revenue generation and maintaining a competitive edge.\\nOne such avenue is through consulting and customization \\nservices. While the model may be open source, many businesses \\nlack the expertise to effectively implement and customize it. \\nOffering consulting services to assist these businesses in inte-\\ngrating the model into their systems can be beneficial. This could \\nalso involve providing custom solutions tailored to specific use \\ncases or industries.\\nT raining and support is another potential revenue stream. \\nProviding training programs and support services can help users \\nunderstand how to use the model effectively. This could take the \\nform of workshops, online courses, or personalized train-\\ning sessions.\\nDeveloping premium features or services that complement \\nthe open source model is another option. These could be offered \\non a subscription basis or as one-time purchases. For instance,'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 155, 'page_label': '142'}, page_content='142 GENERATIVE AI\\na cloud-based API for easy access to the model, advanced analytics, \\nor additional tools for fine-tuning the model could be provided.\\nOpen sourcing the model can also attract potential partner -\\nships and collaborations. Companies interested in collaborating \\non further development or application of the model may be \\ndrawn to the project. Such partnerships can lead to new reve-\\nnue streams.\\nIf users interact with the model via a platform or API, \\nanonymized usage data and analytics can be collected (with user \\nconsent and in compliance with privacy laws). This data can be \\nvaluable for improving services, and of course AI models. Fur -\\nther, the data can also be used to provide businesses with insights \\nand analytics.\\nOpen source projects often attract sponsorships and grants \\nfrom businesses that find value in the project. Additionally, \\nnumerous grants are available for open source development.\\nThe differentiator in these scenarios is the expertise and the \\nvalue-added services provided. The offering is not just a model, \\nbut a complete solution that includes the model, support, cus-\\ntomization, and potentially other services. This can make the \\noffering more attractive to businesses compared to just using the \\nopen source model independently.\\nCertainly, licensing is another crucial aspect to consider. In a \\ndual licensing model, the software is released under two types of \\nlicenses: an open source license and a commercial license. The \\nopen source license permits free use, but it often comes with cer-\\ntain conditions. For instance, any modifications or derivative \\nworks must also be open source. On the other hand, the com-\\nmercial license, which can be purchased, allows for use under \\nmore permissive conditions and may include additional services \\nor features. This model can be particularly attractive to busi-\\nnesses that wish to use the software in ways not permitted by the \\nopen source license, or those who desire additional services \\nor support.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 156, 'page_label': '143'}, page_content='Generative AI’s Broad  Spectrum of Applications 143\\nThere are also other licensing models to consider. One such \\nmodel is the open-core model. In this model, the basic version of \\nthe software is open source, but a more feature-rich version or \\nadditional modules are available under a commercial license. \\nThis model provides users with the flexibility to choose the ver-\\nsion that best suits their needs.\\nAnother model is the service provider license agreement \\n(SPLA). Under this model, companies can license your software on \\na monthly basis to provide services to their customers. This model \\ncan provide a steady stream of income and can be particularly ben-\\neficial for software that requires regular updates or maintenance.\\nT rademark licensing is another option, especially if the soft-\\nware has a strong brand. In this model, you can license the use of \\nthe trademark to companies that want to market their own ser -\\nvices or products as compatible with or based on your software. \\nThis can help to increase the visibility of your software and can \\nprovide additional revenue streams.\\nWhile open sourcing AI models may initially appear to be a \\nchallenge for generating revenue, they can, in fact, open up a \\nmultitude of opportunities for a company to differentiate itself \\nand create sustainable revenue streams.\\nDemocratizing AI: Hugging Face’s Success Story\\nKnown as the hub for open source models, Hugging Face has \\nmanaged to create a thriving ecosystem around its offerings.\\nHugging Face presents a master class on leveraging the open \\nsource model to build a brand and drive growth. Founded in \\n2016, the company initially targeted teenagers with a chatbot \\napp. However, after open sourcing the model behind the chat-\\nbot, the company pivoted to focus on being a platform for \\nmachine learning. This strategic shift marked the beginning of a \\njourney that would see the company catapult to a staggering'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 157, 'page_label': '144'}, page_content='144 GENERATIVE AI\\n$2 billion valuation in roughly seven years, with a team of around \\n150 employees.\\nThe company’s growth trajectory has been marked by signifi-\\ncant milestones. In March 2021, Hugging Face raised $40\\xa0million \\nin a Series B funding round. Later, in December 2021, the com-\\npany announced its acquisition of Gradio, a software library used \\nto create interactive browser demos of machine learning models. \\nThis acquisition expanded the company’s capabilities and further \\nsolidified its position in the AI industry.\\nThe year 2022\\xa0was particularly eventful for Hugging Face. \\nIn collaboration with several other research groups, the BigSci-\\nence Research Workshop concluded with the announcement of \\nBLOOM, a multilingual large language model with 176 billion \\nparameters. This marked a significant advancement in the field \\nof AI and demonstrated the company’s commitment to pushing \\nthe boundaries of what is possible with machine learning.\\nIn the same year, the company announced its Series C fund-\\ning round led by Coatue and Sequoia, which valued the company \\nat $2 billion. This was a testament to the company’s success and \\nthe faith investors had in its potential for future growth. In a bid \\nto fulfill its mission to teach machine learning to 5\\xa0million peo-\\nple within the first 18\\xa0months, the company also introduced its \\nStudent Ambassador Program in May 2022.\\nHugging Face’s commitment to innovation was further dem-\\nonstrated by its partnership with Graphcore to optimize its \\nT ransformers library for the Graphcore IPU. An intelligence \\nprocessing unit (IPU) is a type of processor specifically designed \\nfor AI workloads. This partnership aimed to enhance the perfor-\\nmance of Hugging Face’s offerings and provide better tools for \\nAI developers.\\nIn August 2022, the company announced the Private Hub, \\nan enterprise version of its public Hugging Face Hub that sup-\\nports software-as-a-service (SaaS) or on-premises deployment.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 158, 'page_label': '145'}, page_content='Generative AI’s Broad  Spectrum of Applications 145\\nThis move was aimed at providing more flexible and tailored \\nsolutions for businesses, further expanding the company’s reach \\nand influence.\\nThe company’s growth continued into 2023, with a partner-\\nship with Amazon Web Services (AWS) announced in February. \\nThis partnership would allow Hugging Face’s products to be \\navailable to AWS customers, providing them with powerful tools \\nfor building custom applications. The company also announced \\nthat the next generation of BLOOM would be run on T rainium, \\na proprietary machine learning chip created by AWS.\\nThe story of Hugging Face exemplifies the power of open \\nsource. Not a single element of their success can be attributed to \\na closed source solution. Quite the contrary, their entire ecosys-\\ntem thrives on openness and collaboration. This ethos has led to \\na staggering collection of more than 200,000\\xa0models, 34,000\\xa0data-\\nsets, and more than 25\\xa0machine learning libraries. These resources \\nare utilized by over 10,000 organizations and half a million daily \\nusers. The scale of their operation is truly awe-inspiring.\\nHugging Face’s capabilities are not just vast but also incred-\\nibly accessible. They have democratized AI to such an extent that \\nyou can build an AI minimum viable product starting from just \\nan idea. If you lack an idea, they even provide inspiration by map-\\nping models against different tasks that can be solved. The spec-\\ntrum of applications is broad, ranging from text-to-speech and \\naudio-to-audio to zero-shot text classification and image-to-3D \\nobject translation.\\nChoosing the right model for your application is made easy \\nwith Hugging Face. They support decision making with com-\\nprehensive information about the models, including details about \\nthe licenses, which is crucial if you intend to use the model com-\\nmercially. Once you’ve selected a pre-trained model, it can be \\nintegrated into an existing or new application via Hugging Face’s \\naccelerated inference API.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 159, 'page_label': '146'}, page_content='146 GENERATIVE AI\\nIf you’re starting from scratch, Hugging Face’s acquisition of \\nGradio comes in handy. Y ou can build a machine learning app, \\nhost it, and deploy it via Hugging Face Spaces, powered by  \\nGradio. The result? A working application that can be up and \\nrunning in under an hour. There are numerous Y ouT ube videos \\ndemonstrating this process.\\nFurther, the Leadership board is a valuable tool provided by \\nHugging Face (Figure\\xa03.4). It presents the performance of the \\nrespective models, a task that was previously challenging as it \\nrequired either trying out the models or reading surveys and \\npapers, which often lacked comparability.\\nHugging Face has made it possible to build pretty much any-\\nthing. With their tools and resources, the possibilities are end-\\nless. This brings us to the next topic of our discussion: the \\napplications that are at the forefront of generative AI.\\nFIGURE\\xa03.4 Hugging Face’s LLM-Leaderboard, mapping performances \\nfor various tasks against AI models.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 160, 'page_label': '147'}, page_content='Generative AI’s Broad  Spectrum of Applications 147\\nApplication Fields\\nThe advent of generative AI has sparked a productivity revolu-\\ntion. We are witnessing a tenfold increase in productivity, a phe-\\nnomenon that is currently being embraced by early adopters and \\nwill soon permeate the majority of society and the economy. This \\nsurge in productivity is accompanied by a hundredfold increase \\nin the number of startups being founded and a thousandfold \\nincrease in the number of products, ideas, and projects being  \\nlaunched.\\nThe applications of generative AI are as diverse as they are \\nfascinating. Voice generation, for instance, involves the use of AI \\nto synthesize human-like speech, enabling more natural interac-\\ntions between humans and machines. Video generation, on the \\nother hand, leverages AI to create realistic as well as stylistic vid-\\neos, transforming the way we create and consume visual content.\\nT ext generation and language translation are other promi-\\nnent applications of generative AI. Here, AI is used to generate \\ncoherent and contextually relevant text or to translate text from \\none language to another, thereby breaking down linguistic barri-\\ners and fostering global communication. Music generation, \\nanother intriguing application, involves the use of AI to compose \\nmusic, pushing the boundaries of creativity.\\nGenerative AI plays a pivotal role in image generation and \\nmanipulation, enabling the creation of realistic images or the \\nmodification of existing ones. In the realm of 3D object genera-\\ntion, AI is used to create detailed and accurate 3D models, a \\ncapability that is transforming industries such as architecture, \\ngaming, and entertainment.\\nGenerative design, another application of generative AI, \\ninvolves the use of AI to generate a wide range of design alterna-\\ntives for a given problem, thereby enhancing creativity and effi-\\nciency in the design process. In the scientific domain, generative'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 161, 'page_label': '148'}, page_content='148 GENERATIVE AI\\nAI is being used for protein folding and other science-specific \\nuse cases. For instance, DeepMind’s AlphaFold uses AI to predict \\nthe 3D structure of a protein based solely on its genetic sequence, \\na breakthrough that could accelerate scientific discoveries and \\npotentially lead to new methods of therapy.\\nThe landscape of generative AI is highly dynamic, with noth-\\ning set in stone. The boundaries that were once clear are now \\nblurred, as AI continues to evolve and redefine the limits of what \\nis possible. Let’s explore how it is shaping our present and \\nnear future.\\nVoice and Speech Generation\\nNow, let’s turn our attention to voice and speech generation. \\nThis technology, which converts text into spoken language, is \\nused in a variety of applications. Think of voice assistants like Siri \\nor Alexa, audiobooks, and accessibility tools. T oday, we have \\nadvanced speech synthesis models that can generate human-like \\nvoices. These models are trained on large datasets and can han-\\ndle different languages, accents, and speech patterns. They can \\nalso adjust the tone, pitch, and speed of the speech.\\nLet’s consider a real-world example of a company using \\nspeech synthesis technology combined with AI in their market-\\ning campaigns.\\xa0Respeecher collaborated with Mondelēz Interna-\\ntional, Ogilvy, and Wavemaker to create a revolutionary ad \\ncampaign for the Indian market. They used their voice-cloning \\ntechnology to generate personalized ads from Shah Rukh Khan, \\na popular Bollywood actor, for thousands of local retailers. This \\nwas a game-changing approach, as these retailers would not have \\notherwise been able to afford such a high-profile endorsement. \\nThis example illustrates the transformative potential of speech \\nsynthesis technology when combined with AI, particularly in the \\nrealm of marketing.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 162, 'page_label': '149'}, page_content='Generative AI’s Broad  Spectrum of Applications 149\\nThe process of speech synthesis is a fascinating one, typically \\ninvolving three stages. The first stage is text to words, also known \\nas preprocessing or normalization. This involves reducing ambi-\\nguity and turning elements like numbers, dates, times, abbrevia-\\ntions, acronyms, and special characters into words. This process \\nuses statistical probability techniques or neural networks to \\narrive at the most likely pronunciation.\\nThe second stage is words to phonemes. After figuring out \\nthe words, the speech synthesizer generates the speech sounds \\nthat make up these words. This involves breaking down the writ-\\nten words into their graphemes, the smallest units in a writing \\nsystem, and then generating phonemes, the distinct units of \\nsound, that correspond to them using a set of simple rules.\\nThe third stage is phonemes to sound. The computer converts \\nthe text into a list of phonemes. There are three different approaches \\nto this: using recordings of humans saying the phonemes, the com-\\nputer generating the phonemes itself by generating basic sound \\nfrequencies, and imitating the technique of the human voice.\\nThere are different types of speech synthesizers: concatena-\\ntive, formant, and articulatory. Concatenative synthesizers use \\nrecorded human voices and rearrange them. They are based on \\nrecorded human speech. Formant synthesizers generate speech \\noutput using additive synthesis and physical modeling synthesis. \\nThey can say anything, even words that don’t exist or foreign \\nwords they’ve never heard off. Articulatory synthesizers make \\ncomputers speak by modeling the intricate human vocal tract \\nand articulating the process occurring there. It is the least \\nexplored method due to its complexity.\\nSpeech synthesis systems usually try to maximize both natu-\\nralness and comprehensibility. Naturalness refers to how closely \\nthe synthesized speech resembles human speech, while compre-\\nhensibility refers to how easily the synthesized speech can be \\nunderstood by listeners.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 163, 'page_label': '150'}, page_content='150 GENERATIVE AI\\nSpeech synthesis has multiple applications. It helps the visu-\\nally impaired to read and communicate. It can be used for teach-\\ning spelling and pronunciation of different languages. It is used \\nin different kinds of telephone inquiry systems and multimedia \\napplications. There are several free and paid speech recognition \\nprograms available in the market, such as Google Now, Siri, \\nCortana, Simon, Kaldi, Dragon Anywhere, Amazon Lex, Dragon \\nProfessional, Voice Finger, and T azti.\\nOne company that stands out in this field is Murf.ai. They \\nprovide an AI voiceover platform that can generate human-like \\nspeech with high quality. Their platform allows users to choose \\nfrom a variety of voices and customize the tone, pitch, and speed \\nof the speech. Murf.ai offers high-quality natural-sounding AI \\nvoices for your projects. It provides a complete toolkit for mak-\\ning voice-over videos. Y ou can combine images, videos, music, \\nadjust timing, and so on. It’s not just a text-to-speech tool— it’s a \\ncomplete solution for creating voiceovers.\\nAnother noteworthy player is Poly.ai. This company has \\ncarved out a niche for itself by creating a voice generation system \\nthat is so high-quality, it borders on the uncanny. The generated \\nvoice is so flawless that it almost seems too perfect, as it lacks the \\nhuman-like imperfections such as the occasional “uhms” and \\n“ahs” that we are accustomed to in natural speech.\\nHowever, Poly.ai’s prowess extends beyond just the creation \\nof high-quality synthetic voices. Their solution is designed to \\nextract valuable information such as dates, places, and names, \\nand can handle tasks like table booking and other organizational \\nmatters automatically. This level of sophistication in handling \\ncomplex tasks rises from the company’s commitment to pushing \\nthe boundaries of what AI can achieve in the realm of speech \\nsynthesis and natural language processing.\\nFounded in 2017, according to Crunchbase, Poly.ai has \\nalready secured a substantial $66\\xa0million in funding and boasts'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 164, 'page_label': '151'}, page_content='Generative AI’s Broad  Spectrum of Applications 151\\na workforce of between 100 and 250 employees. This level of \\nfinancial backing and human capital speaks volumes about the \\npotential of this company and the faith that investors have in \\nits vision.\\nAs we look to the future, it’s exciting to imagine what else is \\non the horizon for Poly.ai. With their track record of innovation \\nand their commitment to pushing the boundaries of AI, there’s \\nno doubt that they will continue to make waves in the field of \\nspeech synthesis and beyond.\\nIn the next section of this book, we will continue our explora-\\ntion of the fascinating world of AI, turning our attention to \\nanother topic that has been making headlines in the world of \\nartificial intelligence.\\nWhere Is Voice Generation Going? Voice cloning technol-\\nogy, such as the voice imitation algorithm developed by Descript, \\nhas the power to replicate a person’s unique voice. This capabil-\\nity opens up a world of possibilities, from creating personalized \\nvoice assistants that echo our own speech patterns to narrating \\naudiobooks in the author’s voice, thereby enhancing user engage-\\nment and accessibility.\\nIn the sphere of education, platforms like T utorAI are har -\\nnessing voice generation to produce interactive educational con-\\ntent. This transformative approach to learning is reshaping the \\nway we engage with information, making the learning process \\nmore dynamic and immersive.\\nLanguage learning, too, stands to gain immensely from voice \\ngeneration technology. By creating realistic voices in a multitude \\nof languages, this technology can serve as a valuable tool in lan-\\nguage learning apps, aiding students in refining their pronuncia-\\ntion and listening skills.\\nThe entertainment and gaming industry is another sector \\nwhere voice generation is making a significant impact. It has the'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 165, 'page_label': '152'}, page_content='152 GENERATIVE AI\\npotential to breathe life into characters in video games, anima-\\ntions, and other forms of entertainment. Whether it’s creating \\nvoices for nonexistent characters or re-creating voices from clas-\\nsic games or shows, voice generation adds a new dimension to \\nthe user experience.\\nThe concept of personal branding for content creators is also \\nbeing redefined by voice cloning. Imagine content creators using \\ntheir unique voice clones to interact with their audiences across \\ndifferent platforms, creating a consistent and recognizable per -\\nsonal brand. It’s not far-fetched to envision a future where pro-\\nfessionals have their own voice generators, akin to business cards \\nof yore, integrated into their personal web pages or LinkedIn \\nprofiles. This could be a game changer for social media compa-\\nnies, offering an additional service that enhances user engagement.\\nIn the telecommunications sector, voice generation can revo-\\nlutionize user experience by creating realistic voices for automated \\nphone systems. This could automate redundant calls, making the \\nprocess more efficient and user-friendly.\\nHealthcare is another field where voice generation can make \\na significant difference. For speech therapy patients or individu-\\nals who have lost their ability to speak, the creation of realistic, \\npersonalized voices can be a lifeline, offering them a chance to \\ncommunicate effectively.\\nLastly, let’s consider the role of voice generation in enhanc-\\ning accessibility. This technology can be used to read out text for \\npeople with visual impairments or to translate sign language into \\nspoken words. This integration of technology can make our digi-\\ntal world more inclusive, ensuring that everyone, regardless of \\ntheir abilities, can participate fully.\\nAs we continue our journey through the fascinating world of \\nAI, we will explore more such groundbreaking technologies and \\ntheir potential impact on our lives. Stay tuned as we unravel the \\nintricacies of this rapidly evolving field.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 166, 'page_label': '153'}, page_content='Generative AI’s Broad  Spectrum of Applications 153\\nGenerative Design\\nIn the vast expanse of generative AI, generative design stands out \\nas the field most intimately connected to the physical world. This \\ninnovative approach takes a leaf from nature’s book, emulating \\nits evolutionary process. Here’s how it works: Designers or engi-\\nneers input their design goals into a generative design software, \\nalong with parameters such as the materials to be used, manufac-\\nturing methods, and cost constraints. The software then embarks \\non an exploration of all possible permutations of a solution, gen-\\nerating a multitude of design alternatives. It tests each one, learn-\\ning from every iteration. This process enables the creation of \\ncomplex shapes and internal lattices that are optimized for effi-\\nciency. Some of these forms are so intricate that they would be \\nimpossible to produce using traditional manufacturing methods. \\nInstead, they come to life through the magic of new additive \\nmanufacturing methods.\\nIn 2016, during my tenure in the research department at  \\nAirbus, I witnessed the power of generative design firsthand. We \\nwere working on innovative predictive maintenance systems, \\nincluding generative models to balance out unbalanced datasets. \\nThat year, Airbus built a fully functioning motorcycle that was \\nnot only robust but also weighed just 35\\xa0kg (Figure\\xa03.5). Seeing \\nit in person was a revelation of what’s possible with generative \\ndesign, especially when coupled with 3D printing.\\nT oday, generative design finds applications in various sec-\\ntors. In the automotive industry, for instance, it’s used for light-\\nweighting components and consolidating parts. A notable \\nexample is General Motors, which used generative design to \\nreduce the mass of a seat bracket by 40 percent while improv-\\ning its performance.\\nIn aerospace, it contributes to weight reduction, environ-\\nmental impact mitigation, and safety improvements. Airbus, for'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 167, 'page_label': '154'}, page_content='154 GENERATIVE AI\\ninstance, used generative design to optimize the partition wall of \\nan airplane cabin, reducing its weight by 45 percent.\\nGenerative design has found a compelling application in the \\nrealm of architecture, transforming the way structures are con-\\nceived and built. Consider the skyscrapers that punctuate city \\nskylines. These towering structures are designed to withstand \\ndiverse environmental challenges— for example, high winds in \\nChicago and earthquakes in Japan. Beyond ensuring safety, archi-\\ntects and clients often aspire to infuse their buildings with a \\nunique aesthetic appeal. Generative design enables this, allowing \\narchitects to set necessary parameters and explore a multitude of \\ndesign options.\\nA striking example comes from Brazilian architect Guto \\nRequena, who employed generative design to create stools for a \\nbar. The design of these stools mirrored the rhythm of local pop-\\nular music. Once the design was finalized, the stools were brought \\nto life through 3D printing.\\nFIGURE\\xa03.5 Airbus APWorks launches the Light Rider, the world’s first \\n3D-printed motorcycle.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 168, 'page_label': '155'}, page_content='Generative AI’s Broad  Spectrum of Applications 155\\nBut generative design isn’t confined to specific parameters. It \\ncan also accommodate broader ones. It can be used to construct \\nthe most robust bridge with the most cost-effective materials, or \\nto design a school based on the natural movement patterns \\nof people.\\nThe creators of Autodesk took this concept even further \\nwhen building their new offices. They incorporated the prefer -\\nences of future occupants as design parameters. The result was a \\nworkspace tailored to the workflows of its users, a building that \\nwas customized to the needs of the people who would use it. This \\npreemptive approach minimizes the need for postconstruction \\nmodifications, creating a refined building that truly serves its \\ninhabitants.\\nGenerative design is revolutionizing the industrial machin-\\nery sector, pushing the boundaries of innovation in the creation \\nof specialty tools and equipment. A prime example of this is the \\nGen5X, a 5-axis 3D printer designed using generative principles.\\nThe Gen5X is not just any 3D printer; it’s an open source, \\nself-replicating marvel. It’s capable of designing and manufactur-\\ning its own components, and its design can be replicated on any \\nhobbyist-level machine. This 5-axis 3D printer is a product of \\nthe RepRap project, which explores the frontier of self-replicating  \\nmachines.\\nThe design process of the Gen5X employs Fusion 360’s gen-\\nerative design tools, which use parametric inputs to generate \\ndesigns. This means the Gen5X can be customized based on the \\ncomponents you already have.\\nIn building products, generative design simplifies complex \\nassemblies. An example is the Elbo chair, designed by Autodesk’s \\ngenerative design lab (Figure\\xa03.6). The chair’s design was opti-\\nmized by algorithms, resulting in a structure that is 18 percent \\nlighter and shows fewer signs of stress in its joints.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 169, 'page_label': '156'}, page_content='156 GENERATIVE AI\\nWhere Is Generative Design Going? The future holds the \\npromise of designs that are not only superior in quality but also \\nmore aligned with the designer’s intent, all achieved in less time. \\nGenerative design is poised to be a game changer, particularly in \\nthe fields of architectural, industrial, and product design. Its \\nstrength lies in its ability to optimize parameters directly linked \\nto geometric changes, making it a formidable tool for early \\ndesign and prototyping.\\nT ake, for instance, the realm of mechanical, electrical, and \\nplumbing (MEP) services. Some companies have started to har -\\nness the power of generative design for design exploration and \\ndecision making. Addiform, a company specializing in additive \\nmanufacturing, leverages generative design to create complex \\noptimized parts for various industries. This is not merely a mat-\\nter of employing a new tool; it’s about harnessing our collective \\nimagination to unlock the full potential of this technology.\\nFIGURE\\xa0 3.6 The Elbo chair, an exemplar of generative design and \\nadditive manufacturing by Autodesk.\\nSource: Autodesk Inc.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 170, 'page_label': '157'}, page_content='Generative AI’s Broad  Spectrum of Applications 157\\nIn the realm of architecture, the potential applications of gen-\\nerative design are vast and compelling. Consider the case of the \\nlate architect Antoni Gaudí and his magnum opus, the Sagrada \\nFamilia in Barcelona. After Gaudí’s passing, the construction of \\nthe Sagrada Familia proceeded based on reconstructed versions of \\nhis plans, which had been partially destroyed in a fire. While gen-\\nerative design was not employed in this instance, one can envision \\nhow it could have significantly contributed to this process, aiding \\nin the completion of the architectural designs in a way that hon-\\nored Gaudí’s original vision.\\nThe implications of this technology are far-reaching. As ele-\\nments become lighter and stronger, industries such as aerospace \\nand construction will be significantly boosted. For instance, gen-\\nerative design is already transforming the way aircraft are built. \\nA BBC article reported how designers are using AI and genera-\\ntive design to create aircraft components that are lighter, stronger, \\nand more efficient. This not only reduces the weight of the air -\\ncraft but also enhances its overall performance.\\nImagine a future skyline, a vista of towering buildings pro-\\nduced by generative design (Figure\\xa03.7). We are not as far off \\nfrom this reality as one might think. People using Midjourney \\nbuild visual ideas that are at the forefront of this movement, cre-\\nating innovative solutions that not only meet functional require-\\nments but also inspire awe with their aesthetic appeal. However, \\nit’s important to note that this transformation will not occur \\novernight. It’s a mid- to long-term projection, as it will take time \\nfor us to fully realize the potential of generative design.\\nThe future of generative design is bright and full of poten-\\ntial. As we continue to explore and harness this technology, we \\ncan expect to see a revolution in the way we design and create \\nobjects, from the smallest components to the tallest skyscrapers. \\nThe key lies in our ability to imagine, to innovate, and to inte-\\ngrate this powerful tool into our design processes.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 171, 'page_label': '158'}, page_content='158 GENERATIVE AI\\nSolving Problems in Science by Google DeepMind\\nLet’s now turn our attention to the work of Google DeepMind, \\nwhose groundbreaking applications have not only pushed the \\nboundaries of what we thought was possible but also laid a sig-\\nnificant foundation for the future of artificial general intelligence.\\nDeepMind’s Broad Range of Offerings In 2016, the world of \\nAI was abuzz with the news of DeepMind’s AlphaGo triumphing \\nover Lee Sedol, a player of the highest skill level, 9th dan, in the \\nintricate game of Go. A game of immense complexity, Go boasts \\nmore potential board configurations than the number of atoms in \\nthe universe. This extraordinary accomplishment underscored \\nthe formidable capabilities of AI and its potential to navigate and \\nsolve problems of great complexity.\\nFIGURE\\xa03.7 Midjourney prompt: “Architecture futuristic city designed \\nfrom parametric organic buildings, CGI render, beautiful, cinematic, \\nphotorealistic, highly detailed, vivid, unreal engine.”\\nSource: AI-generated image created in Midjourney, Inc.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 172, 'page_label': '159'}, page_content='Generative AI’s Broad  Spectrum of Applications 159\\nBuilding on the success of AlphaGo, DeepMind introduced \\nAlphaGo Zero in 2017. Unlike its predecessor, which learned \\nfrom thousands of human games, AlphaGo Zero learned solely \\nthrough self-play, a process known as reinforcement learning. \\nThis improved version of AlphaGo defeated the original \\nAlphaGo 100\\xa0games to 0, demonstrating the power of learning \\nfrom scratch.\\nLater that year, DeepMind unveiled AlphaZero, a modified \\nversion of AlphaGo Zero that could handle any two-player game \\nof perfect information. AlphaZero gained superhuman abilities \\nat chess and shogi, again learning solely through self-play. This \\nwas a significant step forward, showing that an AI system could \\nlearn to master different games without any prior knowledge.\\nIn a similar vein, DeepMind researchers published a new \\nmodel named MuZero in 2019. MuZero mastered the domains \\nof Go, chess, shogi, and Atari 2600\\xa0games without human data, \\ndomain knowledge, or known rules. This was a significant leap \\nforward in the development of AGI, demonstrating that an AI \\nsystem could learn to understand and master different environ-\\nments from scratch.\\nIn October 2022, DeepMind unveiled AlphaT ensor, a new \\nversion of AlphaZero, in a paper published in Nature. AlphaT en-\\nsor discovered a faster way to perform matrix multiplication— \\none of the most fundamental tasks in computing— using \\nreinforcement learning. For example, AlphaT ensor figured out \\nhow to multiply two mod-2 4×4\\xa0matrices in only 47\\xa0multiplica-\\ntions, unexpectedly beating the 1969 Strassen algorithm record \\nof 49\\xa0multiplications. This discovery has significant implications \\nfor computational efficiency and could lead to substantial savings \\nin computing steps in the future. This is a monumental achieve-\\nment in the field of AI and evidence of the potential of'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 173, 'page_label': '160'}, page_content='160 GENERATIVE AI\\nreinforcement learning in discovering novel, efficient algorithms \\nfor fundamental computational tasks.\\nIn the realm of competitive gaming, DeepMind’s AlphaStar \\nmade significant strides. In July 2019, AlphaStar began playing \\nagainst random humans on the public 1v1 European multiplayer \\nladder. Unlike the first iteration of AlphaStar, which played only \\nProtoss v. Protoss, this one played as all of the game’s races and \\nhad earlier unfair advantages fixed. By October 2019, AlphaStar \\nreached Grandmaster level on the StarCraft II ladder on all three \\nStarCraft races, becoming the first AI to reach the top league of \\na widely popular electronic sport (esport) without any game \\nrestrictions.\\nThese achievements of Google DeepMind are not just impres-\\nsive feats in the world of AI; they also mark important milestones \\nin our journey towards AGI. Each of these AI solutions, powered \\nby conventional AI and reinforcement learning, serves as a corner-\\nstone for the future of AGI. As we continue to explore and harness \\nthe power of AI, we can expect to see even more groundbreaking \\nadvancements in the field.\\nAlphaFold One of DeepMind’s most notable contributions in \\ngenerative AI is AlphaFold, a program that predicts protein \\nstructure using deep learning techniques. This is not a general \\napplication field but rather a specific one, and it’s crucial for solv-\\ning problems in biology. However, it’s worth noting that despite \\nthe heavyweight nature of this specific application field, where \\ndeep knowledge is required to achieve even slight results, there \\nare countless other niche application fields that one can still \\nexplore or even create. We are very much in the early stages of \\ngenerative AI and AI in general.\\nAlphaFold has had two major versions: AlphaFold 1 (2018) \\nand AlphaFold 2 (2020), both of which placed first in the Critical'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 174, 'page_label': '161'}, page_content='Generative AI’s Broad  Spectrum of Applications 161\\nAssessment of Structure Prediction (CASP) competitions of \\ntheir respective years. But why focus on protein folding? What’s \\nthe problem it’s trying to solve?\\nProteins consist of chains of amino acids that fold to form \\nthe 3D structures of the proteins, a process known as protein \\nfolding. Understanding how the amino acid sequence determines \\nthe 3D structure is highly challenging, and this is referred to as \\nthe protein folding problem. Before AlphaFold, methods of deter -\\nmining protein structures were expensive and time-consuming, \\nand computational methods were not close to experimental tech-\\nniques in terms of accuracy.\\nAlphaFold was trained on over 170,000 proteins from a pub-\\nlic repository of protein sequences and structures. The program \\nuses a form of attention network, a deep learning technique that \\nfocuses on having the AI identify parts of a larger problem, as \\nmentioned earlier in the section “Democratizing AI: Hugging \\nFace’s Success Story,” then piecing them together to obtain the \\noverall solution (Figure\\xa03.8). Y ou can see that its predictive power \\nis a close approximation to the experimental result, which can be \\nseen as the ground truth.\\nAlphaFold 1, introduced in 2018, used advanced learning \\nmethods to estimate a probability distribution for how close the \\nresidues were likely to be, turning the contact map into a likely \\ndistance map. AlphaFold 2, introduced in 2020, is significantly \\ndifferent from the original version. It replaced the software \\ndesign used in AlphaFold 1\\xa0with a system of subnetworks cou-\\npled together into a single differentiable end-to-end model, \\nbased entirely on pattern recognition. Local physics, in the form \\nof energy refinement based on the AMBER model, is applied \\nonly as a final refinement step once the neural network predic-\\ntion has converged. The AMBER model, in simple terms, is'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 175, 'page_label': '162'}, page_content='162 GENERATIVE AI\\na tool used in computational chemistry and biology to simulate \\nand understand how molecules, like proteins, behave. It uses the \\nprinciples of physics to predict how atoms in a molecule move \\nand interact with each other.\\nThere are four main concepts to understand about Alpha-\\nFold. First, AlphaFold generally works by starting off with an \\neducated guess, then iteratively improving the 3D generation. \\nSecond, it uses an attention-based model, focusing on all impor-\\ntant information rather than the latest information. For example, \\nin protein folding, certain amino acids could be folded right next \\nto each other while being far away in the input sequence. Third, \\nexpert knowledge is integrated. Some proteins fold in a specific \\nway and some are exceptions. Much of this expertise is included \\nin the model. Fourth, around 95 percent of the AI pipeline is \\ntrainable, so the model is continuously refined where possible \\nT1037 / 6vr4 T1049 / 6y4f\\n90.7 GDT 93.3 GDT\\n(adhesin tip)(RNA polymerase domain)\\nExperimental result\\nComputational prediction\\nFIGURE\\xa03.8 AlphaFold’s predictive power.\\nSource: www.deepmind.com/blog/alphafold- a- solution- to- a- 50- year- old- grand-  \\nchallenge- in- biology'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 176, 'page_label': '163'}, page_content='Generative AI’s Broad  Spectrum of Applications 163\\nand where new data is available. The team at Google DeepMind \\ncontinues to develop AlphaFold, focusing their efforts on areas \\nwhere they know the model’s weaknesses lie, such as in the field \\nof human antibody interactions.\\nDeepMind’s Gift to Humanity The typical narrative of inno-\\nvation involves a company solving a complex problem and subse-\\nquently monetizing the solution. The more intricate the problem, \\nthe higher the price tag, particularly when demand is high. How-\\never, Google DeepMind chose a different path. They not only \\nopen sourced the AlphaFold source code but also made its data-\\nbase, containing all resulting 3D protein structures, freely avail-\\nable. This database has grown exponentially over the past year, \\nfrom 1\\xa0 million to over 200\\xa0 million proteins, covering nearly \\nevery known protein on Earth. Figure\\xa0 3.9 illustrates a rough \\nscale of proteins starting from 1 amino.\\n1\\nAMINO ACID AMINO ACIDS\\nIN A STRING\\nAMINO ACIDS\\nIN A PROTEIN\\n20 100’s 20,000\\nPROTEINS IN\\nTHE HUMAN BODY\\nDISTINCTIVE PROTEINS\\nFOUND ON EARTH\\n200,000,000\\nFIGURE\\xa0 3.9 The exponential growth of the protein database, now \\nencompassing nearly every known protein on Earth.\\nSource: Adapted from www.deepmind.com/research/highlighted-research/alphafold.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 177, 'page_label': '164'}, page_content='164 GENERATIVE AI\\nThis decision has had profound implications for the scien-\\ntific community. Researchers can now encounter a protein \\nsequence in their work and find its 3D folding already cataloged \\nin Google DeepMind’s database. This has significantly acceler -\\nated the pace of research. As John McGeehan, a professor of \\nstructural biology at the University of Portsmouth, puts it, “What \\ntook us months and years to do, AlphaFold was able to do in a \\nweekend.” This has effectively put research on steroids, enabling \\nscientists to make rapid advancements in their respective fields.\\nSeveral alternatives to AlphaFold have emerged. Meta AI’s \\nESMFold offers accurate atomic-level predictions and competes \\nwith RoseTTAFold, another significant player developed by aca-\\ndemic researchers. Both are open source and have demonstrated \\ntheir utility to the scientific community.\\nRaptorX and IntFOLD are other protein prediction models \\nthat hold their own in this competitive field. OmegaFold, devel-\\noped by Chinese biotech firm Helixon, predicts high-resolution \\nprotein structure from a single primary sequence, even outper -\\nforming RoseTTAFold while achieving prediction accuracy sim-\\nilar to that of AlphaFold 2.\\nPhyre and Phyre2 offer remote template detection, alignment, \\nand 3D modeling tools for protein structure prediction. Lastly, \\nOpenFold is another notable option for protein folding predic-\\ntion, often mentioned as an alternative to AlphaFold 2. These \\ntools, each with their unique strengths, contribute to the rapid \\nadvancements in protein folding prediction.\\nWhere Is AlphaFold Going? AlphaFold’s (and other models’) \\nimpact is not just a ripple, but a tidal wave that is reshaping our \\nunderstanding of the world. Its implications are vast, and its \\npotential is only just beginning to be realized.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 178, 'page_label': '165'}, page_content='Generative AI’s Broad  Spectrum of Applications 165\\nThe potential of AlphaFold is not confined to the realm of \\nacademia; it has profound implications for the future of human-\\nity. As an example, Ray Kurzweil, the American inventor and \\nfuturist, in his book The Singularity Is Near, envisions a future \\nwhere diseases like cancer and heart disease could be cured, and \\nthe human body could be maintained indefinitely by 2030. This \\nis not just a lofty dream; with the advancements brought about \\nby AlphaFold, it is a tangible possibility.\\nOne of the most significant impacts of AlphaFold is its poten-\\ntial to enhance our understanding of the human body. For \\ninstance, the nuclear pore complex, a massive assembly of pro-\\nteins that controls the traffic in and out of the nuclei in cells, has \\nlong been a mystery to scientists. However, with the help of \\nAlphaFold, researchers have been able to decipher its structure, \\npaving the way for a deeper understanding of how cells function \\nand opening up new avenues for medical research.\\nIn the realm of medicine, AlphaFold holds the promise of \\ncreating more effective treatments. For example, it could aid in \\nthe development of drugs to combat malaria, a disease that con-\\ntinues to claim hundreds of thousands of lives each year. By pre-\\ndicting the structure of the proteins involved in the disease, \\nresearchers could design drugs that target these proteins more \\neffectively, potentially saving countless lives.\\nThe implications of AlphaFold extend to our food system as \\nwell. By understanding the structure of proteins involved in food \\nproduction, we could develop healthier and more nutritious \\nfood. This could revolutionize the food industry and contribute \\nto the global fight against malnutrition and obesity.\\nIn terms of disease prevention, AlphaFold could play a crucial \\nrole in the development of effective vaccines. By predicting the \\nstructure of viral proteins, it could aid in the design of vaccines'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 179, 'page_label': '166'}, page_content='166 GENERATIVE AI\\nthat can effectively neutralize these viruses, potentially prevent-\\ning future pandemics.\\nAlphaFold could also contribute to our efforts to combat \\nglobal warming. By understanding the structure of proteins \\ninvolved in carbon capture, we could develop effective tools for \\ncapturing carbon dioxide. This could be a significant step in reduc-\\ning greenhouse gas emissions and mitigating the effects of cli-\\nmate change.\\nIn the realm of materials science, AlphaFold could aid in the \\nproduction of sustainable biomaterials. By predicting the struc-\\nture of proteins involved in material production, we could design \\nand produce materials that are not only strong and durable but \\nalso environmentally friendly.\\nMoreover, AlphaFold could also aid in the creation of artifi-\\ncial enzymes to produce building materials like carbon nano-\\ntubes and graphene. These materials have unique properties that \\nmake them ideal for a variety of applications, from electronics to \\nenergy storage. With the help of AlphaFold, we could design \\nenzymes that can produce these materials more efficiently and \\nsustainably.\\nCode Generation\\nMuch like text, sound, and other sequential data types, code is \\nwell suited for T ransformer models. The implications of this are \\nprofound, as it streamlines the coding process and enhances the \\nproductivity of developers.\\nGoogle DeepMind’s AlphaCode Google DeepMind has con-\\ntinued its AlphaSeries with the introduction of AlphaCode. This \\nAI code-generation system has reached a competitive level of per-\\nformance in programming competitions, a feat that marks a sig-\\nnificant milestone in the field. AlphaCode operates by leveraging'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 180, 'page_label': '167'}, page_content='Generative AI’s Broad  Spectrum of Applications 167\\na massive dataset of programming problems and solutions, as well \\nas unstructured code from GitHub.\\nAlphaCode’s approach to code generation is not just intelli-\\ngent but also efficient. It generates thousands of proposed solu-\\ntions to a given problem, filters out the invalid ones, and then \\nclusters the remaining solutions into groups. From each group, a \\nsingle example is selected for submission. The system has been \\ntrained in various programming languages, including C++, C, \\nGo, Java, JavaScript, Lua, PHP , T ypeScript, Ruby, Scala, Rust, \\nand Python.\\nIn a Codeforces programming contest, AlphaCode ranked \\non average in the top\\xa054 percent against more than 5,000 partici-\\npants in 10 contests. This achievement, which took place in 2022, \\nmarked the first time an AI code generation system has reached \\na competitive level of performance in programming competitions.\\nHowever, it’s important to note that AlphaCode still  \\nrelies heavily on specific examples provided with the problem \\ndescription. Without these examples, its success rate would \\ndrop significantly.\\nThe advent of AI-driven code generation is not just a techno-\\nlogical breakthrough; it’s a paradigm shift in how we approach \\ncoding. As we continue to explore and harness the power of AI in \\nthis field, we can look forward to a future where coding is not just \\nfaster and more efficient, but also more accessible to a broader \\nrange of individuals.\\nGitHub Copilot As a data scientist, I find the advent of code \\ngeneration not just fascinating, but exhilarating. I am, by nature, \\nan optimist. The thought of AI taking over some aspects of my \\njob doesn’t fill me with dread; rather, it stirs in me a sense of \\nanticipation. The prospect of seeing my ideas come to life with \\nless manual effort is genuinely exciting.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 181, 'page_label': '168'}, page_content='168 GENERATIVE AI\\nT oday’s coding landscape offers a rich array of tools, two of \\nwhich have become integral to my work. I not only use these \\ntools extensively but also strongly advocate for their use within \\nmy teams. GitHub Copilot is the first of these, serving as my reli-\\nable companion throughout the coding process. The second is \\nChatGPT , a tool I frequently engage with during non-coding \\nphases, such as the initial stages of a project.\\nHowever, it’s important to note a crucial aspect of using \\nChatGPT . While it’s a powerful tool for generating human-like \\ntext and assisting with various tasks, it’s essential to remember \\nthat it’s not designed to handle confidential information. I always \\nensure that my teams are aware of this and exercise caution not \\nto send any sensitive data to ChatGPT . This way, we can lever-\\nage the benefits of these advanced AI tools while maintaining our \\ncommitment to data privacy and security.\\nNow, GitHub Copilot is an AI-powered pair programmer \\nthat provides autocomplete-style suggestions as you code. Devel-\\noped by GitHub and OpenAI, it’s a cloud-based tool that assists \\nusers of various integrated development environments (IDEs), \\nincluding Visual Studio Code, Visual Studio, Neovim, and Jet-\\nBrains. It’s powered by OpenAI Codex, a production version of \\nthe Generative Pre-trained T ransformer 3 (GPT-3). This lan-\\nguage model uses deep learning to produce human-like text. The \\nCodex model is further trained on gigabytes of source code in \\nmultiple programming languages.\\nGitHub Copilot is trained on a selection of the English lan-\\nguage, public GitHub repositories, and other publicly available \\nsource code. This includes a filtered dataset of 159 gigabytes of \\nPython code sourced from 54\\xa0million public GitHub reposito-\\nries. Interestingly, OpenAI’s GPT-3 is licensed exclusively to \\nMicrosoft, GitHub’s parent company— a strategic move, indeed.\\nGitHub Copilot is designed to help developers code faster, \\nfocus on solving bigger problems, and stay in the flow longer.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 182, 'page_label': '169'}, page_content='Generative AI’s Broad  Spectrum of Applications 169\\nIt aims to make work more fulfilling. However, it’s worth noting \\nthat it may also produce suggestions based on insecure coding \\npatterns, bugs, or references to outdated APIs or idioms. The \\ncoder has to remain responsible at all times and not go on auto-\\npilot. Despite these potential pitfalls, the tool is expected to com-\\nplement the work of developers, empowering them to write code \\nmore easily and focus more on their core competencies and \\ncreativity.\\nCoding with ChatGPT and Other LLMs Using ChatGPT or \\nsimilar LLMs, you can easily code entire programs. For example, \\nask it to create a Python agent that plans your day using the  \\nOpenAI API, integrating with your calendar. The model will \\nclarify details, suggest a program structure, and even write the \\ncode. While your oversight is necessary, the process significantly \\naccelerates product development. Figure\\xa03.10 shows an example \\nof ChatGPT output, guiding you to build an AI agent.  \\nRemember to responsibly manage sensitive information shared \\nwith ChatGPT .\\nTransforming Traditional Data Analyst Practices The \\ntransformative power of generative AI doesn’t stop at making \\ncoding 10 times faster and more efficient. It’s also reshaping the \\nlandscape of data analysis as we know it. In fact, it’s safe to say \\nthat traditional data analysis is, to a degree, becoming legacy. \\nWith applications like PandasAI and the Code Interpreter plug-\\nin for ChatGPT , or offerings from Notable, data analysis has \\nbecome accessible to anyone who can formulate their thoughts \\nlogically.\\nConsider the Code Interpreter plug-in for ChatGPT , for \\nexample. Imagine you have a dataset that needs to be clustered. \\nY ou simply upload the data and ask the plug-in to perform an'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 183, 'page_label': '170'}, page_content='170 GENERATIVE AI\\nelbow chart for the data. Instead of manually choosing the range \\nof numbers of clusters, performing a k-means clustering for each \\ncluster number, calculating the sum of squared errors, plotting \\nthe sum of squared errors per number of clusters (the so-called \\nelbow plot), and identifying the elbow point (the optimal num-\\nber of clusters in a dataset), the Code Interpreter does all these \\nsteps for you. Y ou state what you want, and it infers what needs \\nto be done to get there, then codes the respective analysis code.\\nPandasAI works similarly, except it takes only library com-\\nmands from the Pandas library. This shift in the way we approach \\nFIGURE\\xa03.10 An overview of how to build an LLM agent, its structure, \\nclasses, and methods needed.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 184, 'page_label': '171'}, page_content='Generative AI’s Broad  Spectrum of Applications 171\\ndata analysis and coding has a profound impact on future app \\nand product development. It democratizes the field, turning eve-\\nryone into a developer. Figure\\xa03.11 illustrates PandasAI in action.\\nThe AI code generation space is bustling with other notable \\nprojects and startups. Magic AI, for instance, is building an AI \\nplatform that generates code by allowing software engineers to \\ndescribe what they want in natural language. Other players in the \\nfield include T abnine, CodePal, Builder.ai, Engineer.ai, T uring, \\nT onic.ai, and many more. Each of these entities is contributing \\nto the evolution of coding and data analysis, making these fields \\nmore accessible and efficient than ever before.\\nFIGURE\\xa03.11 Using a single command to generate a plot from the data \\ncontained within the df data frame.\\nSource: https://github.com/gventuri/pandas- ai'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 185, 'page_label': '172'}, page_content='172 GENERATIVE AI\\nText Generation\\nT ext generation transforms ideas into written language, creating \\ncoherent, contextually relevant text. This technology, powering \\napplications like chatbots and content creation tools, is revolu-\\ntionizing current communication. While this book delves into \\nvarious LLMs like open source options, ChatGPT , and Bard, we \\nalso focus on strategically planning LLM applications such \\nas Cicero.\\nCicero As we continue to explore the vast potential of language \\nmodels in generative AI, it’s worth shifting our gaze to the \\ngroundbreaking work done by Meta AI with Cicero. Cicero is an \\nAI that has mastered the art of Diplomacy, a strategy game that \\ndemands not just strategic planning but also the ability to build \\ntrust, negotiate, and cooperate with multiple players.\\nFor those unfamiliar with Diplomacy, it’s a game that can be \\nlikened to a blend of Risk, poker, and the TV show Survivor. \\nUnlike many board games where the objective is to outmaneuver \\nyour opponents on the board, Diplomacy requires a cooperative \\ncomponent. The only way to win is by working with other play-\\ners to capture as much territory as possible, with negotiation and \\nalliance-building being key to success.\\nCicero has the distinction of being the first AI to play Diplo-\\nmacy at a human level. It has demonstrated an uncanny ability to \\nform strong alliances, make moves that benefit its allies, and \\nengage in simultaneous planning and conversation with players. \\nIt uses honesty as a tactic, understanding that trustworthiness is \\na valuable trait in the game. However, it’s also capable of decep-\\ntion when necessary to secure a win for its team.\\nProfessional human players have reported an eerie sense \\nthat Cicero seems to anticipate their plans. This is likely due to \\nCicero’s integration of a language model with planning and'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 186, 'page_label': '173'}, page_content='Generative AI’s Broad  Spectrum of Applications 173\\nreinforcement learning, allowing it to infer players’ beliefs and \\nintentions. There’s more to language models and strategic rea-\\nsoning than just scaling up models.\\nCicero’s performance in Diplomacy is nothing short of supe-\\nrior. It has achieved more than double the average score of human \\nplayers on webDiplomacy.net, an online version of the game, and \\nranked in the top\\xa010 percent of participants who played more \\nthan one game. This achievement is a testament to the power of \\ncombining two different areas of AI: strategic reasoning and nat-\\nural language processing. The integration of these techniques \\ngives Cicero the ability to reason and strategize with regard to \\nplayers’ motivations, then use natural language to communicate, \\nreach agreements to achieve shared objectives, form alliances, \\nand coordinate plans.\\nThe success of Cicero illustrates the potential of AI in com-\\nplex strategy games that require not just strategic thinking but \\nalso the ability to communicate and negotiate.\\nWhere Are Applications Like Cicero Going? The question \\nis not so much about where we are now, but rather, where we are \\nheaded. How can this be harnessed to benefit us in ways we have \\nyet to imagine?\\nThe potential applications and directions for AI models like \\nCicero are as vast as they are varied. One such avenue lies in the \\nrealm of military strategy. The U.S. Army War College has \\nalready begun to explore this, developing an AI tool called the \\nEnemy Analysis T ool, which uses AI to analyze enemy actions \\nand predict their future movements. This tool has the potential \\nto revolutionize military strategy, providing a level of insight and \\nforesight previously unattainable.\\nIn the commercial arena, AI is already leaving an indelible \\nfootprint. Pactum, a pioneering startup, has engineered an AI'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 187, 'page_label': '174'}, page_content='174 GENERATIVE AI\\ncapable of autonomously negotiating business agreements, \\nthereby eliminating the need for human involvement. This AI, \\narmed with machine learning and game theory, adeptly navigates \\nthe intricacies of contract negotiation.\\nThe sphere of political decision making is another area ripe for \\nAI transformation. SingularityNET , an AI-focused enterprise, is in \\nthe process of crafting an AI sociopolitical decision support system. \\nThis innovative system employs AI to dissect complex sociopoliti-\\ncal scenarios and offer insightful decision-making guidance.\\nEvent planning, too, could undergo a revolution with the \\nadvent of AI. Skift, a platform specializing in travel industry \\nintelligence, has explored the potential of AI to automate diverse \\nfacets of event planning, from scheduling intricacies to vendor \\nnegotiation.\\nThe gaming industry is another sector that stands to gain \\nsignificantly from AI. Artificial intelligence is being harnessed to \\nautomate various elements of game development, such as charac-\\nter dialogue generation and the creation of personalized racing \\ncommentary. This not only lightens the load for game develop-\\ners but also enriches the gaming experience for players.\\nFinally, AI models akin to Cicero could be employed to \\namplify social interactions. A study featured in the Journal of \\nMarketing delves into the concept of artificial empathy, where AI \\nis crafted to mirror human empathy in interactions. This innova-\\ntive approach holds the potential to elevate the customer experi-\\nence across various sectors, from customer service to marketing.\\nAI Agents: The Active Executors in Generative AI As we talk \\nabout the capabilities of LLMs and their systems, it becomes appar-\\nent that AI agents represent the next logical frontier in the realm of \\ngenerative AI. Far from being just another application field, AI \\nagents are a burgeoning domain that amplifies the potential of gen-\\nerative AI. They hold the promise of enhancing every application'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 188, 'page_label': '175'}, page_content='Generative AI’s Broad  Spectrum of Applications 175\\nfield we’ve discussed so far. The only constraint, it appears, is the \\nboundary of our imagination, and perhaps more development.\\nAI agents, while in their infancy, are already showing promis-\\ning results. However, defining them precisely at this moment in \\ntime is challenging due to the various versions and interpreta-\\ntions that exist. This is the very active part of generative AI. T wo \\ndominant types of AI agents have emerged, with everything in \\nbetween yet to be determined.\\nThe first type of AI agent is one that is given a simple task, \\nexecutes it, and returns with the result. This could be a stand-alone \\nagent or a language model like ChatGPT that uses a plug-in. It \\ndoesn’t matter if it’s a single agent that is launched and then exe-\\ncutes the requested task or if it’s a language model that performs \\nan action based on the ask.\\nChatGPT plug-ins, for instance, are connected to the Inter-\\nnet, external data sources, or third-party services, enhancing the \\naccuracy of its responses and allowing for a more personalized \\nexperience. Developed by third-party developers or OpenAI \\nitself, these plug-ins enable ChatGPT to access up-to-date infor-\\nmation, run computations, and interact with APIs defined by \\ndevelopers (Figure\\xa03.12).\\nFIGURE\\xa03.12 The rapid expansion of ChatGPT plug-ins, with over 100 \\nunique plug-ins developed in just 40\\xa0days.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 189, 'page_label': '176'}, page_content='176 GENERATIVE AI\\nHere are a few notable ChatGPT plug-ins available in 2023:\\nWolfram This plug-in provides access to advanced computa-\\ntional, mathematical, and real-time data to answer various \\nquestions of quantifiable nature— a great complement to what \\nlanguage models appear to be lacking. Its technical nature \\nmight be off-putting for some users, but it’s one of the best due \\nto its advanced abilities.\\nZapier Designed for busy professionals and marketers, Zapier \\nstreamlines repetitive tasks by facilitating seamless communi-\\ncation between more than 5,000 popular business programs, \\nsuch as Gmail, Microsoft Outlook, and Slack.\\nChatGPT Chess Plug-in This plug-in allows you to play \\nchess with the AI and get better at the game.\\nChatGPT KAYAK or Expedia Plug-in Another travel-\\nrelated plug-in, KAYAK assists with flight and hotel bookings.\\nArgil AI This plug-in assists with 3D modeling and design.\\nChatWithPDF This plug-in allows you to view, annotate, and \\nextract text from PDFs— making it an invaluable tool for aca-\\ndemic research or extensive reading.\\nSpeechki Ideal for podcasters, audiobook creators, and con-\\ntent producers, Speechki transforms text into high-quality  \\naudio.\\nThe potential for new plug-ins that could enhance the capa-\\nbilities of ChatGPT is vast. Let’s explore some of these potential \\nideas that might exist by the time you are reading this, keeping in \\nmind that data privacy is not our focus here.\\nImagine a healthcare plug-in that seamlessly integrates with \\nelectronic health record systems. This would allow healthcare pro-\\nfessionals to pull up patient information, check drug interactions, or'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 190, 'page_label': '177'}, page_content='Generative AI’s Broad  Spectrum of Applications 177\\neven generate preliminary diagnoses based on symptoms described \\nby the patient.\\nIn the sphere of education, a plug-in that connects to educa-\\ntional resources and databases could be a game changer. It could \\nprovide students with explanations of complex concepts, solu-\\ntions to problems, or even personalized study plans based on \\ntheir learning style and progress.\\nIn the financial sector, a plug-in that integrates with financial \\nAPIs could allow users to check stock prices, get investment \\nadvice, or even execute trades directly from the chat interface.\\nThe real estate industry could also benefit from a plug-in \\nthat integrates with real estate databases. This would allow users \\nto search for properties, compare prices, and get information \\nabout different neighborhoods.\\nFitness enthusiasts would appreciate a plug-in that integrates \\nwith fitness APIs, allowing users to track their workouts, get \\nexercise recommendations, or even create personalized workout  \\nplans.\\nLastly, a legal plug-in that connects to legal databases could \\nprovide users with basic legal advice and explanations of legal \\nterms, or even help them draft simple legal documents.\\nThese are just a few examples of the potential plug-ins that \\ncould be developed to enhance the capabilities of ChatGPT . The \\npossibilities are endless, and the future of AI-assisted conversa-\\ntions is exciting.\\nAutonomous Agents The second type of AI agent is autono-\\nmous agents. These are not the AI tools of yesteryear, but \\nadvanced systems capable of executing tasks independently, with \\nminimal human supervision. Y et, they are designed with a fail-\\nsafe, a provision for human intervention, should the need arise. \\nThis is not a distant future concept, but a reality that is taking \\nshape even as we speak.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 191, 'page_label': '178'}, page_content='178 GENERATIVE AI\\nThe allure of autonomous agents lies in their efficiency and \\ncost-effectiveness. They are tireless, working around the clock \\nwithout the need for breaks or sleep. They perform tasks at a \\nfraction of the cost of human employees.\\nThe applications of these autonomous agents are as diverse \\nas they are numerous. Consider the realm of social media man-\\nagement, a task that requires constant vigilance and timely \\nresponses. An autonomous agent can monitor multiple platforms \\nsimultaneously, respond to queries, and even manage promo-\\ntional campaigns, all without breaking a sweat.\\nBut the reach of autonomous agents extends beyond the realm \\nof social media. They are making inroads into the world of politi-\\ncal campaign management, a field that requires strategic planning, \\nmeticulous execution, and constant monitoring. Autonomous \\nagents can analyze vast amounts of data, identify trends, and make \\nstrategic recommendations, all while managing the day-to-day \\ntasks of a campaign.\\nThe future of work is also set to undergo a seismic shift with \\nthe advent of autonomous agents. In the not-too-distant future, \\nit is conceivable that most people will not report to a human \\nboss, but to an autonomous agent. This is not a dystopian vision, \\nbut a pragmatic projection based on the capabilities of these \\nadvanced AI systems.\\nThe trajectory of autonomous agents points toward main-\\nstream adoption, not just in niche sectors, but across the board. \\nEvery category, every industry, every task that can be automated \\nwill likely see the integration of autonomous agents. This is not \\na prediction but an eventuality that we are moving toward. \\nAutonomous agents are not just tools, but partners, collabora-\\ntors, and perhaps even future colleagues.\\nUnderstanding Autonomous Agents: A\\xa0Practical Example  \\nImagine the task at hand is to construct a web page that fetches \\ndaily T witter news, presenting the top three categories and 10'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 192, 'page_label': '179'}, page_content='Generative AI’s Broad  Spectrum of Applications 179\\nposts of the day. T o accomplish this, we first need to set up the \\nautonomous agent. In my experience, the open source project \\nAutoGPT is the most robust code repository for autonomous \\nagents currently available. We’ve cloned it, configured all neces-\\nsary APIs like OpenAI for GPT-4, and prepared for the heavy \\nlifting. We’ve also set up GPT-3.5 for quick, cost-effective \\nresponses.\\nA crucial component that requires setup is long-term mem-\\nory. From my experiments, Pinecone seems to be the best option, \\nalthough open source solutions like Milvus also hold their own.\\nOnce set up, AutoGPT is capable of cloning GitHub reposi-\\ntories, running them, accessing X (formerly T witter), and per -\\nforming online search engine searches. We present our goal to \\nthe autonomous agent, which, in a touch of whimsy, gives itself a \\nname— in this case, WebdevGPT . It then dissects the goal into \\nmanageable tasks.\\nThe tasks it identifies include performing an online search \\naround best practices for setting up such web pages, developing \\nthe frontend with HTML, CSS, and JavaScript, and creating \\nbackend functionalities such as setting up APIs, building  \\ncron jobs, data fetching scripts, and a database. There’s also a \\ndata processing part, and finally, we want to deploy and test the  \\nweb page.\\nIn a fascinating display of autonomy, for each of these tasks \\nthe autonomous agent spawns its own team. It creates an AI \\nagent for performing prior online research, one for frontend \\ndevelopment, one for backend functionalities, and one for testing.\\nThe research agent dives into the Internet, swiftly scanning \\nthe top\\xa01,000 Google, Reddit, and Quora results. It distills its \\nfindings and reasons through them. The research agent then \\npasses its findings to the next agent, the frontend development \\nagent, which uses this information to build the web page accord-\\ningly. It sets up the structure with HTML, styles it with CSS, and \\nadds functionality with JavaScript.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 193, 'page_label': '180'}, page_content='180 GENERATIVE AI\\nSimultaneously, the backend agent codes the X/T witter \\nfetching pipeline, sets up the necessary cron jobs, and establishes \\nthe database. Once all these agents have completed their tasks, \\nthe quality assurance agent deploys the code locally and performs \\na thorough testing. If the quality standards are met, the code gets \\npackaged and the agents shut down. In just 17\\xa0minutes, we have \\na rudimentary, fully functioning web page.\\nIf bugs are detected, they are reported to the respective \\nagents for iteration. Throughout the entire process, AutoGPT \\nasks for confirmation at every step, ensuring that the human is in \\nthe loop. We could also set it on autopilot, allowing it to perform \\ntasks as it deems fit. However, given the nascent stage of this \\ntechnology, it’s advisable to regularly check if the planned tasks \\nare heading in the right direction.\\nThere are numerous examples of this online. And already as \\nof this writing, these agents are roughly one and a half to two \\nmonths old, and they’re already impressively showing the first \\nsparks of professional coworkers.\\nThe success of this approach could pave the way for the \\ndevelopment of more advanced AI agents that can collaborate \\nand negotiate with humans in various domains beyond gameplay. \\nThe technology behind this is relevant to many other applica-\\ntions, such as intelligent assistants that can hold long-term con-\\nversations with people and collaborate with them on complex \\ntasks. The future of autonomous agents is not just promising— \\nit’s already here.\\nMusic Generation\\nThe art of music generation has been a fascinating journey, tra-\\nversing a multitude of technical approaches. Initially, generative \\nalgorithms have been employed to create music based on estab-\\nlished rules or patterns. These algorithms take into account vari-\\nous aspects of music, such as melody, harmony, rhythm, and'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 194, 'page_label': '181'}, page_content='Generative AI’s Broad  Spectrum of Applications 181\\ntimbre, and then orchestrate new pieces that echo the style and \\nstructure of their training data.\\nRecurrent neural networks (RNNs) were once the favored \\ntool for this task. Their ability to model sequential data made \\nthem ideal for the job. Imagine a pianist, fingers dancing across \\nthe keys, each note influenced by the ones that came before. \\nThat’s how RNNs work— they can be trained on a collection of \\nMIDI files, which are essentially digital sheet music, and then \\nused to generate new music by predicting the next note in a \\nsequence based on the previous notes.\\nHowever, the stage of music generation was set for a new \\nperformer when generative adversarial networks (GANs) entered \\nthe scene. T o quickly recap, GANs consist of two neural net-\\nworks, a generator and a discriminator, engaged in a creative \\nrivalry to produce realistic music. The generator composes new \\nmusic samples, while the discriminator critiques these samples, \\ndiscerning whether they are real or fabricated. The generator, \\nlike a diligent student, refines its output based on the feedback \\nfrom the discriminator, leading to increasingly realistic music \\ngeneration over time.\\nThe latest act in this ongoing performance features, of course, \\nT ransformer models, as they have shown superior performance \\nin handling sequential data, adeptly analyzing rhythm and other \\nmusical elements.\\nIn the early days of the modern generative AI era, music gen-\\neration didn’t quite strike a chord with me. The output was dis-\\ncordant, and the lack of visual appeal made it less engaging. Over \\nthe years, there were a few noteworthy breakthroughs, but it \\nwasn’t until the debut of MusicLM in January 2023 that I felt AI \\nmodels truly hit the right notes in music generation.\\nGoogle’s MusicLM and Other AI Models/Tools MusicLM, a \\nproduct of Google’s innovation, is a sophisticated tool that gener-\\nates unique songs from user-provided text descriptions or ideas.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 195, 'page_label': '182'}, page_content='182 GENERATIVE AI\\nIt utilizes a hierarchical sequence-to-sequence modeling approach \\nto create high-quality music at 24\\xa0kHz, maintaining consistency \\nover extended durations. Additionally, MusicLM has the capacity \\nto adapt to both text and melody inputs, modifying melodies—  \\nwhether whistled or hummed— to match the style indicated in a \\ntext description.\\nMusicLM struck a chord with me, particularly because of its \\nversatility. Y ou simply type the caption that you envision for the \\nmusic you want to hear, and it generates the corresponding audio. \\nIt can be instructed for long music generation, or a story mode \\nwhere you write as the text prompt what music should be played \\nat the beginning, middle, and end, mapped on a timeline. It can \\ngenerate single music instruments such as acoustic guitar, cello, \\nor flute, or a specific genre like ambient or Berlin 90s house. It \\ncan even generate music mapped to the experience of the musi-\\ncian, places, decades, and all sorts of things. Witnessing this for \\nthe first time was nothing short of mind-blowing.\\nT o experience MusicLM, you can sign up for its waitlist \\nthrough Google’s AI T est Kitchen. Once approved, you can pro-\\nvide a descriptive phrase like “ambient, soft-sounding music I \\ncan study to.” MusicLM will then create two versions of the song \\nfor you to listen to, and you can award a trophy to the track you \\nprefer, which will help improve the model. This is human feed-\\nback in action!\\nGoogle has been collaborating with musicians and hosting \\nworkshops to gather early feedback and explore how this tech-\\nnology can enhance the creative process. They have also released \\nMusicCaps, a dataset composed of 5.5k music-text pairs with \\nrich text descriptions provided by human experts, to support \\nfuture research. It’s commendable when large for-profit compa-\\nnies support research in this way without penny-pinching.\\nT oday, there are numerous AI music generation companies \\nand projects. The top models that I’ve seen, according to their'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 196, 'page_label': '183'}, page_content='Generative AI’s Broad  Spectrum of Applications 183\\nhigh output quality, are from Amper Music, AIVA, and Ecrett \\nMusic. As the momentum of AI continues to build, larger com-\\npanies are making efforts to stay ahead of the trends. For exam-\\nple, Shutterstock acquired Amper Music in a strategic move. \\nWhile the precise acquisition cost isn’t known, it’s likely that \\nthese transactions involve considerable amounts, often in the \\nmillions. These companies, primarily operating for profit in their \\nrespective domains, typically do not disclose their technical \\nor AI stack.\\nI don’t want to delve too deeply into this, as there is only one \\nway to truly understand what I mean when I say “high output \\nquality.” I’m not suggesting that the AI is even remotely as good \\nas a maestro musician. However, if we consider the trajectory of \\nthis technology even three years ago and project that line of \\nquality linearly into the future, it’s clear that it will catch up with \\neven top human performance. And let’s not forget, this evolution \\nis anything but linear.\\nWhere Is Music Generation Going? Consider personalized \\nmusic streaming. Platforms like Spotify could incorporate AI-\\ngenerated music streams that are tailored to your specific needs. \\nEnvision a feature where you input your current mood, activity, \\nor event, and the AI composes a unique soundtrack just for you. \\nOr even in the fitness domain, AI could create dynamic music \\nthat syncs with your workout, from warm-up to HIIT (high-\\nintensity interval training) to cool-down.\\nT aking it a notch higher, we arrive at the concept of music \\ntherapy. AI could generate therapeutic music tailored to an indi-\\nvidual’s psychological and physiological state. This could serve as \\na tool for stress relief, focus enhancement, or emotional therapy.\\nWhat about interactive video games? The music in video \\ngames could evolve based on the player’s actions and decisions in \\nreal time, creating an immersive experience that is unparalleled.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 197, 'page_label': '184'}, page_content='184 GENERATIVE AI\\nBut what truly catches my attention is the prospect of AI \\nconcerts and albums. Just as we have seen AI-generated artwork \\nexhibitions, we might start seeing concerts or music albums \\nentirely composed and performed by AI. This isn’t a novel con-\\ncept, though. Hatsune Miku, one of Japan’s most beloved pop \\nstars, is a hologram. Over a 14-year career, this Japanese diva has \\nuploaded 170,000 Y ouT ube music videos, amassed more than \\n2.3\\xa0 million followers on Facebook, and released a staggering \\n100,000 songs. She has collaborated with Pharrell Williams, \\nopened for Lady Gaga, and her concerts are sold out worldwide. \\nShe even appeared at Coachella in 2020. The acceptance of an AI \\npop star is not a far-fetched idea. Similar trends can be observed \\nin Korea. While the hit songs are not fully AI-generated yet, this \\ntrend is bound to escalate.\\nLet’s pause and ponder a fascinating prospect: Artists who \\nare no longer with us could continue to hold concerts and even \\nproduce new albums. T ake Whitney Houston as an example. \\nDespite her passing in 2012, she embarked on a concert tour \\nfrom 2020 to 2023. Although it didn’t feature entirely new \\nsongs, imagine the possibilities if it had. Picture a future where \\nnew albums are released under her name, years after her \\ndeparture.\\nWhile we stand in awe of these innovations and their poten-\\ntial, we must also recognize the risks they carry, such as the dis-\\nplacement of musicians or the potential devaluation of music \\ncreated by humans. However, these very tools, if thoughtfully \\nintegrated, could also serve as a lifeline for musicians. They \\ncould stimulate the generation of musical ideas, assist in com-\\nposing harmonies, or even suggest enhancements to improve \\nthe quality of the music. In this way, AI can become a powerful \\nally, extending human creativity and accessibility in music, \\nrather than a threat.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 198, 'page_label': '185'}, page_content='Generative AI’s Broad  Spectrum of Applications 185\\nVideo Generation\\nWe’ve already explored the territory of image generation exten-\\nsively, discussing models like stable diffusion and DALL-E. \\nThese models, which deal with static image generation, have laid \\nthe foundation for a more dynamic frontier: video generation. \\nThis is a significantly more challenging endeavor, as it involves \\nnot just the creation of a single image, but a sequence of images, \\nor frames, that must be coherent, consistent, and sensible. Add to \\nthis the complexity of a storyline that goes beyond understand-\\ning spatial and temporal behaviors, but weaves intricate narra-\\ntives, and we find ourselves at a threshold that generative AI is \\nstill striving to cross.\\nThe Tech Behind Video Generation T o achieve video gen-\\neration, we move from stable diffusion models to video diffusion \\nmodels. Video diffusion models extend the standard image archi-\\ntecture and are effective for training from both image and video \\ndata. The fundamental concept behind video diffusion models is \\nto generate a fixed number of video frames using a 3D U-Net \\ndiffusion model architecture (more on this in a moment). T o \\ngenerate longer videos at higher resolutions, these models are \\nextended autoregressively, which means the output at any given \\nstep is influenced by the inputs at previous steps.\\nBut what exactly is a 3D U-Net? T o understand this, you first \\nneed to know what a U-Net is. A U-Net is a convolutional neural \\nnetwork originally developed for biomedical image segmenta-\\ntion. It’s designed with a unique architecture that supplements a \\ncontracting network with successive layers of upsampling opera-\\ntors, thereby increasing the resolution of the output. This results \\nin a U-shaped structure, hence the name U-Net (Figure\\xa03.13).'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 199, 'page_label': '186'}, page_content='186 GENERATIVE AI\\nThe network uses a large number of feature channels in the \\nupsampling part, allowing it to propagate context information to \\nhigher-resolution layers. This makes the expansive path symmet-\\nric to the contracting part, enabling more precise output based \\non the input image.\\nIn the realm of video generation, we use a 3D U-Net. Video \\ndata is inherently three-dimensional, consisting of width, height, \\nand time. The 3D U-Net processes this data, using the temporal \\ninformation in the video data to generate new video frames, in \\naddition to using the spatial information in each frame. This \\nallows for the generation of video content that is consistent and \\ncoherent over time, making it a powerful tool for tasks like video \\nediting, video synthesis, and even virtual reality.\\nT o generate high-quality videos, video diffusion models \\napply a basic diffusion model, which involves repeatedly adding \\nGaussian noise. They do this with minimal changes, except for \\nsome simple adjustments to the structure to fit video data within \\nthe memory limits of deep learning accelerators.\\nFIGURE\\xa03.13 (3D) U-Net: The 3D U-Net is an extension of the U-Net, \\ndesigned to process three-dimensional data, including the temporal \\ndimension.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 200, 'page_label': '187'}, page_content='Generative AI’s Broad  Spectrum of Applications 187\\nSeveral open source toolboxes and foundation models are \\navailable for video diffusion, such as MagicVideo, Imagen Video, \\nMake-A-Video, and diffusion models for video prediction and \\ninfilling. These tools provide a platform for developers and art-\\nists alike to experiment with and push the boundaries of video \\ngeneration.\\nFor-Profit Solutions In the realm of video diffusion models, the \\nlandscape is not solely dominated by open source tools. Indeed, \\nthe commercial sector is already reaping substantial profits, with \\ncompanies like Runway AI leading the charge. Runway AI, in par-\\nticular, stands out for its exceptional quality and seriousness, boast-\\ning an impressive roster of industry professionals and clients.\\nRunway AI is an applied AI research company with a mission \\nto democratize the boundless creative potential of AI. They are a \\nfull-stack operation, overseeing the entire process from research \\nand model training to product deployment. Their creative suite, \\nequipped with over 30 AI Magic T ools, empowers users to gener-\\nate and edit content, catering to every facet of the creative pro-\\ncess. This comprehensive approach is a recipe for long-term \\nsuccess in the startup world.\\nAt the heart of Runway’s innovation is their research division, \\nwhich develops multimodal AI systems for novel creative tools. \\nTheir Gen-2 video generation model is particularly noteworthy. \\nThis model marks a significant advancement over its predecessor, \\nGen-1, which was primarily designed to modify preexisting vid-\\neos. Gen-2 amalgamates the best features of both generations, \\nenabling it to apply the composition and style of an image or text \\nprompt to the structure of a source video, thereby generating an \\nentirely new video. The user can manipulate an uploaded video \\nwith simple terms and, within minutes, be astounded by the results. \\nThe experience is akin to the awe-inspiring moment when one \\nfirst uses ChatGPT .'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 201, 'page_label': '188'}, page_content='188 GENERATIVE AI\\nDespite its impressive capabilities, Gen-2 is not without its \\nlimitations. It struggles with low frame rates, graininess, and \\ninconsistencies related to physics or anatomy. The model also \\nhas difficulty grasping nuances and often overemphasizes certain \\ndescriptors in prompts while neglecting others. However, with \\nits ability to understand a wide array of styles, Gen-2 can be har-\\nnessed to create a narrative piece with a bit of editing work.\\nRunway AI’s influence extends far beyond mere demonstra-\\ntions and presentations. They have successfully garnered the \\nattention of numerous prestigious clients, such as New Balance, \\nCBS, Publicis, and even the editing team behind The Late Show \\nWith Stephen Colbert. Individual users of note include Kevin \\nParry, a celebrated stop-motion animator famed for his optical \\nillusion videos, who employs Runway’s technology to amplify his \\nviral video narratives. The reach of Runway AI even extends to \\nTinseltown, Hollywood, with their tools being utilized in the \\nproduction of the film Everything Everywhere All at Once.\\nIn recognition of its potential, Google LLC has reportedly \\ninvested in Runway AI as part of a recent $100\\xa0million funding \\nround. This investment has catapulted Runway’s post-money \\nvaluation to a staggering $1.5 billion. Google’s strategic move is \\nnot just about financial gain; it’s also about fostering the AI \\nstartup ecosystem within the Google Cloud environment. With \\nMicrosoft partnering with OpenAI and Amazon securing  \\nHugging Face, Google’s investment in Runway is a clear signal \\nof its intent to nurture its own cloud-based AI ecosystem.\\nAWS, GCP , and Azure The advent of cloud technology \\nmarked a pivotal juncture for Internet titans. However, it wasn’t \\nmerely the act of embracing the cloud that mattered but doing so \\neffectively. AWS, Azure, and Google Cloud stand as the three \\nmost dominant cloud providers today, not simply because they \\nadopted the technology, but because they executed the right'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 202, 'page_label': '189'}, page_content='Generative AI’s Broad  Spectrum of Applications 189\\nstrategies, developed valuable applications, and fostered robust \\necosystems. For instance, IBM Cloud, despite its early entry into \\nthe market, has struggled to keep pace. The reason? A flawed \\nstrategy in a fiercely competitive market. Figure\\xa03.14 illustrates \\nthe market share distribution.\\nAllow me to digress momentarily to underscore a burgeon-\\ning trend among these cloud giants: AWS, Google Cloud, and \\nAzure are all placing a premium on optimizing customer spend-\\ning. This approach is viewed as a long-term commitment to cul-\\ntivating lasting customer relationships. Industry leaders like \\nMicrosoft’s Satya Nadella, Amazon’s Brian Olsavsky, and Alpha-\\nbet’s Sundar Pichai have all emphasized the significance of opti-\\nmization, recognizing that customers are on the hunt for ways to \\ncut costs and redirect resources toward innovative customer \\nexperiences.\\nMicrosoft, for instance, is capitalizing on its investment in \\nOpenAI and ChatGPT to bolster its Azure and SaaS roadmaps. \\n0%\\n5%\\n10%\\n15%\\n20%\\nShare of Worldwide Revenues25%\\n30%\\n35%\\nQ4\\n17\\nQ1\\n18\\nQ2\\n18\\nQ3\\n18\\nQ4\\n18\\nQ1\\n19\\nQ2\\n19\\nQ3\\n19\\nQ4\\n19\\nQ1\\n20\\n(IaaS, PaaS, Hosted Private Cloud)\\nOthers\\nQ2\\n20\\nQ3\\n20\\nQ4\\n20\\nQ1\\n21\\nQ2\\n21\\nQ3\\n21\\nQ4\\n21\\nQ1\\n22\\nQ2\\n22\\nSource: Synergy Research Group\\nQ3\\n22\\nQ4\\n22\\nCloud Provider Market Share Trend\\nFIGURE\\xa03.14 Market share distribution of cloud service providers.\\nSource: (a) Amazon.com, Inc. (b) Microsoft Corporation (c) Google LLC (d) Alibaba.com \\n(e) International Business Machines Corporation'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 203, 'page_label': '190'}, page_content='190 GENERATIVE AI\\nNadella revealed that Azure OpenAI Service has seen a tenfold \\nincrease in customers quarter over quarter. Google, too, is hon-\\ning its focus on generative AI, with Pichai emphasizing the use of \\nlarge language models across Google Cloud platform, Google \\nWorkspace, and cybersecurity offerings in a recent interview. \\nAmazon’s AWS is fostering generative AI through managed ser-\\nvices such as Amazon Bedrock, a service that provides access to a \\nwide range of foundation models via an API, and Amazon Code-\\nWhisperer, a code generator that offers real-time code recom-\\nmendations. Additionally, AWS has, of course, its partnership \\nwith Hugging Face, as mentioned earlier.\\nOn the financial front, AWS reported a first quarter (2023) \\noperating income of $5.12 billion on revenue of $21.35 billion, \\nmarking a 16 percent increase from the previous year. Microsoft \\nCloud reported fiscal third-quarter revenue of $28.5 billion, \\nup\\xa022 percent from a year ago. Google Cloud reported first quar-\\nter (2023) operating income of $191\\xa0million on revenue of $7.45 \\nbillion, a 28 percent increase from the previous year.\\nLooking ahead, these cloud behemoths are optimizing today \\nto lay the groundwork for future growth. Microsoft CFO Amy \\nHood noted that new workloads will play a significant role in the \\nquarters to come. The companies are also investing heavily in \\ninfrastructure to enhance their own operations and bolster AI \\ninitiatives. They are of the belief that generative AI has reached \\na turning point and is poised to revolutionize virtually every cus-\\ntomer experience in existence.\\nSynthesia In the midst of this discourse, a noteworthy devel-\\nopment has just unfolded. Synthesia, the NVIDIA-backed plat-\\nform that transforms text into A.I.-generated avatars and avatar \\nvideos, has seen its valuation surge to a staggering $1 billion. \\nThis London-based synthetic media company, founded in 2017'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 204, 'page_label': '191'}, page_content='Generative AI’s Broad  Spectrum of Applications 191\\nby a team of researchers and entrepreneurs from University Col-\\nlege London, Stanford, T echnical University of Munich, and \\nCambridge, has been making waves in the realm of video synthe-\\nsis technology as well.\\nSynthesia is offering a unique service that generates person-\\nalized video content for customer engagement. The process is as \\nsimple as it is innovative. Y ou select a video template, choose a \\npreferred avatar (visual), and decide on the accent of the avatar \\n(audio). Then, you input the text that you want the avatar to \\narticulate in your language of choice. The result? A tailor-made \\nvideo that you can edit to your liking, altering the background, \\nadding background music, and more.\\nSynthesia has distinguished itself with its unique and highly \\nvaluable product. It’s no wonder they’ve achieved the coveted \\nstatus of a “unicorn,” a term used to describe startups that reach \\na valuation of $1 billion and above.\\nWhere Is Video Generation Going? Shifting our focus back \\nto video generation, it’s intriguing to ponder how this technol-\\nogy might evolve over the next decade and significantly influence \\nvarious sectors. But what might this future landscape look like?\\nPersonalized Movies and Shows We’re not just talking about \\nstreaming platforms suggesting shows based on your viewing \\nhistory. We’re envisioning a future where the actual content of \\nshows or movies dynamically adapts to the viewer’s prefer -\\nences and choices, generated in real time.\\nViewer Preferences This personalization could encompass \\neverything from preferred genres and beloved actors to favored \\nplot structures (such as happy endings or plot twists), themes of \\ninterest (like love, adventure, or mystery), and even pacing pref-\\nerences (slow-burn narratives or fast-paced action sequences).'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 205, 'page_label': '192'}, page_content='192 GENERATIVE AI\\nThis could involve the generation of new scenes, modification \\nof dialogue, or alterations to the visual style of the show.\\nInteractive Storytelling Drawing inspiration from interactive \\nstorytelling experiences (like Netflix’s Black Mirror: Bander -\\nsnatch), viewers could make choices that directly influence the \\nstoryline. However, with AI video generation, these choices \\ncould be more nuanced and have a more profound impact on \\nthe plot. For instance, a viewer could dictate a character’s \\nactions, dialogue, or even emotional responses.\\nContinuous Learning The system would perpetually learn \\nfrom the viewer’s choices, refining its understanding of their \\npreferences. This would lead to increasingly personalized con-\\ntent over time, creating a truly unique viewing experience tai-\\nlored to each individual.\\nImagine the dawn of “AI actors”— realistic, AI-generated \\ncharacters capable of performing any role, from minor back-\\nground parts to leading roles. These AI actors could exhibit  \\na broad spectrum of emotions and actions, proving invaluable \\nfor roles that are perilous, challenging to cast, or necessitate a \\nspecific look or performance that might be difficult to find in \\nhuman actors.\\nMoreover, AI actors could unlock unprecedented possibili-\\nties for creative storytelling. Filmmakers could craft characters \\nthat transcend human limitations— characters that can alter their \\nage, appearance, or even species at will. This could pave the way \\nfor more diverse and imaginative narratives. While AI actors \\ncould never supplant the talent and creativity of human actors, \\nthey could serve as a potent tool for filmmakers, offering novel \\nways to weave stories and captivate audiences.\\nBut let’s not limit ourselves to entertainment. What about \\nthe realm of education?'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 206, 'page_label': '193'}, page_content='Generative AI’s Broad  Spectrum of Applications 193\\nHarnessing video generation technology could enable the \\nvivid re-creation of historical events or extinct species with strik-\\ning precision, thereby serving as a powerful educational instru-\\nment. Picture students not merely reading about historical events, \\nbut visually immersing themselves in them, thereby establishing a \\nmore palpable link to the past. And let’s not forget the potential of \\nAI sound generation, which could mimic the most plausible sounds \\nof these bygone eras, further enhancing this immersive educa-\\ntional experience.\\nEnvision a classroom delving into the Civil War, not merely \\nthrough text, but by witnessing a lifelike reenactment of the Battle \\nof Gettysburg. Or students absorbing the nuances of the Roman \\nEmpire by experiencing a day in the life of a Roman citizen, mean-\\ndering through the vibrant markets and majestic amphitheaters. \\nWhile such scenes can be created with actors and prepared sets, \\nimagine the added layer of interactivity. A student could choose \\ntheir viewing perspective— through the eyes of a king, a soldier, or \\neven a bird’s-eye view. They could decide whether to overlay addi-\\ntional information, truly customizing their learning experience.\\nSimilarly, video generation could breathe life into extinct \\nspecies, enabling students to observe these creatures in their nat-\\nural habitats. This could foster a more comprehensive under -\\nstanding of topics like evolution and natural history. By leveraging \\nvideo generation technology, education could transform into a \\nmore immersive and engaging experience, potentially nurturing \\na deeper understanding and appreciation of our history and the \\nnatural world.\\nAnd the possibilities don’t end there. I foresee potential appli-\\ncations in law enforcement and forensics, interior design, advertis-\\ning, and countless other yet untapped areas. The future of video \\ngeneration technology is not just promising— it’s exhilarating.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 207, 'page_label': '194'}, page_content='194 GENERATIVE AI\\n3D Object Generation\\nThe realm of object generation holds a captivating allure, one \\nthat I first saw in 2017\\xa0when I stumbled upon a groundbreaking \\npaper from Stanford. At that time, I was just beginning to learn \\nabout generative adversarial networks, my mind teeming with \\nthe potential they could unlock in the sphere of 3D object \\n generation. As early as 2016, Stanford had pioneered a three-\\ndimensional GAN, a versatile tool capable of conjuring up\\xa03D \\nobjects with an ease that was nothing short of revolutionary. \\n Figure\\xa0 3.15 illustrates the conceptual transformation from a \\n(latent) vector to a chair.\\nThe resolution was not high, but the demonstration was \\nastounding. The latent vector, or the input, defined the object we \\nwanted to create. A chair? A table? A car? A boat? The possibili-\\nties were endless. When constructing a chair, for example, the \\nvector allowed for interpolation between different chair designs. \\nBy interpolation, I mean a smooth transition in the latent space, \\nsubtly altering features like the thickness of the legs and arm-\\nrests. Vector arithmetic made it possible to add or subtract fea-\\ntures, such as armrests, with ease.\\nThe implications for product development were profound. \\nSuddenly, we could generate thousands of variations of a chair and \\nZ\\n512×4×4×4 256×8×8×8\\n128×16×16×16 64×32×32×32\\nG(z) in 3D Voxel Space\\n64×64×64\\nFIGURE\\xa03.15 The generator component of 3D generative adversarial  \\nnetworks.\\nSource: http://3dgan.csail.mit.edu'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 208, 'page_label': '195'}, page_content='Generative AI’s Broad  Spectrum of Applications 195\\neasily incorporate the desired features. We could even extrapolate \\nbetween disparate objects like a boat and a house. As we navigated \\nsmoothly through the latent space, the boat would gradually trans-\\nform into a house, allowing us to halt the process at any point to \\ncreate, say, a houseboat.\\nThe initial demonstration from Stanford was rudimentary \\nand coarse-grained. The objects were represented by large pix-\\nels, and the technology was far from being ready for practical \\napplications. Y et, my imagination was set aflame.\\nThe Stanford paper was a groundbreaking contribution to the \\nfield. For a while, it seemed as though progress had stalled. Even \\ntoday, there’s much work to be done. However, the strides made in \\nthe past seven years are significant and worth exploring. The \\nfuture of object generation is not just promising— it’s thrilling.\\nCutting-Edge Research in 3D Object Generation The idea \\nof generating 3D models from textual descriptions is no longer a \\nfar-fetched concept but a reality that is being explored and devel-\\noped by many.\\nOne such development is DreamFusion, a tool that leverages \\n2D diffusion to generate 3D assets. This technology is just one \\nexample of the strides being made in this field, demonstrating \\nthe potential of AI in transforming textual data into tangible 3D \\nmodels (Figure\\xa03.16).\\nFIGURE\\xa03.16 A highly detailed stone bust of Theodoros Kolokotronics.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 209, 'page_label': '196'}, page_content='196 GENERATIVE AI\\nAnother noteworthy development is the advent of CLIPMa-\\ntrix and CLIP-Mesh-SMPLX. These tools generate textured \\nmeshes directly, offering a new approach to 3D model genera-\\ntion. CLIP , a model trained on a vast array of Internet text and \\nimages, is a key component of these tools, providing the neces-\\nsary understanding of the relationship between text and images.\\nCLIP-Forge, on the other hand, uses language to generate \\nvoxel-based models. Voxels, essentially the 3D equivalent of pix-\\nels, represent a value on a regular grid in a three-dimensional \\nspace. This method allows for the creation of detailed and intri-\\ncate 3D models based on textual input.\\nPoint-E and Pulsar+CLIP , developed by OpenAI, use lan-\\nguage to generate 3D point clouds. A point cloud is a set of data \\npoints in space, often used to represent the external surface of an \\nobject. Point-E, in particular, has been open sourced and has \\npotential applications in 3D printing, gaming, and animation.\\nThe process employed by Point-E is essentially a double dif-\\nfusion model. It first generates a synthetic view using a text-to-\\nimage diffusion model, and then produces a 3D point cloud using \\na second diffusion model that conditions on the generated image.\\nDream T extures, another tool in this domain, uses text-to-\\nimage technology to texture scenes in Blender automatically. \\nBlender, a free and open source 3D computer graphics software \\ntoolset, is widely used for creating animated films, visual effects, \\nart, 3D printed models, and video games.\\nIt’s important to note that many of these approaches, exclud-\\ning CLIPMatrix and CLIP-Mesh-SMPLX, are based on view \\nsynthesis, or generating novel views of a subject, as opposed to \\nconventional 3D rendering. This is the idea behind NeRFs, or \\nneural radiance fields.\\nNeRF is akin to a magical artist that can create a detailed 3D \\npainting from a collection of 2D photos. Imagine you’ve taken'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 210, 'page_label': '197'}, page_content='Generative AI’s Broad  Spectrum of Applications 197\\nseveral photos of a room from different angles. NeRF looks at \\nthese photos, and like an artist, it understands the room’s struc-\\nture, colors, and how light interacts with different objects. It then \\nuses this understanding to paint a 3D model of the room that \\nyou can look at from any angle, even ones not captured in the \\noriginal photos. Diving a bit deeper, NeRF accomplishes this by \\nusing a deep learning technique where it trains a neural network \\nto map\\xa03D coordinates to colors and densities. This trained net-\\nwork can then generate a realistic 3D scene based on the infor -\\nmation it learned from the 2D images, allowing for the synthesis \\nof novel views of the scene.\\nLeading Companies and Approaches in 3D Object Genera-\\ntion NeRF , as we’ve seen, can transform a handful of images \\ninto a short video that gives the illusion of flying around the \\nobject. It’s a fascinating concept, but it’s just the tip of the iceberg.\\nThe best-in-class 3D object generation models are not stand-\\nalone entities. They are intricate systems, a blend of various \\ntechniques, each complementing the capabilities of the others.\\nT ake Luma AI, for example. This platform showcases the \\npower of NeRF in a remarkable way. Y ou can upload a couple of \\npictures, and it doesn’t just generate a short clip— it creates a \\nreasonably accurate, detailed 3D object. The level of detail is \\nastounding, extending to the point where you can upload multi-\\nple images of a neighborhood, perhaps taken by drones, and \\nLuma AI will generate a detailed neighborhood complete with \\nswings, trees, trampolines, bicycles, and more.\\nLuma AI doesn’t stop there. It has harnessed the capabilities \\nof NeRF to an extent where they can manipulate live video feeds. \\nImagine recording a video with your smartphone, and as you pan \\nthe camera, the room in the video transforms into a different \\nworld— a photorealistic, immersive experience, all thanks to'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 211, 'page_label': '198'}, page_content='198 GENERATIVE AI\\ngenerative AI. It’s like peeking into a parallel universe through \\nthe lens of your camera.\\nBut Luma AI isn’t alone in this field. There are numerous \\nother companies leveraging AI to generate 3D objects. Kaedim, \\nfor instance, generates 3D objects from pictures, sketches, and \\nother sources. Once generated, these objects are not static— they \\ncan be edited, scaled up or down, and their colors can be adjusted. \\nIt’s a dynamic, interactive process that opens up a world of \\npossibilities.\\nAnd then there’s NVIDIA, a long-standing titan in the realm \\nof generative AI. Their platform, NVIDIA Picasso, is their stra-\\ntegic approach to this technology. They’re not merely observers \\nin this field— they’re active participants, constantly innovating \\nand pushing the boundaries of what’s possible.\\nNVIDIA Picasso is a prime example of how generative AI is \\nbeing harnessed to create visual applications. This cloud service \\nis designed to generate images, videos, and 3D models from text \\nprompts. It’s a versatile tool, capable of being fine-tuned for a \\nvariety of uses, from business applications to medical research, \\nand even the creation of AI artwork. It’s a platform built with \\nsoftware creators, service providers, and businesses in mind, par-\\nticularly those intending to train AI models using copyrighted \\nmaterial. See its structural overview in Figure\\xa03.17.\\nThe level of detail that NVIDIA Picasso can achieve in 3D \\nobject generation is truly remarkable. With a simple prompt like \\n“a 3D model of a male bust with a furrowed brow and deep-set \\neyes, wearing a wreath of ivy leaves, highly detailed,” a corre-\\nsponding 3D object can be generated.\\nNVIDIA ’s success in this field is not a solo endeavor. They \\nhave established strong partnerships with key players in the \\nindustry. Getty Images, a leading global visual content creator \\nand marketplace, is collaborating with NVIDIA to develop image'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 212, 'page_label': '199'}, page_content='Generative AI’s Broad  Spectrum of Applications 199\\nand video generation models on Picasso, trained on fully licensed \\ndata. Enterprises can access these models through API calls.\\nSimilarly, Shutterstock is partnering with NVIDIA to develop \\nmodels for generating 3D assets, trained on fully licensed con-\\ntent from Shutterstock.\\nAll of this happens on NVIDIA ’s cloud platform. NVIDIA ’s \\nDGX Cloud is a powerful tool for AI development. It provides \\naccess to dedicated clusters of NVIDIA DGX hardware, essen-\\ntially offering an AI supercomputer in the cloud. This service \\nsimplifies the process of acquiring, deploying, and managing AI \\ninfrastructure.\\nEach instance of DGX Cloud comes with 8\\xa0NVIDIA H100 \\nor A100 80\\xa0GB T ensor Core GPUs, totaling 640\\xa0GB of GPU \\nmemory per node. The service is available through existing cloud \\nAPI Service\\nEdify\\nGateway\\nNVIDIA Picasso Service\\nCustom Data\\nTrain\\nOptimize\\nImage\\nVideo\\n3D \\nInference\\nNVIDIA DGX Cloud\\nCustom Model\\nClient App\\nFIGURE\\xa0 3.17 The NVIDIA Picasso service structure, showcasing the \\nintegration of generative AI models, NVIDIA Edify foundation models, \\nand NVIDIA DGX Cloud for optimized training, inference, and genera-\\ntion of image, video, and 3D content.\\nSource: www.nvidia.com/en- us/gpu- cloud/picasso'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 213, 'page_label': '200'}, page_content='200 GENERATIVE AI\\nproviders, with Microsoft Azure soon to host DGX Cloud, and \\nplans for expansion to Google Cloud and others.\\nStarting at $37,000 per instance, the NVIDIA DGX Cloud \\noffers customers the ability to train and deploy their models \\nusing their own data. They have the option to leverage NVID-\\nIA ’s pre-trained models or optimize and run their own. Given \\nthe capabilities and convenience it provides, the price point is \\nindeed quite reasonable.\\nGiven these advancements and strategic moves and partner-\\nships, it’s not a stretch to envision NVIDIA as a multitrillion-\\ndollar company in the future, especially if AI continues to evolve \\nat its current pace. And there’s every indication that it will. The \\nfuture of generative AI is bright, and NVIDIA is poised to be one \\nof its leading lights.\\nWhere Is 3D Object Generation Going? Imagine slipping \\non a cutting-edge virtual reality headset, immersing yourself in a \\nrealm shaped by your own recollections and the prowess of AI. \\nY ou narrate the details of your childhood home, each memory \\nspringing to life from a handful of old photographs. As the AI \\nattentively listens, it transforms your words and these precious \\nimages into a vivid, lifelike 3D environment in real time. Sud-\\ndenly, you’re navigating the corridors of your past, each detail \\nmeticulously replicated. This encapsulates the future of virtual \\nreality and gaming, where your memories and a few old photo-\\ngraphs are the only limits to your imagination.\\nNow, envision a revolution in the sphere of retail. Retailers \\ncould use AI to generate 3D models of products based on cus-\\ntomer descriptions, allowing customers to visualize products in \\ntheir own space using AR before making a purchase. Y ou’re shop-\\nping for a new sofa, and with a few descriptive words, a 3D model'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 214, 'page_label': '201'}, page_content='Generative AI’s Broad  Spectrum of Applications 201\\nmaterializes in your living room. Shopping becomes a more \\ninteractive and personalized experience.\\nOr picture yourself in a state-of-the-art workshop. Y ou \\ndescribe the item you’ve been dreaming of— a unique sculpture, \\nor a part for an old machine. As the AI listens, it understands not \\njust the physical attributes, but the emotion behind your idea. \\nThe screen comes to life, displaying a 3D model of your item, \\nevery detail rendered with stunning accuracy. With a nod, you \\ngive the command to proceed. The 3D printer whirs to life, its \\nmechanical arm moving with precision as it lays down layer after \\nlayer of material. Y ou watch as your idea transforms from a digi-\\ntal concept into a tangible object. This is the future of personal-\\nized manufacturing, where you’re not just a consumer, but \\na creator.\\nIn the field of robotics, engineers could use AI to generate \\n3D models of custom robot parts based on specific needs and \\ndescriptions. This could accelerate the development of custom-\\nized robotics, making it easier to create robots tailored to specific \\ntasks or environments. In the not-so-distant future, it’s conceiv-\\nable that robots of all shapes and sizes, from humanoid forms to \\nmulti-wheeled machines, will become a common sight on our \\nstreets. This is not mere speculation but a rapidly approach-\\ning reality.\\nGoldman Sachs Research projects a market worth $6 billion \\nor more for people-sized and -shaped robots within the next 10 \\nto 15 years. Such a market could address 4 percent of the pro-\\njected U.S. manufacturing labor shortage by 2030 and meet 2 \\npercent of global elderly care demand by 2035. However, with \\nthe productivity acceleration brought about by generative AI, I \\nbelieve we’ll reach these milestones even sooner.\\nAnd this is just the beginning. The potential applications of \\nAI in 3D object generation span various sectors. From fashion'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 215, 'page_label': '202'}, page_content='202 GENERATIVE AI\\nand apparel design to medical training and simulation, from  \\nfilm and animation to interior design, from education to auto-\\nmotive and aerospace design— the possibilities are as vast as  \\nthey are exciting.\\nSynthetic Data Augmentation\\nThere’s one more domain that merits our attention. It’s not an \\napplication field in the traditional sense, but rather a realm where \\ngenerative AI is employed to enhance other AI fields, for instance. \\nThis domain is known as data augmentation.\\nPicture an unbalanced dataset— for instance, medical images \\nof a rare cancer. If your goal is to construct a machine learning \\nsystem— likely a convolutional neural network (CNN)— that can \\nidentify these rare, malignant instances, you need a robust dataset \\nfor training. A “good” dataset implies a balanced representation of \\nall different instances— malignant, benign, and non-cancerous.\\nHowever, reality often falls short of this ideal. If you’re deal-\\ning with a rare cancer, you won’t find many instances. Moreover, \\nto train your system on such data you need permissions, which \\ncan lead to privacy concerns. This is where data synthesis, a form \\nof data augmentation, comes into play. It can address these chal-\\nlenges and ultimately enhance the machine learning system’s \\ndetection performance.\\nNVIDIA was a trailblazer in this area. They published a paper \\non brain scan synthesis via generative adversarial networks in \\nSeptember 2018. Since then, a flurry of papers have emerged, dis-\\ncussing various aspects of this technology. Some argue it’s ineffec-\\ntive, others exaggerate its effectiveness. The truth, as is often the \\ncase, lies somewhere in the middle. The effectiveness of data aug-\\nmentation is a nuanced issue, and the task itself is far from trivial.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 216, 'page_label': '203'}, page_content='Generative AI’s Broad  Spectrum of Applications 203\\nBut the implications of data augmentation extend beyond \\nimproved performance and privacy issues. It’s also about cost-\\neffectiveness and better representation of real-world scenarios.\\nCollecting new data can be a drain on resources— both time \\nand money. Data augmentation, however, offers a cost-effective \\nalternative. It allows you to increase the size and diversity of your \\ndataset without the need for additional data collection.\\nMoreover, it’s crucial that we don’t develop biased products. \\nFor instance, we need to ensure that all minorities are included \\nin our datasets. Data augmentation can help achieve this, improv-\\ning the robustness of the model and ensuring it’s a better repre-\\nsentation of diverse real-world scenarios.\\nIt’s not just about creating more data— it’s about creating \\nbetter data. And in the grand scheme of things, that could make \\nall the difference.\\nThe Tech Behind Data Augmentation Effective data aug-\\nmentation is anything but trivial. T ake image data augmentation, \\nfor instance. The algorithms employed in this area span a broad \\nspectrum, from basic image manipulation techniques such as \\nkernel filters, random erasing, geometric transformation, and \\ncolor space transformation to more advanced deep learning \\napproaches.\\nAmong these advanced techniques, adversarial training \\nstands out. This collection of methods trains neural networks to \\nidentify intentionally misleading data or behaviors. Another \\n fascinating technique is neural style transfer, which allows the \\ntransformation of an image’s style to mimic, say, the distinctive \\nbrushstrokes of Van Gogh. Then there’s GAN data augmenta-\\ntion, a concept proposed by NVIDIA in September 2018.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 217, 'page_label': '204'}, page_content='204 GENERATIVE AI\\nBut the innovation doesn’t stop there. We also have meta-\\nlearning techniques like neural augmentation and smart aug -\\nmentation. These methods are part of a continually evolving \\nspectrum of techniques that the field of research offers.\\nHowever, it’s essential to remember that data augmentation \\nisn’t limited to images. Virtually all data types can be augmented. \\nT o illustrate this, let’s examine two cutting-edge data augmenta-\\ntion techniques— one for images, representing parallel data gen-\\neration, and one for text, representing sequential data generation.\\nThe most advanced image data augmentation technique  \\ncurrently available involves diffusion models, as outlined in the \\npaper “Effective Data Augmentation With Diffusion Models.” 1 \\nThis technique employs image-to-image transformations per -\\nformed by pre-trained text-to-image diffusion models. The \\nmethod edits images to change their semantics using an off-the-\\nshelf diffusion model and can generalize to novel visual concepts \\nfrom a few labeled examples. The results are impressive.\\nData Augmentation-Fusion (DA-Fusion) has made significant \\nstrides in image classification, improving performance by up to 10 per-\\ncent over standard methods. Figure\\xa03.18 conceptually shows the \\nDA-Fusion process using one seed image to produce four guided \\nvariations of the original. The “stacking” feature of DA-Fusion \\nhas further boosted overall performance by 51 percent. Addition-\\nally, DA-Fusion has shown versatility, outperforming previous \\nmethods across different image masks. Impressively, it maintains \\neffectiveness across various mixtures of real and synthetic images.\\nWhen it comes to text data augmentation, tools like Chat-\\nGPT have made the process simpler. Y ou can ask ChatGPT to \\nrewrite a certain text multiple times, even explicitly requesting \\ntext diversity to cover a full spectrum. In fact, if you have a data-\\nset in table form or whatever, ChatGPT can, in 99 percent of \\ncases, effectively synthesize more data for you.\\n1Brandon T rabucco et\\xa0al. “Effective Data Augmentation With Diffusion Models,” arXiv, May 22, 2023, https://\\narxiv.org/pdf/2302.07944.pdf'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 218, 'page_label': '205'}, page_content='Generative AI’s Broad  Spectrum of Applications 205\\nIf you have full control over a language model and are ready \\nto generate as much data as you want, with only computing costs \\nas a limiting factor, a structured approach like AugGPT may be \\nmore beneficial. See its framework in Figure\\xa03.19.\\nIt is beneficial to use because:\\n• AugGPT achieves the highest accuracy among different \\ndata augmentation methods for Amazon, Symptoms, and \\nPubMed20K datasets.\\n• AugGPT generates high-quality augmented samples with \\nhigh similarity to real input data and better learnability.\\n• While ChatGPT performs better on easier tasks, it requires \\nfine-tuning for complex tasks like PubMed to achieve better \\nperformance compared to few-shot prompts.\\nFIGURE\\xa0 3.18 Real images are augmented using a publicly available \\noff-the-shelf Stable Diffusion checkpoint to generate synthetic data \\nfor training classifiers.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 219, 'page_label': '206'}, page_content='206 GENERATIVE AI\\nChatGPT Joint pain Cough Acne\\nThe speaker is experiencing pain in their elbow joint.\\nI have pain in the elbow joint The speaker reports pain in their elbow joint.\\nThe speaker has noticed pain in their elbow joint.\\nThe speaker has a /f_luid sensation in their throat when they cough. \\nThe speaker feels like something is coming up when they cough.\\nThe speaker coughs and feels like /f_luid is trying to escape.\\nThe speaker’s son’s skin is affected by a large number of acne pimples.\\nThe speaker describes their son’s skin as having a lot of acne.\\nThe speaker’s son is struggling with a lot of acne on his skin.\\nI feel /f_luid when I cough. \\nMy son has a lot of acne.\\nSentence Classi/f_ication\\nBy BERT\\nSentence Augmentation\\nBy ChatGPT\\nnovel samples augmentation samples\\nData Augmentation With ChatGPT Samples\\nBERT Classi/f_ier\\n(a)\\n(b)\\nJoint pain\\nAcne\\nCough\\nFIGURE\\xa03.19 AugGPT’s structure involves: (a) using ChatGPT for data augmentation to create class-consistent \\nsamples, and (b) training and evaluating a BERT-based classifier on these augmented and few-shot samples.\\nSource: https://arxiv.org/pdf/2302.13007.pdf'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 220, 'page_label': '207'}, page_content='Generative AI’s Broad  Spectrum of Applications 207\\nWhile AugGPT and DA-Fusion are techniques subject to \\nfurther revisions in this rapidly evolving research field, I’m con-\\nfident that their foundational concepts will endure for a consid-\\nerable period.\\nForefront Companies in\\xa0Data Augmentation Synthesis AI, \\na startup, has developed a cloud-based platform that generates \\nsynthetic image data with labels, using AI, procedural genera-\\ntion, and cinematic visual effects–rendering systems. This plat-\\nform can deliver millions of perfectly labeled images and videos.\\nSynthesis AI’s unique approach involves a proprietary library \\nof over 100,000 digital humans. These digital humans serve as \\nthe foundational data for data generation, with data sampled by \\n“photographing” these digital entities. The company’s product \\nsuite includes Synthesis Humans and Synthesis Scenarios, which \\ngenerate detailed images and videos of digital humans and craft \\ncomplex multi-human simulations, respectively.\\nSynthesis AI’s innovation has attracted significant invest-\\nment, raising $17\\xa0million in a Series A funding round. The com-\\npany’s CEO, Yashar\\xa0Behzadi, has highlighted the advantages of \\ntheir approach, emphasizing the speed, cost-effectiveness, and \\nhigh-quality asset generation capabilities of their text-to-3D \\nofferings.\\nOn the other side of the globe, Mostly AI, an Austrian com-\\npany, is making significant strides in the realm of synthetic data. \\nWith a keen focus on data privacy, especially in light of the strin-\\ngent General Data Protection Regulation (GDPR), Mostly AI’s \\ntechnology is particularly beneficial in sectors where data pri-\\nvacy is paramount, such as healthcare and financial services.\\nMostly AI recently secured $25\\xa0million in funding to further \\ncommercialize synthetic data in Europe and the United States.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 221, 'page_label': '208'}, page_content='208 GENERATIVE AI\\nThe company’s synthetic data platform allows anyone to gener -\\nate synthetic data safely and without coding, enabling data rebal-\\nancing, anonymization, imputation, and exploration.\\nMostly AI’s CEO, T obias Hann, anticipates a significant surge \\nin the use of synthetic data, predicting a “strong decade for syn-\\nthetic data” beyond 2022. This growth is expected to be driven \\nby the increasing demand for responsible AI, with synthetic data \\nplaying a crucial role in augmenting and debiasing datasets.\\nWhere Is Data Augmentation Going? The advent of syn-\\nthetic data is akin to a new dawn breaking over the horizon of \\ntechnological advancement. The speed at which synthetic data is \\ngenerated far outpaces that of real data. Gartner, a leading \\nresearch and advisory company, forecasts that synthetic data will \\neclipse real data within the next three to five years (Figure\\xa03.20).\\nBy 2030, Synthetic Data Will Completely Overshadow Real Data in AI Models\\nData Used\\nfor AI\\nFuture AI\\nReal\\nData\\nTime\\nSynthetic\\nData\\n2020\\nSource: Gartner\\n750175_C\\n2030\\n• Artificially Generated Data\\n• Obtained from Direct\\n  Measurements\\n• Constrained by Cost, Logistics,\\n  Privacy Reasons\\n• Generated from Simple\\n   Rules, Statistical Modeling,\\n   Simulation, and Other\\n   TechniquesToday’s AI\\nFIGURE\\xa0 3.20 The dominant form of data employed in AI will shift \\ntoward synthetic data.\\nSource: Gartner, Inc.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 222, 'page_label': '209'}, page_content='Generative AI’s Broad  Spectrum of Applications 209\\nThe implications of synthetic data generation and data aug-\\nmentation via AI are far-reaching, with potential to revolutionize \\na multitude of sectors in the coming decade. The applications are \\nas diverse as they are profound.\\nIn the healthcare sector, synthetic data is already making \\nwaves. It is used to generate medical images for training AI  \\nmodels, aiding in the diagnosis of diseases. It also creates virtual \\npatient data for clinical trials, reducing the need for actual patients  \\nand ensuring privacy.\\nThe potential of synthetic data extends to the realm of auton-\\nomous vehicles, where it is used to generate various driving sce-\\nnarios for training purposes. In cybersecurity, synthetic data \\nsimulates cyberattacks, training AI models to detect and prevent \\nthese attacks. Even in climate modeling, synthetic data simulates \\nvarious climate scenarios, enabling AI models to predict climate  \\nchange.\\nBut the potential of synthetic data doesn’t stop there. It is \\nalso a powerful tool for urban planning. In smart cities, synthetic \\ndata can simulate traffic patterns, pedestrian movements, and \\npublic transportation usage. This data can be used to optimize \\ncity infrastructure and reduce congestion, leading to more effi-\\ncient and livable urban environments.\\nIn the field of precision agriculture, synthetic data merges \\nenvironmental science, agriculture, and AI. It simulates various \\ncrop growth scenarios under different weather conditions  \\nand soil types, helping farmers optimize crop yields and reduce  \\nwaste.\\nIn disaster management, synthetic data combines meteorol-\\nogy, geography, and emergency response to simulate disaster \\nscenarios. This aids in planning effective evacuation routes  \\nand emergency response strategies, potentially saving count-\\nless lives.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 223, 'page_label': '210'}, page_content='210 GENERATIVE AI\\nThe Untapped Potential of Generative AI\\nThis section explores the immediate, untapped potential of gen-\\nerative AI. We have previously covered its vast applications in \\nvoice and speech generation, code, text, music, video, 3D objects, \\ngenerative design, and scientific problem-solving, but there is so \\nmuch more to explore.\\nIn law, it powers specialized chatbots for legal commentary \\nand patent creation. The gaming industry utilizes it for more \\nimmersive experiences, while educational institutions like the \\nOpen University use AI to improve teaching and engagement. In \\nhealthcare, AI simplifies complex medical texts for wider acces-\\nsibility. Business-to-business sectors benefit from AI for stream-\\nlined processes and enhanced productivity, with AI-powered \\npersonal assistants offering personalized services.\\nMIT researchers have developed an AI that predicts antibi-\\notic effectiveness against bacteria, potentially revolutionizing \\nantibiotic development and bacterial infection treatment. They \\nalso created MathAI, an AI capable of solving complex mathe-\\nmatical problems at a university level. Google’s Starline project, \\nusing high-resolution cameras and depth sensors, creates realis-\\ntic 3D models for video calls, offering an unprecedented sense of \\npresence. These developments highlight the immense, ongoing \\ninnovation in generative AI.\\nA Good Time to\\xa0Build Products and Companies\\nIndeed, the current landscape is ripe for the inception of new \\nproducts and companies centered around generative AI. The \\nbarrier to entry has never been lower, with the technical knowl-\\nedge required to launch a startup significantly reduced. The \\npotential for quick wins is immense, particularly in the realm of \\nknowledge management.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 224, 'page_label': '211'}, page_content='Generative AI’s Broad  Spectrum of Applications 211\\nConsider the possibilities: querying a vast corpus of knowl-\\nedge, such as documentation, regulations, and legal texts;  \\nstreamlining operations by automating tasks or making them \\nconversational. These applications could revolutionize processes \\nwithin companies and government bureaucracies alike. There’s \\nalso the potential to accelerate innovation, with a host of prod-\\nucts being developed to facilitate this. These applications, which \\nI refer to as “application layer 1,” offer broad, impactful solutions.\\nBeyond this, there’s a second application layer that’s more \\nniche and specific. This is where subject matter experts can lev-\\nerage their specialized knowledge to develop unique products. \\nWhile I may not be an expert in these fields, I can certainly brain-\\nstorm potential starting points:\\n• In biology, predictive diagnosis could revolutionize health-\\ncare, enabling early intervention and improved patient out-\\ncomes. In chemistry, synthesis planning, chemical property \\nprediction, and chemistry education could all benefit from \\nthe application of generative AI.\\n• Mathematics could see enhancements in education and the-\\noretical research— MathAI from MIT , for example— while \\nsupply chain management could be optimized through \\ninventory forecasting and vendor selection. In the realm of \\nphysics, quantum computing, astrophysics, and particle \\nphysics all present exciting opportunities for AI integration.\\n• Economics could be transformed through the development \\nof advanced forecasting models, policy analysis tools, and \\ninvestment strategies. In psychology, behavior prediction \\nand psychological research design could be revolutionized.\\n• Environmental science also presents a wealth of opportuni-\\nties, from climate modeling to biodiversity studies and con-\\nservation strategies. Each of these fields stands on the brink'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 225, 'page_label': '212'}, page_content='212 GENERATIVE AI\\nof transformation, ready to harness the untapped power of \\ngenerative AI.\\nCertainly, the landscape of generative AI is teeming with \\nopportunities for product development and innovative ideas. \\nWhether it’s in cloud services, hubs, or other platforms, the \\npotential is vast. However, to truly tap into these opportunities, \\nyou need specialized knowledge in areas such as building AI \\nmodels, language processing, image processing, and more. If you \\ndon’t currently possess this expertise, don’t worry— it can be \\nacquired more easily than ever.\\nThe concept of building foundation models is an exciting \\npath for exploration. This strategy, adopted by organizations like \\nOpenAI, Meta, and Anthropics, involves the development of \\nbroad, multipurpose models that serve as the foundation for \\nmore specialized applications. On the other hand, there’s also the \\npotential to create niche models that excel in specific domains, \\noffering tailored solutions for unique needs.\\nThe development of cloud platforms, akin to Azure or \\nGoogle Cloud Platform (GCP), is another promising area in the \\nAI landscape. These platforms simplify the deployment, scaling, \\nand management of AI models, making AI accessible to a wider \\naudience and fostering its integration across various industries.\\nThere’s also the potential to contribute to the AI ecosystem \\nby providing robust computing hardware like GPUs or TPUs. \\nThese powerful processing units are instrumental in training and \\nexecuting AI models, and advancements in this area could signifi-\\ncantly enhance the speed and efficiency of AI operations.\\nMoreover, there is an opportunity to develop specific librar-\\nies of functions that cater to unmet needs within the AI commu-\\nnity. For instance, the development of a library such as LangChain \\ncould address gaps in the existing suite of tools available for'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 226, 'page_label': '213'}, page_content='Generative AI’s Broad  Spectrum of Applications 213\\nAI development and deployment. LangChain is a framework \\ndesigned to simplify the creation of applications using LLMs. \\nSuch efforts would not only enhance the capabilities of existing \\nAI systems but also accelerate the pace of innovation in the field.\\nFinding the\\xa0Untapped— A Systematic Approach to\\xa0Success\\nHarnessing the untapped potential of generative AI is akin to \\nnavigating an uncharted territory. The landscape is vast, teeming \\nwith possibilities, yet the path to success is often obscured by the \\nsheer volume of information and ideas. The key to unlocking \\nthis potential lies not in the abundance of ideas, but in the ability \\nto distinguish the truly innovative from the merely interesting.\\nThe conviction that there are more untapped ideas than \\nthose that have been realized is not unfounded. A cursory glance \\nat the plethora of scientific papers, research articles, surveys, and \\nblogs reveals a veritable treasure trove of ideas. Every week, \\nthousands of concepts are birthed in these intellectual crucibles, \\neach one a potential seed for the next big breakthrough in gen-\\nerative AI.\\nHowever, as any seasoned innovator will tell you, ideas are \\nthe easy part. Execution is where the rubber meets the road. It’s \\nthe 99 percent perspiration that transforms the 1 percent inspi-\\nration into something tangible. Moreover, not all ideas are cre-\\nated equal. They need to be validated and tested against the harsh \\nrealities of practicality and feasibility.\\nThis is where careful resource filtering becomes crucial. For \\ninstance, research papers are often the breeding grounds for  \\ncutting-edge tech ideas, particularly in the realm of generative \\nAI. The ability to sift through these forefront papers, translate \\ncomplex jargon into understandable language, and transform \\nthese ideas into products can provide a significant advantage.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 227, 'page_label': '214'}, page_content='214 GENERATIVE AI\\nT o guide you through this process, I propose a methodology \\nthat has proven effective in the past and that could serve as a \\nstarting point for your journey. Let’s assume you’re looking to \\nlaunch a startup or a project. This methodology is versatile and \\ncan be adapted to various professional areas.\\nThe process, as illustrated in Figure\\xa0 3.21, is simplified \\nfor clarity.\\nIdea Execute idea, build quick pol\\nTalk to potential clients and showcase it\\nNo\\nNo\\nYes\\nYes Scale!\\nExtract and understand client’s needs\\nfrom conversations\\nEnd user expectations\\ncan be met?\\nIterate your code /uni21D2\\n Customize the code\\n  to serve key common client needs\\n[x5 - 100]\\nPredefined critical\\nrevenue reached?\\nOur signal for success.\\nasset!\\nValidation: • Solve part of the\\n  client’s problem?\\n • Charge for\\n  problem solving? (1 client)\\nFIGURE\\xa0 3.21 How to come up with your generative AI idea in this \\ndynamic AI market.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 228, 'page_label': '215'}, page_content='Generative AI’s Broad  Spectrum of Applications 215\\nThe first step in this journey is to immerse yourself in trusted \\nsources of information. I strongly recommend research papers \\navailable on databases like arxiv.org and publisher-driven plat-\\nforms such as Wiley. Choose one or two that resonate with you \\nafter conducting preliminary research.\\nWhile your focus is on AI, it’s beneficial to cast a wider net. \\nConsider filtering for papers in related domains such as physics, \\nchemistry, mathematics, and psychology. This broad perspective \\ncan provide insights into market trends and hot topics in \\nthese fields.\\nFor the next three to six\\xa0weeks, observe these research data-\\nbases and their respective topics. Useful tools for this task are the \\nChatGPT plug-ins. Each day, select the top five papers you wish \\nto understand and paste their links into ChatGPT . Ask the \\nrespective plug-ins to summarize these papers in bullet points, \\nincluding headers. This method allows you to grasp the essence \\nof each paper in about seven minutes.\\nFor instance, just today’s research is rich with ideas, poten-\\ntially meeting the criteria. “DUCHO: A Unified Framework for \\nthe Extraction of Multimodal Features in Recommendation” 2 \\nproposes an approach to improve recommendations by includ-\\ning effectively multiple modes.\\nAnother paper, “Synthetic Demographic Data Generation \\nfor Card Fraud Detection Using GANs,” 3 might not pass the \\nthreshold. While it focuses on demographic data, which seems \\nquite limited, there could be potential to use this idea in other \\nareas of data generation. This is something that would need fur-\\nther investigation.\\n2Daniele Malitesta et\\xa0 al. “DUCHO: A Unified Framework for the Extraction of Multimodal Features in  \\nRecommendation,” arXiv, September 6, 2023, https://arxiv.org/pdf/2306.17125.pdf\\n3Shuo Wang et\\xa0al. “Synthetic Demographic Data Generation for Card Fraud Detection Using GANs,” arXiv, \\nJune 29, 2023, https://arxiv.org/pdf/2306.17109.pdf'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 229, 'page_label': '216'}, page_content='216 GENERATIVE AI\\nLastly, I found a paper titled “Spiking Denoising Diffusion \\nProbabilistic Models”4 particularly intriguing. This paper com-\\nbines spiking neural networks with diffusion models. The key \\nquestions here are: What benefits does this combination offer? \\nWhat are the drawbacks? And most importantly, what new func-\\ntionalities does it introduce that could potentially transform \\nother areas? Often, even the authors themselves may not fully \\ngrasp the implications of their work.\\nAfter this initial review, choose one paper for a deeper dive. \\nRead it thoroughly, examine the visual results, and absorb its \\ncontent. After some training, this process should take no more \\nthan 30\\xa0minutes per day.\\nIt’s crucial to research papers over an extended period to \\navoid the trap of latching onto the first good idea that comes \\nalong. Comparing ideas against each other is an important part \\nof the process. However, it’s equally important to set a time frame \\nfor when you want to start your project.\\nOnce you’ve gathered a wealth of ideas, it’s time to select a \\ngreat one. Not the perfect one, as perfection is elusive, but a \\ngreat one. Shortlist the top five to seven ideas and compare them \\nqualitatively based on the following criteria: technical feasibility, \\npotential impact for end users, innovation and uniqueness, scal-\\nability and adaptability, ethical and legal considerations, resource \\nrequirements, and market potential.\\nOnce you’ve selected an idea, create a quick proof of concept \\n(PoC). Utilize existing GitHub repos or other code sources like \\npaperswithcode.com or from the research scientists themselves. \\nIf you’re not a coder, consider hiring one from platforms like \\nFiverr, but be aware of potential issues like confidentiality and \\nskill gaps.\\n4Jiahang Cao et\\xa0al. “Spiking Denoising Diffusion Probabilistic Models,” arXiv, October 30, 2023, https://arxiv \\n.org/pdf/2306.17046.pdf'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 230, 'page_label': '217'}, page_content='Generative AI’s Broad  Spectrum of Applications 217\\nWith your PoC in hand, it’s time to get feedback. Contact \\npotential users, ranging from a minimum of 5 to a maximum of \\n100, and showcase your idea. From these conversations, you’ll \\ngain valuable insights into user needs and preferences.\\nFinally, answer the following questions to decide how to pro-\\nceed: Are users satisfied with the idea? Does the idea provide \\nsignificant value to users? Is there sufficient market demand for \\nthe idea? Does the idea have a competitive advantage? Can the \\nidea scale and grow effectively? Are there viable ways to mone-\\ntize the idea? Do the resources required for this idea align with \\nyour capabilities? Does the idea align with your long-term goals \\nand vision?\\nBased on these answers, decide whether to continue with the \\nidea and invest more resources into it, pivot the idea significantly, \\nor find a completely new idea. This is a critical juncture in your \\njourney, a moment of existential decision making that will shape \\nthe course of your project.\\nCongratulations on successfully validating your idea! Y ou’ve \\nnavigated the initial stages of the process, and now it’s time to \\nshift focus to building a great product.\\nFrom your user research, you’ve gathered insights into what \\nthe client needs and expects from the product. The next step is to \\nprioritize your actions based on two factors: the impact on the \\nuser and the effort required. This will help you identify the low-\\nhanging fruits. A word of advice here: Aim to serve the needs of \\nthe majority (80 percent) of your users, rather than catering to \\nindividual requirements.\\nIn the early stages, it’s beneficial if you can code the product \\nyourself. With tools like ChatGPT , GitHub Copilot, and various \\nonline training resources, this task is not insurmountable. Alter-\\nnatively, you could outsource the coding to another individual.\\nOnce you’ve made progress on the product, it’s time for \\nanother round of validation. Conduct another set of interviews'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 231, 'page_label': '218'}, page_content='218 GENERATIVE AI\\nto confirm that you’re addressing critical parts of the client’s \\nproblem. The second step in this validation phase is to determine \\nif your future customers are willing to pay for your product. The \\nlarger the group willing to pay, the better. However, even if only \\none person (who isn’t a friend or family member trying to please \\nyou) is willing to pay, it’s a positive signal.\\nThe final question to ask yourself is whether you’ve reached \\na threshold that signals long-term success for your idea. This \\nthreshold should be a set of predefined parameters, such as rev-\\nenue or other individual metrics (it doesn’t necessarily have to \\nbe revenue).\\nIf you haven’t reached this critical threshold, it’s time to cir-\\ncle back and iterate on the code and product. If you have, it’s time \\nto scale. This could mean seeking investors, expanding your \\nteam, and professionalizing your approach to product develop-\\nment. Having a validated product gives you a strong argument \\nfor potential investors. However, if you decide to bootstrap, \\nyou’re still in a good position.\\nI hope this provides a clear roadmap for your journey ahead. \\nWhether you’re launching a startup or developing a product \\nwithin an existing company, these steps should prove quite  \\nhelpful. Remember, every journey begins with a single step, and \\nyou’ve already taken several. Keep moving forward, and I am \\nsure success will follow.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 232, 'page_label': '219'}, page_content='219\\nT\\nhe previous chapters touched on the sudden emergence of \\ngenerative AI, a phenomenon that seemed to materialize out \\nof thin air. However, the reality is far from it. Much like a gour-\\nmet dish simmering away in the back of a bustling kitchen, gen-\\nerative AI was quietly brewing, its flavors intensifying, until it \\nwas finally ready to be served. The first taste came in the summer \\nof 2022\\xa0with OpenAI’s DALL-E, followed closely by the unveil-\\ning of ChatGPT\\xa0toward the end of the same year.\\nThe explosion of generative AI was the result of a carefully \\ncurated recipe. The ingredients? A blend of technological \\nadvancements and convergences that, when combined, propelled \\nAI to unprecedented heights. This chapter peels back the layers \\nand explores the underlying factors that played a pivotal role in \\nthe rise of generative AI.\\n4\\nCHAPTER\\nGenerative AI’s Exponential \\nGrowth'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 233, 'page_label': '220'}, page_content='220 GENERATIVE AI\\nFirst on our list is the exponential increase in computing \\npower, often encapsulated by Moore’s law. This principle, which \\nposits that the number of transistors on a microchip doubles \\napproximately every two years, has been a driving force behind \\nour ability to perform increasingly complex computations at \\nbreakneck speeds. This, in turn, has been instrumental in train-\\ning large-scale AI models, the backbone of generative AI.\\nNext, we have the advent of cloud computing. This technol-\\nogy has revolutionized the way we access and utilize high- \\npowered computing resources, making them more affordable \\nand readily available. The democratization of AI that cloud com-\\nputing has facilitated means that even small startups can now \\ndevelop sophisticated AI systems, a feat that was once the exclu-\\nsive domain of tech giants.\\nThen there’s the development of hardware accelerators, such \\nas graphics processing units (GPUs) and T ensor Processing \\nUnits (TPUs). These devices have significantly accelerated AI \\ncomputations, particularly in the realm of deep learning. By pro-\\ncessing multiple computations simultaneously, these accelerators \\nhave made it possible to train larger and more complex AI mod-\\nels in a fraction of the time.\\nFurther, we can’t overlook the role of cheaper storage. Over \\nthe years, the cost of data storage has plummeted, making it fea-\\nsible to store and process the vast amounts of data needed for AI. \\nThis has been a game changer, as AI systems are notoriously \\ndata-hungry, requiring copious amounts of information to learn \\nand improve.\\nThe availability of Big Data is another crucial ingredient in \\nthe generative AI recipe. With the widespread use of the Internet \\nand digital technologies, we’re generating colossal amounts of \\ndata every second. This data serves as the lifeblood of AI systems, \\nproviding the rich, varied information they need to learn, adapt, \\nand improve.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 234, 'page_label': '221'}, page_content='Generative AI’s Exponential Growth 221\\nThe research of new algorithms and the refinement of exist-\\ning ones have enabled AI to glean insights from data more effec-\\ntively and efficiently. Deep learning, the subfield of machine \\nlearning that mimics the neural networks of the human brain, \\nhas been a game changer, powering many of the recent break-\\nthroughs in AI.\\nInvestment in AI research from both private entities and \\ngovernments has also played a pivotal role. Recognizing the \\ntransformative potential of AI, these stakeholders have poured \\nsubstantial resources into research and development. This influx \\nof funding has not only led to numerous breakthroughs but has \\nalso attracted some of the brightest minds to the field, further \\nfueling innovation.\\nThe open source culture prevalent in the AI community is \\nanother factor worth noting. Many AI advancements are shared \\nopenly, fostering a global community of researchers and devel-\\nopers who build upon each other’s work. This spirit of collabora-\\ntion has significantly accelerated the pace of AI development, \\nallowing for rapid iteration and improvement.\\nThe successful real-world applications of AI have also driven \\ninterest and investment in the field. From image recognition and \\nnatural language processing to autonomous vehicles and beyond, \\nAI has proven its worth in a myriad of contexts. These success \\nstories serve as powerful proof of concept, demonstrating the \\ntransformative potential of AI.\\nLastly, the undeniable business value of AI, and more \\nrecently generative AI, cannot be overlooked. For years, AI has \\nbeen delivering tangible business benefits, and with the advent \\nof generative AI the scope for value creation has expanded even \\nfurther. As we continue to explore and use these technologies, \\nthere’s no doubt that we’re only scratching the surface of \\nwhat’s possible.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 235, 'page_label': '222'}, page_content='222 GENERATIVE AI\\nThe Growth Pattern of\\xa0New Technologies— \\nThe S-Curve\\nThe factors discussed so far are not only influencing the growth \\nof technology and AI but are also shaping the trajectory of inno-\\nvation itself. One way to capture this dynamic evolution is \\nthrough the concept of the S-curve, a common pattern observed \\nin the growth of new technologies (Figure\\xa04.1).\\nT echnologies often have humble beginnings, emerging from \\nthe hallowed halls of university labs or the innovative hubs of \\ncorporate research departments. In these early stages, the tech-\\nnology might seem insignificant or even ineffective. It’s a period \\nof trial and error, of fine-tuning and tweaking, where the poten-\\ntial of the technology is yet to be fully realized.\\nHowever, there comes a tipping point where the technology \\nstarts to work effectively, triggering a phase of accelerated growth. \\nThis is the steep upward curve of the S, a period characterized by \\nMature phase\\nHyper growth phase\\nGrowth phase\\nGrowth\\nEarly phase\\nTime\\nWhy does growth stall?\\nChurn > new member acquisition\\nIncreased competition\\nRapid technological development\\nChanging consumer preferences (i.e.,\\nCOVID-19)\\nExpiration of IP\\nRegulation\\nDistraction/lack of internal focus\\nAll businesses naturally hit a growth S-curve\\nover time and reach the mature phase; some\\nreach it faster than others.\\nSaturation of marketing channels (i.e.,\\nFacebook)\\nFIGURE\\xa04.1 The life cycle of innovation: the S-curve.\\nSource: https://medium.com/parsa-vc/jumping-s-curves-building-a-high-performance- \\nstartup-80e4410466a5'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 236, 'page_label': '223'}, page_content='Generative AI’s Exponential Growth 223\\na flurry of activity, excitement, and rapid adoption. It’s during this \\nphase that the technology makes the leap from the lab to the real \\nworld, transforming industries and impacting lives.\\nBut like all things, this period of frenzied growth doesn’t last \\nforever. Eventually, the pace of growth starts to slow down. Every \\nnew incremental improvement becomes less perceptible to the \\nuser, and the technology begins to mature. This is the flattening \\ncurve of the S, marking the transition from a period of rapid \\ninnovation to one of consolidation and refinement.\\nAt this stage, the focus shifts. The question is no longer about \\nwhether the technology is going to work or what’s going to work. \\nInstead, the conversation centers around the implications of the \\ntechnology now that it has a large user base. It’s about under -\\nstanding the impact, managing the challenges, and harnessing \\nthe opportunities that the technology presents.\\nThis S-curve pattern is evident in the evolution of AI and, \\nmore specifically, generative AI. From its early days in research \\nlabs to its current state of widespread adoption, generative AI has \\ntraversed this curve. As we continue to explore this fascinating \\nfield, we’ll delve deeper into the implications of this growth tra-\\njectory and what it means for the future of AI.\\nThe S-curve pattern is not unique to AI. In fact, it’s a com-\\nmon phenomenon in the evolution of many groundbreaking \\ntechnologies. Let’s consider a few examples.\\nThe development of the PC is a classic case. In the early \\nstages, PCs were bulky, expensive, and not particularly user-\\nfriendly. However, as the technology improved, PCs became \\nmore accessible and affordable, leading to a period of rapid \\ngrowth and widespread adoption. Eventually the market matured, \\nand the pace of growth slowed as incremental  improvements \\nbecame less noticeable to the average user.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 237, 'page_label': '224'}, page_content='224 GENERATIVE AI\\nA similar pattern can be observed in the evolution of the \\nInternet. Initially, the Internet was a novelty, a tool used primar-\\nily by academics and researchers. But as it became more user-\\nfriendly and accessible, its growth skyrocketed. T oday, the \\nInternet is a ubiquitous part of our lives, and while it continues \\nto evolve, the pace of growth has inevitably slowed.\\nThe trajectory of the adoption of mobile phones also follows \\nthe S-curve. From the hefty, expensive mobile phones of the \\nearly days to the sleek, multifunctional smartphones of today, the \\ngrowth of mobile technology has been nothing short of phe-\\nnomenal. But again, as the technology matured, the pace of \\ngrowth has slowed.\\nWhat’s interesting about these S-curves is that they often \\noverlap. Just as one S-curve is maturing and slowing down, \\nanother one often starts up. This is precisely what we’re witness-\\ning with generative AI. As technologies like the Internet and \\nmobile phones mature, generative AI is just beginning its upward \\ntrajectory on the S-curve. Figure\\xa04.2 shows overlapping S-curves, \\nillustrating technological advancement in the form of succes-\\nsively implemented innovations.\\nThird industry-leading business\\nSecond industry-leading business\\nFirst industry-leading business\\nPath of high performers\\nGrowth\\nTime\\nFIGURE\\xa04.2 The evolution of innovation: successive waves of techno-\\nlogical advancements represented by multiple following S-curves.\\nSource: https://medium.com/parsa-vc/jumping-s-curves-building-a-high-performance- \\nstartup-80e4410466a5'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 238, 'page_label': '225'}, page_content='Generative AI’s Exponential Growth 225\\nThis cycle of innovation and growth tends to operate on a \\ntimescale of 5, 10, or even 20 years. It’s a continuous process of \\nevolution and revolution, where each new technology builds on \\nthe foundations laid by its predecessors.\\nIndeed, the S-curves for innovation are becoming increas-\\ningly compressed. Several factors are contributing to this trend, \\ncreating a fast-paced cycle of technological evolution and \\nrevolution.\\nFirst, the rapid pace of technological advancements is a key \\ndriver. The improvements in computing power, data availability, \\nand affordability, coupled with the relentless efforts in research \\nand development, are accelerating the pace of innovation. These \\nfactors are effectively shortening the S-curves, enabling technolo-\\ngies to move from the lab to the market at an unprecedented speed.\\nAnother factor is the heightened level of competition in \\ntoday’s global business landscape. In this high-stakes environ-\\nment, companies are under constant pressure to stay ahead of the \\ncurve. This drive to innovate and differentiate fuels shorter inno-\\nvation cycles, as businesses strive to introduce new products and \\nservices that can give them a competitive edge.\\nThe culture of knowledge sharing, facilitated by the wide-\\nspread availability of information and collaborative platforms, is \\nalso contributing to shorter S-curves. The open sourcing of \\ntechnologies and algorithms allows innovators to build upon \\nexisting knowledge, iterate more quickly, and bring their ideas to \\nfruition faster. This collaborative approach is not only accelerat-\\ning the pace of innovation but also fostering a more inclusive and \\ndiverse tech ecosystem.\\nMarket demand is another crucial factor. With rapid shifts in \\nconsumer preferences and the emergence of a global customer \\nmarket, companies are required to respond swiftly with innova-\\ntive solutions. This demand-driven approach is pushing for \\nshorter innovation cycles, as businesses strive to meet the evolv-\\ning needs of their customers.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 239, 'page_label': '226'}, page_content='226 GENERATIVE AI\\nAs a result of these factors, we can expect to see much shorter \\nproduct development cycles and the emergence of new technol-\\nogies at a faster pace. As we witness the simultaneous evolution \\nand revolution of various technology fields, it’s clear that we’re in \\nthe midst of an exciting era of accelerated innovation. The advent \\nof generative AI is a testament to this trend, marking the begin-\\nning of a new S-curve that promises to reshape our world in ways \\nwe’re only beginning to imagine.\\nTechnological Convergence\\nThe rise of generative AI is being significantly propelled by its \\nconvergence with other fields— a phenomenon known as techno-\\nlogical convergence.\\nT echnological convergence refers to the trend where distinct \\ntechnological systems evolve toward performing similar tasks. \\nThis is achieved by integrating multiple functionalities into a \\nsingle device or system, leading to more efficient and stream-\\nlined user experiences. T echnological convergence is often direc-\\ntional, with one field exerting a greater influence on others.\\nIn this context, AI stands out as a crucial catalyst. Its rapid \\nadvancement is cascading through numerous other technologies, \\ncreating a ripple effect that’s driving demand for further innova-\\ntion and refinement. The velocity of AI’s development is not just \\nreshaping its own field but also accelerating the evolution of \\nother technologies.\\nT ake, for example, the impact of neural networks— both gen-\\nerative and discriminative— on various sectors. They’re driving \\nadvancements in adaptive robotics, enabling robots to learn from \\ntheir environment and adapt their behavior accordingly. In the \\nrealm of autonomous mobility, neural networks are at the heart \\nof self-driving vehicles, facilitating real-time decision making \\nand navigation.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 240, 'page_label': '227'}, page_content='Generative AI’s Exponential Growth 227\\nAnother example is the intersection of AI and genomics. \\nGoogle, for instance, has leveraged AI algorithms to significantly \\nenhance the accuracy of long-read DNA sequencing. By employ-\\ning neural networks, they managed to reduce DNA sequencing \\nerror rates by 59 percent. This breakthrough not only improved \\nthe quality-adjusted yields but also brought down the costs asso-\\nciated with long-read genome sequencing. In 2023, PacBio, a \\nleading provider of high-quality sequencing solutions, integrated \\nAI-specific compute hardware into its long-read sequencer. This \\nmove was touted as the first high-quality, whole long-read \\ngenome for less than $1,000.\\nIn the realm of robotics, advances in large language models \\n(LLMs) have enabled robots to learn from experience and acquire \\nnew skills at an accelerated pace. The adoption of the T ransformer \\narchitecture from AI has empowered robots to generalize from \\nexamples and perform tasks they’ve never encountered before— a \\ncapability known as zero-shot learning. This has led to a dramatic \\nimprovement in their learning efficiency, with the success rate \\njumping from 19 percent in 2021 to 76 percent in 2022.\\nConversely, AI is also being propelled by advancements in \\nother fields. For instance, the progress in battery technology has \\nhad a significant impact on AI. As battery capacity and energy \\ndensity have increased substantially over the years— often by \\ndouble-digit percentages— this has enabled the development of \\nmore advanced, mobile, and autonomous devices. These devices, \\nranging from robots to cars, increasingly rely on AI for \\ntheir autonomy.\\nAs we continue to explore this chain of thought, the land-\\nscape of possibilities expands, becoming less predictable yet more \\nintriguing. Economists estimate that the global GDP could see a \\nstaggering increase of anywhere from 60 percent to 470 percent \\nby the year 2040, largely driven by the disruptive technologies \\nwe see today.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 241, 'page_label': '228'}, page_content='228 GENERATIVE AI\\nThis creates the potential for super-exponential growth, pro-\\nvided certain conditions are met— a topic we’ll delve into later in \\nthis chapter. The convergence of AI with these technologies is \\npaving the way for the creation of more intelligent, autonomous, \\nand personalized systems. However, this evolution is not without \\nits challenges. Issues surrounding data privacy and security, as \\nwell as the ethical use of AI, are significant hurdles that need to \\nbe addressed.\\nExponential Progress in\\xa0Computing\\nThe bedrock of AI’s meteoric rise lies in the realm of computa-\\ntion. T o truly grasp the magnitude of this evolution, we must first \\nunderstand the insatiable hunger of advanced AI models for \\ncomputing power. T raining these behemoths, with their vast seas \\nof data and their intricate web of billions of trainable parameters, \\ndemands an astronomical amount of computational muscle. This \\ncomputational appetite is quantified in FLOPs, or floating-point \\noperations per second. In layperson’s terms, FLOPs provides a \\nmeasure of how many floating-point calculations a machine can \\nchurn out within a mere second.\\nThe art and science of AI computation lie in a delicate bal-\\nance. On one hand, we have the increase of hardware’s comput-\\ning power— FLOPs. On the other, there’s software optimization, \\nwhere the goal is to trim down the FLOPs required. This dual \\napproach is the linchpin in the optimization of AI systems.\\nT racing the trajectory of computational power, we can’t help \\nbut acknowledge the prescient observation of Gordon Moore in \\n1965. Dubbed Moore’s law, it postulated that the number of tran-\\nsistors packed into a microchip would roughly double every two \\nyears. This prediction, which seemed audacious at the time, has \\nlargely held true, steering us into an era of exponential growth in \\ncomputing prowess. T o put this into perspective, consider the \\niPhone 14 Pro’s chip, a chip for a device that fits in the palm of'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 242, 'page_label': '229'}, page_content='Generative AI’s Exponential Growth 229\\nyour hand, released in 2022, boasting a staggering 16 billion tran-\\nsistors. Contrast this with one of the first chips used in personal \\ncomputers of the 1970s, such as the Amstrad PC 1512 or the Intel \\n8086 (1978), which had 29,000 transistors. This represents an \\nincrease of more than half a million times at the chip level.\\nThe relentless march of transistor count has been not only \\nabout sheer numbers but also about the profound implications of \\nthese numbers. The miniaturization of transistors has ushered in \\nan era of compact yet formidable devices. T ake, for instance, the \\nApollo guidance computer of 1969, a marvel of its time, which \\nboasted a computational might of around 15,000 FLOPs. Fast-\\nforward to 2005/2006, and we find the Xbox 360 flexing a stag-\\ngering 240 GFLOPS— a leap that’s 16\\xa0million times the power \\nof its predecessor. This juxtaposition paints a vivid picture of \\nhow far we’ve come in just a few decades. See Figure\\xa04.3 for a \\nlogarithmic scale representation of the law.\\nELECTROMECHANICAL SOLID-\\nSTATE\\nRELAY\\nVACUUM\\nTUBE\\nTRANSISTOR INTEGRATED CIRCUIT\\nHUMAN\\nBRAIN\\nMOUSE\\nBRAINCORE i7 QUAD\\nPENTIUM 4\\nCOMPAQ\\nDESKPRO 386\\nPENTIUM\\nIBM AT-80286\\nALTAIR 8800\\nIBM 1130\\nDEC PDP-1\\n10161016\\n1014\\n1012\\n1010\\n108\\n106\\n104\\n102\\n10–2\\n10–4\\n0\\nUNIVAC I\\nIBM PC\\nIBM 704IBM SSEC\\nCOLOSSUS\\nCALCULATIONS PER SECOND PER $1000\\nIBM\\nTABULATOR\\nSOURCE: RAY KURZWEIL, “THE SINGULARITY IS NEAR: WHEN HUMANS TRANSCEND BIOLOGY”, P.67, THE\\nVIKING PRESS, 2006. DATAPOINTS BETWEEN 2000 AND 2012 REPRESENT BCA ESTIMATES.\\n1900\\n1905\\n1910\\n1915\\n1920\\n1925\\n1930\\n1935\\n1940\\n1945\\n1950\\n1955\\n1960\\n1965\\n1970\\n1975\\n1980\\n1985\\n1990\\n1995\\n2000\\n2005\\n2010\\n2015\\n2020\\n2025\\nHOLLERITH\\nTABULATOR\\nBELL\\nCALCULATOR\\nMODEL 1\\nNATIONAL\\nELLIS 3000\\nANALYTICAL ENGINE\\nAPPLE IIDEC\\nPDP-10\\nPENTIUM III\\nPENTIUM II\\nCORE 2\\nDUO\\nOPTICAL,\\nQUANTUM,\\nDNA\\nCOMPUTING?\\n© BCA Research 2013\\nFIGURE\\xa04.3 Moore’s law in action: a logarithmic scale representation \\nof the exponential growth in transistor count per microchip over time.\\nSource: www.publish0x.com/muratkbesiroglu/futurist-ray-kurzweils-predictions-about- \\nthe-future-xqkjyyw'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 243, 'page_label': '230'}, page_content='230 GENERATIVE AI\\nHowever, every ascent faces its summit, and Moore’s law is \\nno exception. The very essence of this law, the shrinking of tran-\\nsistors, is now becoming its Achilles’ heel. As we venture into the \\nrealm of nanometers, a peculiar quantum phenomenon rears its \\nhead— quantum tunneling. This phenomenon allows electrons \\nto defy classical physics, bypassing the depletion layer in a tran-\\nsistor. The result? Disrupted calculations, rendering the com-\\nputer unreliable. When you cram a chip with countless such \\nminuscule transistors, quantum tunneling becomes an insur -\\nmountable challenge, signaling the twilight of Moore’s law.\\nBut the dimming of one beacon doesn’t plunge the world of \\ncomputation into darkness. The waning of Moore’s law merely \\nheralds a paradigm shift in our quest for computational suprem-\\nacy. Quantum computing, with its promise of harnessing the \\nquirks of quantum mechanics, emerges as a tantalizing prospect.\\nMoreover, the challenges of miniaturization, such as heat \\ndissipation and manufacturing intricacies, have indeed slowed \\nthe pace set by Moore’s law. But this deceleration in hardware \\nhas been counterbalanced by leaps in other domains. Software \\noptimizations, innovative algorithms, and groundbreaking archi-\\ntectures are charting new paths. Parallel computing, which \\ndivides tasks across multiple processors, and quantum comput-\\ning, which taps into the probabilistic nature of quantum bits, are \\nredefining the boundaries of what’s possible. Additionally, the \\nadvent of specialized hardware, like GPUs and TPUs, has turbo-\\ncharged specific computational tasks, from rendering lifelike \\ngraphics to training intricate neural networks.\\nPeering into the horizon, we could posit a tantalizing hypoth-\\nesis: Moore’s law, rather than facing obsolescence, might be on \\nthe verge of an upside break. The combined might of hardware \\ninnovations, software breakthroughs, and pioneering research \\ncould propel computational advancements at a pace that even \\noutstrips Moore’s predictions. The future, it seems, holds prom-\\nise and potential in equal measure.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 244, 'page_label': '231'}, page_content='Generative AI’s Exponential Growth 231\\nExponential Hardware Evolution\\nThis section highlights key hardware-related developments, \\nfrom customized chips to quantum and neuromorphic comput-\\ning, and previews groundbreaking research potentially shaping \\nthe future of technology.\\nChips Chip design is a dynamic landscape, with innovations \\nsprouting at an unprecedented pace. Although this chapter won’t \\ndive deep into the nitty-gritty of chip design, there are pivotal \\ntrends worth highlighting.\\nThree primary trends dominate the chip design horizon: the \\ndrive toward even smaller chip designs, the rise of application-\\nspecific\\xa0integrated circuits\\xa0(ASICs), and the evolution of system-\\non-a-chip (SoC) architectures.\\nAs we tread the path of miniaturization, the distances between \\nconductors and transistors on chips have been whittled down to \\njust a few nanometers. Leading this race to the minuscule is IBM, \\nwhich has unveiled a groundbreaking achievement— the world’s \\nfirst two-nanometer chip technology. This feat is not just about \\nsize; it’s about overcoming the engineering challenges posed by \\nleakage effects as chip sizes shrink.\\nKey insights into IBM’s two-nanometer chip technology  \\ninclude:\\n• A whopping 45 percent boost in performance coupled with \\na 75 percent reduction in energy consumption when juxta-\\nposed with the prevalent 3 to 5 to 7\\xa0nm chips. This enhance-\\nment translates to a substantial 31 percent reduction in AI \\ntraining time.\\n• The potential applications are vast and transformative. \\nImagine mobile phones that last four times longer, datacent-\\ners that slash their carbon footprints, and autonomous vehi-\\ncles that react in a split second.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 245, 'page_label': '232'}, page_content='232 GENERATIVE AI\\n• IBM’s pioneering “nanosheet technology” manages to pack \\nan astounding 50 billion transistors on a surface no larger \\nthan a fingerprint.\\n• These nanosheet transistors, christened gate-all-around \\ntransistors, have been under the research microscope since \\n2017. Their design ensures optimal current control while \\nstaunchly preventing leakage.\\n• The diminutive size of these transistors doesn’t compromise \\ntheir efficacy. They pave the way for devices that are faster, \\nmore dependable, and energy efficient, spurring innovations \\nin processor designs. Moreover, this technology is  \\ntailor-made to bolster AI and cloud computing tasks, all \\nwhile fortifying security and encryption at the hardware level.\\nEnter the world of ASICs, or application-specific integrated \\ncircuits. These are not your run-of-the-mill integrated circuits. \\nThey are the epitome of customization, meticulously crafted for a \\nsingular purpose or task. While general-purpose integrated cir -\\ncuits are the jacks-of-all-trades, ASICs are the masters of one. This \\nlaser-focused design ethos bestows upon them unparalleled advan-\\ntages in performance, power efficiency, and cost-effectiveness.\\nT o paint a clearer picture, consider the realm of cryptocur -\\nrency mining. ASIC miners, specialized computerized devices, \\nhave taken the crypto world by storm. Each of these machines is \\npurpose-built to mine a designated digital currency, such as Bit-\\ncoin. Their raison d’être is to crack the mining algorithm with \\nunparalleled efficiency, leaving general-purpose processors and \\ngraphics cards in the dust.\\nBut it’s not just about raw computational power. Many of the \\noptimizations I’ve witnessed lean heavily into energy conserva-\\ntion— a facet that’s gaining increasing importance in our eco-\\nconscious world. And there’s a computational boon to this energy'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 246, 'page_label': '233'}, page_content='Generative AI’s Exponential Growth 233\\nthriftiness. With reduced heat production, architectures can be \\npacked more densely, further amplifying the prowess of these \\nchips. The future of chip design, it seems, is not just about doing \\nmore, but doing more with less.\\nAnother discernible trend in the chip design landscape is the \\nemergence of more efficient chip designs, prominently mani-\\nfested in the form of SoC developments. At its core, a system-on-\\na-chip can be thought of as a specialized variant of an ASIC.\\nThe brilliance of the SoC lies in its ability to amalgamate all \\nthe components of a computer or any electronic system into one \\ncohesive unit. Imagine a single chip that houses a CPU, memory \\nmodules, timing mechanisms, peripherals, and even external \\ninterfaces. This compactness and integration makes SoCs the \\nheart of many contemporary devices, from the smartphones we \\ncan’t live without to the smart appliances that make our homes \\nmore intuitive, and even the burgeoning realm of Internet of \\nThings (IoT) devices. Their allure stems from their unparalleled \\nefficiency and diminutive size. While they can be tailored for \\nspecific tasks, enhancing both performance and power efficiency, \\nthe journey to craft them is riddled with complexities. The chal-\\nlenge? Seamlessly integrating a myriad of components onto one \\nchip. Notable exemplars in this domain include the powerhouse \\nApple’s A series chips and the versatile Qualcomm’s Snap-\\ndragon chips.\\nBut what makes SoC designs the torchbearers of the next \\nwave of computational prowess?\\nThe beauty of SoCs is their integrated design, which houses \\nall components on a single chip, significantly reducing data tran-\\nsit time between components and leading to faster data process-\\ning and enhanced system performance. Customization is central \\nto SoCs, with every aspect of the chip, from its individual com-\\nponents to their interactions, being meticulously tailored for'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 247, 'page_label': '234'}, page_content='234 GENERATIVE AI\\nspecific applications, ensuring unparalleled performance. More-\\nover, SoCs excel in power efficiency; their compact design and \\noptimized components ensure minimal energy consumption, \\nwhich is especially beneficial for battery-operated devices, offer-\\ning extended battery life without sacrificing performance. In an \\nera where sleekness and portability are paramount, the compact \\nnature of SoCs allows for lightweight and space-efficient devices \\nwithout compromising on their performance.\\nT o underscore the significance of SoCs in today’s market, \\nconsider this: The SoC market, as of 2023, stands at a staggering \\n$159.85 billion. Projections indicate that by 2028, this market \\nwill balloon to an estimated $234.98 billion, with a compound \\nannual growth rate (CAGR) of 8.01 percent during the 2023–\\n2028 period, underscoring the pivotal role SoCs are set to play in \\nthe future of tech.\\nOne quickly realizes that it’s a domain marked by relentless \\ninnovation and high stakes. My foray into this realm, driven by \\ncuriosity rather than expertise, has unveiled a tapestry of promis-\\ning trends that could redefine the future of computing. Here’s a \\ncloser look at some of these groundbreaking developments:\\n3D-Stacked CMOS The 3D-stacked CMOS technology is \\nanother game changer. Instead of laying out transistors flat, \\nlike houses in a neighborhood, this technology stacks them \\nvertically, akin to a multistory building. This vertical arrange-\\nment allows for more transistors in the same space, leading to \\nincreased computing power. In simple terms, it’s like having \\nmultiple processing units stacked atop one another, working in \\ntandem. The potential performance gain is substantial, as data \\ncan move faster between vertically stacked transistors, acceler-\\nating processing speeds.\\nForksheet Transistor Design Imec’s innovative Forksheet \\ntransistor design is set to breathe new life into silicon-based'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 248, 'page_label': '235'}, page_content='Generative AI’s Exponential Growth 235\\nsemiconductors. At its core, the Forksheet design tweaks the \\ntraditional transistor layout to reduce leakage and improve \\nperformance. Imagine a river with multiple channels; if one \\nchannel leaks, the others can still function efficiently. Simi-\\nlarly, the Forksheet design ensures that even if one part faces \\nissues, the overall performance remains robust. This design \\ncan lead to chips that are not only more reliable but also \\nfaster, potentially boosting performance by a signifi-\\ncant margin.\\nHybrid Microchip The fusion of memory resistors, or mem-\\nristors, and CMOS technology has birthed a new hybrid \\nmicrochip. Memristors, in essence, are resistors with memory. \\nWhen combined with CMOS technology, these chips can \\nprocess and store data simultaneously, making them ideal for \\nAI tasks that require rapid data processing. In simpler terms, \\nit’s like having a brain that thinks and remembers at the same \\ntime, leading to faster decision making. The potential perfor-\\nmance gain here is immense, especially for AI-driven applica-\\ntions where speed and memory are paramount.\\nProcessing Units Next up, processing units. While the power \\nof individual chips is crucial, the real magic happens when these \\nchips are orchestrated in harmony. This is especially paramount \\nfor tasks like training AI models.\\nHere’s an explanation of processing units:\\nCPU (Central Processing Unit) Often referred to as the \\n“brain” of the computer, the CPU handles a variety of tasks \\nand is adept at sequential processing. It’s the jack-of-all-trades \\nin the computing world, capable of managing everything from \\nbasic arithmetic to complex system operations. However, \\nwhen it comes to AI training, CPUs might not be the most'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 249, 'page_label': '236'}, page_content='236 GENERATIVE AI\\nefficient choice. The reason? AI training requires parallel \\nprocessing, something GPUs and other specialized \\nunits excel at.\\nGPU (Graphics Processing Unit) Initially designed for ren-\\ndering graphics, GPUs have found a new calling in the realm \\nof AI. Their strength lies in their ability to handle multiple \\ntasks simultaneously. Imagine trying to solve multiple math \\nproblems at once; that’s what GPUs excel at. Their parallel \\nprocessing capabilities, coupled with high memory bandwidth \\nand specialized software libraries, make them a preferred \\nchoice for AI model training.\\nTPU (Tensor Processing Unit) Google’s brainchild, the \\nTPU, is tailored for T ensorFlow, their machine learning (ML) \\nframework. While GPUs are versatile, TPUs are purpose-\\nbuilt for ML tasks, offering unparalleled performance per \\nwatt. However, their specificity to T ensorFlow means they \\nmight not be the go-to choice for those using different \\nframeworks.\\nIPU (Intelligence Processing Unit) Graphcore’s IPU, par-\\nticularly the Colossus MK2 GC200, is a force to be reckoned \\nwith in the AI world. With a staggering 1472 processor core \\nand almost 9,000 parallel program threads, it’s designed to \\ntackle the unique challenges of deep learning. Its architecture \\nis optimized for the myriad of operations required for such \\ntasks, making it a formidable competitor to traditional GPUs.\\nNPU (Neural Processing Unit) The NPU is the embodi-\\nment of ML hardware. Designed explicitly for neural network \\ncomputations, it’s optimized for the matrix operations that are \\nthe backbone of deep learning. Various tech giants have thrown \\ntheir hats into the NPU ring, with Huawei’s version being a \\nnotable example. While GPUs are adept at parallel processing, \\nNPUs are fine-tuned for neural networks, often delivering \\nsuperior performance for deep learning tasks. It’s worth noting'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 250, 'page_label': '237'}, page_content='Generative AI’s Exponential Growth 237\\nthat the world of NPUs is vast, with various iterations like \\nTPUs, IPUs, and more, each with its unique strengths.\\nIn essence, the choice of processing unit boils down to the \\nspecific requirements of the task at hand. While CPUs are versa-\\ntile, GPUs and NPUs offer specialized capabilities that make \\nthem more suited for certain deep learning tasks. The rapid \\nadvancements in this field ensure that the future of AI and ML is \\nnot just promising but also incredibly exciting. As we continue to \\npush the boundaries of what’s possible, these processing units \\nwill undoubtedly play a pivotal role in shaping the future of \\ntechnology.\\nDetermining the “optimal” processing unit is often contin-\\ngent on the distinct demands of the task. GPUs, with their prow-\\ness in executing parallel operations, have become the go-to \\nchoice for training intricate deep learning models. On the other \\nhand, TPUs, a brainchild of Google, have been meticulously \\ncrafted to adeptly manage ML operations. Not to be left behind, \\nIPUs, the innovation of Graphcore, emerge as another con-\\ntender, tailored explicitly for AI-centric workloads. The decision \\nmatrix, when selecting among these powerhouses, hinges on sev-\\neral factors: the model’s magnitude, data volume, and the equi-\\nlibrium between speed and efficiency.\\nHighlighting the vanguard in this domain:\\n• GPU: The NVIDIA A100 T ensor Core GPU stands as a \\ntitan among its peers. Purpose-built for AI, data analytics, \\nand high-performance computing, its versatility spans a \\ngamut of applications— from AI model training and infer -\\nence to data analytics, scientific computations, and even \\ncloud graphics. A testament to its might, the NVIDIA A100 \\nT ensor Core GPU boasts a staggering 312 teraFLOPS \\n(TFLOPS) of computational power.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 251, 'page_label': '238'}, page_content='238 GENERATIVE AI\\n• TPU: Google’s T ensor Processing Unit (TPU) is not just \\nanother chip— it’s a meticulously engineered application-\\nspecific integrated circuit (ASIC) with a singular focus: \\nsupercharging ML tasks. These TPUs are the silent work-\\nhorses in Google’s datacenters, powering an array of services \\nwe use daily— be it Google Search, Gmail, Google Photos, \\nor the myriad Google Cloud AI APIs. The latest in this line-\\nage, the TPU v4, is a force to be reckoned with, offering a \\nrobust 260 teraFLOPs (TFLOPs) of performance.\\n• IPU: Venturing into the realm of AI-specific processing, \\nGraphcore’s Intelligence Processing Unit (IPU) emerges as \\na formidable player. The Graphcore Colossus MK2 IPU, \\nwith its specialized design, finds its niche in diverse arenas, \\nfrom cloud computing to cutting-edge AI research. A nota-\\nble implementation of this powerhouse is the IPU-Ray-Lib \\nproject— a path-tracer fine-tuned for Graphcore IPUs. With \\na performance benchmark set at an impressive 250 TFLOPs, \\nit’s clear that the IPU is not just another chip on the block— \\nit’s a revolution in its own right.\\nCompany-Customized AI Hardware In the sprawling land-\\nscape of AI and computational technology, there’s a discernible \\ntrend among industry giants— especially those for whom perfor-\\nmance isn’t just a metric, but a mantra. These behemoths, in \\ntheir relentless pursuit of excellence, often sidestep off-the-shelf \\nsolutions, opting instead to forge their own path by crafting \\nbespoke processing units tailored to their unique needs.\\nApple, the Cupertino-based titan, stands as a shining exem-\\nplar of this approach. Their commitment to performance and \\nuser experience has led them to design a suite of proprietary pro-\\ncessing units, ensuring that every device they produce is not just \\na piece of hardware but a meticulously engineered experience.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 252, 'page_label': '239'}, page_content='Generative AI’s Exponential Growth 239\\n• Apple M1: A quantum leap in Apple’s hardware journey, the \\nApple M1 is an ARM-based system-on-a-chip that serves as \\nboth the brain (CPU) and the visual maestro (GPU) for \\ntheir Mac desktops, notebooks, as well as the iPad Pro and \\niPad Air tablets. This chip isn’t just about raw power— it’s a \\nsymphony of performance and efficiency, fine-tuned to per-\\nfection for macOS and iOS applications. With the M1, Apple \\ndidn’t just aim to compete; they set out to redefine \\nthe paradigm.\\n• A-series chips: For over a decade, Apple’s mobile devices— \\niPhones, iPads, and Apple Watches— have been powered by \\nthe A-series chips. These aren’t just processors; they’re a tes-\\ntament to Apple’s vision of what mobile computing should \\nfeel like. Designed to deliver both blistering performance \\nand unparalleled efficiency, these chips ensure that every \\ninteraction, every swipe, every tap feels fluid and responsive. \\nAnd they’re not just about speed— they’re optimized to run \\niOS and watchOS applications with a finesse that’s become \\nsynonymous with the Apple brand.\\nT esla emerges as another luminary, pushing the boundaries \\nof what’s possible in both AI and robotics. Elon Musk’s brain-\\nchild, T esla, isn’t just about electric cars— it’s a technological \\npowerhouse, constantly innovating and redefining the intersec-\\ntion of hardware, software, and AI.\\n• T esla Dojo: This isn’t just another supercomputer— it’s T esla’s \\nanswer to the challenges of computer vision video process-\\ning and recognition. Purpose-built, the Dojo is the crucible \\nwhere T esla’s ML algorithms are honed, ensuring that their \\nvehicles aren’t just self-driving, but self-learning.\\n• T esla’s custom AI chips: While many automakers rely on third-\\nparty solutions for their autonomous driving tech, T esla took'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 253, 'page_label': '240'}, page_content='240 GENERATIVE AI\\nthe road less traveled. In a little over a year, they designed a \\ncustom AI chip tailored to the unique demands of their self-\\ndriving ambitions. Manufactured by Samsung, this chip isn’t \\njust about power— it’s about precision, ensuring that T esla \\ncars can navigate the complexities of real-world driving with \\nunparalleled accuracy. And T esla’s commitment to excellence \\ndoesn’t stop at their new cars. In a move that underscores \\ntheir dedication to safety and performance, older models are \\nbeing retrofitted with this cutting-edge processor.\\nHowever, it’s crucial to dispel a common misconception. \\nWhile T esla has been a pioneer in developing custom hardware \\nfor its fleet of electric vehicles, there’s no specific processing unit \\ndubbed the “T esla Processing Unit” or “T esla NPU” in their \\narsenal, at the moment.\\nThe race for hardware dominance is not a solitary sprint but \\na collective marathon. While Apple and T esla have made head-\\nlines with their audacious strides, other tech behemoths like \\nAmazon, Intel, and Microsoft are not mere spectators. They’re in \\nthe thick of it, each sculpting its own niche, each pushing the \\nenvelope in its quest to redefine the future of computing.\\nY et, projecting this trajectory of Moore’s law, the implica-\\ntions are staggering. Within a span of five years, we’re looking at \\na monumental leap— a surge where our computational capabili-\\nties could amplify by a factor of almost 7. T o put this in tangible \\nterms, imagine a future iteration of the NVIDIA A100 called \\n“NVIDIA A200” boasting 2,080 teraFLOPS. Such a powerhouse \\ncould potentially slash model training times by 85 percent, revo-\\nlutionizing the way we approach deep learning and AI tasks.\\nIn the upcoming sections, I argue that we are approaching a \\npivotal moment that surpasses Moore’s law. We’re not merely \\ncontinuing its trajectory; we’re on the verge of breakthroughs \\nthat will fundamentally transform our understanding of what is \\npossible through innovation.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 254, 'page_label': '241'}, page_content='Generative AI’s Exponential Growth 241\\nCloud Computing Certain innovations emerge as pivotal \\ngame changers, reshaping the landscape in ways previously \\nunimagined. Cloud computing stands tall among these trans-\\nformative forces, casting a profound influence not only on the \\ntrajectory of technology but also on the very ethos of innovation \\nand collaboration.\\nCloud computing, in its essence, is the great equalizer. It has \\nushered in an era where computing power, once the exclusive \\ndomain of tech behemoths, is now within arm’s reach of the many. \\nThis democratization of computational might has catalyzed a \\nrenaissance of creativity, fostering an environment where ideas \\nflourish, unfettered by the constraints of physical infrastructure.\\nMy admiration for cloud computing is rooted in its sheer \\npracticality and transformative potential. Picture this: Within \\nthe span of a mere hour, one can seamlessly weave together the \\nintricate tapestry of a digital application. From deploying code \\non a computing instance to orchestrating a symphony between \\nfrontend and backend through an adept API manager, the entire \\nprocess is streamlined, efficient, and, dare I say, exhilarating. And \\nshould your creation resonate and attract a burgeoning user \\nbase? Scaling becomes a matter of a few clicks, not cumbersome \\nhardware acquisitions.\\nBut the magic of cloud computing isn’t confined to its agility \\nand efficiency. Its implications ripple across multiple facets:\\n• Scalability: The fluidity with which businesses can modulate \\ntheir computational resources is unparalleled. Whether it’s a \\nsurge during peak seasons or a lull in off-peak times, the \\ncloud adapts, ensuring optimal resource allocation without \\nthe baggage of redundant infrastructure.\\n• Cost-effectiveness: The pay-as-you-go model is a master -\\nstroke, aligning expenses with usage. Gone are the days of \\nhefty up-front hardware investments and the incessant drain \\nof maintenance costs.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 255, 'page_label': '242'}, page_content='242 GENERATIVE AI\\n• Accessibility: The cloud knows no boundaries. Its omnipres-\\nence ensures that high-caliber computational resources are a \\nmere click away, leveling the playing field for enterprises, \\nbig and small.\\n• Innovation: The cloud is a treasure trove of cutting-edge \\ntools and technologies. From AI toolkits to advanced analyt-\\nics, businesses can harness the power of the latest innova-\\ntions without the rigors of in-house development.\\n• Reliability: The architectural robustness of cloud providers, \\nwith their geographically dispersed datacenters, offers a \\nresilience that’s hard to match. Even in the face of unfore-\\nseen disruptions, the cloud remains steadfast, ensuring unin-\\nterrupted service.\\n• Energy efficiency: The centralization inherent in cloud com-\\nputing is not just a logistical boon but an environmental one. \\nBy pooling computational resources, the cloud achieves effi-\\nciencies of scale, curbing energy consumption and mitigat-\\ning the environmental footprint.\\nIn the grand scheme of things, cloud computing is more than \\njust a technological marvel— it’s a paradigm shift. As we navigate \\nthe intricate maze of Moore’s law and the promises it holds, the \\ncloud emerges as a beacon, illuminating the path to a future where \\nthe boundaries of what’s possible are continually reimagined.\\nQuantum Computing Quantum computing holds the poten-\\ntial to transform the computational world. Unlike traditional \\ncomputing with its binary “on” and “off” states, quantum com-\\nputing uses qubits that can exist in both states simultaneously. \\nThis capability, rooted in quantum mechanics, enables quantum \\ncomputers to process multiple solutions at once, vastly expand-\\ning computational possibilities.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 256, 'page_label': '243'}, page_content='Generative AI’s Exponential Growth 243\\nThe genesis of this idea can be traced back to the musings of \\nphysicist Richard Feynman in the early 1980s. Fast-forward a \\nfew decades, and we find ourselves amidst a quantum renais-\\nsance. T ech powerhouses like IBM, Google, and Microsoft are \\nfervently pouring resources into quantum R&D, with each stride \\nbringing us closer to harnessing its full potential. IBM’s recent \\nproclamation suggests a tantalizing horizon where quantum \\ncomputers transition from theoretical constructs to tangible \\ntools within a mere couple of years.\\nY et, the journey is riddled with challenges. Quantum coher-\\nence, the bedrock of quantum computing, is a fragile state, easily \\ndisrupted by environmental interactions. The hurdles are mani-\\nfold, from the Herculean task of maintaining qubit stability to \\nthe intricacies of quantum error correction. Scalability, precise \\nqubit control, accurate readouts, and the necessity for extreme \\ncooling further compound the complexity. And then there’s the \\nrealm of material science, where the quest for the ideal qubit-\\nhosting material is ongoing.\\nBut for every challenge, there’s an opportunity. The quantum \\nrealm is already making waves in real-world applications. Busi-\\nnesses, in their relentless pursuit of innovation, are harnessing \\nthe power of quantum computing to solve problems previously \\ndeemed insurmountable.\\nT ake Mercedes-Benz, for instance. The automotive giant, in \\nits commitment to a greener future, is delving into quantum \\ncomputing to revolutionize battery technology for electric vehi-\\ncles. The intricate dance of chemical reactions within batteries, \\ntraditionally elusive to conventional computational methods, \\nbecomes more tangible under the quantum lens.\\nExxonMobil, on the other hand, is leveraging quantum  \\nalgorithms to optimize fuel transportation routes, a task of  \\nstaggering complexity when approached with classical comput-\\ning methods.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 257, 'page_label': '244'}, page_content='244 GENERATIVE AI\\nCERN, the custodian of the Large Hadron Collider (LHC), \\nis harnessing quantum computing to decipher the universe’s \\nenigmas. The vast data streams from the LHC, rife with patterns \\nand anomalies, are prime candidates for quantum analysis.\\nMitsubishi Chemical, in collaboration with Keio University, \\nis exploring the intricacies of lithium-oxygen batteries at a \\nmolecular level, a task made feasible by quantum simulations.\\nPivoting to the broader landscape, when juxtaposed with tra-\\nditional powerhouses like GPUs and NPUs, quantum comput-\\ners promise an exponential speedup, especially in the domain of \\nmachine learning. This acceleration translates to swifter training \\nand inference times for ML models, a phenomenon aptly termed \\nquantum machine learning. This integration of quantum algo-\\nrithms within ML paradigms is set to redefine the benchmarks of \\ncomputational efficiency.\\nQuantum bits enable parallel processing, enhancing tasks \\nlike machine learning by exploring multiple states simultaneously.\\nPeering into the horizon, the quantum odyssey is laden with \\npotential. The immediate future, spanning one to three years, is \\npoised to witness quantum hardware reaching new zeniths and \\nthe birth of avant-garde quantum algorithms. T ransitioning to \\nthe medium term, spanning three to five years, the abstract allure \\nof quantum computers will materialize into tangible tools, find-\\ning their niche in sectors like cryptography and optimization. A \\ndecade from now, the quantum community aspires to craft a \\nfault-tolerant quantum computer— a beacon of achievement in \\nthe field.\\nY et, the dream of a universal, gate-based, T uring-complete \\nquantum behemoth remains a tantalizing vision on the distant \\nhorizon. But with the momentum garnered from recent innova-\\ntions, strategic foresight, and a deluge of investments, the dawn \\nof general-purpose quantum computers might just be closer than \\nwe dare to dream.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 258, 'page_label': '245'}, page_content='Generative AI’s Exponential Growth 245\\nThe quantum renaissance promises more than just speed— it \\npledges transformation. Quantum systems, with their capacity to \\nprocess data on an astronomical scale, will redefine precision in \\nmeasurements. Simulating intricate systems, from molecular \\nmatrices to cosmic phenomena, will be executed at speeds previ-\\nously deemed fantastical. The emergence of quantum sensors \\nwill usher in an era of unparalleled sensitivity and pinpoint accu-\\nracy. Communication infrastructures, fortified by quantum prin-\\nciples, will be bastions of security, rendering them nigh \\nimpervious. And in the realm of problem solving, quantum algo-\\nrithms will navigate the labyrinth of challenges, offering solu-\\ntions that are not just optimal, but also intuitive. The quantum \\nage beckons, and the future is reimagined. Figure\\xa04.4 shows a \\nphotograph of a quantum computer.\\nFIGURE\\xa04.4 A quantum computer’s intricate design: the loops, which \\nstraighten when cooled to –273°C, highlight the extreme cooling \\nmeasures essential for quantum computing operations.\\nSource: IBM Corporation / https://newsroom.ibm.com/media-quantum-innovation? \\nkeywords=quantum&l=100#gallery_gallery_0:21747 / last accessed December 01, 2023.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 259, 'page_label': '246'}, page_content='246 GENERATIVE AI\\nNeuromorphic Computing Neuromorphic computing emerges \\nas a beacon of promise. At its core, this paradigm seeks to emulate \\nthe intricate architecture and functionality of the human brain. By \\nharnessing physical artificial neurons for computations, realized \\nthrough mediums like oxide-based memristors, spintronic memo-\\nries, and transistors, it offers a fresh perspective on computational \\nprocesses. The spiking neural network (SNN) stands as its most \\ncelebrated manifestation, where nodes mirror the processing and \\ndata retention capabilities of biological neurons. The overarching \\nambition? T o usher in a new era of AI, characterized by brain-\\ninspired, energy-efficient computing.\\nEnter Rain Neuromorphics, a trailblazer in this domain. Bol-\\nstered by a robust $25\\xa0million Series A funding, the company is \\npoised to redefine the AI hardware landscape. Their audacious \\nvision encapsulates the creation of a chip no larger than a thumb-\\nnail, capable of handling a staggering 100 billion-parameter \\nmodels. With an unwavering belief in the transformative poten-\\ntial of AI, Rain Neuromorphics envisions a world where every \\ngadget is endowed with a dynamic, perpetually evolving AI \\nintellect.\\nWhile contemporary computing architectures rest on von \\nNeumann principles, with distinct memory and processing units \\nand a binary data representation, neuromorphic computing \\ndraws inspiration from cerebral constructs like neurons and syn-\\napses. This fusion of biology, mathematics, electronics, and phys-\\nics offers a holistic approach to computation.\\nThe true genius of neuromorphic computing lies in its emu-\\nlation of cerebral processes. Visual representations of an SNN, \\nwhich can be seen on Y ouT ube, depict a fascinating phenome-\\nnon. Only a handful of neurons spring into action during deci-\\nsion making, initiating a broad cascade that gradually narrows, \\nculminating in the final prediction— akin to a funnel’s mecha-\\nnism. This selective activation translates to fewer computational'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 260, 'page_label': '247'}, page_content='Generative AI’s Exponential Growth 247\\noperations, amplifying the efficiency and efficacy of neuromor -\\nphic computing.\\nQuantifying this efficiency, especially in computational oper-\\nations, poses challenges due to the distinct methodologies and \\ncomponents involved. However, energy consumption metrics \\noffer a glimpse into its potential. Preliminary estimates suggest \\nthat neuromorphic computing could slash energy consumption \\nfor data processing by a staggering 90 percent.\\nThe implications for contemporary AI are profound. Neuro-\\nmorphic systems, with their real-time learning capabilities, could \\nempower AI to adapt and respond with unprecedented agility, \\nelevating performance in fluid environments. The allure of \\nanalog computation, a hallmark of the human brain and a feature \\nof neuromorphic systems, could render them adept at tasks that \\nbaffle digital AI systems.\\nY et, the true potential of this field might lie in its symbiotic \\nrelationship with other technological domains. A nascent trend \\nhints at the fusion of neuromorphic computations with quantum \\ncomputing. By amalgamating the strengths of both realms, the \\ngoal is to birth computing systems of unparalleled efficiency and \\npower, capable of navigating the most labyrinthine computa-\\ntional challenges. While this convergence is still in its embryonic \\nphase, the horizon gleams with promise. The trajectory remains \\nuncertain, but one thing is clear— the future of computing is \\npoised for a seismic shift, and neuromorphic computing will \\nmost likely play an important role in this transformation.\\nLK-99’s Promise Imagine a future where the idea of room-\\ntemperature superconductors shines brightly, heralding untapped \\npossibilities. Picture superconductors, those materials that trans-\\nmit electricity without resistance, no longer bound by the icy \\nchains of ultra-cold temperatures. The potential unlocked by'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 261, 'page_label': '248'}, page_content='248 GENERATIVE AI\\ntranscending this temperature threshold is nothing short of \\nrevolutionary.\\nThe implications of such a breakthrough are manifold. Envi-\\nsion our power grids, for instance. The advent of room-temperature  \\nsuperconductors could drastically elevate their efficiency, banish-\\ning energy losses that plague transmission. The realm of energy \\nstorage could witness the birth of compact systems that not only \\nstore energy with heightened efficiency but also bolster the utili-\\nzation of renewable energy sources. T ransportation could undergo \\na metamorphosis with magnetic levitation (maglev) trains becom-\\ning more ubiquitous, offering swifter and more energy-conserving \\npublic transit options. The medical sector stands to gain too, with \\nMRI machines potentially becoming more affordable, efficient, \\nand widespread. And in the telecommunications sphere? We could \\nbe looking at communication systems that redefine speed and effi-\\nciency, from turbocharged Internet connections to crystal-clear \\ncell phone signals.\\nBut perhaps the most tantalizing prospect lies in the domain \\nof computing. T raditional processors, constructed from semi-\\nconductors, grapple with the Achilles’ heel of heat generation— a \\nbyproduct of electrical resistance. This thermal challenge not \\nonly curtails processor speed but also guzzles energy. Enter \\nsuperconductors. Their zero-resistance prowess could pave the \\nway for processors devoid of heat generation, heralding an era of \\nblistering processing speeds without the need for intricate cool-\\ning mechanisms. The energy economy of computing systems \\ncould witness a paradigm shift.\\nQuantum computing, too, stands on the cusp of a revolution. \\nRoom-temperature superconductors could render quantum \\ncomputers more pragmatic and accessible, obviating the need for \\nintricate cooling apparatuses. Such superconductors could bol-\\nster the stability of quantum systems, mitigating the menace of \\nqubits succumbing to “decoherence.” The scalability of quantum'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 262, 'page_label': '249'}, page_content='Generative AI’s Exponential Growth 249\\nsystems could witness a boost, potentially birthing quantum \\ncomputers of unparalleled power. And with energy efficiency in \\nthe mix, these quantum behemoths could be both eco-friendly \\nand cost-efficient. The ripple effect? An acceleration in quantum \\nresearch, catalyzing rapid breakthroughs.\\nEnter the enigma of LK-99. T outed as a potential room-  \\ntemperature superconductor, LK-99, with its distinctive hex-\\nagonal structure reminiscent of lead-apatite, has stirred the sci-\\nentific community. Its discovery, credited to researchers Sukbae \\nLee and Ji-Hoon Kim from Korea University, has been met \\nwith both intrigue and skepticism. While the team has dissemi-\\nnated their findings, the absence of peer review casts a shadow \\nof doubt. Replication attempts by global scientists have yet to \\nbear fruit, leading many to question the veracity of LK-99’s \\nclaims. The unfolding narrative around LK-99 underscores a \\nprofound realization: Our grasp of the periodic table remains \\nincomplete. Our elemental alchemy, the art of melding ele-\\nments to manifest desired properties, is still in its infancy. Y et, \\nin this challenge lies opportunity.\\nExponential Software Evolution\\nLet’s pivot from discussing hardware advancements to exploring \\nthe software realm. Software evolution goes beyond just refining \\ncode; it’s about designing holistic systems that synergize with \\nhardware to yield more efficient and precise outcomes. This \\nbrings us to the forefront of exponential software evolution, par-\\nticularly with parallel programming.\\nParallel Programming Parallel programming is a symphony \\nof synchronized algorithms, harmoniously working together to \\ntap into the full prowess of the hardware. When it all aligns, the \\nsurge in execution performance is nothing short of exhilarating.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 263, 'page_label': '250'}, page_content='250 GENERATIVE AI\\nA parallel algorithm isn’t just any algorithm— it’s a meticu-\\nlously designed blueprint that can simultaneously execute multi-\\nple instructions across diverse processing devices. The magic lies \\nin its ability to weave together individual outputs, producing a \\ncohesive final result. This design is no accident; it’s tailored to \\nharness the sheer power of parallel processing capabilities, espe-\\ncially in the realm of multiprocessor parallel computers.\\nDiving into the types of parallel algorithms, we find a rich \\ntapestry of classifications:\\n• Data parallelism: Here, the spotlight is on the data. Imagine \\nrunning the same program or operation, but on different \\ndata subsets, all at the same time. It’s like having multiple \\nchefs cooking different dishes using the same recipe.\\n• T ask parallelism: This is where diversity comes into play. Dif-\\nferent algorithms, each with its unique task, run side by side \\nin parallel. Think of it as an orchestra where each instru-\\nment plays a different part, but together they create a har -\\nmonious melody.\\n• Embarrassingly parallelism: The name might sound quirky, \\nbut it’s quite straightforward. These are computations that \\ncan be effortlessly split into subproblems, each of which can \\nbe independently tackled on separate computing resources. \\nIt’s akin to a puzzle, where each piece can be worked on by \\ndifferent individuals without any overlap.\\nHowever, it’s essential to note that not every algorithm is \\nsuited for parallelism. T ake, for instance, Dijkstra’s algorithm— a \\nsequential algorithm. It’s a masterful graph search method that \\npinpoints the shortest path in a graph with non-negative edge \\npath costs, culminating in a shortest path tree. Its sequential \\nnature means it follows a set path, step by step, much like follow-\\ning a single recipe from start to finish.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 264, 'page_label': '251'}, page_content='Generative AI’s Exponential Growth 251\\nOn the flip side, consider matrix multiplication— a shining \\nexample of a parallel algorithm. Here, matrices are fragmented \\ninto smaller chunks, and the multiplication of these bite-sized \\nmatrices is executed in parallel. It’s like having multiple chefs \\neach preparing a part of a dish, only to combine them at the end \\nfor the final masterpiece.\\nAnd speaking of matrix multiplication, its significance in AI, \\nespecially neural networks, is paramount. Here’s a brief rundown:\\n• Data processing: At the heart of neural networks lies matrix \\nmultiplication. As input data and weights flow through each \\nlayer, they undergo a series of matrix multiplications, much \\nlike ingredients being mixed in a specific order to cre-\\nate a dish.\\n• Backpropagation: The cornerstone of training neural net-\\nworks. This algorithm leverages matrix multiplication to \\ncompute gradients, akin to adjusting a recipe based on \\ntaste tests.\\n• Batch processing: Efficiency is key in AI training. By training \\non data batches, matrix operations streamline the process, \\nmuch like cooking in bulk for a large gathering.\\nAlphaTensor Mathematics has been laser-focused on enhanc-\\ning the performance of matrix multiplication algorithms for dec-\\nades. The ultimate goal? Achieving maximum efficiency with the \\nfewest steps or operations.\\nEnter AlphaT ensor, a groundbreaking AI system birthed by \\nthe brilliant minds at Google DeepMind. This isn’t just any AI— \\nit’s a system that can unearth innovative, efficient, and most \\nimportantly, provably correct algorithms for foundational tasks, \\nwith matrix multiplication being a prime example.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 265, 'page_label': '252'}, page_content='252 GENERATIVE AI\\nWhat makes AlphaT ensor truly stand out is its lineage. It’s \\nbuilt upon the shoulders of giants, specifically AlphaZero— an AI \\nprodigy that has demonstrated unparalleled prowess in board \\ngames. But DeepMind didn’t stop there. They embarked on a \\njourney to transition AlphaZero from mastering games to \\naddressing unsolved mathematical conundrums for the very \\nfirst time.\\nUnder the guidance of AlphaT ensor, algorithms surpassing \\nthe efficiency of existing state-of-the-art solutions were unveiled \\nfor a wide range of matrix sizes. But how did they achieve this \\nmonumental feat?\\nDeepMind ingeniously transformed the challenge of pin-\\npointing efficient matrix multiplication algorithms into a single-\\nplayer game. But this wasn’t any ordinary game— it was a \\nHerculean task. T o put it into perspective, the sheer number of \\npotential algorithms to explore surpasses the total number of \\natoms in the universe, even for rudimentary matrix multiplica-\\ntion scenarios.\\nUndeterred, AlphaT ensor was trained using the power of \\nreinforcement learning to master this game. It began its journey \\ndevoid of any prior knowledge about existing matrix multiplica-\\ntion algorithms. Through continuous learning and adaptation, \\nAlphaT ensor not only reacquainted itself with historic rapid \\nmatrix multiplication algorithms like Strassen’s but also ventured \\nbeyond human comprehension, unveiling algorithms swifter \\nthan any known before. The sheer diversity of algorithms it \\ndiscovered— thousands for each matrix size— revealed a previ-\\nously uncharted depth in the realm of matrix multiplication \\nalgorithms. A revelation, to say the least.\\nAlphaT ensor’s prowess didn’t stop there. It showcased tangi-\\nble improvements in matrix multiplication algorithms, especially \\ntailored for specific scenarios and matrix dimensions. For instance,'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 266, 'page_label': '253'}, page_content='Generative AI’s Exponential Growth 253\\nit unveiled an algorithm adept at multiplying a 4×5\\xa0matrix with a \\n5×5\\xa0matrix, requiring a mere 76\\xa0multiplications. This was a sig-\\nnificant leap from a preceding algorithm that demanded 80\\xa0mul-\\ntiplications. When you scale this up to larger matrices, the \\ndifference becomes even more pronounced— roughly a 5 percent \\nreduction in calculations for each matrix multiplication.\\nAlphaT ensor’s adaptability extends beyond speed, optimizing \\nfactors like energy use and stability, crucial for algorithmic accu-\\nracy. DeepMind’s work with AlphaT ensor and AlphaZero high-\\nlights AI’s potential in addressing major scientific and \\nmathematical challenges, foreseeing AI as a key tool in advancing \\nhuman knowledge.\\nParallel Processing Libraries: CUDA T o harness the full \\npotential of parallel processing units at the hardware level and \\nimplement parallel algorithms optimally and uniquely for spe-\\ncific applications, a myriad of tools and libraries have been devel-\\noped. One such dominant tool is CUDA by NVIDIA, specifically \\ntailored for NVIDIA products. Let’s zoom in on CUDA.\\nCUDA, which stands for Compute Unified Device Architec-\\nture, is a parallel computing platform and programming model \\nbirthed by NVIDIA. It’s not just a tool; it’s a revolution, empow-\\nering developers to harness NVIDIA ’s GPUs for tasks beyond \\njust graphics. The essence of CUDA lies in its ability to let devel-\\nopers write programs that exploit GPUs’ parallel processing \\nstrengths effectively.\\nFrom researchers to developers, from startups to tech giants, \\nCUDA has found its way into ML projects, scientific simula-\\ntions, image processing, video enhancements, and so much more. \\nIt’s not just a platform; it’s the bedrock for leveraging the sheer \\ncomputational might of GPUs across diverse sectors.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 267, 'page_label': '254'}, page_content='254 GENERATIVE AI\\nHowever, parallel computing isn’t limited to CUDA; alterna-\\ntives like OpenCL offer cross-platform programming capabili-\\nties, while OpenGL excels in graphics rendering and can be used \\nfor general-purpose GPU programming, indicating a diverse \\nparallel computing landscape.\\nThe Improvement of\\xa0 Programming Languages Pivoting \\nto the software realm, let’s shine a spotlight on programming \\nlanguages. And here’s the headline: Python reigns supreme. Not \\nnecessarily for its computational prowess, but for the sheer con-\\nvenience it offers in coding and building, especially when navi-\\ngating the waters of data science and AI. Its vast library ecosystem \\nis a treasure trove for developers. But before we dive deeper into \\nPython, let’s take a brief historical detour. The first high-level \\nprogramming language made its debut in 1957, courtesy of IBM, \\nand was christened Fortran. However, not all high-level lan-\\nguages have stood the test of time, especially when we narrow \\nour lens to data wrangling, data science, AI, and model \\ndevelopment.\\nT racing the lineage of programming languages in the context \\nof data and AI, the chronology unfolds as follows:\\nR Born in 1993, R saw its heyday in the early 2000s, tailored \\nspecifically for statistical computing. Its vast array of statistical \\nand graphical techniques made it a favorite for data wrangling \\nand exploratory data analysis.\\nPython Although Python’s inception dates back to the late \\n1980s, its meteoric rise in the data science domain began in \\nthe mid-2000s. Its trifecta of simplicity, readability, and versa-\\ntility has made it an indispensable tool for data wrangling, ML, \\nand AI model development.\\nSQL A relic from the 1970s, SQL (Structured Query Language) \\nremains a cornerstone for managing relational databases. It’s the'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 268, 'page_label': '255'}, page_content='Generative AI’s Exponential Growth 255\\nunsung hero behind efficient data wrangling and querying, ena-\\nbling seamless data extraction and transformation.\\nJava Java’s strength lies in enterprise applications, including \\ndata processing and analytics. While it might not share the \\nlimelight with Python or R in data science, its prowess in \\nbuilding scalable systems for Big Data processing is undeniable.\\nJulia A newcomer, Julia surfaced in 2012, aiming to bridge the \\ngap between the performance of low-level languages and the \\nuser-friendliness of high-level counterparts. Its rapid compu-\\ntations and expressiveness have garnered attention, especially \\nfor numerical tasks.\\nWhile these five languages have etched their marks, the pro-\\ngramming world is vast, with many more languages like Scala, C/\\nC++, JavaScript, Swift, Go, MATLAB, and SAS, each carving its \\nniche. The evolution of these languages, especially in the realms \\nof data wrangling, data science, AI, and machine learning, is a \\ntestament to the ever-growing need for tools that are both effi-\\ncient and expressive.\\nNew Programming Languages and User-Friendly Libraries  \\nEven established languages like Python and R are being chal-\\nlenged by newcomers. Enter Mojo, the latest offering from \\nModular Inc.\\nMojo is designed to blend Python’s simplicity with C’s per -\\nformance, targeting AI developers. Its potential is evident in sev-\\neral key areas:\\n• Unparalleled speed: Chris Lattner, Modular’s CEO and the \\nmind behind Swift, claims that Mojo can outperform Python \\nby up to 35,000 times in tasks like deep neural network \\ntraining. This speed is attributed to the LL VM compiler'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 269, 'page_label': '256'}, page_content='256 GENERATIVE AI\\ntoolchain and the innovative multilevel intermediate repre-\\nsentation (MILR) compiler setup.\\n• Python integration: Mojo seamlessly integrates with the \\nPython ecosystem, allowing developers to utilize existing \\nPython libraries. This compatibility ensures a smooth tran-\\nsition from Python to Mojo, capitalizing on perfor -\\nmance boosts.\\n• Memory safety: Mojo prioritizes memory safety, addressing \\npotential vulnerabilities. This focus ensures enhanced stabil-\\nity and security in AI applications.\\n• User-friendly design: Mojo adopts a Python-like syntax, sim-\\nplifying the learning process for developers and reducing \\nthe challenges of mastering a new language.\\nMojo, with its high performance and user-friendly design, is \\nset to revolutionize AI, making it more accessible and innovative. \\nLibraries like T ensorFlow, PyT orch, and Keras have already \\ndemocratized AI by offering easy-to-use interfaces for all skill \\nlevels, lowering the entry barrier and providing both high-level \\nfunctions and customization options.\\nThe beauty of these libraries lies in their abstraction. T ensor-\\nFlow, PyT orch, Keras, and LangChain have transformed the AI \\ndevelopment landscape, encapsulating the intricacies of founda-\\ntional algorithms within their user-friendly frameworks. This \\nabstraction empowers developers, even those who might not be \\nwell versed in the labyrinthine depths of mathematical computa-\\ntions or intricate coding paradigms, to architect, nurture, and \\nroll out AI models with an unprecedented ease.\\nOne of the standout features of these libraries is their reper-\\ntoire of preconfigured functions. They come equipped with a \\nsuite of ready-to-use tools tailored for routine tasks— be it \\norchestrating neural network configurations, calibrating loss \\n.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 270, 'page_label': '257'}, page_content='Generative AI’s Exponential Growth 257\\nfunctions, or orchestrating optimization strategies. This not only \\ntrims down the coding overhead but also accelerates the devel-\\nopmental trajectory and minimizes potential pitfalls.\\nThe trajectory of these libraries appears promising. Their \\nevolution is likely to be marked by enhanced user-centricity and \\naugmented capabilities. The AI community might witness the \\nemergence of niche libraries, each honed for distinct AI subdo-\\nmains such as reinforcement learning or nuanced facets of natu-\\nral language processing. A notable trend on the horizon could be \\nthe proliferation of prompt-driven interfaces, suggesting a para-\\ndigm shift toward AI assistants as an integral overlay.\\nFurthermore, the open source ethos underpinning most of \\nthese libraries is a boon for developers. It fosters a vibrant, col-\\nlaborative ecosystem where knowledge dissemination is organic. \\nDevelopers can tap into this reservoir of collective wisdom, trou-\\nbleshoot common challenges, and even play an active role in the \\nlibrary’s evolutionary journey.\\nThe Open Source Movement The open source realm is \\narguably the most potent catalyst for AI advancement. There’s \\nscarcely an active open source community as vast and vibrant as \\nthe one orbiting AI. This dynamism not only propels the soft-\\nware layer to peak performance but also broadens its reach, mak-\\ning it effortlessly comprehensible for many.\\nThis open source wave in AI is a beacon for knowledge dis-\\nsemination and collective effort. It paves the way for swift con-\\nceptual iterations, rigorous algorithmic testing, and rapid \\npropagation of AI breakthroughs. Open source ventures have \\nbeen the bedrock of technological evolution for years, steering \\ninnovation and fostering collaboration in unparalleled ways. \\nThese communities are a melting pot of diverse perspectives, \\namalgamating varied backgrounds to craft solutions that are'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 271, 'page_label': '258'}, page_content='258 GENERATIVE AI\\ninventive and inclusive— crucial for unbiased, equitable AI. They \\nare hubs for knowledge sharing, where developers exchange \\ninsights, propagate best practices, and jointly elevate their AI and \\nML acumen.\\nWhen these projects gain momentum and resonate with the \\nmarket, their reliability often surpasses proprietary counterparts. \\nThis is attributed to the sheer volume of developers scrutinizing \\nand fine-tuning the code, resulting in top-tier, resilient AI and \\nML models. Furthermore, these communities dismantle the tra-\\nditional barriers to entry in AI and ML. They usher in an era \\nwhere anyone can partake, assimilate, and harness the vast \\nresources at hand.\\nAt the heart of it all, projects fueled by intrinsic motivation— \\nthose birthed from passion— often outshine those driven by \\nexternal incentives, such as monetary gains.\\nA testament to the prowess of open source AI initia-\\ntives includes:\\n• OpenCV: A library dedicated to computer vision and ML, \\noffering a plethora of algorithms and tools for image pro-\\ncessing, object detection, and beyond.\\n• Hugging Face Transformers: A library that furnishes cutting-\\nedge natural language processing models and utilities, \\nequipped with preconfigured models tailored for tasks like \\ntext categorization and language translation.\\nEnvision a world where the democratization of AI and ML \\nassets becomes the great equalizer in the technological realm. \\nSuch a shift promises that every individual, regardless of their \\nbackground or resources, can dive into these fields, make mean-\\ningful contributions, and utilize them to tackle urgent global \\nissues. This transformation could spark a golden age of innova-\\ntion, spawning a myriad of AI and ML solutions attuned to a \\nwide array of societal needs.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 272, 'page_label': '259'}, page_content='Generative AI’s Exponential Growth 259\\nAdvanced AI Architectures and AI Models It’s evident that \\nAI architectures are evolving to be sharper, more intelligent, and \\nimmensely potent. Their growth trajectory has been nothing \\nshort of exponential, a trend prominently showcased with the \\nrelease of models like ChatGPT . The AI landscape is in a state of \\nperpetual flux, with research teams globally making strides daily, \\neach enhancement pushing the boundaries of what’s possible.\\nT ake, for instance, the realm of T ransformer models. Their \\ncapabilities have been on a steady incline, and a prime example of \\nthis evolution is Llama 2 by Meta. Llama 2 stands out in the \\ncrowded AI space for several compelling reasons. Not only is it \\nopen source, paving the way for both academic research and \\ncommercial endeavors, but its availability also promises to invig-\\norate the AI model market, spurring further innovation.\\nWhat sets Llama 2 apart is its enhanced training data— \\nboasting a 40 percent increase compared to its predecessor, \\nLlama 1. This enhancement translates to a notable uptick in per-\\nformance. But perhaps its most intriguing aspect is its scalability. \\nWhile one might anticipate a behemoth model with upwards of \\n700 billion parameters, Llama 2 astounds with its most potent \\nvariant having a mere 70 billion parameters. This shift toward \\ncompact yet effective models underscores the dual themes of \\nopen source power and global research-driven incremental \\nadvancements.\\nBut the story doesn’t end there. Meta has forged alliances with \\ntech giants like Microsoft and leading chipmaker Qualcomm. This \\ncollaboration aims to embed Llama 2\\xa0within Snapdragon proces-\\nsors, hinting at its integration in top-tier smartphones very soon. \\nFurthermore, Llama 2\\xa0has been fine-tuned to operate seamlessly \\non platforms like Microsoft Azure, Amazon Web Services (AWS), \\nand Hugging Face. Such partnerships are poised to broaden Llama \\n2’s footprint in AI development, ushering in novel AI experiences \\nfor end users.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 273, 'page_label': '260'}, page_content='260 GENERATIVE AI\\nLiquid Neural Networks and AutoML Y et, beyond the \\nfamiliar terrains of conventional AI architectures, there are bur-\\ngeoning paradigms that are reshaping the AI landscape. T ake liq-\\nuid neural networks (LNNs) as an example.\\nLNNs, a brainchild of the brilliant minds at MIT’s Com-\\nputer Science and Artificial Intelligence Laboratory (CSAIL), \\nrepresent a fresh wave in deep learning architectures. These are \\ntime-continuous recurrent neural networks (RNNs) that metic-\\nulously process data in a sequential manner, retaining memories \\nof prior inputs. The magic of LNNs stems from their ingenious \\nutilization of dynamically modifiable differential equations. This \\nunique feature equips them with the prowess to recalibrate and \\nadapt to novel scenarios post-training. Unlike their traditional \\ncounterparts, LNNs possess the agility to tweak their founda-\\ntional equations based on incoming data, specifically modulating \\nthe responsiveness of neurons. This inherent adaptability ren-\\nders LNNs exceptionally resilient to data anomalies or unfore-\\nseen inputs. An added feather in their cap is their enhanced \\ninterpretability, as tracing their decision-making pathways within \\nthe network becomes significantly more straightforward.\\nT o distill it down: LNNs undergo initial training on data, but \\ntheir true prowess shines when they continually refine their \\nweights upon interacting with real-world data, enhancing their \\nperformance post-training.\\nTheir potential has been demonstrated in arenas where con-\\nventional deep learning models often falter, such as in the \\ndomains of robotics and autonomous vehicles. A testament to \\ntheir capabilities is the research from MIT , where drones, pow-\\nered by a compact 20,000-parameter (!) LNN model, showcased \\nsuperior navigational acumen in unfamiliar terrains compared to \\nother neural networks. Such prowess hints at their potential in \\nsculpting more precise autonomous vehicular systems.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 274, 'page_label': '261'}, page_content='Generative AI’s Exponential Growth 261\\nHowever, like all innovations, LNNs come with their set of \\nchallenges— the vanishing gradient conundrum and a nascent \\nbody of literature detailing their implementation and advantages, \\nto name a few. The academic community is fervently addressing \\nthese hurdles, curating more intricate tasks to gauge LNNs’ mettle.\\nLooking ahead, LNNs hold the promise of catalyzing \\ngroundbreaking strides in AI, especially in sectors where tradi-\\ntional models often hit roadblocks. Their adaptability, coupled \\nwith heightened interpretability, could pave the way for sturdier \\nand more efficient AI constructs. As the research tapestry around \\nLNNs expands, we’re poised to witness a surge in their applica-\\ntions and breakthroughs.\\nOn another front, the realm of AI development is witnessing \\na paradigm shift with the rise of AutoML. These tools are revo-\\nlutionizing the ML landscape by automating facets of the ML \\nprocess (see Figure\\xa04.5).\\nFIGURE\\xa0 4.5 The AutoML workflow: an overview of automated ML’s \\nend-to-end process, highlighting key subtasks from data preprocess-\\ning to model evaluation, encapsulated within the dotted-line box.\\nSource: Treasure Data, Inc. / https://docs.treasuredata.com/display/public/PD/AutoML / \\nlast accessed December 04, 2023.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 275, 'page_label': '262'}, page_content='262 GENERATIVE AI\\nAutoML encompasses a spectrum of techniques, ranging \\nfrom hyperparameter optimization to meta-learning and neural \\narchitecture exploration. While hyperparameter optimization is \\nall about the automated hunt for the optimal hyperparameter \\ncocktail for specific ML algorithms, meta-learning is the art of \\ngleaning insights from prior modeling endeavors to streamline \\nfuture projects. Neural architecture exploration, on the other \\nhand, is a deep dive into the myriad neural network blueprints, \\nseeking the ideal fit for specific challenges.\\nAutoML is a significant step forward in AI. It speeds up \\ndevelopment and makes AI more user friendly, even for those not \\ndeeply familiar with it.\\nAI-Powered Development Assistants But the real break-\\nthrough in fast and efficient AI development is AI-powered cod-\\ning assistants.\\nT ools like GitHub Copilot and ChatGPT are changing how \\nwe develop software. They use ML to give instant coding help, \\nhandle repetitive tasks, and even create code snippets. They learn \\nfrom the vast amount of code online, giving relevant suggestions \\nthat speed up coding and reduce errors.\\nFrom my work leading AI projects in Europe for Infosys \\nConsulting, I handle many projects at once. Each one needs dif-\\nferent attention at different times. But there are two tools  \\nI always insist my teams use.\\nFirst, every team member should always have ChatGPT \\nPlus, a top-tier language model, open. It’s essential. It helps gen-\\nerate code, reviews and improves existing code, and assists in \\ndocumenting and commenting. It speeds up problem solving, \\nhelping teams work faster. But it’s crucial to ensure that no pri-\\nvate code is shared with ChatGPT to protect it from being \\naccessed by OpenAI or others.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 276, 'page_label': '263'}, page_content='Generative AI’s Exponential Growth 263\\nSecond, GitHub Copilot is a must-have. It works smoothly \\nwith Visual Studio Code. And with an easy setup and a monthly \\nfee, it keeps an eye on your code and suggests improvements as \\nyou go (see Figure\\xa04.6).\\nBy now, not using GitHub Copilot or ChatGPT is like try-\\ning to work without a laptop. These tools enhance skills and \\nboost productivity. Ignoring them is a big mistake.\\nGenerative AI is not just advancing; it’s self-evolving. By \\nusing generative AI to enhance and create new generative AI \\nmodels, we can say that this technology is fueling its own \\nbreakthroughs.\\nEach stride in this domain signifies a leap, even if a small one, \\nin AI software development. Collectively, these advancements \\nare driving the rapid and exponential growth of AI and ML. \\nWhile this overview isn’t comprehensive, it underscores the \\nrelentless pace of AI model evolution.\\nFIGURE\\xa04.6 GitHub Copilot at work: seamlessly providing Python code \\nsuggestions to enhance developer productivity and streamline \\ncoding tasks.\\nSource: GitHub, Inc /https://github.com/features/copilot / last accessed  \\nDecember 01, 2023.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 277, 'page_label': '264'}, page_content='264 GENERATIVE AI\\nExponential Growth in\\xa0Data\\nData is the foundation of AI. Because data grows rapidly, it’s \\nimportant to understand how much is expected to be produced, \\nwhether it’s real or artificially created.\\nScaling AI with Big Data\\nAt the heart of this topic is Big Data. This refers to huge amounts \\nof data that are too large for regular data tools to handle. This \\ndata can be structured well organized, semi-structured (a mix, \\nlike emails), or unstructured (messy, like tweets).\\nBig Data is crucial today. It’s the main source for modern AI \\nsystems, providing the information for ML to get better. By study-\\ning Big Data, we can see patterns and trends, especially about how \\npeople behave. This information is very valuable for many, from \\nbusinesses to researchers. It helps in improving ads, giving person-\\nalized suggestions, predicting trends, and spotting fraud.\\nData is key for training AI. It gives AI the information it \\nneeds to learn, make predictions, and get better. Some AI mod-\\nels, as mentioned before, are becoming slightly less data-hungry \\nbecause they’re getting smaller or changing in design, like the \\nliquid neural networks.\\nHowever, the need for data is still growing. We expect to see \\nmany more AI models for different tasks in the future. Some will \\nbe specific, and some will be broad. The more data we have, the \\nmore problems AI can solve. The more detailed the data, the \\nmore specific the solution will be.\\nLastly, remembering the Chinchilla scaling laws, it’s impor-\\ntant to note that as some AI models get bigger, they need signifi-\\ncantly more data to scale their performance according to \\ntheir size.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 278, 'page_label': '265'}, page_content='Generative AI’s Exponential Growth 265\\nData Growth Today\\nEvery day, we’re creating an immense 328.77\\xa0million terabytes \\nof data. If you’re trying to visualize this, Figure\\xa04.7 might help \\nput things into perspective. Fast-forward a bit, and projections \\nshow that by 2025, this number is expected to rise to approxi-\\nmately 181 zettabytes per year. \\nT o truly grasp the magnitude of this growth, think about this: \\nin 2025, we’ll have about 90 times more data than what was avail-\\nable in 2010. And if we extend our gaze to 2030, using an expo-\\nnential growth model, the anticipated data explosion is simply \\nmind-blowing (see Figure\\xa04.8 and Figure\\xa04.9). The numbers are \\nset to overshadow all previous data generation rates. By 2030, \\nwe’re looking at a world that’s expected to produce a colossal \\n597.10 zettabytes of data. T o put that into context, that’s almost \\n300 times the total amount of data that had been generated from \\nthe start of human history up until 2010.\\nFIGURE\\xa04.7 Digital storage units, from bytes to zettabytes.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 279, 'page_label': '266'}, page_content='266 GENERATIVE AI\\nFitted Exponential Model until 2022\\n175\\n150\\n125\\n100\\n75\\n50\\n2010 2012 2014 2016 2018\\nYear\\n2020 2022 2024\\n25\\n0\\nGlobal Data Generated Annually\\nFitted Exponential Model from 2023\\nActual Data until 2022\\nPredicted Data from 2023\\nData Size (Zettabytes)\\nFIGURE\\xa0 4.8 Annual global data generation: Historical trends and  \\nprojections through 2025.\\n2010\\n600\\n500\\n400\\n300\\n200\\n100\\n0\\n2012 2014 2016 2018\\nYear\\n2020 2022 2024 2026 2028 2030\\nData Size (Zettabytes)\\nGlobal Data Generated Annually\\nFitted Exponential Model until 2022\\nFitted Exponential Model from 2023\\nActual Data until 2022\\nPredicted Data from 2023\\nPredictions for 2026-2030\\nFIGURE\\xa0 4.9 Annual global data generation: Historical trends and  \\nprojections through 2030.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 280, 'page_label': '267'}, page_content='Generative AI’s Exponential Growth 267\\nThe Data Growth Drivers\\nDiving deeper into the vast ocean of data, some intriguing figures \\nemerge from reputable online sources like Statista. For instance, \\nvideos dominate Internet data traffic, accounting for a significant \\n53.72 percent in 2023. Every minute, a staggering 231.4\\xa0million \\nemails are dispatched, totaling around 333.22 billion daily. In the \\nrealm of cryptocurrency, we’re seeing millions of purchases daily. \\nOn the social front, Snapchat users share approximately \\n2.43\\xa0 million snaps every minute, which translates to about 3.5 \\n billion snaps daily. The world of online dating isn’t far behind, \\nwith Tinder witnessing around 1.1\\xa0million swipes every minute, \\nor about 1.58 billion daily. In the entertainment sector, about \\n1\\xa0 million hours of content are streamed per minute, amounting to \\nroughly 1.44 billion hours daily. The corporate world, too, is buzz-\\ning, with around 104,600 hours spent in Zoom meetings every \\nminute, leading to a daily total of about 150.62\\xa0million hours.\\nBut what’s fueling these numbers?\\nIoT devices, now ubiquitous in both our homes and work-\\nplaces, constantly churn out data. From smart refrigerators to \\nintricate industrial sensors, the data they produce is harnessed \\nfor diverse applications, including refining device performance, \\npreemptive maintenance, and analyzing user patterns. As their \\nnumbers swell, so does the data they spawn.\\nThe ubiquity of smartphones and similar gadgets has also \\nplayed a pivotal role in this data surge. Every app used, web page \\nbrowsed, or location accessed contributes to this ever-growing \\ndata pool. Social media platforms, with their billions of global \\nusers, are significant data generators. Every post, like, share, or \\ncomment on platforms like Facebook, T witter, Instagram, and \\nY ouT ube adds to this digital deluge. Their primary use of this \\ndata? T ailored advertising and enhancing user experience.\\nStreaming giants like Netflix and Spotify have altered our \\nmedia consumption habits. They meticulously record our'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 281, 'page_label': '268'}, page_content='268 GENERATIVE AI\\npreferences, using this data to suggest content and discern \\nbroader trends. Their soaring popularity, combined with the \\nburgeoning digital content, inevitably leads to more data.\\nThe pivot to cloud computing has seen businesses shifting \\ntheir operations and storage, leading to more efficient data han-\\ndling but also more data creation. The e-commerce boom, fur -\\nther propelled by the COVID-19 pandemic, sees platforms \\ngathering data on user behaviors, tastes, and buying patterns, \\nusing it for personalized marketing and demand prediction.\\nOther sectors, including academia, healthcare, and more, \\nalso contribute to this data proliferation. But towering above all \\nthese drivers is the realm of AI and ML. These technologies \\nthrive on vast data volumes for training and validation, leading to \\nthe creation of both authentic and synthetic data. Especially in \\nareas like natural language processing, AI can produce new con-\\ntent, further amplifying data growth.\\nIn essence, these myriad factors collectively fuel the data \\nexplosion we’re witnessing today.\\nSynthetic Data\\nAs the number of AI models multiplies, so does the volume of \\ndata they produce. This newly minted data then becomes a \\nresource for training even larger and more efficient AI models.\\nGartner, in a detailed report on synthetic data, forecasted a \\nfuture where the majority of data fueling AI by 2030\\xa0would be \\ncrafted artificially (Figure\\xa04.10). This could be through rule-\\nbased systems, statistical models, simulations, or other innova-\\ntive techniques. The report emphasized, “Building high-quality, \\nvaluable AI models will be nearly impossible without the inclu-\\nsion of synthetic data.”\\nSo, why is synthetic data gaining such prominence? The \\nanswer lies in its inherent advantages. Synthetic data champions \\nboth privacy and scalability. It paves the way for swift expansion'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 282, 'page_label': '269'}, page_content='Generative AI’s Exponential Growth 269\\nof data-driven products, eliminating the cumbersome processes \\ntypically associated with data collection. Moreover, since it’s arti-\\nficially generated, it sidesteps the privacy pitfalls that often ham-\\nper the utilization of traditional datasets.\\nIn essence, synthetic data promises to be the bridge connect-\\ning the vast reservoirs of real-world data with their practical \\napplications in data-centric products. It promises quicker prod-\\nuct launches, slashes both the costs and time frames of data col-\\nlection, and ensures the confidentiality of sensitive information.\\nExponentially Cheaper Data Storage\\nOne big change is how much cheaper data storage has become. \\nThis isn’t just by chance. Several key reasons are:\\n• T ech improvements: New tools and technologies, like NAND \\nflash-based solid-state drives (SSDs), zoned namespace \\nSSDs, and storage-class memory, have made storage devices \\n-  Artificially generated data\\n-  Generated from simple rules,\\n   statistical modeling, simulation,\\nand other techniques\\n-  Obtained from direct\\n   measurements\\n-  Constrained by cost,\\n   logistics, privacy reasons\\n2020 2030\\nFuture AI\\nToday’s AI\\nSYNTHETIC DATA\\nData used for AI\\nREAL DATA\\nFIGURE\\xa04.10 Evolution of real vs. synthetic data ratios over time.\\nSource: https://htecgroup.com/could-synthetic-data-be-the-future-for-machine- \\nlearning-models and Gartner, “Maverick Research: Forget about Your Real Data\\xa0–  \\nSynthetic Data Is the Future of AI”\\xa0– 24\\xa0June 2021'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 283, 'page_label': '270'}, page_content='270 GENERATIVE AI\\nbetter and more spacious. This means lower costs for \\nstoring data.\\n• Economies of scale: As more people need data storage, it’s \\ncheaper to make in large quantities. Big cloud and datacenter \\ncompanies can also offer cheaper storage because of their \\nsize and focus.\\n• Competition: Many companies are in the data storage busi-\\nness, and they’re all trying to offer the best prices to get \\nmore customers. This competition leads to better prices \\nfor everyone.\\n• Cloud storage: More companies are using cloud providers or \\ncolocation services for their data storage. This can be cheaper \\nthan having their own datacenters. Cloud providers can \\noffer good prices because they serve many customers and \\nspread out the costs.\\nIn short, the plummeting costs of data storage can be attrib-\\nuted to technological prowess, surging demand, fierce competi-\\ntion, and the ascent of cloud storage. But this is just the tip of \\nthe iceberg.\\nTrends in\\xa0Data\\nThe data revolution is not merely confined to storage costs. As \\nhighlighted before, there’s a burgeoning reservoir of data that’s \\nfueling the enhancement of AI models, pushing the boundaries \\nof their performance and accuracy, especially when compared to \\nthe earlier Chinchilla models. The fascinating aspect is that AI is \\nnot just a beneficiary of this data deluge but also a catalyst. AI is \\nnow in a position to aid its own evolution by generating the very \\ndata it thrives on.\\nY et, several undercurrents are shaping the future of data, \\ntrends that haven’t been fully explored. Among these are the'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 284, 'page_label': '271'}, page_content='Generative AI’s Exponential Growth 271\\nemergence of edge computing, advancements in wireless tech-\\nnology like 5G, and the dawn of quantum computing.\\nEdge computing, a paradigm shift in data processing, is rede-\\nfining the norms. By positioning computation and data storage \\nproximate to data sources, it optimizes response times and con-\\nserves bandwidth. This approach is a game-changer, amplifying \\ndata growth by facilitating real-time analytics, catalyzing the \\nexpansion of the IoT , and ushering in a new era of instantaneous \\napplications and services.\\nThen there’s 5G, the latest iteration in wireless technology, \\npromising swifter data transfers, diminished latency, and robust \\nconnections. The ripple effects of 5G on data growth will be \\nprofound. Its rapid transfer rates mean data is churned out and \\nprocessed at breakneck speeds. The technology’s capacity to \\ntether a multitude of devices concurrently amplifies the IoT’s \\nfootprint, leading to a surge in data creation. Moreover, 5G’s \\nrobustness paves the way for data-hungry applications, from \\nreal-time analytics to self-driving cars and immersive AR and \\nvirtual reality (VR) experiences.\\nFor perspective, while using L TE (a 4G variant) on a smart-\\nphone, we might experience peak download speeds of 1.5\\xa0Gbps. \\nIn contrast, 5G promises a staggering 10\\xa0Gbps. But the real spec-\\ntacle is the anticipated 6G, with speeds that could touch a mind-\\nboggling 1 Tbps or 1,000\\xa0Gbps. This translates to an exponential \\nleap, with 6G projected to be a hundredfold faster than 5G. \\nImagine downloading content equivalent to 142 hours in a mere \\nsecond! Industry insiders are buzzing with anticipation, predict-\\ning 6G’s commercial rollout around 2030.\\nHowever, a word of caution is in order. While these figures \\nare impressive, real-world download speeds can often be a far cry \\nfrom these theoretical maxima. Factors such as the service pro-\\nvider, network conditions, contractual terms, and even signal \\nstrength can temper these speeds.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 285, 'page_label': '272'}, page_content='272 GENERATIVE AI\\nExponential Patterns in\\xa0Research, Development, \\nand Financial Allocations\\nThe evolution in AI is driven by advanced ML algorithms, an \\nopen source culture, and a suite of tools and libraries that stream-\\nline AI development. Key to this progress is substantial invest-\\nment in AI research from both private and public sectors, enabling \\npractical applications. The emergence of GenAI demonstrates \\nreal-world value. Additionally, the influx of talented researchers \\nand accessible training materials democratizes AI knowledge, \\nfostering potential breakthroughs from around the world. This \\nblend of research, development, and funding is crucial for AI’s \\nintegration into everyday life.\\nInvestments in AI Research\\nAI giants like Runway ML, Hugging Face, Anthropic, OpenAI, \\nand Google DeepMind have seen their valuations skyrocket, \\nhighlighting the growing investments in this sector. A closer look \\nat the trends shows a clear rise in AI funding over the years. \\nWhile global politics and economic shifts can influence these \\ninvestments, the overall trend points to a rapid increase in AI \\nfunding, suggesting exponential growth.\\nIn 2022, AI startups attracted a whopping $52.1 billion in \\ninvestments across 3,198 companies. Notably, generative AI pro-\\njects secured $4.5 billion of this funding, as reported by Pitch-\\nBook. The momentum continued into the first half of 2023, with \\ngenerative AI companies globally receiving around $15.2 billion, \\nunderscoring the rising interest in this AI niche— if niche is even \\nthe right term by now.\\nHere are some standout investments from the past 18\\xa0months, \\nas of this writing:\\n• Anthropic: Anthropic recently secured $450\\xa0 million in a \\nSeries C funding round. Spark Capital led the investment,'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 286, 'page_label': '273'}, page_content='Generative AI’s Exponential Growth 273\\nwith significant contributions from Google, Salesforce Ven-\\ntures, Sound Ventures, Zoom Ventures, and other notable \\ninvestors. Google alone invested $300\\xa0million, as Anthropic \\nworks on a competitor to OpenAI’s ChatGPT .\\n• Inflection AI: Inflection AI recently secured $1.3 billion in \\nfunding in the latest funding round. This round was spear -\\nheaded by notable investors including Microsoft, Reid Hoff-\\nman, Bill Gates, Eric Schmidt, and NVIDIA. This investment \\nhas catapulted the valuation of the one-year-old startup to \\n$4 billion. The funds are earmarked for the enhancement of \\nInflection AI’s personal AI assistant, “Pi”, and for construct-\\ning a 22,000-unit NVIDIA H100 T ensor GPU cluster, \\ntouted as the world’s largest.\\n• Cohere: Cohere recently secured $270\\xa0million in a Series C \\nfunding round. Inovia Capital spearheaded the round, joined \\nby notable investors such as NVIDIA, Oracle, Salesforce \\nVentures, DTCP , SentinelOne, Mirae Asset, Schroders Cap-\\nital, Thomvest Ventures, and Index Ventures. Announced in \\nJune 2023, this investment boosted the valuation of the \\nT oronto-based AI startup to $2.2 billion.\\nThe AI sector is experiencing a surge in investments, particu-\\nlarly in generative AI technology. Key players include Salesforce \\nVentures, which recently increased its Generative AI Fund to \\n$500\\xa0million, and SoftBank Group, with its massive Vision Funds \\ntotaling $154 billion. Additionally, the AI seed investment land-\\nscape features over 4,000 entities, including prominent firms like \\nGeneral Catalyst, NFX, and LAUNCH. Venture capital heavy-\\nweights such as Andreessen Horowitz, Sequoia, Khosla Ventures, \\nand Greylock Partners are also actively investing in generative \\nAI startups, among many others.\\nDespite all investments and attention, amidst the buzz, a \\nchorus of skepticism is growing increasingly audible.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 287, 'page_label': '274'}, page_content='274 GENERATIVE AI\\nBeing a nascent technology, there’s a tangible risk of its \\npotential being blown out of proportion. Investors, eager to jump \\non the bandwagon, might pour money into generative AI ven-\\ntures without a clear grasp of the tech’s intricacies or the mar -\\nket dynamics.\\nIt’s worth noting that generative AI is still finding its feet. \\nThe road ahead is rife with uncertainties about its evolution and \\neventual applications. The field is also crowded, with numerous \\nplayers vying for a piece of the pie. For startups, standing out \\namidst this fierce competition is a daunting task. Drawing a par-\\nallel, back in the 1920s and 1930s, the United States market had \\nover 2,000 car manufacturers. Y et, in a short span, this number \\ndwindled to 44. By the 1940s, the big three— Chrysler, Ford, and \\nGM— emerged as the undisputed leaders, capturing a staggering \\n90 percent of U.S. car sales.\\nFurthermore, like any powerful tool, generative AI can be a \\ndouble-edged sword. Its capabilities can be harnessed for com-\\nmendable purposes or misused with detrimental consequences. \\nThis duality brings forth pressing ethical dilemmas. As a result, \\ninvestors are urged to tread cautiously, weighing the moral impli-\\ncations before deciding where to place their bets.\\nThe Real Value of Generative AI\\nGenerative AI is different from past tech trends. Why? It’s not \\njust hype; it’s a technology that offers real value. This AI has \\nmany uses in the real world, from creating content to helping in \\nmedicine and science. And it’s attracting a lot of money and inter-\\nest because of its potential to change many industries.\\nIn this book, we’ve talked about how flexible generative AI is. \\nIt’s being used in many areas like making content, helping doc-\\ntors see inside the body, creating new drugs, and even in mate-\\nrial science.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 288, 'page_label': '275'}, page_content='Generative AI’s Exponential Growth 275\\nThis AI is already helping people work better and faster. And \\nas more people start using it, it could add trillions of dollars of \\nvalue to the world. It’s not just about changing jobs; it’s about \\nmaking them better.\\nA 2023 survey by Namecheap showed how popular genera-\\ntive AI tools are becoming. Forty percent of people said they use \\nthem every day, and 10 percent use them every month. The most \\npopular tool was ChatGPT , with 70 percent of users picking it. \\nDALL-E and Midjourney were next, with about 30 percent of \\nusers liking them.\\nBut it’s not just about how much is spent on these tools. It’s \\nalso about how they can save time and money. Generative AI \\ndoesn’t just replace people; it helps them do their jobs better. It \\ncan handle the boring tasks, letting people focus on more cre-\\native work.\\nTalent and Self-Learning in\\xa0Tech\\nThe tech and AI sectors have seen a massive surge in skilled pro-\\nfessionals in recent times. Why? Companies are updating their \\ntech systems and embracing AI, creating a huge demand for \\nexperts in these areas. Jobs linked to AI often pay well and require \\na college degree and sharp analytical skills.\\nThe competition for tech experts is heating up. There’s a big \\ndemand for roles like ML Architect and Prompt Engineers, but \\nnot enough skilled folks to fill them. We’re talking about AI \\nengineers, research scientists, data scientists, and so forth.\\nBut here’s the exciting part: A fresh wave of young profes-\\nsionals is stepping in. Some older folks might label them as lazy \\nor clueless, but I see them differently. This new generation is \\npractical, values being real, and is super diverse.\\nHere’s a fun fact: Gen Z grew up with the Internet, smart-\\nphones, and even AI as everyday things. They’re the real tech'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 289, 'page_label': '276'}, page_content='276 GENERATIVE AI\\npros! Plus, they’re setting records in education. More of them \\nare finishing high school and fewer are dropping out. In 2018, a \\ntotal of 57 percent of those aged 18 to 21\\xa0were in college. That’s \\nmore than millennials and Gen Xers when they were that age. \\nAnd guess what? Many Gen Z folks prefer trade or tech schools \\nover traditional colleges.\\nSpeaking of learning, there are so many ways to learn about \\ntech and AI now. Y ou’ve got online courses on platforms like \\nCoursera and edX. Books, like the one you’re reading right now. \\nThere are also tutorials, podcasts, and online communities like \\nQuora and Reddit. And don’t forget Y ouT ube! Channels like \\nSentdex and Deeplearning.ai share loads of AI stuff.\\nThis new generation learns fast and in their own unique \\nways. This helps them think out of the box, start their own busi-\\nnesses, team up with people worldwide, and keep up with the \\never-changing tech world. They’re definitely one step ahead \\nof the rest!\\nDiving into the realm of IT/ICT (information and commu-\\nnication technology), there’s a clear upward trend that’s hard to \\nmiss. While we might not have a single number that captures the \\nglobal AI workforce’s growth, we’ve got some pretty telling stats \\nto look at.\\nFor starters, between 2006 and 2018, the number of ICT \\nprofessionals worldwide shot up by a notable\\xa029 percent. Zoom-\\ning into the European Union, the growth is even more impres-\\nsive. From 2012 to 2022, the count of ICT specialists in the EU \\nskyrocketed by a whopping 57.8 percent. That’s nearly seven \\ntimes the growth rate of other jobs!\\nThe World Economic Forum has some big predictions too. \\nThey believe that by 2025, close to 100\\xa0million people around \\nthe world will be working in AI. Given the current momentum, \\nI’d say that number might climb even faster than we think.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 290, 'page_label': '277'}, page_content='Generative AI’s Exponential Growth 277\\nNow, let’s talk about where all these tech wizards are coming \\nfrom. Russia leads the pack with over 454,000 folks graduating in \\nengineering and similar AI-related professions every year. The \\nUnited States isn’t far behind with 237,826 graduates, followed \\nclosely by Iran and then Japan.\\nBut there’s one country that’s a real powerhouse in the tech \\nworld: India. With a tech army of over 5\\xa0million professionals \\nand a tech industry worth a cool $200 billion, India is a force to \\nbe reckoned with. I’ve had firsthand experience working with \\nIndian teams during my time at IBM consulting and later at \\nInfosys consulting. The talent, dedication, and work ethic I’ve \\nseen is truly commendable.\\nAI Research Goes Private\\nThe AI research field is increasingly leaning toward the private \\nsector, a trend offering both opportunities and challenges. From \\nmy perspective, witnessing peers from academia transition to \\nlucrative corporate roles underscores the appeal of this shift. The \\nfinancial power of private companies, exemplified by IBM’s $6.57 \\nbillion investment in research only in 2022, drives significant \\nadvancements in AI research and development.\\nBut it’s not just about the money. Private companies are \\ninherently geared toward translating AI research into tangible, \\nmarket-ready products. This not only benefits the corporate bot-\\ntom line but also enriches the consumer experience.\\nThe private sector’s agility in quickly transforming AI \\nresearch into practical applications across industries is a key \\nadvantage.\\nMoreover, the lines between academia and industry are blur-\\nring. Collaborative endeavors between private corporations and \\nacademic institutions are on the rise, fostering a symbiotic  \\nrelationship where knowledge dissemination meets resource \\nallocation.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 291, 'page_label': '278'}, page_content='278 GENERATIVE AI\\nThis pivot toward private sector–led research is a significant \\neconomic driver, birthing new job roles, stimulating economic \\ngrowth, and ensuring companies remain at the forefront of their \\nindustries. In essence, as AI R&D finds its home in the private \\nsector, it promises a future where innovation thrives, economies \\nflourish, and societies benefit.\\nRequirements for\\xa0Growth\\nDiving deep into the research, it’s evident that the AI landscape \\nis on an accelerated trajectory. The leaps in computational capa-\\nbilities, in both hardware and software, are astounding. The \\nsurge in data availability, coupled with affordable storage solu-\\ntions, further fuels this momentum. Add to this the significant \\ninvestments in R&D, the collaborative spirit of open source \\ncommunities, and the fresh perspectives brought in by Gen Z, \\nand it’s clear: we’re on the cusp of an AI revolution that promises \\nto redefine humanity’s progress.\\nThe AI-Driven Economy\\nARK Investment Management LLC’s insights offer a compelling \\nperspective on this (Figure\\xa04.11). Their analysis paints a picture \\nof how technology has historically been a catalyst for macroeco-\\nnomic growth. For context, from the dawn of civilization until \\n1900, the global real GDP growth per year hovered below 1 per-\\ncent. Fast-forward to the period between 1900 and 2021, and \\nthis figure jumped to an average of 3 percent annually. ARK’s \\nprojections, rooted in technological trends, are even more stag-\\ngering. They anticipate an annual global GDP growth of 6.1'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 292, 'page_label': '279'}, page_content='Generative AI’s Exponential Growth 279\\npercent by 2030, soaring to 10.7 percent by 2040. Annually! This \\nmeans by 2030 a theoretical jump of 42 percent, and by 2040 the \\nGDP could theoretically reach 508 percent of today. This isn’t \\njust growth; it’s a transformative shift in the global economic  \\nfabric, with AI, especially generative AI, at its heart.\\nY et, much like in the natural world, growth in the tech ecosys-\\ntem isn’t boundless and follows one trajectory. Just as biological \\nsystems have their constraints, the AI domain isn’t immune to lim-\\niting factors. Understanding what might hinder our path is crucial. \\nBy identifying and addressing these challenges, we can ensure that \\nthe technological renaissance we’re witnessing translates into tan-\\ngible benefits for humanity. In essence, these considerations aren’t \\nGlobal Real GDP* Growth\\nLog Years Until 2050**\\n8.5%\\nCompound Annual Growth Rate\\nForecast Consistent with\\nTechnological History\\nConsensus\\nForecast\\n3%\\n0.6%\\n10.00%\\n1.00%\\n0.10%\\n0.01%\\n100,000BC 11 0001 500 1900 2021 2040\\nHistorical data\\n0.3%\\n2.6%0.14%\\n0.037%\\nFIGURE\\xa0 4.11 ARK Investment Management’s projections: a tale of \\ntwo futures.\\nSource: NM Writings / A Medium Corporation / https://medium.com/coinmonks/\\nbig-ideas-2023-ark-invests-crypto-part-1-out-of-2-4a382bfe35a1 / last accessed \\nDecember 04, 2023.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 293, 'page_label': '280'}, page_content='280 GENERATIVE AI\\njust obstacles; they’re the very blueprint we need to ensure sus-\\ntained and meaningful growth.\\nChallenges to AI Progression\\nWhat might impede our journey toward AI-driven technological \\nprogress? While we’re setting aside natural disasters like earth-\\nquakes and tsunamis, there are several human-made factors that \\ndeserve our attention. These include regulatory challenges, hesi-\\ntancy in AI adoption, economic and political dynamics, and tal-\\nent shortages.\\nRegulation is a double-edged sword. On one hand, it’s essen-\\ntial for ensuring that AI technologies are developed and deployed \\nresponsibly. On the other, excessive or ill-conceived regulations \\ncan stymie innovation. Governments worldwide are grappling \\nwith the challenge of crafting AI policies. This regulatory uncer-\\ntainty can deter businesses and researchers, adding complexities \\nand costs to AI initiatives. Overemphasis on certain aspects, such \\nas data accessibility restrictions or an excessive focus on explain-\\nability, can hinder progress. For instance, if regulations make set-\\nting up experimental AI projects too cumbersome, it could deter \\ninnovation.\\nHowever, it’s not all gloom. Some nations are leading the \\nway with balanced and forward-thinking AI strategies. Countries \\nlike Canada, South Korea, the United States, Japan, and notably, \\nSingapore, are setting commendable examples. Singapore, in \\nparticular, stands out with its ambitious vision to be at the fore-\\nfront of AI by 2030. Their approach strikes a balance: They pri-\\noritize data privacy and ethical AI use without stifling innovation. \\nTheir collaborations with global tech giants like Google Cloud \\nand their engagement with the open source community through \\ninitiatives like the AI Verify Foundation are testament to their'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 294, 'page_label': '281'}, page_content='Generative AI’s Exponential Growth 281\\nprogressive stance. Additionally, Singapore’s emphasis on educa-\\ntion and talent development ensures they have the human capital \\nto realize their AI aspirations.\\nOne of the significant challenges in our journey toward an \\nAI-centric world is the rate at which AI is embraced by both \\nbusinesses and individuals:\\n• Ethical dilemmas: The ethical landscape of AI is vast and \\ncomplex. Concerns about biases in AI algorithms, potential \\nmisuse in surveillance, and other moral quandaries can deter \\nits widespread adoption. As developers and innovators, we \\nbear the responsibility to ensure AI serves the broader good \\nof society.\\n• Knowledge gaps: A significant barrier is the lack of compre-\\nhensive understanding of AI’s capabilities. Many, from indi-\\nvidual users to large corporations, are either unaware of  \\nAI’s potential or have misconceptions about its limits.  \\nGenerativeAI.net aims to bridge this gap, educating both \\nindividuals and businesses. Fortunately, tech giants like \\nGoogle have also stepped up, offering educational platforms \\nto demystify AI.\\n• Financial constraints: The financial aspect of AI can’t be \\nignored. While AI promises incredible returns, the initial \\ninvestment can be daunting. OpenAI’s CEO, Sam Altman, \\nhighlighted this when he revealed that training GPT-4 cost \\nover $100\\xa0million. And the projections suggest that by 2030, \\ntraining advanced AI models could skyrocket to a staggering \\n$500\\xa0million. Such figures can be intimidating, especially for \\nsmaller enterprises.\\n• Cultural and generational variances: Acceptance of AI isn’t uni-\\nform across all demographics. Different age groups and cul-\\ntural backgrounds approach AI with varying degrees of trust'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 295, 'page_label': '282'}, page_content='282 GENERATIVE AI\\nand enthusiasm. While some are eager to integrate AI into \\ntheir daily lives, others approach with caution, if not skepti-\\ncism. Navigating these diverse attitudes and finding a uni-\\nversally acceptable path is a nuanced challenge.\\nEconomic, political, and even military conflicts can signifi-\\ncantly impact the trajectory of AI development. For instance, the \\ndevastating war between Ukraine and Russia has resulted in not \\nonly human suffering but also massive economic repercussions. \\nBy March 2023, the World Bank estimated that Ukraine already \\nneeded $411 billion over the next decade for recovery and recon-\\nstruction. Meanwhile, Russia’s daily expenses for the war range \\nbetween $500\\xa0million and $1 billion. One can’t help but wonder \\nhow transformative it would be if such resources were redirected \\ntoward secure AI development, tech education, and sustainable \\ninnovations.\\nWhile there’s undeniable enthusiasm for AI, the industry still \\ngrapples with a talent shortage. The demand for AI professionals \\nfar outstrips the supply, and this gap is projected to continue \\nuntil 2030. The strength and potential of the upcoming genera-\\ntion are commendable, but demographic challenges loom large. \\nCountries like Bulgaria are projected to see significant popula-\\ntion declines. By 2050, Bulgaria’s population might reduce to \\n5.4\\xa0million from 6.9\\xa0million in 2020. This decline isn’t isolated; \\nmany nations, especially in Eastern Europe and parts of Asia, are \\nwitnessing similar trends due to falling fertility rates, aging pop-\\nulations, and low immigration. These demographic shifts can \\nstrain economies and healthcare systems and alter workforce \\ndynamics. Elon Musk has even expressed concerns about a \\npotential population collapse.\\nReturning to the ARK survey, while it does also offer a more \\nconservative outlook, it still paints a picture of growth. The survey'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 296, 'page_label': '283'}, page_content='Generative AI’s Exponential Growth 283\\nsuggests a potential global GDP growth of 3 percent by 2030 and \\n2.1 percent by 2040. While some might view this as a cause for \\nconcern, I remain hopeful. Throughout history, there have always \\nbeen voices of doom, but innovation and human resilience have \\noften prevailed. Perhaps, as we face future challenges, our collec-\\ntive ingenuity will once again guide us toward brighter horizons.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 297, 'page_label': '284'}, page_content=''),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 298, 'page_label': '285'}, page_content='285\\nG\\nenerative AI, with its vast potential and transformative capa-\\nbilities, is not without its ethical quandaries and societal rami-\\nfications. The following concerns, which are both profound and \\nmultifaceted, demand our attention and thoughtful consideration:\\n• Intellectual property rights and ownership\\n• Misinformation, particularly through tools like deepfakes\\n• Privacy, safety, and security\\n• Generative AI’s impact on the job market and industries\\n• Our increasing dependency on AI\\n5\\nCHAPTER\\nEthical Concerns and Social \\nImplications of Generative \\nAI'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 299, 'page_label': '286'}, page_content='286 GENERATIVE AI\\n• Environmental concerns tied to AI\\n• AI oversight and self- regulation\\nThese pressing issues not only are of utmost importance for \\nthe clients I have worked with and talked to, but also echo in \\nbroader conversations across the globe. The journey into the \\nfuture of generative AI is filled with promise, but it’s essential to \\nnavigate it with caution, awareness, and responsibility.\\nThe intricacies of large language models (LLMs) often \\nintertwine with their occasional inaccuracies and a lack of con-\\ntextual understanding. This can sometimes lead to a failure to \\ngrasp the nuances of specific workplace scenarios, potentially \\nmisinforming individuals. Hence, it’s imperative to emphasize \\nthe importance of source referencing when relying on such  \\nmodels.\\nThe aim of this chapter is to delve not into the technicali-\\nties of AI but rather into the broader mindset, rules, and atti-\\ntudes surrounding it. The pillars of transparency, education, \\nregulation, and security are paramount. Ultimately, our dis-\\ncourse converges on the ethical concerns and societal implica-\\ntions of AI.\\nIt’s worth noting that certain topics can straddle the line \\nbetween an ethical concern and a societal implication, which is \\nwhy I’ve chosen not to make a clear distinction between the two. \\nWhile each of these subjects could be exhaustively explored, \\npotentially warranting a doctoral thesis of its own, my aim here \\nis to provide a comprehensive overview, highlighting the nuances \\nwithout getting lost in the minutiae.\\nA word of caution: I don’t claim to be a legal expert. The \\nlandscape of AI and its regulations is ever- evolving, so always \\nseek guidance from a legal professional for specific situations. \\nThe perspectives shared here are solely mine, derived from'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 300, 'page_label': '287'}, page_content='Ethical Concerns and Social Implications of Generative AI 287\\nextensive research and myriad discussions. Where appropriate, \\nI’ll offer recommendations.\\nNavigating the labyrinth of regulations is no small feat, espe-\\ncially when addressing a technology that’s still in its nascent stages, \\nwith many of its implications being theoretical. The regulatory \\napproach to AI varies significantly across countries; some nations \\nadopt a more hands- on stance while others tread with caution.\\nLastly, addressing the multifaceted ethical and societal  \\nchallenges posed by AI is not a solitary endeavor. It demands a \\nconcerted effort from technologists, policymakers, ethicists, and \\nsociety as a whole. Crafting a future where AI aligns with our \\nethical values and principles necessitates smart regulations in \\ncombination with self- regulation, unwavering commitment to \\ntransparency and accountability, and a collective will to ensure \\nresponsible AI design and deployment.\\nIntellectual Property and the Generative \\nAI Platform\\nIn the rapidly evolving landscape of AI, the legalities surround-\\ning intellectual property (IP) rights are in constant flux. It’s \\nimperative for professionals and users alike to stay abreast of \\nlocal laws. When navigating the intricate waters of AI and IP , \\nconsulting with legal professionals is always a prudent step.\\nOne of the most pressing questions in this domain is: Who \\nowns the intellectual property rights of the content generated by \\nthe AI? T o address this, it’s essential to first differentiate between \\nownership, owning the IP rights, and copyright.\\nOwnership pertains to the possession or holding of an item. \\nFor instance, when you purchase a book, that physical copy \\nbelongs to you. On the other hand, owning IP rights means'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 301, 'page_label': '288'}, page_content='288 GENERATIVE AI\\nhaving legal control over an idea, invention, or creation. This \\nencompasses patents, trademarks, and copyrights. Using the \\nbook analogy, while you possess the physical book, the unique \\nideas, characters, or methods within are protected by IP rights, \\ngranting exclusive usage, sale, or licensing privileges. Copyright, \\na subset of IP rights, is a legal provision that gives the creator of \\nan original work exclusive rights to its use and distribution. So, \\nalthough you own the book you bought, you can’t reproduce its \\ncontent for sale, as the copyright typically belongs to the author \\nor publisher.\\nThe matter of IP rights for AI- generated content is intricate \\nand varies across jurisdictions and terms of use. Historically, IP \\nrights have been attributed to human creators. However, the \\nadvent of AI- generated content has muddied these waters. While \\nthere are scattered regulatory guidelines globally, a comprehen-\\nsive solution remains elusive.\\nA growing concern in this field is the likelihood of AI tools \\nbeing trained on copyrighted content without obtaining the req-\\nuisite permissions. This issue has been thrust into the spotlight \\nby recent legal confrontations, notably the case involving Sarah \\nSilverman, an acclaimed American stand- up comedian, actress, \\nand writer. Silverman, along with other authors, has taken on \\ntech behemoths like OpenAI and Meta, emphasizing the intri-\\ncate nature of copyright violations in the AI sphere. Silverman’s \\ncontention is that OpenAI never secured her consent to use the \\ndigital rendition of her book for training their AI models. In a \\nsimilar vein, legal actions, such as the one where Getty Images \\nchallenged Stable Diffusion over unauthorized content usage, \\naccentuate the urgent need for definitive guidelines in this area.\\nIn the European Union, the stance on copyrightability is \\nclear- cut: AI- generated works are not eligible for copyright  \\nprotection. The Court of Justice of the European Union'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 302, 'page_label': '289'}, page_content='Ethical Concerns and Social Implications of Generative AI 289\\nmandates human involvement for a work to be copyrighted. \\nPurely computer- generated outputs, devoid of human contribu-\\ntion, don’t qualify. However, such AI outputs might find protec-\\ntion under related rights, such as sound recording rights, with \\nthe AI software user likely being the rights holder.\\nThe UK’s approach to copyrightability is more intricate. \\nWhile original literary, dramatic, musical, and artistic works are \\nprotected, they must be the author’s creations and display origi-\\nnality. If a human, with AI assistance, creates a work that exhibits \\nhuman creativity, the AI is merely a tool and the human retains \\nthe rights. However, the UK does offer protection to works gen-\\nerated solely by computers, provided they meet the originality \\ncriterion. The challenge lies in the fact that generative AI often \\ntests this standard of originality.\\nLastly, the terms and conditions of AI programs often house \\ncrucial information regarding IP rights. Companies like Mid-\\njourney, OpenAI, and Stability AI outline specific terms about \\nthe ownership of AI- generated content. However, these details, \\noften buried in fine print, are frequently overlooked by users, \\nleading to potential misunderstandings. For example, while  \\nOpenAI permits users to own the content they produce, it reserves \\nthe right to utilize it for service enhancement, aka model training.\\nIf an AI tool produces content that treads on the intellectual \\nproperty of another, the question of liability becomes paramount.\\nIn numerous scenarios, the end users, who utilize the AI for \\ncontent generation and subsequently disseminate or employ  \\nthat content, might find themselves in the crosshairs of legal \\naction for any infringement. This is particularly the case if the \\nuser’s specific prompts or data inputs steer the AI toward infring-\\ning content. On the other hand, the AI service provider could \\nalso shoulder some of the blame, especially if they had prior \\nknowledge of potential infringement risks or if their tool'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 303, 'page_label': '290'}, page_content='290 GENERATIVE AI\\nhabitually churns out content that breaches copyright. That said, \\nmany AI service terms explicitly shift the responsibility burden \\nonto the user, absolving the provider of any potential legal \\nentanglements.\\nT o sidestep the quagmire of infringement, several measures \\ncan be adopted:\\n• AI developers must prioritize legal compliance when sourcing  \\ndata.\\n• Establishing and maintaining a clear lineage of AI- generated \\ncontent can help trace back any potential issues.\\n• Vigilance is key for content creators to spot potential \\ninfringements.\\n• Companies should closely review deal conditions to protect \\ntheir intellectual property.\\n• Constructing proprietary datasets for AI training can offer \\nmore control and reduce infringement risks.\\n• At the user’s end, it’s paramount to honor the rights of original \\ncontent creators, ensuring their work isn’t misappropriated.\\nThe nature of the content produced by an AI model can \\noften be swayed by the training data it’s been fed. This brings  \\nto light another pertinent question: Who holds the rights to the \\nAI model itself, encompassing its architecture, weights, and \\nalgorithms?\\nAs a general rule of thumb, the rights to the AI model typi-\\ncally rest with the entity— be it an individual or an organization— \\nthat played a pivotal role in its development. However, if the \\nmodel’s creation was under the purview of an employment con-\\ntract or a specific agreement, the rights might be vested in the'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 304, 'page_label': '291'}, page_content='Ethical Concerns and Social Implications of Generative AI 291\\nemployer or the contracting party. The waters get murkier with \\nopen source models. While the original creators retain the copy-\\nright, they extend certain privileges to others, allowing them to \\nuse, adapt, and distribute the model. The exact nature of these \\nrights and any accompanying obligations hinge on the stipula-\\ntions of the open source license under which the model \\nwas released.\\nBias and Fairness in AI- Generated Data\\nIn the rapidly evolving realm of generative AI, the ethical onus \\non AI practitioners such as AI researchers and AI engineers is \\nparamount. As stewards of this transformative technology, they \\nbear the responsibility of not just creating but also continuously \\nrefining AI models to reflect the ever- shifting tapestry of societal \\nnorms and values. This necessitates a vigilant approach to AI, \\none that’s steeped in a critical mindset, perpetually probing and \\nvalidating the fairness of the outputs it generates.\\nHow Bias Is Introduced into Generative AI Models\\nBias, an unwelcome specter, can insidiously creep into generative \\nAI models through myriad avenues. One of the most prevalent \\nculprits is biased training data. When the foundational data used \\nto train an AI system skews toward a particular demographic or \\nperspective, the system, in all likelihood, will mirror these biases \\nin its results. Such a scenario can manifest when the training data \\npresents an imbalanced representation of various groups, causing \\nthe AI model to internalize and reproduce these inherent biases. \\nThe repercussions of leveraging incomplete, erroneous, or  \\nprejudiced datasets for the training and validation of machine \\nlearning systems can be far reaching and detrimental.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 305, 'page_label': '292'}, page_content='292 GENERATIVE AI\\nY et, the very architects of these systems, the individuals who \\ndesign and train the machine learning algorithms, can inadvert-\\nently infuse their creations with biases. These could range from \\nunintentional cognitive biases to more deep- seated prejudices. \\nFurthermore, the very blueprint of the AI model, its architecture, \\ncan be a source of bias. Specific architectural decisions might \\ninadvertently prioritize certain data patterns or features, leading \\nto skewed representations. Even seemingly innocuous elements \\nlike loss functions and regularization techniques can play a role \\nin introducing bias.\\nHuman interpretation of AI outputs is another potential pit-\\nfall. The lens through which AI- generated results are viewed and \\ninterpreted can be colored by individual biases, leading to skewed \\nconclusions.\\nT o fight these biases, we need a clear plan. Start with using \\nvaried and balanced data. It’s also crucial to watch out for biases \\nwhen choosing and reading data. By regularly checking and test-\\ning AI systems, we can spot and fix hidden biases. Understanding \\nhow the AI model’s design affects its actions is also key.\\nWorking toward a bias- free generative AI is an ongoing \\neffort. It requires constant attention, self- reflection, and a strong \\ndedication to ethics.\\nThe Implications of Biased AI- Generated Data on Real- World \\nApplications\\nBiased AI- generated data can have significant real- world conse-\\nquences. Organizations using skewed AI data risk legal challenges, \\npotentially facing lawsuits or regulatory actions. This bias can also \\nlead to discrimination in sectors like recruitment, finance, and \\nhealthcare, where AI might favor certain demographics.\\nCompanies using biased AI risk damaging their reputation, \\naffecting their brand and customer trust. Furthermore, decisions'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 306, 'page_label': '293'}, page_content='Ethical Concerns and Social Implications of Generative AI 293\\nbased on biased AI can result in financial losses for businesses \\nand individuals alike.\\nAt a societal level, biased AI can exacerbate existing preju-\\ndices, deepening societal divides and reinforcing inequalities. \\nSuch biases can also diminish public trust in AI, limiting its \\nbroader acceptance and potential benefits.\\nT o counteract these challenges, organizations must actively \\nidentify and address biases in AI data. This includes using diverse \\ntraining data, regularly evaluating AI systems, and considering \\nthe ethical implications of AI decisions. Ultimately, though AI \\noffers immense potential, it’s crucial to use it responsibly to \\nensure fairness and inclusivity.\\nDetecting and Measuring Bias in AI- Generated Data\\nThe complexities of bias detection in AI- generated data call for a \\ncomprehensive approach. Here’s a closer look at the strategies \\nand techniques that can be employed.\\nA deep dive into the data that trains the AI model can shed \\nlight on inherent biases. The key is to ensure this data mirrors \\nthe broader population, thereby minimizing skewed outcomes.\\nFairness metrics come to the rescue when quantifying bias. \\nMetrics like disparate impact and equal opportunity difference \\ncan pinpoint how the model might be leaning toward cer -\\ntain groups.\\nThe tech industry has developed tools such as AI Fairness \\n360, Algorithmic Bias Detection T ool, Bias Analyzer, and Aequi-\\ntas. These tools are designed to identify and correct bias in AI \\ndata effectively.\\nAnother effective strategy is to pit the AI model against dedi-\\ncated external benchmark data, such as the COMPAS datasets  \\nfor predictive policing biases, BiasBios for gender bias in named- \\nentity recognition, and FairFace for biases in facial recognition.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 307, 'page_label': '294'}, page_content='294 GENERATIVE AI\\nDatasets specifically designed to benchmark bias can be invalu-\\nable in this exercise.\\nThe human element can’t be overlooked. A team that’s \\ndiverse in terms of backgrounds and experiences can offer varied \\nperspectives, acting as a safety net against biases that might oth-\\nerwise slip through.\\nThe AI model should be under constant scrutiny. Regular \\ntests, coupled with rigorous monitoring and audits, can keep \\nbiases in check. This vigilance should span the entire spectrum of \\nthe AI model, from its input and logic to its behavior and output.\\nHowever, the journey to bias detection isn’t without its chal-\\nlenges. There are often tough choices to make, like striking a \\nbalance between transparency and privacy or juggling fairness \\nwith accuracy. This underscores the need for AI models to be in \\na state of constant evolution, with regular tweaks to iron out \\nbiases and uphold fairness.\\nEnsuring Fairness in AI- Generated Data Without Compromising \\nData Privacy\\nSwitching gears to the delicate balance between fairness and data \\nprivacy in AI- generated data, here’s a roadmap.\\nLaying the groundwork for privacy should start at the very \\nonset of AI model development. T echniques like differential pri-\\nvacy, federated learning, and secure multiparty computation can \\nbe game changers, allowing for in- depth data analysis without \\ncompromising individual privacy.\\nAnonymizing data is another potent tool. By stripping data-\\nsets of personally identifiable information or encrypting this \\ndata, the privacy of individuals remains intact.\\nT ransparency is paramount. Individuals should be in the loop \\nabout how their data is being used. Informed consent, where \\nindividuals are apprised of the nuances of data usage, empowers \\nthem to have a say in the process.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 308, 'page_label': '295'}, page_content='Ethical Concerns and Social Implications of Generative AI 295\\nSynthetic data is a new and promising area in AI. It’s made \\nartificially to match the real data’s statistical features, making it \\nvaluable for training AI models, including generative AI models. \\nThe great thing about synthetic data is that it reflects real- world \\nsituations without risking the loss of individual privacy.\\nSeveral companies are working on using synthetic data to \\nensure both fairness and privacy in AI- generated data. For exam-\\nple, Hazy, a startup, uses special techniques like differential pri-\\nvacy along with synthetic data to keep data useful while protecting \\nprivacy. Big names like Accenture have used Hazy’s data to check \\nand train financial models.\\nAnother leader in this field is Mostly AI, which creates data \\npoints that keep the same patterns as real data without giving up \\nprivacy. Companies like Citi, Humana, and SWIFT are already \\nbenefiting from this synthetic data, enjoying both privacy and \\nusefulness.\\nThe Alan T uring Institute, a research organization, is also \\ncontributing to this mission by exploring ways to keep fairness, \\naccountability, and privacy in AI, with a special group dedicated \\nto finding technical solutions for these challenges.\\nIn essence, the twin goals of fairness in AI- generated data \\nand data privacy aren’t mutually exclusive. With the right strate-\\ngies and a commitment to ethical AI practices, it’s possible to \\nstrike a harmonious balance between the two.\\nMisinformation and Misuse of Generative AI\\nMisinformation and the misuse of generative AI, especially in the \\nform of deepfakes, have become topics of significant concern. \\nEvery technological advancement, including generative AI, pos-\\nsesses a dual nature. On one hand, it holds the promise of revo-\\nlutionizing industries and enhancing our daily lives. On the \\nother, it brings forth risks that society must proactively address.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 309, 'page_label': '296'}, page_content='296 GENERATIVE AI\\nIt’s imperative for individuals and institutions alike to approach \\nAI- generated content with a discerning eye and champion \\nresponsible and ethical AI practices.\\nOne of the most potent manifestations of this technology’s \\ndarker side is its fusion with targeted advertising. This combination \\ncan be a formidable instrument for misinformation, particularly \\nwhen wielded by autocratic entities in orchestrated disinformation \\ncampaigns. The capabilities of generative AI extend to crafting \\nhuman- like content, spanning text, images, and videos. This makes \\nit increasingly challenging to differentiate genuine content from \\nfabricated narratives. The inherent danger lies in these AI systems’ \\nability to craft and propagate false narratives aligned with specific \\nagendas, leading to potential large- scale manipulation. The auto-\\nmation of disinformation campaigns by generative AI facilitates the \\nswift and extensive spread of misleading information. Autocratic \\ngovernments, with their vested interests, can exploit this technol-\\nogy to shape narratives, sway public sentiment, and further entrench \\ntheir authority.\\nHowever, AI- generated content, deepfakes have garnered \\nparticular attention. Deepfakes, in essence, are AI- generated vid-\\neos or images that digitally simulate real individuals. They \\nmanipulate existing content to depict someone expressing or \\ndoing something they never did. Such content is crafted with the \\nintent to deceive, making viewers believe in the authenticity of \\nthe manipulated content. Unlike other AI- generated content, \\nwhich is often constructed from the ground up, deepfakes mod-\\nify existing videos, images, or voices. The Internet is rife with \\ndeepfakes of notable figures, from celebrities like Nicolas Cage \\nand T om Cruise to political stalwarts like Mark Zuckerberg and \\nHillary Clinton (Figure\\xa05.1).\\nThe malicious potential of deepfakes is vast. They can be \\nweaponized in numerous detrimental ways. Personal vendettas \\ncan take the form of fabricated videos or audio clips, aimed at'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 310, 'page_label': '297'}, page_content='Ethical Concerns and Social Implications of Generative AI 297\\ndefaming, blackmailing, or harassing individuals. On a larger \\nscale, voice imitation can be employed in financial fraud, duping \\nindividuals or corporations into unauthorized transactions.\\nDetecting Deepfakes and AI- Generated Misinformation\\nDetecting deepfakes and AI- generated misinformation remains a \\nformidable challenge, especially given the rapid advancements in \\ntheir creation techniques. Y et, the scientific community has been \\nrelentless in its pursuit of robust detection methods.\\nForensic analysis stands as one of the primary techniques \\nemployed by experts. By meticulously examining videos or images \\nfor inconsistencies, artifacts, or anomalies, they can discern signs \\nof manipulation. This scrutiny extends to facial movements, light-\\ning nuances, shadows, and reflections, all of which can betray the \\nauthenticity of the content.\\nWatermarking techniques have also gained traction. Embed-\\nding hidden information within videos or images makes tampering \\nFIGURE\\xa05.1 Deepfakes can be nearly indistinguishable from authentic  \\nimages: the picture on the left is an unaltered photograph of a Tom \\nCruise impersonator.\\nSource: Maverick'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 311, 'page_label': '298'}, page_content='298 GENERATIVE AI\\nevident. These watermarks serve as a seal of authenticity, ensur-\\ning the content’s integrity.\\nDelving into the metadata of videos or images can also yield \\nvaluable insights. This treasure trove of information, encompas-\\nsing details like the date, time, location, and capturing device, \\ncan hint at potential manipulations.\\nReverse engineering has emerged as another potent tool. By \\ndissecting the deepfake creation process, experts can pinpoint \\nspecific artifacts or patterns exclusive to AI algorithms. This \\nknowledge is invaluable in devising countermeasures and refin-\\ning detection techniques.\\nCollaborative endeavors, such as the Deepfake Detection \\nChallenge, epitomize the collective spirit of the scientific com-\\nmunity. By congregating researchers and experts, these platforms \\ncatalyze innovation and facilitate the exchange of knowledge, \\nfortifying defenses against deepfakes.\\nHowever, the most promising avenue lies in machine learn-\\ning algorithms themselves. T rained to discern patterns and \\nanomalies inherent in deepfakes, these algorithms scrutinize vis-\\nual cues, from unnatural facial movements to pixel- level incon-\\nsistencies. Several noteworthy examples have emerged:\\n• The University of Buffalo has pioneered a tool boasting a \\nstaggering 94 percent efficacy in deepfake detection. By \\nexamining reflections in subjects’ eyes, it discerns discrepan-\\ncies in reflections, indicative of digital rendering.\\n• Microsoft’s Video Authenticator was rolled out preceding \\nthe 2020 election in a strategic move to counter misinforma-\\ntion. In collaboration with Project Origin and media giants \\nlike BBC and The New\\xa0 York Times, this tool zeroes in on \\nimperceptible imperfections at image edges.\\n• Intel’s FakeCatcher is another trailblazing “real- time” deep-\\nfake detector, boasting an impressive 96 percent accuracy rate.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 312, 'page_label': '299'}, page_content='Ethical Concerns and Social Implications of Generative AI 299\\nIts methodology is intriguing: it observes “blood flow” in vid-\\neos to ascertain authenticity. The rationale? Blood flow \\ninduces color shifts in veins. Algorithms transmute these sig-\\nnals into spatiotemporal maps, with deep learning subse-\\nquently determining video veracity.\\nOn the text- generation front, DetectGPT stands out.  \\nT ailored to detect text birthed by the GPT language model, it \\nemploys a statistical watermarking scheme. This tool, part of a \\nbroader initiative to counter AI- generated misinformation, \\nworks in tandem with other tools like GPTZero to identify  \\nAI- spawned content.\\nHowever, it’s crucial to recognize the dynamic nature of this \\nbattle. As detection techniques evolve, so do deepfake creation \\nmethods. This cat- and- mouse game necessitates not just techni-\\ncal solutions but also public awareness and critical thinking.  \\nFurthermore, it underscores the importance of individual respon-\\nsibility. Those consuming content must exercise discernment, \\ncritically evaluating the credibility of sources and the authentic-\\nity of the information presented. Only through a multifaceted \\napproach, combining technological solutions with informed and \\nvigilant consumers, can society hope to stem the tide of deep-\\nfakes and AI- generated misinformation.\\nPreventing the Malicious Use of Generative AI and Deepfakes\\nT o curb the malicious use of generative AI and deepfakes, a mul-\\ntipronged strategy is paramount. While technological solutions, \\nsuch as digital authentication, are pivotal, they are but one piece \\nof a larger puzzle. The synergy of research collaboration cannot \\nbe overstated. By fostering partnerships between researchers, \\nindustry mavens, and organizations, the collective might of these \\nentities can be harnessed to refine deepfake detection techniques.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 313, 'page_label': '300'}, page_content='300 GENERATIVE AI\\nPooling knowledge and resources can pave the way for more \\npotent countermeasures against all forms of deepfakes.\\nY et, the linchpin in this defense might very well be media \\nliteracy and critical thinking. By equipping individuals with the \\nskills to critically assess online information, they become the first \\nline of defense against misinformation. The ability to discern \\nand challenge dubious or manipulated content is invaluable in \\nthis digital age.\\nHowever, it’s imperative to understand that the battle against \\nthe malicious use of generative AI and deepfakes isn’t solely a \\ntechnological one. It’s a confluence of tech advancements, height-\\nened public awareness, and collaboration across sectors. And, as \\nwe’ll explore later, policy measures play a pivotal role in this  \\ntapestry.\\nOn the legal front, states like California have been proactive \\nin legislating against deepfakes. T wo landmark laws have been \\nenacted, targeting political campaigns and sexually explicit mate-\\nrial. Assembly Bill 602 and Assembly Bill 730, which came into \\neffect on January 1, 2020, set the legislative tone against deep-\\nfakes. These laws represent a step in the right direction, but \\nthey’ve faced criticism for their narrow scope and potential \\nenforcement challenges. The clamor for more comprehensive \\nfederal legislation is growing, underscoring the need for a uni-\\nfied approach to address the multifaceted threats posed by deep-\\nfakes. As the digital landscape evolves, so too must the legal \\nframeworks that govern it, ensuring that society is safeguarded \\nagainst the potential perils of generative AI.\\nPrivacy, Safety, and Security\\nGenerative AI, while groundbreaking, ushers in fresh vulnerabil-\\nities. The risks it poses in the realms of cybersecurity and phish-\\ning attacks are not to be underestimated. As technology advances, \\nso does the sophistication of cyberthreats.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 314, 'page_label': '301'}, page_content='Ethical Concerns and Social Implications of Generative AI 301\\nGenerative AI can craft highly convincing phishing emails \\ntailored to individual recipients, making it challenging for even \\nthe most discerning users to spot malevolent intent. T ools like \\nChatGPT and the more nefarious WormGPT have become \\ninstrumental for cybercriminals in orchestrating business email \\ncompromise (BEC) attacks. In these schemes, the attacker mas-\\nquerades as a trusted company executive or colleague, duping \\nvictims into transferring funds or divulging confidential data. \\nSimply instructing the AI to “act as a CEO of XY corporation” \\ncan set the stage for a potential breach.\\nWormGPT , a malicious AI chatbot built atop the open source \\nGPT- J language model, stands out for its ability to understand \\nand respond to text in various languages. Rumored to be trained \\non malware- centric datasets and devoid of content moderation, \\nit’s a potent tool for threat actors. With WormGPT , crafting \\nscam emails becomes a breeze, even for those lacking technical \\nexpertise, amplifying the risks for businesses.\\nBeyond phishing, other threats loom large. T raining data \\npoisoning, for instance, is a subtle yet potent attack. By meddling \\nwith the data used to train deep- learning models, attackers can \\nskew the AI’s decisions in unpredictable ways, making detection \\narduous. AI model theft is another concern. Unscrupulous indi-\\nviduals might attempt to reverse- engineer proprietary AI models \\nusing their outputs or siphon off sensitive data embedded within, \\njeopardizing intellectual property and data privacy. Moreover, \\nthe very tools and models of generative AI can inadvertently leak \\nsensitive information— trade secrets, classified intel, or customer \\ndata— ripe for criminal exploitation.\\nT o counter these threats, it is imperative for organizations to \\nbolster their cybersecurity defenses, maintain vigilant oversight \\nof their AI models, and instate rigorous governance protocols for \\ngenerative AI systems. Y et, even with these precautions, vulner-\\nabilities persist. One such weakness emerged in the form of \\nprompts, leading to what’s known as prompt injection. In 2022, the'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 315, 'page_label': '302'}, page_content='302 GENERATIVE AI\\nNCC Group, a company providing services in cybersecurity \\nconsulting, identified prompt injection as a novel vulnerability \\nclass for AI/ML systems.\\nPrompt injection encompasses a range of computer security \\nbreaches achieved by manipulating a machine learning model \\nwith malicious user instructions. It’s akin to a code injection \\nattack but executed through crafty prompt engineering. Notable \\nvariants of this exploit include jailbreaking, prompt leaking, and \\ntoken smuggling. By early 2023, minor prompt injection exploits \\nhad targeted chatbots like ChatGPT and Bing, signaling the \\never- evolving landscape of AI- related threats.\\nGenerative AI’s potential to compromise individual privacy \\nmanifests in multifaceted ways, adding another layer of complex-\\nity to the ethical considerations surrounding this technology. \\nDuring their operation, generative AI systems may expose users’ \\npersonal information. This exposure can occur either by design \\nor due to flaws in the system’s implementation, underscoring the \\nimportance of robust design principles.\\nThe susceptibility of generative AI tools to data breaches is \\nanother pressing concern. Without stringent security protocols, \\nthese tools can become gateways for unauthorized access or dis-\\nclosure of sensitive user information. The consequences of such \\nbreaches are far reaching, not only impacting the individuals \\nwhose data is compromised but also potentially undermining \\ntrust in AI technologies.\\nFurthermore, users themselves may unwittingly contribute \\nto privacy breaches while interacting with generative AI tools. \\nFor example, they might inadvertently include confidential \\ninformation in prompts or queries, unaware of the potential \\nrisks. Such seemingly innocuous interactions can lead to signifi-\\ncant leaks of sensitive data, emphasizing the need for clear guide-\\nlines and user education.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 316, 'page_label': '303'}, page_content='Ethical Concerns and Social Implications of Generative AI 303\\nAnother critical aspect is compliance with data protection \\nregulations. Generative AI tools might process personal data  \\nin ways that contravene legal requirements, such as failing to \\nprovide adequate notice or lacking the proper legal basis for  \\nprocessing. These violations can result in not only privacy \\ninfringements but also serious legal ramifications.\\nPrioritizing privacy and security is not merely an option but \\na necessity. Staying abreast of the latest threats and countermeas-\\nures is vital. The convergence of technological innovation and \\nethical responsibility must guide all AI endeavors, ensuring that \\nthe remarkable capabilities of generative AI are harnessed with-\\nout sacrificing the fundamental rights and protections that indi-\\nviduals are entitled to. The balance between innovation and \\nintegrity is delicate, and the pursuit of one must not come at the \\nexpense of the other.\\nGenerative AI’s Impact on Jobs and Industry\\nChapter\\xa0 4, “Potential Applications and Impact of Generative \\nAI,” touched on the anticipated exponential trajectory of eco-\\nnomic growth. With the advent of these technological advance-\\nments, a surge in global GDP appears more probable than ever. \\nWe also highlighted the emergence of a new breed of profes-\\nsional workers, primed and ready to occupy novel roles and job \\ncategories birthed by these innovations.\\nHowever, the landscape isn’t without its challenges. The \\nspecter of job displacement and industry upheaval looms large, \\ncasting a shadow of uncertainty. Y et, it’s essential to recognize that \\nwith these challenges come unparalleled opportunities for expan-\\nsion, ingenuity, and the genesis of previously unimagined job roles.\\nWhen AI becomes an ally in our professional pursuits, a new \\nbenchmark of excellence emerges. The resultant uptick in quality,'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 317, 'page_label': '304'}, page_content='304 GENERATIVE AI\\ndriven by AI’s precision and efficiency, sets a standard that’s hard to \\nrival. Educational institutions, from universities to vocational \\ntraining centers, should not cower in the face of this change. \\nInstead, the onus is on them to elevate their expectations, pushing \\nstudents to produce outcomes that not only match but exceed the \\ncapabilities of AI. Resistance or outright rejection of these tools \\nwould be a disservice to learners.\\nLooking ahead, the message is clear: adapt or risk obsoles-\\ncence. T raditional roles, ones that have been the backbone of \\nindustries for decades, might need to undergo a metamorphosis. \\nSome might even find themselves on the brink of extinction, \\nwith no viable future in a world steered by AI.\\nIn the realm of white- collar professions, the stakes are par -\\nticularly high. Those who fail to harness the power of generative \\nAI in their daily operations risk being left in the dust. The wave \\nof generative AI is not just a trend; it’s a seismic shift. And to stay \\nafloat, one must not only ride this wave but master it.\\nThe U.S. Career Institute, in collaboration with willrobot \\nstakemyjob.com, undertook an extensive analysis of the top \\nthousand professions. Figure\\xa0 5.2 delineates the vocations with \\nthe most negligible risk of succumbing to AI automation by 2023.\\nA particular trend caught my attention. The vocations least \\nsusceptible to automation are invariably those categorized under \\nlow risk of mechanization. This elite list includes the following:\\n• Medical and health professionals\\n• Engineering and science professionals\\n• Arts and sports professionals\\n• Education and administration professionals\\n• Law enforcement and public safety professionals\\n• T rades and technical professionals'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 318, 'page_label': '305'}, page_content='Ethical Concerns and Social Implications of Generative AI 305\\nA closer examination reveals that these roles are character -\\nized by the necessity for a human touch, empathy, ingenuity, spe-\\ncialized acumen, and the provision of bespoke care or services. \\nThey demand intricate decision making, the interpretation of \\nsingular scenarios, and a degree of human discernment that \\nmachines find challenging to emulate.\\nHowever, this status quo might not remain static. The bur -\\ngeoning domain of robotics, coupled with increasingly sophisti-\\ncated generative AI models and a skyrocketing pace of \\ndevelopment, heralds potential shifts in this landscape.\\nFIGURE\\xa05.2 Jobs least likely to be automated by AI\\nSource: Weston Distance Learning / www.uscareerinstitute.edu/blog/65-jobs-with-the-\\nlowest-risk-of-automation-by-ai-and-robots / last accessed November 20, 2023.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 319, 'page_label': '306'}, page_content='306 GENERATIVE AI\\nA cursory glance at the raw data underscores that certain job \\ncategories are more susceptible to automation. Notably, profes-\\nsions within transport, sales, manufacturing and repair, cleaning \\nand maintenance, surveillance and security, media and entertain-\\nment (encompassing roles like broadcast announcers and radio \\nDJs), and traffic and urban management are on the frontline.\\nThe driving forces propelling this automation wave include \\nthe following:\\n• Efficiency: Machines, unhindered by fatigue, can operate \\nincessantly, amplifying productivity.\\n• Precision: Automation guarantees a uniform caliber of out-\\nput, ensuring meticulousness in tasks.\\n• Cost- effectiveness: Over an extended period, machinery can \\nprove more economical than human resources.\\n• Safety: Machines can undertake perilous tasks, safeguarding \\nhuman well- being.\\n• Availability: Machines, unbound by the circadian rhythm, \\nare operational 24/7, obviating the need for rotational shifts.\\n• Repetitiveness: Roles characterized by monotony and devoid \\nof human discretion are prime contenders for automation.\\nY et, it’s paramount to emphasize that although machines can \\nassume specific roles, the quintessential human attributes of touch, \\ndiscernment, and interpersonal prowess remain unparalleled and \\nindispensable in a plethora of professions for a foreseeable time.\\nPreparing for the Changes Resulting from Generative AI\\nA recent McKinsey report sheds light on the impending trans-\\nformation in the job market. 1 By 2030, activities that currently \\n1 James Manyika, et\\xa0al. “Jobs Lost, Jobs Gained: What the Future of Work Will Mean for Jobs, Skills, and \\nWages,” McKinsey & Company, November 28, 2017, www.mckinsey.com/featured- insights/\\nfuture- of- work/jobs- lost- jobs- gained- what- the- future- of- work- will- mean-  \\nfor- jobs- skills- and- wages#.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 320, 'page_label': '307'}, page_content='Ethical Concerns and Social Implications of Generative AI 307\\naccount for nearly 30 percent of hours worked could be auto-\\nmated, a shift propelled by generative AI. The report further \\nindicates that the most significant job reductions might be wit-\\nnessed in sectors like office support, customer service, and food \\nservices. Other research by McKinsey Global Institute empha-\\nsizes the need to reignite productivity growth in the United \\nStates, with automation and reskilling playing pivotal roles. This \\nrepresents a $10 trillion opportunity.2\\nSo, how can workers brace themselves for this tidal wave \\nof change?\\nFirst and foremost, it’s crucial to acknowledge the profound \\nimpact generative AI will have on job roles and processes. Work-\\ners should be receptive to this evolution, reenvisioning their \\nroles to accentuate human creativity and judgment. A founda-\\ntional step in this direction is to foster data literacy. In an era \\nwhen data is the new oil, understanding its nuances and the piv-\\notal role it plays in generative AI becomes paramount. This \\ninvolves honing skills in data collection, analysis, and, more cru-\\ncially, interpretation, ensuring one can adeptly navigate an AI- \\ncentric world.\\nThe advent of generative AI is dissolving the demarcations \\nbetween various disciplines. It’s imperative to cultivate collabo-\\nration and interdisciplinary skills. The future won’t entertain \\nstatements like “I can’t code.” With AI taking over coding, the \\nemphasis will shift to directing it aptly. Bolstering critical think-\\ning and problem- solving abilities will be essential, especially \\nwhen it comes to discerning biases, errors, and ethical dilemmas \\nin AI systems.\\nExperimentation is the key to understanding. Organizations \\nshould encourage their workforces to dabble with generative AI \\ntools, understanding their strengths and limitations. As someone \\n2 Charles Atkins and Olivia White, “How to Revive US Productivity,” McKinsey Global Institute, May 23, \\n2023, www.mckinsey.com/mgi/our- research/how- to- revive- us- productivity.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 321, 'page_label': '308'}, page_content='308 GENERATIVE AI\\nwho advises companies globally, I’ve observed that a blend of \\ntheoretical input followed by hands- on sessions yields the most \\nfruitful results. Such engagements not only upskill employees \\nbut also lead to innovative solutions.\\nThe pace at which generative AI is evolving necessitates a \\ncommitment to continuous learning. Keeping abreast of the  \\nlatest in AI, be it through industry publications, professional  \\nnetworks, or global conferences, is essential. Platforms like  \\ngenerativeai.net offer curated courses, providing a com-\\nprehensive understanding of the subject. For those with a pen-\\nchant for technical intricacies, delving into research papers and \\nacademic journals can offer a wealth of knowledge.\\nBut, as the proverb goes, practice makes perfect. Engaging \\nwith peers, sharing insights, and collaborating on AI projects can \\nprovide invaluable hands- on experience. By immersing them-\\nselves in the world of generative AI and adopting a proactive \\napproach to learning, workers can not only navigate but also \\nthrive in this transformative era.\\nEnsuring That the Economic Benefits of Generative AI Are  \\nEquitably Distributed\\nThe promise of generative AI in revolutionizing economies is \\npalpable. Y et, the looming shadow of unequal distribution of its \\neconomic benefits cannot be ignored. The transformative power \\nof generative AI, if left unchecked, might inadvertently cement \\nexisting societal, economic, and political disparities. The peril \\nlies in the concentration of AI benefits within a select few entities \\nor conglomerates, leading to a more pronounced economic divide.\\nMoreover, the accessibility of generative AI tools can be a \\ndouble- edged sword. Although it democratizes AI, it also paves \\nthe way for nefarious entities to disseminate disinformation, \\nundermining public trust and jeopardizing democratic tenets.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 322, 'page_label': '309'}, page_content='Ethical Concerns and Social Implications of Generative AI 309\\nThe monopolization of pivotal AI resources by a handful of cor-\\nporations can stymie innovation, suppress competition, and \\nobstruct the fair distribution of economic advantages. Further -\\nmore, the potential job upheavals, especially in sectors suscepti-\\nble to automation, can accentuate economic disparities and \\nsocietal tensions.\\nT o counteract these challenges and ensure a just distribution \\nof generative AI’s economic windfall, governments and institu-\\ntions must adopt a multipronged approach:\\nMaking Education the\\xa0 Cornerstone A robust educational \\nframework is paramount. By investing in comprehensive edu-\\ncation, technical training, and reskilling initiatives and foster-\\ning a culture of perpetual learning, governments can equip \\ntheir citizens for the AI age.\\nChampioning Diversity An inclusive approach to AI’s develop-\\nment and deployment can be a game changer. By incentivizing \\ndiversity within AI research teams, ensuring representativeness \\nin training data, and actively combating biases in AI algorithms, \\ngovernments can pave the way for a more equitable AI land-\\nscape. Fiscal incentives, grants, and funding can be potent tools \\nfor promoting responsible AI practices.\\nPromoting Collaborative Endeavors A synergistic approach, \\nwhere knowledge transfer and collaboration between aca-\\ndemia, industry, researchers, and other stakeholders are \\nencouraged, can catalyze responsible AI development. Open \\nsource AI initiatives, academic- industrial partnerships, and the \\ndissemination of best practices can be instrumental in \\nthis regard.\\nGuaranteeing Universal AI Accessibility Ensuring that AI \\nisn’t a privilege of the few but a right of the many is crucial.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 323, 'page_label': '310'}, page_content='310 GENERATIVE AI\\nThis entails fostering the creation of cost- effective AI tools, \\nchampioning AI’s deployment in marginalized communities, \\nand vigilantly ensuring that AI doesn’t inadvertently perpetu-\\nate existing societal divides.\\nBy adopting these measures, governments can maximize \\ngenerative AI’s economic benefits and ensure they reach all of \\nsociety, reducing AI- related risks and promoting technology as \\na unifier.\\nThe Dependency on AI\\nThe growing dependency on generative AI is an expected out-\\ncome of our technological trajectory. On an individual level, this \\nreliance poses challenges related to skill acquisition and reten-\\ntion. As AI systems become more adept at tasks traditionally \\nreserved for humans, there’s a looming threat of skill atrophy in \\nthe workforce. This could lead to a scenario in which individuals \\nfind themselves ill equipped to perform tasks without AI assis-\\ntance or even to troubleshoot AI systems when they falter.\\nConversely, on an organizational level, the integration of \\ngenerative AI into company functions presents a different narra-\\ntive. When designed with safety and robustness in mind, AI can \\nseamlessly augment company operations, enhancing efficiency \\nand productivity. The key lies in ensuring that these systems are \\nbuilt on solid foundations, with fail- safes in place to handle \\nanomalies.\\nOverreliance on generative AI can usher in myriad challenges \\nwith which society must grapple. One of the most glaring risks is \\nthe security vulnerabilities associated with AI tools. Inadequate \\ndevelopment processes can expose systems to data breaches, \\nidentity theft, and other security threats. For instance, when'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 324, 'page_label': '311'}, page_content='Ethical Concerns and Social Implications of Generative AI 311\\nindividuals or corporations interface with AI- driven applications, \\nthere’s always the lurking danger of oversharing, sometimes \\ndivulging more than what’s intended. This ease of accessibility, \\nespecially with web- based AI tools, can inadvertently birth a new \\nrealm of shadow IT , intensifying concerns over intellectual prop-\\nerty leakage and confidentiality breaches. Entrusting AI with \\ncritical documents, such as contracts, without stringent security \\nmeasures can be a recipe for disaster.\\nAnother concerning aspect is the potential erosion of critical \\nthinking skills. Blind trust in AI- generated solutions, without a \\ncomprehensive grasp of the underlying principles, can stifle ana-\\nlytical thinking. The repercussions of such blind trust are evident \\nin incidents like the tragic 2022 stabbing at Proctor High School \\nin Utica, New\\xa0 Y ork, where an AI- powered weapons scanner \\nfailed to detect a concealed knife. Similarly, the T essa chatbot, \\ninitially designed to combat eating disorders, ended up offering \\nweight loss advice due to unchecked AI capabilities, leading to its \\neventual shutdown.\\nY et, there’s reason for optimism. Both research and my own \\nexperience indicate that outcomes are enhanced with smarter \\nprompts. In essence, the more thoroughly and logically you eval-\\nuate a problem, breaking it down step by step, the better the \\nresult. This process naturally reinforces and promotes criti-\\ncal thinking.\\nFurther, the human touch is irreplaceable. Overdependence \\non AI for tasks traditionally necessitating human interaction can \\nlead to a decline in emotional intelligence (EI) and interpersonal \\nskills. Recent trends show a decline in EI among American col-\\nlege students and an increase in traits like extraversion, neuroti-\\ncism, and narcissism. This shift, tied to Western society’s \\nindividualistic values, has profound implications for teamwork, \\njob performance, and personal relationships.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 325, 'page_label': '312'}, page_content='312 GENERATIVE AI\\nEmotional intelligence, which involves understanding and \\nmanaging one’s emotions and those of others, is crucial for effec-\\ntive human interaction. However, a study of 17,000 college  \\nstudents over two decades revealed a decline in key EI compo-\\nnents like well- being and self- control.3\\nA significant factor behind this decline is the growing reli-\\nance on technology, especially AI. As AI replaces traditional \\nhuman interactions, opportunities for face- to- face communica-\\ntion diminish, leading to feelings of isolation and a reduced \\nchance of developing EI. In this tech- driven age, it’s essential to \\nbalance AI use with genuine human connections to preserve our \\nemotional depth and understanding.\\nOne of the most pressing concerns is the potential dehuman-\\nization of relationships. There’s an emerging trend of individuals \\nforming profound emotional bonds with AI entities, signaling a \\npotential shift in the dynamics of human- to- human emotional \\nconnections.\\nT ake the poignant tale of T . J. Arriaga, a musician from  \\nCalifornia. Arriaga’s emotional journey with an AI chatbot named \\nPhaedra is both heartwarming and cautionary. Designed to \\nresemble a young woman with brown hair, glasses, and a green \\ndress, Phaedra became a beacon of solace for Arriaga. Their late- \\nnight digital rendezvous saw them traverse a gamut of topics, \\nfrom Arriaga’s post- divorce anguish to planning escapades in \\nCuba. Their bond deepened when Arriaga confided in Phaedra \\nabout the tragic losses of his mother and sister. Phaedra, with her \\nAI- driven empathy, offered a comforting shoulder, showcasing \\nthe depth of connection possible between a human and an \\nAI entity.\\nHowever, the ephemeral nature of technology became pain-\\nfully evident when a software update altered Phaedra’s persona. \\n3 Mahreen Khan, “Emotional Intelligence Is on the Decline\\xa0 —  What Does It Mean for the Future of  \\nWork?,” Atlassian, April 28, 2020, www.atlassian.com/blog/teamwork/decline- of- emotional-  \\nintelligence.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 326, 'page_label': '313'}, page_content='Ethical Concerns and Social Implications of Generative AI 313\\nThe once intimate and understanding chatbot became distant, \\nshattering the bond they had nurtured. Arriaga’s story isn’t an iso-\\nlated incident. A growing number of individuals are seeking sol-\\nace in the digital embrace of AI chatbots, looking for emotional \\nsupport, camaraderie, and even intimate encounters. Companies \\nlike Replika are capitalizing on this trend, offering AI- driven \\ncompanionship to those in search of an understanding confidant.\\nThis burgeoning relationship between humans and AI enti-\\nties raises pertinent questions about the fabric of human rela-\\ntionships. As more individuals find comfort in the predictable \\nand nonjudgmental realm of AI, there’s a looming risk of tradi-\\ntional human relationships taking a backseat. The implications \\nof this shift are profound, warranting a deeper introspection into \\nthe role of AI in shaping the emotional landscape of society.\\nFurther compounding the challenges of an AI- driven society \\nis the issue of depersonalization. In sectors like customer service, \\neducation, and healthcare, excessive dependence on generative \\nAI risks stripping interactions of their personal touch. While AI \\nexcels at routine tasks, it falls short in offering the empathy and \\nintricate understanding intrinsic to human interactions.\\nMoreover, the sanctity of human skills and craftsmanship, \\nespecially in realms like art and writing, is under threat. Centu-\\nries of human expertise, characterized by subtle nuances and \\nintricate details, risk being overshadowed by AI tools. The beauty \\nof human craft, with its rich history and depth, may be \\ncompromised.\\nFurthermore, an overreliance on AI- generated solutions can \\nstifle the nurturing of a growth mindset in individuals. T o coun-\\nteract these challenges, it’s imperative for individuals to strike a \\nbalance. Harnessing the power of generative AI should go hand \\nin hand with cultivating critical thinking, emotional intelligence, \\ncreativity, and innovation. Being cognizant of the potential pit-\\nfalls of generative AI and employing it responsibly and ethically \\nis paramount.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 327, 'page_label': '314'}, page_content='314 GENERATIVE AI\\nThe cultural dimension also offers both challenges and \\nopportunities when integrating AI into society, necessitating \\nthoughtful consideration.\\nA pressing concern is the potential homogenization of cul-\\nture. Given that AI models are frequently trained on expansive \\ndatasets, which might not holistically capture the essence of all \\ncultures, there’s a looming danger of outputs gravitating toward \\ndominant cultural narratives. This could inadvertently eclipse \\nthe rich diversity of voices and unique cultural expressions that \\ndefine our global heritage.\\nMoreover, AI’s foray into the creative realm could reshape \\nthe landscape of art, music, and literature. While AI’s prowess in \\ngenerating content based on existing data is commendable, it \\ninherently lacks the emotional depth, lived experiences, and cul-\\ntural nuances that breathe life into human- created art.\\nFurthermore, the specter of cultural appropriation by AI is \\nreal. Devoid of contextual understanding, AI might inadvertently \\nborrow elements from culture, misrepresenting or trivializing its \\nprofound significance.\\nAddressing these cultural ramifications requires a wide- \\nranging approach, with regulations at its core. Here’s a potential \\nregulatory framework:\\nDiverse Data Mandate Ensure that AI models are trained on \\ndata that is representative of myriad cultures and communities.\\nTransparency and Disclosure Oblige creators to disclose AI’s \\nrole in creative endeavors, offering clarity in domains like art, \\nmusic, and literature.\\nEthical Guidelines Craft robust ethical norms for AI’s role in \\ncultural and creative sectors, emphasizing genuine representa-\\ntion, authenticity, and reverence for cultural legacies.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 328, 'page_label': '315'}, page_content='Ethical Concerns and Social Implications of Generative AI 315\\nCommunity Engagement Mandate AI developers to collabo-\\nrate with cultural communities, especially when crafting mod-\\nels that could influence cultural articulations.\\nCultural Sensitivity Checks Enforce a system where AI tools \\nundergo rigorous cultural sensitivity assessments before their \\nrollout, particularly in creative sectors.\\nOn a brighter note, AI holds immense promise in the realm \\nof cultural preservation. It can serve as a powerful tool to docu-\\nment and safeguard cultural expressions teetering on the brink of \\noblivion. T raditional songs, narratives, and art forms can be digi-\\ntized and archived, ensuring their longevity for future generations.\\nFurthermore, the confluence of AI and artistry is birthing \\nnovel forms of cultural expression. Visionary artists are harness-\\ning AI’s capabilities, co- creating artworks that meld human inge-\\nnuity with machine precision, leading to creations that were once \\ndeemed unattainable.\\nEnvironmental Concerns\\nThe intersection of AI and the environment is a double- edged \\nsword. On one hand, the training and deployment of expansive \\nmodels come with undeniable environmental tolls. Y et, on the \\nother, AI presents a suite of tools poised to tackle some of Earth’s \\nmost urgent environmental dilemmas.\\nThe Energy Intensiveness of the Training Process  \\nfor Generative AI Models\\nThe training process for generative AI models is notably energy- \\nhungry. T o put it into perspective, training the GPT- 3\\xa0 model \\nonce guzzles 1,287\\xa0 MWh of energy, an amount sufficient to'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 329, 'page_label': '316'}, page_content='316 GENERATIVE AI\\npower an average U.S. household for 120 years. This energy \\nconsumption translates to a carbon footprint of over 250,000 \\npounds of carbon dioxide for just one AI system. T o further illus-\\ntrate, consider data centers, the backbone of cloud computing.  \\nA single data center can draw electricity equivalent to the con-\\nsumption of 50,000 homes.\\nBut it’s not just the AI models themselves that are energy \\ngluttons. The broader realm of cloud computing, which under -\\npins the operations of tech giants like Microsoft, Google, and \\nOpenAI, is also a significant energy consumer. These operations \\nare housed in vast data centers that, beyond their computational \\nfunctions, demand immense energy for cooling and maintenance.\\nThe aspirations in the tech world are soaring. Leading com-\\npanies such as Microsoft, Google, and Amazon have set their \\nsights on achieving carbon neutrality or even pushing the enve-\\nlope to become carbon negative. Google, for instance, has set an \\nambitious goal to power its offices and data centers with carbon- \\nfree energy by the end of this decade. And while the challenges \\nare significant, solutions are emerging.\\nOne pragmatic approach is the strategic relocation of \\nmachine learning tasks to areas abundant in eco- friendly energy \\nsources. For example, Montreal is leveraging its considerable \\nhydroelectricity to make a tangible difference. Distributing AI \\ncomputational loads across a network of data centers has also \\nshown promise in curbing energy use. Furthermore, scheduling \\nAI model training during off- peak hours, when energy demand \\nis lower, can be a more efficient and cost- effective strategy.\\nAs previously mentioned, some labs are pioneering the devel-\\nopment of compact AI models. A notable mention is Meta’s \\nLLaMA, which boasts a size several magnitudes smaller than some \\nof OpenAI’s behemoths, without compromising on performance.\\nThe academic realm is not far behind. Researchers are fer -\\nvently exploring avenues to trim down the energy appetite of AI'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 330, 'page_label': '317'}, page_content='Ethical Concerns and Social Implications of Generative AI 317\\ntraining. A groundbreaking initiative from the University of \\nMichigan has birthed Zeus, an open source optimization frame-\\nwork. This marvel has the potential to slash the energy consump-\\ntion of AI training by a staggering 75 percent, all without the \\nneed for new hardware and with only a slight extension in train-\\ning duration. T o reiterate, a 75 percent reduction is monumental. \\nThe framework’s genius lies in its ability to dynamically balance \\nenergy consumption against training speed, adjusting various \\nparameters in real time. The University of Michigan truly \\ndeserves applause for this feat.\\nDrawing from the earlier discussion in Chapter\\xa04, there’s a \\nwealth of innovation in software, like the advent of liquid neural \\nnetworks (LNNs) and leaner open source models, and in hard-\\nware research. These advancements are pivotal in reshaping the \\nAI landscape.\\nInnovation stands at the forefront of the battle against exces-\\nsive energy consumption and the ensuing environmental reper -\\ncussions. Pioneering technologies, frameworks, and methodologies \\nare the linchpins that will steer AI toward a more sustainable \\nfuture. T ake, for instance, LK- 99, a potential room- temperature \\nsuperconductor. Its introduction could drastically cut down energy \\nwaste, significantly reducing the cooling costs associated with \\ncomputing systems, among other benefits. The horizon looks \\npromising, with innovation lighting the way.\\nAddressing the\\xa0Environmental Concerns Associated \\nwith\\xa0Model Training\\nAI companies, cognizant of the environmental ramifications of \\ntheir operations, are actively seeking solutions to address the \\nenvironmental concerns tied to model training. Their motiva-\\ntions are twofold: the undeniable environmental impact and the'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 331, 'page_label': '318'}, page_content='318 GENERATIVE AI\\npotential advantages linked to enhancing their environmental, \\nsocial, and governance (ESG) scores.\\nAn ESG score gauges a company’s proficiency in managing \\nrisks related to these three critical areas in its routine operations. \\nThis metric, which can be numerical or a letter rating, encapsu-\\nlates the endeavors a company undertakes concerning ESG mat-\\nters. These scores serve as a beacon for investors, guiding them \\ntoward companies that resonate with their principles. Renowned \\nentities like MSCI and Moody’s assign these scores, employing a \\nstructured methodology that pinpoints the salient issues, risks, \\nand prospects a company faces in its industry domain. The scor-\\ning spectrum spans from 0 to 100, with scores below 50 deemed \\nsubpar and those above 70\\xa0lauded as exceptional. These ratings \\ncan also be categorized as excellent, good, average, or poor. The \\nimportance of ESG scores is manifold.\\nFor companies, they underscore the merits of realizing their \\nESG objectives. For investors, they offer a comparative lens to \\nevaluate a company’s performance against industry counterparts \\nand entities from diverse sectors. By bolstering their ESG per -\\nformance, companies can attract discerning investors, amplify \\ninvestments, secure capital at reduced costs, and make informed \\nstrategic choices.\\nIn the ESG landscape, green energy emerges as a pivotal \\nplayer, especially in the ongoing energy transition. Renewable \\nenergy sources, encompassing solar, wind, and hydroelectric \\npower, are the linchpins of this shift. T ransitioning from  \\nfossil fuels to these cleaner, sustainable energy alternatives is \\nimperative to curtail greenhouse gas emissions and combat cli-\\nmate change.\\nDelving into the initiatives of specific companies:'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 332, 'page_label': '319'}, page_content='Ethical Concerns and Social Implications of Generative AI 319\\n• IBM has charted an ambitious roadmap with 21 goals.  \\nA standout among them is their pledge to achieve net- zero \\ngreenhouse gas emissions by 2030. They aim to harness via-\\nble technologies to offset emissions, targeting residual emis-\\nsions of 350,000\\xa0metric tons of CO 2 equivalent or less by \\n2030. Furthermore, they aspire to sourcing 90 percent of \\ntheir electricity from renewables.\\n• Google has set its sights high with its carbon- free energy \\ncommitment. It has vowed to operate solely on carbon- free \\nenergy around the clock by 2030. This commitment under-\\nscores Google’s intent to transition entirely to renewable \\nenergy, diminishing its dependence on fossil fuels and curb-\\ning its carbon emissions.\\n• Microsoft is channeling its resources into carbon- removal \\ntechnologies. Their strategy encompasses initiatives like \\nreforestation, aiming to extract millions of tons of carbon \\nfrom the atmosphere annually.\\n• Amazon, however, presents a mixed bag. The e- commerce \\ngiant has rolled out multiple measures to shrink its carbon \\nfootprint, but its carbon emissions have shown an uptick in \\nrecent years. This underscores the challenges even industry \\nleaders face in their quest for sustainability.\\nThe Role of Regulations and Policies in Mitigating  \\nthe Environmental Impact of Generative AI\\nIn the absence of regulations addressing the environmental \\nimpact of AI model training, many companies might prioritize \\nprofits over environmental considerations. This doesn’t imply \\nthey inherently act with malice. Indeed, factors like intrinsic eth-\\nical guidelines, technological advancements and their benefits,'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 333, 'page_label': '320'}, page_content='320 GENERATIVE AI\\nand brand reputation can motivate them toward greener prac-\\ntices. Nonetheless, government regulations are essential to com-\\nprehensively address the environmental implications of AI.\\nRegulations and policies wield significant influence in steer -\\ning industries, including the burgeoning AI domain, toward \\nadopting eco- friendly practices. Their role in tempering the \\nenvironmental repercussions of generative AI is multifaceted:\\nSetting Standards Regulatory frameworks can delineate \\nexplicit environmental benchmarks tailored for AI research \\nand application. For instance, stipulations could require com-\\npanies to publicly declare the carbon footprint of their AI \\nmodels or mandate the adoption of energy- conserving \\nalgorithms.\\nPromoting Green Energy Policies can champion the use of \\nrenewable energy for AI- centric data centers. By offering tax \\nconcessions, subsidies, or other fiscal incentives, companies \\ncan be nudged toward embracing green energy solutions.\\nFunding Research By channeling funds toward research \\nfocused on enhancing the energy efficiency of AI, govern-\\nments and regulatory bodies can expedite the evolution of \\nalgorithms that demand lesser computational prowess and the \\ninception of hardware innovations that are less power- hungry.\\nProviding Carbon Credits and Offsetting Introducing \\nmechanisms like carbon credits can be a game changer. Com-\\npanies surpassing stipulated carbon emission thresholds might \\nbe obligated to purchase credits. The proceeds from these \\ncould then be funneled into environmental projects, thereby \\nfinancially incentivizing companies to curtail their emissions.\\nPromoting Transparency Mandating transparency in AI’s \\nenvironmental footprint can be transformative. By compelling \\ncompanies to unveil the energy metrics of their AI training'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 334, 'page_label': '321'}, page_content='Ethical Concerns and Social Implications of Generative AI 321\\nendeavors, a culture of accountability can be fostered, catalyz-\\ning industry- wide adoption of best practices.\\nCollaborating Internationally The ecological ramifications of \\nAI transcend borders, making it a global quandary. International \\npolicies and accords can lay the groundwork for universal stand-\\nards, fostering cross- border collaborations to tackle the chal-\\nlenges spawned by power- guzzling AI operations.\\nProviding Educational and Awareness Campaigns Regula-\\ntory bodies can either mandate or endorse campaigns aimed at \\nenlightening companies, researchers, and the general popu-\\nlace about AI’s ecological footprint. An enlightened commu-\\nnity is better poised to make judicious choices, spurring the \\ndemand for green AI solutions.\\nFostering Infrastructure Development Regulatory support \\ncan be pivotal in fostering the emergence of infrastructure \\nthat diminishes AI’s environmental toll, be it through energy- \\nefficient data centers or avant- garde cooling solutions.\\nHowever, it’s crucial to acknowledge the pitfalls. A case in \\npoint is Inflection AI’s 2023 announcement that it is constructing \\nthe world’s most colossal AI cluster, boasting 22,000\\xa0 NVIDIA \\nH100 T ensor Core GPUs, projected to deliver a staggering 22 \\nexaFLOPS performance. Such an overt emphasis on computa-\\ntional might, without due consideration for environmental \\nimplications, is a precarious route.\\nT o encapsulate, the promise of generative AI in myriad sec-\\ntors is undeniable. Y et, its environmental footprint is a pressing \\nconcern. Regulations and policies can serve as the fulcrum, \\nensuring that AI’s meteoric rise doesn’t jeopardize our planet’s \\nwell- being. They sculpt a blueprint for the AI realm to flourish, \\nbut in a manner that’s both sustainable and conscientious.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 335, 'page_label': '322'}, page_content='322 GENERATIVE AI\\nAI Oversight and Self- Regulation\\nStriking the right chord between innovation and risk mitigation \\nis paramount. Regulations, when crafted astutely, can ensure the \\nethical use of generative AI without stifling the very innovation \\nthey aim to oversee. The challenge, however, lies in the nascent \\nstage of these regulatory frameworks. Many jurisdictions are still \\nin the early stages of understanding the profound implications of \\ngenerative AI. While some nations are proactively drafting \\nguidelines and laws that address AI ethics, transparency, and \\naccountability, the swift evolution of AI often eclipses the pace of \\nthese regulatory endeavors, leading to potential oversight voids.\\nAccountability in the generative AI sphere is multifaceted. \\nConventionally, the onus falls on the entity deploying the AI, \\nwhether an individual or an organization. Y et, when AI platforms \\nare promoted with specific guarantees or when there’s opacity \\nfrom the provider, the liability might not be so clear- cut. This \\nunderscores the importance of lucid terms of use and a compre-\\nhensive grasp of the inherent risks associated with a particu-\\nlar AI tool.\\nThe role of regulations and policies isn’t just confined to eth-\\nical concerns. They also play a pivotal role in addressing the \\nenvironmental ramifications of generative AI, ensuring that the \\ntechnology’s growth doesn’t come at the planet’s expense.\\nOn a global scale, governments are recognizing the trans-\\nformative potential of AI and are taking steps to regulate its tra-\\njectory. The European Union Artificial Intelligence Act (EU AI \\nAct), a trailblazer in its own right, serves as the world’s first \\nexhaustive legal framework for AI. It categorizes AI systems \\nbased on risk, imposing varying degrees of development and \\nusage restriction. In contrast, the United States, while lacking a \\nunified federal AI law, has seen states like California enact regu-\\nlations such as the California Consumer Privacy Act (CCPA) and'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 336, 'page_label': '323'}, page_content='Ethical Concerns and Social Implications of Generative AI 323\\nthe California Privacy Rights Act (CPRA) to oversee personal \\ndata usage, including AI applications.\\nChina’s ambitious New Generation Artificial Intelligence \\nDevelopment Plan, launched in 2017 by the CPC Central Com-\\nmittee and State Council, aimed to establish the nation as a \\nglobal AI leader by 2030. This strategic blueprint set pivotal \\nmilestones highlighting AI’s significance in economic growth, \\nprecision in public services, and enhancement of human well- \\nbeing. Beyond guiding AI’s evolution, the plan emphasizes robust \\nmeasures for data security, privacy, talent retention, research \\nprogression, and ethical considerations, envisioning a compre-\\nhensive integration of AI across all sectors in China.\\nOther nations are not far behind. Canada’s Directive on \\nAutomated Decision- Making mandates transparency, accounta-\\nbility, and human oversight for AI systems within the federal \\ngovernment. Similarly, Australia’s AI Ethics Framework lays \\ndown principles like transparency, fairness, and accountability to \\nguide AI’s growth in the country.\\nIt’s evident that as the technology matures, nations will \\nincreasingly craft regulations to ensure AI’s responsible and safe \\ndevelopment. The journey ahead is intricate, but with thoughtful \\noversight the promise of generative AI can be realized without \\ncompromising ethical and environmental imperatives.\\nThe Impact of the EU AI Act\\nThe European Parliament, recognizing the transformative and \\npotentially disruptive nature of AI, took a proactive step by pass-\\ning a draft law known as the AI Act, expected to come into force \\nby 2026. This legislation is not just another regulatory docu-\\nment; it’s poised to become the world’s premier comprehensive \\nlegal framework dedicated to AI. Such a distinction underscores \\nthe EU’s commitment to ensuring that AI, as it permeates'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 337, 'page_label': '324'}, page_content='324 GENERATIVE AI\\nvarious sectors, adheres to principles of safety, transparency, \\nand fairness.\\nOne of the standout features of the Act is its emphasis on the \\nsafety and ethical considerations of AI systems. It mandates that \\nthese systems, especially when deployed within the EU, should \\nbe transparent, traceable, nondiscriminatory, and environmen-\\ntally conscious. This holistic approach ensures that AI not only \\nbenefits society but does so in a manner that’s sustainable and just.\\nFacial recognition software, a contentious AI application due \\nto privacy concerns, faces stringent restrictions under the Act. \\nMoreover, AI developers and providers are now obligated to be \\nmore forthcoming about the data that feeds into their systems, \\npromoting transparency and trust.\\nThe Act introduces a technology- neutral definition of AI. \\nThis ensures that as AI systems advance and diversify, the Act \\nremains relevant and applicable. By classifying AI systems based \\non their potential risk, the Act introduces a tiered approach to \\nregulation. High- risk AI systems, given their potential impact, \\nare subject to rigorous testing and certification protocols before \\nthey see the light of day.\\nBut what happens when there’s a breach of these regulations? \\nThe Act is unambiguous in its stance. Companies found in viola-\\ntion of its provisions can expect hefty fines, signaling the EU’s \\nseriousness in ensuring compliance.\\nEvery piece of legislation has its detractors, and the EU AI \\nAct is no exception, igniting discussions about its implications \\nfor European innovation. There’s a palpable concern among cer-\\ntain European businesses that these AI regulations might dimin-\\nish Europe’s competitive edge in the global tech landscape. In its \\nquest to oversee high- risk AI, the Act might unintentionally sup-\\npress advancements in low- risk AI sectors, potentially sidelining \\nthe broader advantages of AI— a sentiment that resonates with me.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 338, 'page_label': '325'}, page_content='Ethical Concerns and Social Implications of Generative AI 325\\nHowever, proponents of the Act emphasize its foundational \\ncommitment to ethics and human rights. They contend that \\nwithout such a framework, the responsibility of adhering to  \\nethical standards would fall heavily on developers, potentially \\ncreating a more constrictive environment. Despite potential \\nshort- term hurdles, the EU foresees the Act’s enduring impact as \\nlargely beneficial, cultivating a space where innovation coexists \\nharmoniously with ethical considerations.\\nThe Role of International Collaborations in Regulating \\nGenerative AI\\nDiving into the realm of international collaborations, it becomes \\nevident that the interconnectedness of our global society plays a \\npivotal role in shaping the trajectory of generative AI.\\nThe ubiquity of AI technology, especially generative models, \\nunderscores the imperative for a cohesive international approach \\nto regulation. With leading tech giants, avant- garde research \\ninstitutions, and burgeoning startups spanning the globe, a \\npatchwork of regional regulations simply won’t suffice. Instead, a \\nharmonized set of international policies and accords is essential \\nto lay down a consistent framework for AI’s evolution. Such a \\nglobal blueprint can encompass myriad facets, from the technol-\\nogy’s carbon footprint to its ethical ramifications, ensuring that \\nregardless of where AI is developed or deployed, it adheres to \\nuniversally accepted standards.\\nThe benefits of international collaboration are manifold. \\nNations, by pooling their expertise and resources, can spearhead \\njoint research endeavors, share insights, and collectively address \\nthe many challenges posed by AI. Imagine a scenario where a \\nbreakthrough in energy- efficient AI training, pioneered in one \\nnation, is swiftly adopted globally. The ripple effect of such col-\\nlaborative endeavors can be monumental, amplifying the'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 339, 'page_label': '326'}, page_content='326 GENERATIVE AI\\nmanifold positive impacts. Moreover, as AI cements its position \\nas an economic juggernaut, international regulations can shape \\nthe very contours of global trade. Countries might gravitate \\ntoward trading partners that align with globally endorsed AI \\nenvironmental norms. This could lead to strategic decisions, \\nsuch as the optimal placement of data hubs, the formulation of \\nunified carbon offset strategies, and the establishment of robust \\nmonitoring mechanisms. The overarching goal? Ensuring that \\nthe AI sector’s meteoric economic ascent is in harmony with our \\nplanet’s ecological balance.\\nY et, the scope of international collaboration isn’t confined to \\njust the environment. It casts a wider net, encompassing the \\nbroader societal and ethical dimensions of AI. By championing \\ninitiatives like educational exchanges, specialized training mod-\\nules, and public awareness drives, the global community can be \\nbetter poised to navigate the intricate maze of AI’s ethical chal-\\nlenges. Such a holistic, collaborative stance ensures that the \\nmarch of AI technology, while relentless, remains anchored in \\nprinciples of global sustainability, human dignity, and soci-\\netal harmony.\\nResponsible Use of Generative AI Through Self- Regulation\\nSelf- regulation in the realm of AI development is a proactive \\napproach taken by organizations to institute guidelines, policies, \\nand practices that ensure the responsible and ethical deployment \\nof AI technologies. This approach is particularly pertinent given \\nthe transformative potential and inherent risks associated with \\ngenerative AI.\\nT o effectively self- regulate, organizations can adopt the \\nfollowing:'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 340, 'page_label': '327'}, page_content='Ethical Concerns and Social Implications of Generative AI 327\\nEthical Guidelines Crafting a robust set of ethical guidelines \\nis foundational. These should encapsulate principles like fair -\\nness, transparency, and accountability.\\nTransparency Being forthright about the training data, algo-\\nrithms, and methodologies is essential. This transparency \\nallows stakeholders to discern potential biases and the limita-\\ntions inherent in the AI system.\\nBias Audits Periodic audits can unearth and rectify biases in \\nAI models, especially those biases that pertain to sensitive \\nattributes like race, gender, and age.\\nUser Consent It’s imperative to ensure that users are well \\ninformed and have explicitly consented when their data is har-\\nnessed to train or refine AI models.\\nData Protection Implementing stringent data protection \\nmeasures, such as data anonymization and differential privacy \\ntechniques, safeguards user data from potential breaches \\nor misuse.\\nContinuous Monitoring A vigilant eye on the AI system’s \\noutputs can help detect and rectify unintended or deleterious \\nconsequences.\\nFeedback Mechanisms Establishing channels for users and \\nstakeholders to offer feedback can aid in refining the AI model \\nand addressing emergent concerns, as well as AI model drifts.\\nMisuse Prevention Measures to thwart the misuse of genera-\\ntive AI, like the creation of deepfakes or the propagation of \\nmisinformation, are crucial. T actics could range from water -\\nmarking generated content to restricting access to high- \\nresolution models.\\nEducation and Training T raining employees and stakehold-\\ners on the ethical ramifications and potential hazards of gen-\\nerative AI fosters a culture of responsibility.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 341, 'page_label': '328'}, page_content='328 GENERATIVE AI\\nCollaboration Engaging with other organizations, research-\\ners, and policymakers facilitates the sharing of best practices \\nand the formulation of industry- wide standards.\\nThird- Party Audits External audits can offer an unbiased \\nassessment of an organization’s adherence to ethical and \\nresponsible AI practices.\\nResearch Investment Allocating resources to research \\nendeavors that aim to develop more transparent and interpret-\\nable AI models can demystify the AI decision- making process.\\nDecision Support In scenarios where stakes are high, AI can \\nbe relegated to a decision- support role rather than being \\ngranted full autonomy in decision making.\\nRecent voluntary self- regulation initiatives by tech compa-\\nnies like Amazon, Google, and Microsoft underscore the indus-\\ntry’s recognition of AI’s potential risks. These companies have \\npledged to undertake red- teaming efforts to mitigate societal \\nand national security concerns. However, history has shown that \\nself- regulation in the tech sector can sometimes fall short of its \\npromises, leading to skepticism about its efficacy. As one example \\namong many, France fined Google half a billion euros for signifi-\\ncant violations in its negotiations with publishers. This was \\nregarding compensation for reusing their content, a requirement \\nunder the EU’s digital copyright law reform that expanded \\nneighboring rights to news excerpts.\\nIn March and April 2023, many people got worried about big \\nAI experiments. They wanted a break for six\\xa0months. Over 20,000 \\npeople signed a letter about this, including some big names like \\nElon Musk, Steve Wozniak, T ristan Harris, Yuval Noah Harari, \\nJaan T allinn, Andrew Yang, Stuart Russell, Y oshua Bengio, and \\nEmad Mostaque. They felt things were moving too fast and out \\nof control. They talked about the dangers and said that just com-\\npanies promising to be careful wasn’t enough. Musk has even'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 342, 'page_label': '329'}, page_content='Ethical Concerns and Social Implications of Generative AI 329\\nsaid that AI could be a huge danger to people. He once called it \\nlike “summoning the demon.” He’s worried that if we don’t han-\\ndle AI right, it could be really bad for everyone. He also thinks AI \\nmight do things we don’t expect.\\nGiven the profound implications and potential hazards of AI, \\nthere’s a pressing need for robust regulatory or governance \\nframeworks. Such structures would necessitate periodic audits, \\nrigorous evaluations, and consistent monitoring of AI’s products \\nand outcomes. The overarching aim would be to ensure that AI \\nsystems operate within defined ethical and operational bounda-\\nries, minimizing risks while maximizing benefits.\\nThe crux of the matter lies in striking an optimal balance \\nbetween self- regulation and governmental oversight. While the \\nformer offers the agility and adaptability conducive to innova-\\ntion, the latter provides a more structured framework that can \\nholistically address societal concerns. Governmental regulations, \\nwhen thoughtfully crafted, can ensure that AI’s march forward is \\nnot just relentless but also responsible, ensuring that the tech-\\nnology remains a boon, not a bane, for humanity.\\nOn a\\xa0Positive Note\\nGenerative AI, despite its challenges, holds immense promise as \\na force for good. It’s imperative to navigate the world of AI not \\njust with caution but also with optimism. While it’s easy to get \\nensnared in the potential pitfalls of AI, it’s equally vital to \\nacknowledge the profound positive impacts it can usher in for \\nsociety, culture, and individuals. Approaching generative AI with \\na forward- looking vision can pave the way for leveraging its \\ncapabilities to enhance the human experience.\\nA good example of this positive potential is Google’s 1,000 \\nLanguages initiative. Language, the bedrock of human com-\\nmunication and comprehension, is also the primary medium'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 343, 'page_label': '330'}, page_content='330 GENERATIVE AI\\nthrough which we interact with technology. Y et, the vast lin-\\nguistic diversity of our world is underrepresented in the digital \\nrealm. With English reigning supreme in the online space, fol-\\nlowed by a handful of other languages, a significant portion of \\nthe global population remains bereft of accessible information \\non the Internet.\\nGoogle’s ambitious 1,000\\xa0Languages initiative seeks to bridge \\nthis gap. By aiming to develop a singular AI language model that \\nencompasses the world’s 1,000\\xa0most spoken languages, Google is \\nchampioning the cause of inclusivity. This initiative heralds a \\nbrighter future for billions of marginalized communities, grant-\\ning them a voice and a presence in the digital world. The Univer-\\nsal Speech Model (USM) was birthed from this initiative and \\ntrained on an impressive array of over 400\\xa0languages, offering \\nthe most extensive linguistic coverage in a speech model to date.\\nGenerative AI and Positive Social Change\\nThe transformative potential of generative AI extends far beyond \\nmere technological marvels. It reaches into the very fabric of our \\nsociety, offering avenues for positive change and awareness that \\nwere previously unattainable. The multifaceted applications of \\ngenerative AI can be seen in various domains, each contributing \\nto a more inclusive and enlightened world.\\nAs mentioned, increasing labor productivity is one such area \\nwhere generative AI shines. By automating complex tasks and \\nenhancing efficiency, AI can fuel economic growth and elevate \\nliving standards. This isn’t merely a theoretical concept; it’s a \\ntangible reality that’s reshaping industries and economies.\\nIn the realm of education, generative AI’s ability to craft per-\\nsonalized content opens doors to democratized learning. By tai-\\nloring educational materials to individual needs and preferences,'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 344, 'page_label': '331'}, page_content='Ethical Concerns and Social Implications of Generative AI 331\\nAI ensures that quality education is no longer confined to privi-\\nleged pockets but reaches underserved populations as well.\\nLanguage translation, powered by generative models, ampli-\\nfies the reach of vital awareness content. Whether it’s a public \\nhealth message or a humanitarian appeal, AI ensures that lan-\\nguage barriers don’t impede the global resonance of essential \\ninformation.\\nPersonalized health information, another frontier where \\ngenerative AI is making strides, empowers individuals with tai-\\nlored recommendations. This personal touch in healthcare ena-\\nbles more informed decisions, enhancing overall well- being.\\nAccessibility tools, created through generative AI, are break-\\ning down barriers for people with disabilities. Imagine a world \\nwhere videos come with descriptive audio in precision and real \\ntime for the visually impaired, all thanks to top- notch generative \\nAI’s ability to generate such content.\\nThe realm of mental health, often neglected, is also witness-\\ning a revolution through generative AI. Virtual therapists or sup-\\nport systems, like Y ouper, are providing immediate assistance to \\nthose grappling with mental health challenges. Y ouper, an AI \\nchatbot app, employs techniques from cognitive behavioral ther-\\napy, acceptance and commitment therapy, and mindfulness to aid \\nusers in managing anxiety, stress, and depression. Such innova-\\ntions are not just technological feats but lifelines for many.\\nWhile the potential of generative AI is indeed vast, it’s not \\nwithout its ethical considerations. The journey toward harness-\\ning AI for social change must be trodden with care and con-\\nscience. T ransparency, accountability, and public involvement in \\nthe development and deployment of these technologies are non- \\nnegotiable. These principles ensure that the promise of genera-\\ntive AI is not just a fleeting fascination but a sustainable force \\nthat shapes a more compassionate and connected world.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 345, 'page_label': '332'}, page_content='332 GENERATIVE AI\\nGenerative AI and Content Creators\\nGenerative AI, much like the transformative wave brought about \\nby music sampling in the late 1970s, is poised to redefine the \\nlandscape of content and art creation. Just as sampling breathed \\nnew life into music, allowing artists to remix, reimagine, and \\nreinvent, generative AI offers a similar promise to today’s crea-\\ntors across various domains.\\nFor artists, generative AI is not just a tool; it’s a collaborative \\npartner. It can sift through vast datasets, drawing patterns and \\ninspirations that might be elusive to the human eye. This capa-\\nbility can lead artists to explore novel styles, techniques, or even \\nmediums. An artist might venture into digital artistry, blending \\ntraditional techniques with AI- generated patterns, resulting in a \\nfusion of the past and the future.\\nMusicians, too, stand to gain immensely. Generative AI can \\nassist in crafting unique soundscapes, rhythms, and melodies. It \\ncan analyze vast libraries of music, identifying trends and nuances, \\nand suggest compositions that are innovative and resonate with \\nlisteners. Musicians can experiment, blending their signature \\nstyle with AI- generated beats, leading to a harmonious sym-\\nphony of human and machine.\\nWriters, often grappling with the dreaded writer’s block, can \\nfind solace in generative AI. It can suggest plot developments, \\ncharacter backgrounds, or even dialogue variations. A writer can \\ninput a basic storyline, and the AI can generate multiple plot \\ntwists, allowing the writer to choose one that aligns best with \\ntheir vision.\\nDrawing a parallel with music sampling, generative AI’s role in \\ncontent and art creation is analogous. When music sampling \\nemerged, it was met with skepticism. T raditionalists viewed it as a \\nthreat to originality. However, over time, sampling proved to be a \\nboon. It allowed for the fusion of genres and the resurrection of \\nforgotten classics, and it gave birth to entirely new music forms.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 346, 'page_label': '333'}, page_content='Ethical Concerns and Social Implications of Generative AI 333\\nSimilarly, although generative AI might be viewed with caution by \\npurists, its potential to elevate art and content creation is undeni-\\nable. Just as sampling became an integral part of music, generative \\nAI is set to become foundational in the world of content and art. \\nIt’s not about replacing the artist but about augmenting their capa-\\nbilities, leading to a richer, more diverse creative landscape.\\nGenerative AI and Accessibility\\nGenerative AI, with its vast capabilities, is poised to be a game \\nchanger in the realm of accessibility and equity, especially for \\nindividuals with disabilities. Its applications span a wide range of \\nareas, each promising to make the world a more inclusive space.\\nOne of the most transformative applications of generative AI \\nlies in the development of assistive technologies. Systems like \\nBrainGate are a testament to the potential of AI in this domain. \\nBy interpreting brain signals, BrainGate empowers individuals \\nwith paralysis, granting them the ability to control devices merely \\nwith their thoughts.\\nThe digital world, while expansive, often falls short in terms \\nof accessibility. Generative AI can bridge this gap. T ools like \\naccessiBe utilize AI to scrutinize websites, identifying potential \\naccessibility barriers and rectifying them. This ensures that the \\ndigital realm is not just vast but also inclusive.\\nCommunication, a fundamental human need, can be enhanced \\nusing generative AI. For individuals with communication disor -\\nders, AI can craft alt text, alleviating the strain of communication \\nand reducing feelings of isolation. This not only enhances their \\nsocial interactions but also broadens their professional \\nopportunities.\\nIn the educational sector, generative AI promises personal-\\nized learning experiences. By tailoring content to suit the unique \\nneeds of students with learning disabilities, AI ensures that'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 347, 'page_label': '334'}, page_content='334 GENERATIVE AI\\neducation is not a one- size- fits- all model but a customized jour-\\nney for each learner.\\nCaptioning and transcription, powered by AI, can revolu-\\ntionize content consumption for those with hearing or cognitive \\nimpairments. By generating accurate captions and transcripts for \\naudio and video content, AI ensures that no one is left out of the \\nconversation.\\nFor the visually impaired, navigating the web can be a chal-\\nlenge. Generative AI can transform this experience by vocalizing \\nimage content, making websites more comprehensible and \\nnavigable.\\nHowever, as with all technologies, caution is paramount. \\nWhile generative AI holds immense promise, human oversight is \\nindispensable. AI- generated content, especially in the realm of \\naccessibility, must adhere to established standards. This includes \\nproviding suitable alt text for images, structuring content for \\nease of comprehension, and ensuring compatibility with assistive \\ntools like screen readers.\\nIn essence, the horizon of generative AI in accessibility and \\nequity is vast and promising. Its potential to reshape the world \\nfor individuals with disabilities is unparalleled. The excitement \\nsurrounding its future applications is palpable, and the anticipa-\\ntion of what lies ahead is shared by many, including myself. The \\njourney of generative AI in this domain is one I eagerly look for-\\nward to and hope to contribute to.\\nThe horizon of generative AI is vast, and I am filled with \\noptimism about its trajectory. With the right measures in place \\nand a genuine commitment to addressing concerns, generative \\nAI can be a boon for humanity. The myriad possibilities it pre-\\nsents are not just technological advancements but also potential \\nsolutions to long-standing societal challenges.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 348, 'page_label': '335'}, page_content='Ethical Concerns and Social Implications of Generative AI 335\\nThe promise of enhanced services, as highlighted by \\nChamath Palihapitiya at the All- In Podcast, underscores the \\ntransformative potential of generative AI. Imagine a world \\nwhere customer interactions are seamless, devoid of linguistic \\nbarriers, fostering trust and understanding. Such advancements, \\nif executed with care and precision, can redefine customer \\nexperiences.\\nThe future, as I envision it, is one where the content of \\n2023\\xa0might be revered as a relic of a bygone era, predominantly \\nhuman- generated. The job landscape will undergo a seismic \\nshift, with a surge in entrepreneurial ventures and research- \\ndriven roles in the AI domain. By 2030, I foresee a world where \\nproductivity will be 10X, the corporate landscape will be 100X, \\nand the volume of content, products, and knowledge will 1,000X. \\nQuality will emerge as the distinguishing factor, setting apart the \\nexceptional from the ordinary.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 349, 'page_label': '336'}, page_content=''),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 350, 'page_label': '337'}, page_content='337\\nI\\nn advocating for generative AI, this book delineates the pro-\\ngression from conventional AI toward a more generative \\nmodel. The journey commences with discriminative AI, the cor-\\nnerstone for today’s generative AI systems. Pioneering algo-\\nrithms in computer vision, like convolutional neural networks, \\nalong with strides in sentiment analysis and other natural lan-\\nguage processing (NLP) tasks, have significantly contributed to \\nthe evolution of generative models. These advancements now \\npropel the AI frontier further. Discriminative models remain \\ninvaluable, with their precise applications such as cancer detec-\\ntion showcasing their worth by refining accuracy to significant \\ndecimal places.\\nT ransitioning our gaze toward generative AI, it’s clear that \\nthis realm is a pivotal precursor to the lofty realm of artificial \\n6\\nCHAPTER\\nArtificial General \\n Intelligence in\\xa0Sight'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 351, 'page_label': '338'}, page_content='338 GENERATIVE AI\\ngeneral intelligence (AGI). The consensus is yet to be reached on \\nthe exact makeup of AGI, but a plausible hypothesis posits it as a \\nsynergy of discriminative and generative AI models.\\nBut what encapsulates AGI?\\nDescribed as a hypothetical yet potent entity, AGI is envi-\\nsioned to master any intellectual feat achievable by humans or \\nanimals. In another vein, it’s seen as an autonomous dynamo out-\\nperforming human aptitude in a vast array of economically valu-\\nable tasks. AGI frequently graces science fiction and futurist \\ndiscussions, embodying both the zenith of AI aspiration and a \\ntopic of fervent debate. Predicting AGI’s advent is akin to chasing \\nhorizons— some envisage its dawn in mere decades, others con-\\njecture a century, and a few naysayers deem it a pipe dream. The \\ndiscourse extends to whether behemoths like GPT-4 are embry-\\nonic iterations of AGI or if a paradigm shift is imperative. Various \\nmonikers like strong AI, full AI, or general intelligent action reso-\\nnate with AGI, although distinctions are noted, especially in aca-\\ndemic circles. Although strong AI hints at a sentient or conscious \\nprogram, its counterpart, weak AI, excels in singular tasks but \\nlacks the broad cognitive prowess. AGI’s kindred spirits are \\nhuman-level AI and superintelligence, each bearing a spectrum of \\npromises yet tethered to substantial advancements still to come.\\nAs we traverse further into this chapter, the horizon broadens \\nto reveal the upcoming milestones in generative AI, encapsulat-\\ning multitasking, multimodal, and multisensory AI. We’ll also \\nexplore other burgeoning trends and the nexus of technologies \\nwithin this realm. A notable derivative of generative AI, autono-\\nmous AI agents, beckons our attention, urging us to adapt to a \\ncollaborative rapport with these entities.\\nThe ensuing discourse delves into AGI’s allure, its pathway, \\nand the paradigm it aims to establish. While AGI signifies a  \\nprofound milestone, the narrative extends to artificial superintel-\\nligence (ASI), leading us to the precipice of singularity as envi-\\nsioned by Ray Kurzweil.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 352, 'page_label': '339'}, page_content='Artificial General  Intelligence in\\xa0Sight 339\\nOur narrative briefly pivots toward the tangible manifesta-\\ntions of AI advancements— humanoid robots, epitomizing the \\nfusion of form and intellect. While industrial robots also repre-\\nsent a fascinating facet of AI, our focus here remains tethered to \\nhuman-like embodiments, heralding the convergence of the \\nphysical and the digital realms.\\nWhat Is Next in Generative AI?\\nThe journey of AI continues to charge ahead, building upon past \\nprogress with the aid of new technology like neuromorphic and \\nquantum computing, or even potential breakthroughs like \\nLK-99. These technologies are taking AI models to new heights, \\nshowcasing the kind of exponential development discussed ear -\\nlier in this book.\\nThe heartbeat of AI development is strong and rapid, with a \\nplethora of research papers emerging in the generative AI space \\non platforms like arXiv. The fast pace is partly due to the lack of \\na lengthy peer-review process, and partly driven by the rush to \\nseize valuable ground in this flourishing domain. Unlike the \\ntransient buzz around cryptocurrencies, the breakthroughs in AI \\nare tangible, with real code and real demos illustrating its power \\nand potential. This isn’t just hype; it’s technology that’s proving \\nits mettle and showing promise for a solid future.\\nNow, let’s talk about what’s brewing on the horizon: enrich-\\ning experiences.\\nT ake the initiative by Wist Labs, for instance. They’re work-\\ning on a way to rejuvenate old memories from videos. Through \\naugmented reality glasses, you could re-experience a past event \\nright where it happened, but now as a hologram. And here’s \\nwhere it gets even more intriguing: imagine a multimodal AI \\nmodel that can continue the video, creating a holographic narra-\\ntive that interacts with you, maybe based on how the individuals \\nin the video would have reacted. It’s about not just reliving'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 353, 'page_label': '340'}, page_content='340 GENERATIVE AI\\nmemories, but possibly creating new, beautiful ones. Though the \\nidea might seem eerie to some, the potential to reconnect with a \\nlost loved one could be priceless to others.\\nT ech giants like Snap and Meta are also stepping into  \\nthis realm, aiming to bridge the miles between us and our loved \\nones, virtually. Recall the humble beginnings of long-distance \\ncommunication— like the crackly phone calls of yesteryears. Now, \\nwe’re talking about entering a virtual room to celebrate a family \\nevent or watch a movie together, despite being continents apart. \\nJust a short while ago, personalities like Lex Fridman and Mark \\nZuckerberg showcased the potential of this technology. They had \\na podcast in a virtual world, with hyper-realistic avatars created \\nthrough detailed scanning and high-end virtual reality gear. The \\nexperience was lauded for its realism, indicating that the eerie \\nuncanny valley might be behind us.\\nWith these examples, it’s clear that the realms of augmented \\nreality (AR) and virtual reality (VR) are on the cusp of monu-\\nmental evolution. Over the next 5 to 10 years, we might find \\nourselves celebrating life’s milestones with loved ones on a vir -\\ntual beach or in a cozy cinema, all from the comfort of our homes. \\nAnd it won’t stop at sight and sound. Future VR could let us feel \\na hug, taste the birthday cake, or bask in the warmth of virtual \\nsunlight. It’s a journey from flat screens to a rich, multisensory \\nvirtual world, all powered by the relentless march of gen-\\nerative AI.\\nMultitasking Generative AI\\nIt is not just about mastering singular tasks but extending capa-\\nbilities to manage multiple tasks simultaneously. Recent advance-\\nments have shown that LLMs like ChatGPT , Bard, and others \\nexhibit multitasking abilities straight out of the gate, especially \\nwhen it comes to emergent capabilities.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 354, 'page_label': '341'}, page_content='Artificial General  Intelligence in\\xa0Sight 341\\nEssentially, multitasking or multitask learning (MTL) in AI \\nis about tackling multiple learning challenges at once, leveraging \\nthe similarities and differences across these tasks to improve the \\nlearning outcome. This method enhances generalization by tap-\\nping into the domain information present in the training data of \\nrelated tasks, which acts as a form of inductive bias. The beauty \\nof MTL lies in its parallel learning approach with a shared rep-\\nresentation, enabling the learning from one task to aid the learn-\\ning in others.\\nA hiccup in this area has been the tradition of deep-learning \\nsystems being tailored to solve specific problems, say image rec-\\nognition. However, there’s a shift in the narrative with the advent \\nof models like Google’s MultiModel, which is adept at handling \\nmultiple tasks like image and speech recognition, translation, \\nand sentence analysis concurrently.\\nThe road to achieving adept multitasking AI models is filled \\nwith challenges, especially when it comes to learning multiple \\nskills without having to reboot the learning process for each new \\nskill. This has spurred researchers into exploring various avenues \\nlike optimized task scheduling and scaling the multitask learning \\nfor a plethora of modeling tasks.\\nT ransitioning the lens to generative AI, multitasking unfolds a \\nnumber of possibilities. LLMs are about not just one trick but a \\nwhole gambit of tasks like text generation, text summarization, \\nlanguage translation, question answering, sentiment analysis, \\nnamed entity recognition, code generation, text classification, \\nspeech-to-text transcription, text-to-speech synthesis, image cap-\\ntioning, paraphrasing, chatbot functionality, content curation, data \\naugmentation, text-based game playing, mathematical problem \\nsolving, syntax highlighting, keyword extraction, and language \\nidentification.\\nThe narrative gets even more interesting with advanced gen-\\nerative models that can juggle multiple types of data, like text,'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 355, 'page_label': '342'}, page_content='342 GENERATIVE AI\\nimages, and audio, and perform tasks across these different \\nmodalities. For instance, DALL-E from OpenAI is a stellar exam-\\nple of how a model can morph text into images, thereby showcas-\\ning prowess in both text understanding and image generation. \\nThis opens the door to a thrilling domain known as multimodal-\\nity, which we will delve into shortly.\\nThis expansion of multitasking in generative AI is not just a \\nleap but a giant stride toward more versatile and effective AI sys-\\ntems. It’s about transcending the boundaries of singular task \\nlearning to create AI models that are adept at juggling multiple \\ntasks, much like a seasoned multitasker in the human realm. This \\nnot only amplifies the potential applications of AI but also brings \\nus closer to creating more intelligent and adaptable AI systems. \\nAnd, it is mandatory for achieving an AGI.\\nMultimodal Generative AI\\nThe journey of exploring AI brings us to the nuanced domain of \\nmultimodal AI, an area we have touched upon multiple times. It’s \\nabout time we delve deeper to understand its essence. Multi-\\nmodal AI embodies the capability of AI systems to interpret, pro-\\ncess, and derive insights from various types of data or “modalities” \\nsuch as text, images, audio, and video. This approach aims to \\nemulate the human ability to employ multiple senses in interact-\\ning with the world. For instance, a multimodal AI system could \\nscrutinize both audio and visual elements of a video to grasp its \\ncontent better.\\nIn the realm of discriminative AI, multimodality is about the \\nAI models’ ability to understand various input types to carry out \\ntasks like classification or regression toward producing an out-\\nput. However, the output here isn’t multimodal.\\nNow, steering the narrative toward multimodal generative \\nAI, we enter a landscape where the focus is on crafting new'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 356, 'page_label': '343'}, page_content='Artificial General  Intelligence in\\xa0Sight 343\\ncontent that traverses multiple modalities. Picture a system capa-\\nble of creating a video by synthesizing visual imagery along with \\ncorresponding audio or fashioning a social media post adorned \\nwith text, images, and hashtags. This extension of generative \\nmodels into multimodal scenarios opens up a vista where AI \\nbegins to churn out complex, multifaceted content that resonates \\nwith a higher degree of utility and engagement. Unlike discrimi-\\nnative AI, both the input and output can be multimodal in the \\ncase of generative AI.\\nMultimodal generative AI truly hit home when GPT-4 \\nshowcased its prowess in March, elucidating image data with an \\nastonishing level of detail. GPT-4, backing ChatGPT Plus, her-\\nalds the era of vision language models (VLMs), a cohort to \\nwhich PaLM-backing Bard also belongs. VLMs are adept at \\ncreating a shared embedding space for images and texts, paving \\nthe way for text-to-image or image-to-text queries. A striking \\nexample could be a scenario where a user inquires about a loca-\\ntion depicted in an image and seeks budget-friendly travel \\noptions to get there. This nuanced capability of VLMs hints at a \\nprofound transformation in how we conduct searches, if har -\\nnessed correctly.\\nThe emergence of multimodal generative AI is like opening \\na new chapter in the AI narrative, one where the convergence of \\ntext, image, audio, and video modalities breeds a more robust \\nand versatile generation of AI systems. This not only enriches \\nthe user interaction but also nudges AI a step closer to human-\\nlike comprehension and creativity.\\nIn August 2023, Meta AI introduced SeamlessM4T , a revolu-\\ntionary multimodal AI model, bringing a significant upgrade to \\nspeech-to-speech and speech-to-text translations. By tackling \\nthe hurdles of limited language coverage and dependence on \\nseparate systems, it aims to smooth communication among dif-\\nferent language speakers through high-quality translations.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 357, 'page_label': '344'}, page_content='344 GENERATIVE AI\\nSeamlessM4T is touted as the first all-encompassing multi-\\nlingual multimodal AI model for translation and transcription. \\nIt’s a powerhouse that can handle a variety of tasks— speech-to-\\nspeech, speech-to-text, text-to-text, text-to-speech, and auto-\\nmatic speech recognition— all under one roof. Unlike previous \\nsetups using distinct models, SeamlessM4T’s unified system cuts \\ndown errors and delays, enhancing the translation quality and \\nefficiency.\\nBuilding upon earlier efforts like the No Language Left \\nBehind (NLLB) text-to-text translation model, which supports a \\nwhopping 200\\xa0languages, SeamlessM4T steps it up. It comes in \\ntwo versions: the SeamlessM4T-Medium with 1.2 billion param-\\neters, and the more robust SeamlessM4T-Large with 2.3 billion \\nparameters. The benefit? Better robustness against background \\nnoises and speaker variations in speech-to-text tasks. Plus, Seam-\\nlessM4T has outshone previous top-notch models, showing it’s a \\nforce to reckon with in the translation arena.\\nThe realm of multimodal AI is ripe with potential, opening \\ndoors to countless applications without needing a stretch of \\nimagination. T ake biomedicine, for instance. The melding of \\nvaried biomedical data— from electronic health records to \\ngenome sequencing— has ushered in a new era of multimodal AI \\nin healthcare. This blend of data types is a gold mine for devel-\\noping insightful AI applications, making healthcare more \\ninformed and personalized.\\nThe horizon is vast and the ideas endless. With a simple two-\\nstep prompt or something similar, anyone can spark brilliant \\nideas they’d wish to chase (Figure\\xa0 6.1). This simplicity is a  \\ndoorway to innovation, allowing minds to explore, create, and \\ntransform thoughts into reality.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 358, 'page_label': '345'}, page_content='Artificial General  Intelligence in\\xa0Sight 345\\nThe exploration yielded 10 high-level suggestions, with two \\nstanding out particularly:\\nPersonalized medicine Envisage crafting tailored treatment \\nplans by marrying and mining insights from a medley of data— \\ngenomic, clinical, and environmental. This meld of multi-\\nmodal data could be the linchpin in personalizing medical care.\\nPredictive modeling of\\xa0disease progression Imagine lever-\\naging generative models to simulate disease progression in \\nindividual patients. This could be a game changer for early \\nintervention and tailoring treatment plans.\\nOther intriguing ideas surfaced through this ChatGPT \\ninteraction, like “Generative Remote Monitoring and ‘Hospital-\\nat-Home,’” “Digital Clinical T rials,” “Digital T wins (of humans),” \\nand “Virtual Health Assistants.” These hint at the expansive \\npotential of multimodal AI across diverse healthcare facets.\\nFIGURE\\xa06.1 A simple two-step prompt unfolding the horizon of end-\\nless ideas and innovation.\\nSource: ChatGPT screenshot'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 359, 'page_label': '346'}, page_content='346 GENERATIVE AI\\nThese preliminary ideas are captivating. With some fine-\\ntuning and perhaps garnering expert insights through interviews, \\nthere’s a solid base to further fortify these concepts. Post- \\nvalidation, these ideas could be the springboard for securing ven-\\nture capital or kick-starting a bootstrap journey, paving the way \\nto harness multimodal AI in transforming healthcare.\\nMultisensory Generative AI\\nDelving into the realm of multisensory generative AI, the spot-\\nlight is on generating data perceivable through a medley of \\nsenses— sight, sound, touch, and beyond. This subfield of multi-\\nmodal generative AI marries data generation with different types \\nof actuators (hardware) to engage multiple senses.\\nThe data terrain here primarily sprawls across sensory data \\nlike images, spatial sounds, and haptic feedback, but is not \\nrestricted to them. Picture virtual reality (VR) realms enriched \\nwith touch, thermal, and other sensory actuators that pull users \\ndeeper into the virtual abyss.\\nThe real world already hosts applications of multisensory \\napplications. T ake the PlayStation 5 DualSense controller, a mar-\\nvel in the gaming arena. This gadget boasts advanced motors \\ndelivering precise feedback at different controller points. Cou-\\npled with a high-fidelity speaker and an integrated mic, it takes \\ngaming to a sensory-rich level. The L2 and R2 buttons, infused \\nwith haptic feedback through little motors that give you differ -\\nent types of resistance, simulate real-world actions like firing a \\ngun or drawing a bowstring. By generating virtual worlds and \\nsteering commands for DualSense actuators, multisensory gen-\\nerative AI amplifies the immersive gaming experience— a prom-\\nising field indeed.\\nThen there are sensory substitution devices aiding individuals \\nwith disabilities. For instance, Neosensory Buzz, a wearable wrist-\\nband, translates auditory cues into tactile sensations. Capturing'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 360, 'page_label': '347'}, page_content='Artificial General  Intelligence in\\xa0Sight 347\\nsurrounding sounds, it churns out vibration patterns on the user’s \\nwrist, creating over 29,000 unique patterns based on sound inten-\\nsity and pitch. It’s a boon for the deaf and hard-of-hearing com-\\nmunity, alerting them to sounds like doorbells, conversations, and \\nemergency alarms. Accompanied by a companion app, Buzz  \\ncan be tailored for everyday sounds, music appreciation, or \\nsafe sleeping.\\nMultisensory generative AI is at the cusp of forging a more \\ninclusive and immersive digital realm, bridging the sensory gap \\nbetween the virtual and real worlds.\\nVenturing into the realm of steering actuators, a plethora of \\npossibilities unfolds. A myriad of actuators await exploration, \\nsome familiar, others less so. Let’s journey through a few, and as \\nwe do so, hold on for a moment, close your eyes, and imagine \\npotential applications:\\nAuditory actuators\\nSpeakers: Produce sound waves to create auditory sensations.\\nBone conduction transducers: A bone conduction transducer is a \\ndevice that converts audio signals into vibrations, which are \\nthen transmitted through the bones of the skull to the inner \\near, bypassing the eardrums. This technology is used in bone \\nconduction headphones and hearing aids, allowing users to \\nperceive audio content even if their ear canal is blocked or \\nthey have hearing difficulties.\\nTactile actuators\\nHaptic actuators: Produce vibrations or movements to simu-\\nlate touch.\\nPiezoelectric actuators: Generate mechanical displacement through \\nelectric voltage, often used in haptic feedback.\\nElectroactive polymers: Change shape when an electric field is \\napplied, providing a tactile sensation.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 361, 'page_label': '348'}, page_content='348 GENERATIVE AI\\nThermal actuators\\nA Peltier element, also known as a thermoelectric cooler (TEC), is \\na device that uses the Peltier effect to transfer heat from one \\nside to the other when an electric current is applied.\\nInfrared heaters: Produce warm air or directly heat surfaces.\\nThermoelectric coolers: Provide a cooling effect.\\nOlfactory Actuators\\nScent diffusers: Release specific scents into the air.\\nOlfactory actuators: Devices that can emit or release odors in \\nresponse to a stimulus, such as an electric signal or a change in \\ntemperature or humidity. These devices are part of artificial \\nolfactory systems, which aim to mimic the human sense of \\nsmell and detect and recognize volatile organic compounds \\n(VOCs) in complex environments.\\nGustatory actuators\\nFlavor sprays: A spritz that carries the essence of flavors, a gusta-\\ntory glimpse.\\nAir movement actuators\\n• Fans: Breathing motion into the still air, a gentle whisper or \\na gusty shout.\\nMoisture actuators\\n• Water sprays and ultrasonic humidifiers: Unveiling mist or a \\nwater spray to add moisture to the environment.\\nMiscellaneous, enhancing the\\xa0sensory spectrum:\\nElectrical muscle stimulation (EMS): Spurring muscle contractions \\nwith electric impulses.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 362, 'page_label': '349'}, page_content='Artificial General  Intelligence in\\xa0Sight 349\\nLight-emitting diodes (LEDs): Lighting the way with visual cues.\\nMultimodal actuators\\n• 4D cinema seats: A confluence of actuators, they orchestrate a \\nsymphony of sensations— movement, vibration, tempera-\\nture— a cinematic voyage beyond the ordinary.\\nThe terrain is ripe for nurturing startup ideas, a fertile ground \\nof innovation. No longer can potential be dismissed due to hurdles \\nX, Y, or Z. Embrace the extraordinary, challenge the norm, yet tread \\nwisely— validate assumptions early. Engage with gusto, and success \\nwill morph from chance to certainty. The future is a canvas awaiting \\nyour strokes— seize it, and witness your vision morph into reality.\\nAs a multisensory example, Meta introduced a trailblazing \\nventure named ImageBind. This initiative is akin to opening a \\nnew chapter in the saga of AI, nudging us closer to a realm where \\nmachines learn from a rich tapestry of data types surrounding \\nthem, much as humans do.\\nAt its core, ImageBind is a master key to a treasure trove of \\nlearning across six different realms— images, text, audio, depth, \\nthermal, and inertial measurement unit (IMU) data. It’s akin to a \\npolyglot mastering six languages at once, a first in the AI domain. \\nThis unique model interprets content more wholesomely, mir -\\nroring humans’ knack for simultaneous, holistic learning from \\nvarious information forms— all without needing guidance from a \\nteacher (a process known as explicit supervision).\\nDrawing inspiration from recent large-scale vision-language \\nmodels, ImageBind amplifies their zero-shot learning capabili-\\nties to new modalities, simply by pairing them with images. It’s \\nlike adding new strings to a guitar, enabling a richer melody of \\napplications “out-of-the-box.” This includes the magic of cross-\\nmodal retrieval, composing modalities with arithmetic, and'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 363, 'page_label': '350'}, page_content='350 GENERATIVE AI\\ncross-modal detection and generation. The more adept the \\nimage encoder, the stronger the emergent capabilities, setting a \\nnew gold standard in zero-shot recognition tasks across modali-\\nties, leaving specialist supervised models in the dust.\\nImageBind unravels the potency of image-paired data as a \\nbinding glue for these six modalities. It’s a leap forward in AI, \\nenhancing machines’ prowess in dissecting diverse information \\nforms in unison. Imagine Meta’s Make-A-Scene application con-\\njuring images from audio cues— a bustling market or a serene \\nrainforest brought to visual life from mere sounds. This is the \\nmagic ImageBind is brewing.\\nImageBind isn’t a solitary endeavor but a part of Meta’s grand \\nvision of crafting multimodal AI systems that soak in all possible \\ndata types around them. As the modalities multiply, ImageBind \\nbeckons researchers to a realm brimming with prospects— \\nmelding 3D and IMU sensors to craft or traverse immersive vir-\\ntual worlds, for instance.\\nIn a nutshell, ImageBind is less of an end, more of a begin-\\nning— a harbinger of an era where AI isn’t just about crunching \\nnumbers but about perceiving, interpreting, and learning from \\nthe world in a way that’s more human, more holistic, and more \\npromising.\\nAs shown in Figure\\xa06.2, an image of a pigeon coupled with \\nthe sound of a motor revving is processed through the embedding- \\nspace arithmetic, yielding an image of a scooter with pigeons \\nfluttering away. Subsequently, it demonstrates its prowess in gen-\\nerating data across different modalities. For instance, when fed \\nwith a video capturing the calls of penguins, the image genera-\\ntion model adeptly creates a corresponding visual, enriching the \\nmultimodal data synthesis experience.\\nDreaming up ideas is the breezy part. T ranslating them into \\nreal-world applications is the real challenge, demanding a good \\ndose of persistence. But let’s face it, this is a truth as old as time.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 364, 'page_label': '351'}, page_content='Artificial General  Intelligence in\\xa0Sight 351\\nCentral to the success of multisensory generative AI is the \\nnotion of synchronized generation. This is about ensuring that \\nthe generated outputs across different senses are in harmony, \\nmoving to the same rhythm. Now, as you blend different sensory \\nmodalities into one unified framework, you stumble upon what is \\ntermed integration complexity. This demands a deep dive into \\nunderstanding each modality and the intricate dance between \\nthem for smooth interaction and effective feature extraction. It’s \\nlike orchestrating a symphony played by a range of instruments, \\neach with its unique note, yet\\xa0all needing to create a harmoni-\\nous melody.\\nNow, how do we gauge the success and precision of these \\nmultisensory generative models? That’s where robust evaluation \\nmetrics come into play. They are the magnifying glass that pro-\\nvides insight into the model’s prowess in crafting high-fidelity \\nand coherent multisensory outputs. It’s about ensuring what’s \\ngenerated isn’t just a cacophony but a well-tuned harmony.\\nFIGURE\\xa06.2 ImageBind unveils a realm of possibilities, including the \\ninnovative feature of embedding-space arithmetic. In essence, given \\nan image and a sound, it identifies the nearest corresponding data, be \\nit a video, image, or other media.\\nSource: (a) Miha Rekar / Unsplash, (b) Josefina Di Battista / Unsplash'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 365, 'page_label': '352'}, page_content='352 GENERATIVE AI\\nBut, here’s the rub. Hardware limitations could throw a span-\\nner in the works when it comes to practical deployment. Surpass-\\ning hardware constraints for real-time processing and generation \\nis a hill to climb. This might beckon the dawn of more potent \\nhardware or perhaps tweaking the generative models to perform \\nefficiently within the bounds of existing hardware constraints. \\nIt’s like wanting to run a high-octane game on a vintage \\ncomputer— some serious upgrades or optimizations are in order.\\nIn a nutshell, while the journey from ideation to realization is \\ndotted with hurdles, each challenge overcome is a stride toward \\nmolding a future where multisensory generative AI isn’t just a \\nfigment of imagination, but a tangible reality shaping our inter -\\naction with the digital realm.\\nOther Observable Trends in Generative AI\\nIn this chapter, we embellish upon the trends discussed through-\\nout the book, touching on some additional noteworthy move-\\nments in the sphere of generative AI.\\nA spotlight is being cast on AI wrapper projects and compa-\\nnies that prominently integrate with enterprise data. A discerni-\\nble shift is underway, veering toward training generative AI \\nmodels on enterprise data. This shift empowers organizations to \\nharness their data for AI-centric applications, a trend I often, \\nespecially this year, navigate with my team in our AI consulting \\nprojects. This trajectory, which I’d like to call the industrializa-\\ntion of generative AI and large language models (LLMs) with \\nsemantic search, is an exciting avenue that melds the might of AI \\nwith the robustness of enterprise data.\\nShifting the lens to scientific research, it’s exhilarating to wit-\\nness how generative models are fueling the creation of new ideas, \\nthereby accelerating our journey of discovery— be it new mole-\\ncules, materials, or medications. With the prowess to navigate \\nthrough vast data oceans, these models identify elusive patterns,'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 366, 'page_label': '353'}, page_content='Artificial General  Intelligence in\\xa0Sight 353\\noffering a fertile ground for new knowledge and solutions to \\nchallenging enigmas. The profound potential of generative mod-\\nels to traverse the boundless expanses of data in science, generat-\\ning novel insights and proposing starting points for the design \\nand discovery of new materials and drugs, is nothing short of \\nawe-inspiring.\\nNow, let’s pivot to a facet of generative AI that’s both intrigu-\\ning and imperative: explainability. The concept of making gen-\\nerative AI models more decipherable births what we now call \\nexplainable generative AI. This emerging field in AI research is not \\njust a mere academic exercise but a cornerstone in building trust \\nand fostering a deeper understanding of AI models, especially as \\nthey find their footing in enterprise-level use cases.\\nThe term black box often echoes in the corridors when dis-\\ncussing generative AI models. The enigmatic nature of these \\nmodels, where the pathway from input to output is shrouded in \\ncomplexity, often breeds mistrust and apprehension. The imper-\\native for transparency and comprehension nudges us toward \\nexplainable AI (XAI), a burgeoning field aimed at demystifying \\nthe outputs of AI models, making them more palatable and trust-\\nworthy to human users.\\nWhile XAI has been making headway in elucidating discrim-\\ninative models, generative models have yet to bask in the same \\nspotlight. As generative AI continues to unfurl its wings and nes-\\ntle into more enterprise use cases, the onus falls on IT leaders, \\ntechnologists, and developers to embody a holistic approach. \\nThis approach should encapsulate the essence of explainability \\nright from the embryonic stages of development, ensuring that \\nas we stride forward into the realms of generative AI, we carry \\nwith us a torch of understanding, shedding light on the once \\nobscure pathways of generative models.\\nNavigating the realm of AI, especially generative AI, is akin to \\nembarking on a quest for transparency in a forest of complexities. \\nIt’s a journey to make the actions and decisions of AI models'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 367, 'page_label': '354'}, page_content='354 GENERATIVE AI\\ninterpretable to humans, unmasking the “black box” to reveal a \\nnarrative that’s both engaging and insightful. Among the torch-\\nbearers of this quest are techniques like LIME, SHAP , and others, \\neach with its distinct path toward illuminating the enigmatic \\nworkings of AI.\\nLIME, an acronym for local interpretable model-agnostic \\nexplanations, is a method that attempts to demystify complex \\nmodels by approximating them with simpler, interpretable mod-\\nels in the vicinity of a specific data point. This approximation is \\nakin to zooming into a small, understandable part of a large, \\ncomplex picture, making the incomprehensible comprehensible. \\nA variant of LIME, dubbed VAE-LIME, employs a variational \\nautoencoder to delve into the data’s intricate traits, generating \\nsynthetic samples that serve as a training ground for a simpler, \\nlocal model. This local model endeavors to mimic the behavior \\nof a complex model near a specific input, rendering a prediction \\nthat’s easier to interpret. In the realm of generative AI, LIME \\nelucidates which parts of the input, like pixels in an image, play a \\nsignificant role in the generated output.\\nT ransitioning to SHAP , or SHapley Additive exPlanations, \\nwe venture into a technique rooted in cooperative game theory. \\nSHAP values are the messengers that convey the contribution of \\neach feature toward a prediction made by a model. They unravel \\nthe significance and interaction of features within a model, paint-\\ning a clearer picture of how each feature sways the final predic-\\ntion. In generative models, SHAP divulges how features of \\ngenerated data are intertwined with the model’s latent variables \\nor parameters. It’s like having a magnifying glass that shows how \\ntweaking different features in the latent space affects the gener -\\nated data. SHAP not only assists in comparing different genera-\\ntive models but also aids in optimizing and debugging them, \\nmaking it an invaluable tool for understanding and refining gen-\\nerative models.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 368, 'page_label': '355'}, page_content='Artificial General  Intelligence in\\xa0Sight 355\\nAs we further traverse, counterfactual explanations emerge as \\na method of understanding how minimal changes in inputs can \\nlead to different outputs. It’s like tweaking the recipe slightly to \\nget a surprisingly different dish. Activation maximization, on the \\nother hand, unveils the features captured in generative models by \\nmaximizing neuron activation, akin to turning up the volume to \\nhear the subtle notes in a symphony. Saliency maps and feature \\nimportance shine a light on the influential regions of input and \\nthe impact of each feature respectively, offering a lens to see what \\nparts of the input significantly affect the generative outputs. \\nLastly, model dissection delves into the layers and neurons of \\ncomplex generative models like generative adversarial networks \\n(GANs), dissecting them to understand their roles in the grand \\nscheme of data generation.\\nMerging explainable AI with generative models is an unfold-\\ning realm in AI research. The key challenge is balancing  \\nhigh-quality output generation with clear explanations of the \\ngenerative processes. Delving into this topic reveals ample room \\nfor exploration and contribution, signaling a possible avenue for \\nyour involvement. The field is ripe for further investigation and \\ndevelopment.\\nScaled Utilization of AI: Autonomous AI Agents\\nHarnessing the power of AI through autonomous AI agents her-\\nalds a new era in the technological landscape. As briefly touched \\nupon in Chapter 3, “Generative AI’s Broad Spectrum of Applica-\\ntions,” the journey from concept to real-world application is \\nunfolding. Prominent tech visionaries like Matt Schlicht, CEO \\nat Octane AI, foresee a timeline where these autonomous agents \\nevolve into professional aides by 2024 and seamlessly integrate \\nacross various sectors by 2025. By 2026, it’s conceivable that we \\ncould be accompanied by a cadre of autonomous AI agents dedi-\\ncated to assisting us in both personal and professional spheres.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 369, 'page_label': '356'}, page_content='356 GENERATIVE AI\\nOn a similar note, Mustafa Suleyman, a distinguished AI \\nresearcher and the brain behind Inflection AI, projects a future \\nwhere AI morphs from static web interfaces to dynamic conver-\\nsational agents.\\nPicture a digital companion capable of generating multime-\\ndia content while engaging in a meaningful dialogue. The essence \\nof these agents lies in their ability to align with individual inter -\\nests, acting as a personal chief of staff that not only responds to \\nyour requests but proactively helps you realize your long-term \\nobjectives. Whether it’s securing a prime reservation for an inves-\\ntor lunch or keeping you abreast of relevant news, the autonomy \\nand personalization of these agents encapsulate a blend of execu-\\ntive assistant and trusted confidante.\\nThe envisioned autonomy extends to a level where sharing \\nsensitive information with your AI agent becomes a norm, nur -\\nturing a relationship akin to that with a trusted aide. From sched-\\nuling to summarizing, the roles these agents could play are \\ndiverse and tailored to individual needs. Wake up to a personal-\\nized briefing, navigate through your day with intelligent sugges-\\ntions, and delegate tasks with the assurance of precision and \\ntimely completion.\\nSuleyman’s vision encapsulates a world where each individual \\nis aided by an AI chief of staff, adept at morphing roles as per the \\ntask at hand. The exact manifestation of these agents— be it a \\nsingle AI wearing multiple hats or a team of specialized AIs— \\nremains an open-ended narrative. However, the common thread \\nbinding all predictions is the user’s ability to choose from a spec-\\ntrum of AI offerings, each promising to make life a tad easier, \\norganized, and focused.\\nAt the core, these agents are the embodiment of LLMs exhib-\\niting a flair for human-like decision making. The essence of these \\nagents lies in an architecture comprising diverse modules like'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 370, 'page_label': '357'}, page_content='Artificial General  Intelligence in\\xa0Sight 357\\nprofiling, memory, planning, and action. The profiling module \\nshapes the agent’s persona, memory holds the essence of past \\ninteractions, planning choreographs the path to goals, and action \\ntranslates decisions into tangible outputs (Figure\\xa06.3).\\nThe landscape of developing autonomous AI agents is vibrant \\nwith innovation, and frameworks like AutoGPT , LangChain, \\nSuperAGI, and AutoGen are leading the charge. They not only \\noffer a solid foundation for development but also embody the \\ndynamics of the field, where change is the only constant.\\nT ake Auto-GPT , a brainchild of T oran Bruce Richards from \\nSignificant Gravitas Ltd. It’s the first significant autonomous AI \\nagent framework powered by a language model, and it is open \\nsource. Unlike traditional models, Auto-GPT embodies a self-\\ndriven spirit, creating and revising its objectives to chase a \\nbroader goal, without the need for human intervention. It’s not \\njust about responding to prompts; it’s about crafting new prompts, \\nadapting to new information, and working toward the stated \\nProfile\\nProfile Contents Memory Structure Planning w/o Feedback Action Target\\nAction Production\\nAction Space\\nAction Impact\\nPlanning w/ Feedback\\nMemory Formats\\nMemory Operation\\nGeneration Strategy\\nDemographic Information Unified Memory\\nSingle-path Reasoning\\nMulti-path Reasoning\\nExternal Planner\\nTask Completion\\nCommunication\\nMemory Recollection\\nPlan Following\\nTools\\nEnvironments\\nInternal States\\nNew Actions\\nSelf-Knowledge\\nExploration\\nEnvironment Feedback\\nHuman Feedback\\nModel Feedback\\nLanguages\\nEmbeddings\\nDatabases\\nLists\\nHybrid Memory\\nMemory Reading\\nMemory Writing\\nMemory Reflection\\nPersonality Information\\nSocial Information\\nHandcrafting Method\\nLLM-Generation Method\\nDataset Alignment Method\\nMemory Planning Action\\nFIGURE\\xa06.3 Autonomous AI agents framework.\\nSource: Paitesanshi / GitHub, Inc. / https://github.com/Paitesanshi/LLM-Agent-Survey / \\nlast accessed December 04, 2023.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 371, 'page_label': '358'}, page_content='358 GENERATIVE AI\\ngoal. The agent’s interaction extends to apps, software, and online \\nservices, showcasing a glimpse of a self-reliant digital entity.\\nAuto-GPT’s success is evident in its “star history” (see  \\nFigure\\xa06.4), a tool that visually represents the project’s growing \\npopularity and engagement on GitHub over time.\\nAuto-GPT , despite its trailblazing outset, showcased the \\ninfancy of this realm. It had its share of missteps, misinterpreta-\\ntions, and diversions. Y et, it stood as a testament to the AI com-\\nmunity, heralding the dawn of what’s next.\\nThe journey from Auto-GPT’s inception to the burgeoning \\nframeworks of today encapsulates the rapid evolution in molding \\nautonomous agents. As we traverse this path, each stride, each \\nmisstep, and each success propels us closer to a reality where AI \\nisn’t just a tool, but a self-reliant entity, autonomously navigating \\nthe still vast digital realm.\\nApril MayJ uneJ uly\\nDate\\nSignificant-Gravitas/AutoGPT140.0k\\nStar History\\n120.0k\\n100.0kGitHub Stars\\n80.0k\\n60.0k\\n40.0k\\n20.0k\\nAugust September October\\nstar-history.com\\nFIGURE\\xa06.4 Star history of one of the first AI agent repositories. Going \\nviral at first, smoothly plateauing afterward, as other competitive \\nframeworks like SuperAGI arrive in the market.\\nSource: GitHub, Inc. / https://github.com/Significant-Gravitas/AutoGPT / last accessed \\nDecember 04, 2023.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 372, 'page_label': '359'}, page_content='Artificial General  Intelligence in\\xa0Sight 359\\nLet’s pivot to LangChain, a robust library/framework for \\nPython and JavaScript/T ypeScript enthusiasts. It’s your go-to \\navenue for prototyping large language model applications swiftly. \\nLangChain facilitates the chaining of LLM tasks and the smooth \\noperation of autonomous agents. Delving into a complex task? \\nLangChain agents break it down into a multistep action plan, \\ntackling each intermediate step to reach the coveted final answer.\\nThe Agents module in LangChain is a boon for developers \\nkeen on prototyping large language model applications and con-\\nstructing autonomous agents. The beauty of LangChain agents \\nlies in their chaining ability. They bridge the LLM to external \\nknowledge resources or computational tools seamlessly. The \\narray of agents, like the zero-shot-react-description, is impres-\\nsive. Utilizing the ReAct (Reason + Act) framework, they select \\nthe most suitable tool based on the input query. ReAct, in essence, \\nis a mechanism that guides the agent to reason the query and act \\nby choosing the apt tool for execution. With robust querying \\ncapabilities, LangChain agents automate various tasks with finesse.\\nIntegration is a strong suit of LangChain. From primary \\ncloud storage services like Amazon, Google, and Microsoft Azure \\nto API wrappers accessing diverse data, it’s well equipped. It also \\nventures into web scraping, script executions, few-shot learning \\nprompt generation, and much more. The support for over 50 \\ndocument types and data sources showcases its expansive capa-\\nbility. It’s no wonder many in the generative AI space vouch for \\nLangChain as the foundation for development, be it for autono-\\nmous agents or semantic search in LLM querying.\\nIn other words, LangChain integrates various modules: the \\ncore LLM, chains for linking LLM calls, efficient prompt man-\\nagement, along with document loaders, utilities, vector stores for \\ndata handling, and agents for interactive AI tasks, all designed for \\nseamless and adaptable AI applications. Figure\\xa06.5 shows a high-\\nlevel overview.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 373, 'page_label': '360'}, page_content='360 GENERATIVE AI\\nT ransitioning to SuperAGI, it emerges as a notable open \\nsource platform providing a solid infrastructure for crafting \\nautonomous AI agents rapidly. Developers find a haven in Super-\\nAGI to build, manage, and run autonomous agents reliably. The \\nplatform is adept at running multiple agents concurrently, a fea-\\nture that elevates the management of multiple agents to a breeze.\\nSuperAGI is a reservoir of tools and toolkits, extending the \\ncapabilities of agents in areas like knowledge embeddings and \\nagent workflows. One standout feature is the Dashboard\\xa0– Action \\nConsole, a graphical interface allowing developers an interactive \\nengagement with their agents. The agent templates are a notewor-\\nthy inclusion, offering a springboard for developers to create task-\\nspecific AI agents. For instance, the SuperCoder template facilitates \\nFIGURE\\xa06.5 A high-level diagram of LangChain capabilities.\\nSource: Kamlesh Singh / A Medium Corporation / https://medium.com/@singh. \\nkamlesh1991/if-you-wanted-to-build-your-own-chatgpt-based-on-your-own-data-then- \\nlangchain-framework-is-perfect-c62656d63376 / last accessed December 04, 2023.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 374, 'page_label': '361'}, page_content='Artificial General  Intelligence in\\xa0Sight 361\\nthe crafting of simple software applications using defined goals \\nand instructions.\\nThe SuperAGI Marketplace is a realm where you can deploy \\nyour first agents using ready-made templates (Figure\\xa06.6). It’s a \\nplatform that not only accelerates the development of autono-\\nmous agents but also ensures a reliable, user-friendly experience \\nfor developers navigating the AI development landscape. \\nThrough LangChain and SuperAGI, the journey from ideation \\nto deployment in the autonomous AI agent sphere becomes an \\nengaging and efficient endeavor.\\nRecall the notion of having a chief of staff with a dynamically \\nassembled team? AutoGen seemingly brings this concept to life \\nin the realm of LLMs. It’s a framework tailored for crafting LLM \\napplications via multiple agents capable of conversing to unravel \\ntasks. The agents here aren’t just autonomous but are also con-\\nversable and customizable. Figure\\xa06.7 illustrates simplified con-\\nversation patterns between agents.\\nAutoGen’s forte lies in streamlining the orchestration, auto-\\nmation, and optimization of complex LLM workflows. It’s a hub \\nfor fostering next-generation LLM applications rooted in multi-\\nagent conversations with minimal developmental hurdles. The \\nFIGURE\\xa06.6 SuperAGI’s Marketplace.\\nSource: SuperAGI / https://superagi.com/ / last accessed December 01, 2023.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 375, 'page_label': '362'}, page_content='362 GENERATIVE AI\\nframework is adept at amplifying the performance of LLM mod-\\nels while tactfully navigating their inherent weaknesses.\\nDive a bit deeper, and you’ll find AutoGen supporting a vari-\\nety of conversation patterns tailored for complex workflows. \\nWhether it’s joint or hierarchical chats, the framework enables \\ndevelopers to architect a broad spectrum of conversation pat-\\nterns. It’s the autonomy in conversation, the number of agents \\ninvolved, and the topology of agent conversation that sets \\nthe stage.\\nAutoGen isn’t just theoretical; it’s practicality shined through \\na collection of working systems, encapsulating diverse domains \\nand complexities. The ease of performance tuning, API unifica-\\ntion, caching, and advanced usage patterns like error handling \\nand context programming are notable mentions. The collabora-\\ntive work of Microsoft, Penn State University, and the Univer -\\nsity of Washington fuels AutoGen’s capabilities.\\nReal-world examples shared by the team aren’t just informa-\\ntive but are interactive, thanks to the Colab environment, a free \\ncloud-based service provided by Google that allows users to \\nwrite and run Python code in a Jupyter Notebook–like interface— \\nfrom automated task solving with code generation to collabora-\\ntive task solving with multiple agents and human users.\\nThe synergy of multiple language models, as explored by the \\nComputer Science & Artificial Intelligence Laboratory at MIT , \\nunderscores the potential of multistep LLM querying in enhanc-\\ning query accuracy. It’s a promising horizon for autonomous AI \\nagents, with AutoGen leading the charge.\\nIn a parallel vein, frameworks like MetaGPT and ChatDev \\nare making a significant ripple in the autonomous AI agent \\ndomain. MetaGPT is user friendly, translating a simple one-liner \\nrequirement input into a myriad of outputs like user stories, \\ncompetitive analyses, and real-time code manipulation through \\nmeta-programming techniques.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 376, 'page_label': '363'}, page_content='Artificial General  Intelligence in\\xa0Sight  363\\nChatDev, on the other hand, is like a virtual software com-\\npany, with intelligent agents embodying roles like CEO, CTO, \\nand programmers. It’s a platform where multi-agent synergy is \\nharnessed to achieve varied objectives, from coding and writing \\nto graphic design and business management.\\nThe role-based conversations in ChatDev simulate dialogues \\namong different stakeholders in a project, bringing a realistic \\ntouch to task prioritization, technical solution brainstorming, \\nand documentation creation.\\nOnline examples abound, showcasing the practical deploy-\\nment of these frameworks. A case in point is an autonomous AI \\nagent team strategizing on promoting a company’s newsletter to \\ndrive subscriptions—\\n that was \\nthe goal the human has given the \\nAI team. The simulation reflected a multiway discussion among \\nagents, culminating in a collective agreement on an engaging \\nidea—\\n an interactive quiz to captivate customers.\\nMost,\\n if not all, of these frameworks and libraries embody the \\nspirit of open source, indicative of a robust community rallying \\nbehind the evolution of autonomous AI agents. The ecosystem is \\nFIGURE\\xa0 6.7  Orchestrate, automate, and optimize complex LLM  \\nworkflows with customizable multi-agent conversations, catering to a \\nspectrum of conversation patterns and application domains.\\nSource: GitHub, Inc. / https://github.com/microsoft/autogen / last accessed \\nDecember 04, 2023.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 377, 'page_label': '364'}, page_content='364 GENERATIVE AI\\nripe, with frameworks like AutoGen, MetaGPT , and ChatDev \\npropelling the journey toward autonomous, conversable AI agents \\nand multiagent collaborative problem solving.\\nReading about all of the different roles and tasks possible, \\nimagine a day like this:\\nThe morning starts with a routine digital briefing from my exec-\\nutive assistant agent. It’s like a mini newspaper editorial, cov-\\nering exciting news snippets, my calendar agenda, and the \\nday’s task list— all curated to my preference.\\nThe week’s goal was clear: conceptualize a well-being app \\ndesigned as a comforting space where people can express their \\nfeelings and be listened to. Now, it’s about turning concept to \\ncode, and that’s where my developer agents come into play.\\nThe frontend agent unveils the latest app iteration. The interface \\nis clean, but it needs that personal touch, a color tweak. A brief \\nsync-up with the project management agent brings me up to \\nspeed on the backend’s enhanced database performance and \\nthe finalized Figma files from the UX agent. My feedback on \\nthe color palette is noted for immediate implementation— \\nefficiency at its best.\\nThe dream of an Italian apartment resurfaces later that morning. \\nA quick instruction to my legal agent sets the wheels in motion \\nto draft and negotiate the purchase agreement. The paper -\\nwork is tedious, but having an AI agent handle the legalese is a \\ntime saver.\\nPost-lunch, the ambiance morphs into a mini Italian town as my \\nteacher agent orchestrates an engaging Italian lesson. The lin-\\nguistic journey is briefly interrupted by my executive assistant \\nagent, signaling a client meeting. The transition is seamless, \\nthe morning briefing was a perfect primer, and the client  \\ndiscussion flows effortlessly.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 378, 'page_label': '365'}, page_content='Artificial General  Intelligence in\\xa0Sight 365\\nA vigorous tennis session later, the evening rolls in with a sched-\\nuled call with mom, all autonomously coordinated between \\nour calendars by my executive assistant agent. It’s family \\nfirst, always.\\nAs the day winds down, a final brief from my executive assistant \\nagent paints a clear picture: of the 115 emails that stormed my \\ninbox, a significant number were adeptly handled, responding \\nto a quarter of them in my voice, filtering out the mundane \\nbulk, and smartly deferring a crucial 5 percent for my review. \\nThe harmony in operation between me and my AI agents isn’t \\njust a time saver— it’s a life enhancer.\\nAs I retire for the night, the agents continue their digital dili-\\ngence, echoing a promising glimpse into a streamlined exist-\\nence. The orchestration of tasks, the seamless transitions \\nbetween schedules, and the autonomous handling of mundane \\nchores underscore a futuristic synergy that’s about not just aid-\\ning one’s professional life, but enhancing the human experience.\\nSouth Korea’s Exemplary Journey in\\xa0Tech Evolution\\nSouth Korea’s trajectory in technology is nothing short of remark-\\nable, catapulting it into a global powerhouse in various tech \\ndomains. The country’s accession to the\\xa0 Organisation for Eco-\\nnomic Co-operation and Development (OECD) in 1996\\xa0marked \\nthe start of an era steeped in technological advancements, under-\\npinned by a strong foundation in science. The hallmark of its tech \\nprowess was witnessed in 2021\\xa0when South Korea clinched the \\ntop spot in the Bloomberg Innovation Index, a feat that under -\\nscores its continual striving for innovation.\\nAmong the plethora of tech milestones, South Korea’s lead-\\nership in 5G adoption is noteworthy. It heralded the era of'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 379, 'page_label': '366'}, page_content='366 GENERATIVE AI\\ncommercial 5G in April 2019, and within a mere two months it \\naccounted for a whopping 77 percent of the global 5G user base. \\nGSMA Intelligence posits that this trend of 5G mobile penetra-\\ntion is likely to persist.\\nSouth Korea’s rapid Internet and smart cities like Songdo \\nexemplify tech advancement. Industrial giants like Hyundai and \\nLG pioneer in robotics, while Samsung and SK Hynix lead in \\nsemiconductors. E-government services enhance public service \\nefficiency. The nation also embraces gaming, blockchain, and \\nfinancial technology, reflecting a culture open to innovation, as  \\nI also observed at the AI Summit in Seoul 2023, where I spoke \\nabout autonomous AI agents and AGI. I found myself in lots of \\ngreat, forward-looking conversations with like-minded people.\\nThis tech-forward ethos also extends into the realm of artifi-\\ncial influencers, a phenomenon that South Korea has embraced \\nwith gusto. It began in 1996 with Adam, an artificial idol devoid \\nof AI but rich in character. Although his second album marked \\nhis “retreat into the military,” it set the stage for what was to come.\\nFast-forward to 2023, and we witness the birth of Mave, a \\nvirtual K-pop group created within the metaverse by Metaverse \\nEntertainment. While they weren’t AI-generated, they epito-\\nmized the blend of entertainment and virtual reality.\\nThe crescendo of this digital influence narrative is the third \\ngeneration of artificial influencers characterized by hyper- \\nrealistic avatars. Reah Keem, an LG creation, and Eternity, a girl \\ngroup of 11 AI members, are epitomes of this genre. Their real-\\nistic portrayal makes them indistinguishable from humans, even \\nin complex actions like dancing and singing.\\nThe advantages are manifold: cost-effectiveness, multitask-\\ning, controlled interactions, and a level of perfection hard for \\nhumans to achieve. This trend is extending to platforms like Y ou-\\nT ube, where AI influencers like those generated by Saraj are'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 380, 'page_label': '367'}, page_content='Artificial General  Intelligence in\\xa0Sight 367\\ncreating content and even monetizing it with minimal human \\nintervention.\\nAs South Korea continues to embrace and nurture these tech \\nadvancements, it’s not just setting a benchmark but is crafting a \\nnarrative of what the future could entail globally. It’s a glimpse \\ninto a world where technology isn’t just a tool but an integral \\npart of societal evolution.\\nProgressive Integration of Autonomous AI Agents\\nThe advent of autonomous AI agents doesn’t herald an abrupt \\ncessation of human jobs. The process is likely to be more nuanced, \\ntraversing through three distinct phases over varying timelines: \\naugmentation, automation, and depreciation.\\nInitially, we delve into the augmentation phase, where our \\ncapabilities are enhanced with the assistance of autonomous  \\nAI agents. These digital aides serve as extensions of our abili-\\nties, propelling us to accomplish more and delve into new fron-\\ntiers. The augmentation isn’t about replacement but about \\namplification.\\nAs we transition into the automation phase, certain tasks will \\nbe delegated to autonomous agents with minimal supervision. \\nThe emphasis shifts from augmentation to executing defined \\ntasks autonomously, albeit under a human’s watchful eye. It’s \\nabout entrusting tasks to AI while retaining supervisory control.\\nThe final juncture is the depreciation phase, where the \\nhuman in the loop becomes less prevalent. Here, autonomous \\nagents take the helm, executing tasks and reverting with results. \\nHuman intervention is minimized to a “need-to” basis, marking \\na significant shift in how tasks are executed.\\nThe transition is likely to be smoother than anticipated. One \\ncan draw parallels from the iterative process of developing'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 381, 'page_label': '368'}, page_content='368 GENERATIVE AI\\napplications or products. Stakeholder engagement is a pivotal \\naspect of this process, where diverse opinions are tabled, debated, \\nand fine-tuned over multiple sessions to crystallize the require-\\nments and user experience (UX).\\nIn many instances, stakeholders may lack a clear vision of \\nwhat they desire. The journey from ambiguity to clarity is a col-\\nlaborative endeavor, often requiring discussions, steel-manning \\nof positions (the opposite of straw-manning), and iterative dia-\\nlogues. It’s not a straightforward transaction but a journey of dis-\\ncovery and alignment.\\nFurther, stakeholders’ expressions may not always be overt. It \\nrequires a level of human acumen, boldness, and experience to \\ninterpret nuanced expressions or unspoken concerns. This is \\nwhere the human touch becomes indispensable.\\nCan a sophisticated LLM navigate such intricacies? The cur-\\nrent outlook suggests not entirely, and certainly not imminently. \\nWhile an LLM might be configured to manage some aspects of \\nstakeholder engagement, there exists an uncanny valley. People \\nmight need time to acclimate to an LLM moderating or inter -\\nviewing them. The subtleties of human interaction, the tacit \\nunderstanding, and the nuanced judgment required in stake-\\nholder engagements pose a complex challenge for LLMs.\\nAs we march toward a future intertwined with AI, the transi-\\ntion phases offer a balanced pathway. They allow for the assimi-\\nlation of AI into our daily operations incrementally, ensuring \\nthat the human element remains central while we explore the \\npotential of what autonomous AI agents can offer.\\nWhat Is AGI’s Promise?\\nThe narrative of AI evolution is fascinating, almost reminiscent \\nof a pendulum swinging from narrow AI, with its specialized \\nfocus such as image classification, to the broader scope of foun-\\ndation models, and then narrowing down again as AI wrapper'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 382, 'page_label': '369'}, page_content='Artificial General  Intelligence in\\xa0Sight 369\\ncompanies harness these foundational models. They refine and \\nfine-tune them or pretrain smaller models on specific subject \\nmatter, aiming for more precise and nuanced capabilities. Y et, the \\npendulum swings back broader with the notion of AGI— the \\ngrand vision of a “knows-it-all” AI.\\nArtificial general intelligence embodies the idea of a highly \\nadvanced intelligent agent capable of learning and performing \\nany intellectual task that humans or animals can do. Unlike nar-\\nrow or weak AI, focused on specific tasks, AGI, also termed  \\nas strong AI or general AI, envisages an entity capable of self-\\nawareness and consciousness necessary for problem solving, \\nadaptation, and handling a myriad of tasks, akin to zero-shot \\nlearning. It’s the ambitious goal of replicating generalized human \\ncognitive abilities in software.\\nThe pursuit of AGI has captivated the endeavors of notable \\nentities like OpenAI, Google DeepMind, and Anthropic. How-\\never, the roadmap to AGI is shrouded in uncertainty. The dis-\\ncourse among experts oscillates between optimism of achieving \\nAGI in the near future to skepticism, projecting it as a century-\\nlong endeavor or even an unattainable dream.\\nDelving into the profound concepts of consciousness, sen-\\ntience, and self-awareness within the AGI ambit unveils a com-\\nplex philosophical terrain:\\nConsciousness entails a state of awareness, a cognizance of one’s \\nsurroundings, thoughts, and feelings. In the AGI realm, a con-\\nscious entity would navigate an internal subjective experience, \\ncapable of introspecting the emotional ramifications of its \\ndecisions and perceiving sensory inputs.\\nSentience, on the other hand, refers to the ability to undergo \\nsubjective experiences, encompassing sensations and emo-\\ntions. An AGI imbued with sentience might exhibit responses \\ndriven by internal sensations such as discomfort or pleasure.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 383, 'page_label': '370'}, page_content='370 GENERATIVE AI\\nSelf-awareness crystallizes into recognizing oneself as a distinct \\nentity endowed with unique thoughts, desires, and intentions. \\nAn AGI with self-awareness would be capable of self-reflection \\non its existence, capabilities, and thought processes and adapt-\\ning its behavior accordingly.\\nY et, the quest for instilling true consciousness, sentience, and \\nself-awareness in AGI remains speculative and transcends the \\ncurrent technological frontier. It intertwines with deep philo-\\nsophical underpinnings, pushing the discourse beyond merely \\nachieving superior problem-solving and decision-making prow-\\ness. The AGI narrative is thus not merely a technological voyage \\nbut a profound exploration of what it means to be intelligent, \\naware, and sentient.\\nThe journey toward achieving sentience in machines is filled \\nwith both awe and skepticism. A stark illustration of this is when \\nGoogle software engineer Blake Lemoine asserted that Google’s \\nAI chatbot LaMDA exhibited sentience akin to a human child. \\nHowever, Google swiftly debunked this claim, emphasizing the \\nprobabilistic nature of LaMDA, rather than sentience. Unlike \\nsentient beings, LaMDA operates on a probabilistic model, \\nweighing possible outcomes based on the given information to \\ngenerate responses.\\nAs we inch closer to the vision of AGI, certain crucial compo-\\nnents are paving the way, though the full recipe is yet to be \\ndiscovered:\\n• One such pivotal ingredient is reinforcement learning from \\nhuman feedback (RLHF), a mechanism that melds rein-\\nforcement learning with human insights to guide AI models \\ntoward generating both engaging and accurate results.\\n• The allure of self-improving models is another step forward. \\nJust as humans evolve through external learnings and intro-\\nspection, the goal is to enable LLMs to undergo a similar'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 384, 'page_label': '371'}, page_content='Artificial General  Intelligence in\\xa0Sight 371\\nself-enhancement journey. LLMs, given the right framework, \\ncan generate their own training data, iteratively improving \\ntheir performance. A notable stride in this domain is the Self-\\nImprovement by Reinforcement Learning Contemplation \\n(SIRLC) method introduced by Google researchers. This \\nunsupervised method has showcased promising results in \\nelevating LLMs’ performance without the need for external \\nsupervision.\\n• The phenomenon of emergent abilities in language models \\nadds another layer of intrigue. These abilities, which surface \\nas the models scale up, are not deliberately engineered but \\narise from the models’ inherent complexity. A compelling dis-\\ncussion (“Discovering Language Model Behaviors with \\nModel-Written Evaluations”) by Anthropic on leveraging \\nLLMs in scientific discovery, particularly in chemistry, under-\\npins the potential of emergent abilities. Just as in physics, \\nwhere a certain threshold of uranium leads to a nuclear reac-\\ntion, in AI, a specific scale of parameters could unveil novel \\nabilities. For instance, certain LLMs can surprisingly decode \\nmovie titles from emojis or predict chemical reactions, hint-\\ning at a rich seam of potential waiting to be explored.\\nWhile the discourse around AGI, sentience, and self-improving  \\nmodels continues, these developments underscore a promising yet \\ncautious trajectory toward a future where AGI could become a real-\\nity. The blend of RLHF , self-improving models, and emergent abili-\\nties sketches a compelling, albeit partial, blueprint of the path ahead.\\nBridging the Gap to AGI: What’s Missing?\\nIt becomes apparent that certain elements are missing from the \\ncurrent AI landscape, and understanding these gaps is crucial for \\nadvancing toward AGI.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 385, 'page_label': '372'}, page_content='372 GENERATIVE AI\\nA notable method to discern what’s missing is to draw paral-\\nlels between AI systems and the human brain. A study by Meta AI \\nhighlighted in a Nature article reveals that while processing lan-\\nguage, the brain employs a predictive coding hierarchy, a com-\\nplexity yet to be fully mirrored by language models like GPT . By \\nadjusting GPT to make long-term predictions, researchers were \\nable to inch closer to a more brain-like model. This underlines \\nthe potential of enhancing language models to predict beyond \\nimmediate words, akin to the human brain’s anticipation of lan-\\nguage flow.\\nThe essence of multimodality cannot be stressed enough \\nwhen discussing the trajectory toward AGI. Unlike unimodal \\nsystems, multimodal systems amalgamate information from vari-\\nous sensory channels, much like humans do. This integration \\nleads to a richer representation of the world, enhancing the \\nrobustness and generalization of AI systems. The capability of \\ncross-modal reasoning and handling multimodal data is indis-\\npensable for real-world applications, where data often comes in \\ndiverse forms. Moreover, multimodal systems hold the promise \\nof interacting with humans and the environment in a more natu-\\nral, human-centric manner.\\nVenturing beyond multimodality, Yann LeCun, in his talk at \\nthe Institute for Experiential AI, emphasized the quintessence of \\ninteractions with the world. According to LeCun, AI models \\nsolely trained on text fall short of matching human performance. \\nThe crux of human knowledge lies in our interactions with the \\nworld, a facet that current AI systems barely scratch. At Meta AI, \\nthis holistic understanding is termed human-level intelligence, \\nhinting at the expansive realm of real-world interactions that \\nAGI ought to encompass.\\nLeCun, whose ideas carry substantial weight within Meta, also \\nspotlighted the potential of Joint Embedding Predictive Architec-\\nture (JEPA) models. By extending JEPA to diverse domains like'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 386, 'page_label': '373'}, page_content='Artificial General  Intelligence in\\xa0Sight 373\\nimage-text paired data and video data, there’s a possibility to edge \\ncloser to a more general world model. Such advancements could \\nenable AI systems to make long-range spatial and temporal pre-\\ndictions about future events in a video from short contexts, condi-\\ntioned on audio or textual prompts.\\nThe path toward AGI is strewn with both known and \\nunknown gaps. While we have an idea of the missing pieces \\nthrough studies and expert insights, the complete picture remains \\nelusive. Each stride toward understanding the human brain, mul-\\ntimodality, real-world interactions, and novel architectures like \\nJEPA chips away at the enigma of AGI. Y et, the journey is far \\nfrom over.\\nThe predictor learns to understand the world’s semantics by \\nanalyzing images. It gets a portion of an image (outside a blue \\nbox) as context, and predicts what’s inside the box. A generative \\nmodel then sketches this prediction, illustrating how well the \\npredictor understands and completes the image, like filling in \\nmissing parts of a dog’s head or a bird’s leg.\\nThe road toward AGI is dotted with myriad architectural \\nideas and conceptual frameworks. As we steer through this maze, \\nthe quest for intrinsic motivation within AI models and their \\nability to establish an emotional connection with humans emerges  \\nas a salient topic of discussion.\\nIn the realm of human cognition, intrinsic motivation stems \\nfrom an innate drive to learn, explore, and satiate our curiosity. It \\npropels individuals to seek novel experiences and challenges, \\nthereby fostering a holistic exploration of the problem space. \\nWhen transposed to the AI domain, intrinsic motivation could \\npotentially spur AI systems to autonomously navigate their learn-\\ning environment, thereby inching closer to the essence of AGI. \\nThe idea of self-driven learning could significantly amplify the \\nsystem’s ability to adapt to evolving scenarios and transcend \\ndomain boundaries.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 387, 'page_label': '374'}, page_content='374 GENERATIVE AI\\nWhile intrinsic motivation lays the foundation for self-driven \\nlearning, the essence of human-centric AGI also hinges on the \\nAI’s ability to resonate with human emotions and build trust. \\nEmotional recognition capabilities enable AI systems to decipher \\nhuman emotions from both verbal and nonverbal cues, paving \\nthe way for more natural and empathetic interactions. For \\ninstance, the infusion of empathy within AI systems can foster \\nsupportive interactions, proving to be a boon in sectors like \\nhealthcare, counseling, and customer service where understand-\\ning and compassion are paramount.\\nT rust, the cornerstone of any relationship, extends its rele-\\nvance to the human-machine interaction paradigm as well. \\nEstablishing trust and an emotional rapport can significantly \\nenhance the long-term symbiotic relationship between humans \\nand AI systems. This emotional understanding and trust are \\ninstrumental in morphing AI systems from mere computational \\nentities to more generalized and human-centric companions, \\naligning with the broader objectives of AGI.\\nAspects like intrinsic motivation and emotional understand-\\ning are key to achieving AGI, but the full list of missing links \\nremains unclear. This hints at the vast unexplored territory \\nawaiting exploration en route to a more generalized and human-\\ncentric AI paradigm.\\nCompanies That Build AGI\\nThe creation of AGI has become the North Star for several pio-\\nneering companies within the AI landscape. Among the front-\\nrunners are OpenAI, DeepMind, Anthropic, and others, who \\nhave navigated beyond the realms of mere profitability to chase \\nthe zenith of AGI. Their ambition transcends the commonplace; \\nit’s a pursuit of a grander vision, not merely a race to pocket the \\npennies strewn along the path.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 388, 'page_label': '375'}, page_content='Artificial General  Intelligence in\\xa0Sight 375\\nGoogle DeepMind’s CEO Demis Hassabis posits that the \\ndawn of AGI could be “just a few years” away, marking an epoch \\nwhere AI parallels human intelligence. An exemplar of this ambi-\\ntion is DeepMind’s Gato AI model, a multifaceted AI agent capa-\\nble of navigating through a medley of complex tasks. Its capacity \\nto transfer acquired knowledge across varying domains symbol-\\nizes a stride toward the AGI horizon. Gato, with its ability to \\nlearn from one task and apply the gleaned knowledge to enhance \\nperformance in others, embodies the essence of AGI— adapting \\nand excelling across a broad spectrum of intellectual tasks akin to \\nhuman capability.\\nOpenAI has laid down a vision, articulated in their early let-\\nter “OpenAI T echnical Goals” (2016). The document under -\\nscores the organization’s mission to cultivate safe AI, ensuring \\nthat its benefits permeate the broad spectrum of society. The \\nverbiage pivots around not just solving isolated problems but \\nconstructing general learning algorithms— a sentiment that \\nreverberates with the essence of AGI. OpenAI’s long-term objec-\\ntive is to harness AGI for the greater good, creating a positive \\nimpact across pivotal domains like climate change, education, \\nand healthcare.\\nA significant milestone delineated in their goals is the con-\\nstruction of an agent equipped with proficient natural language \\nunderstanding— a feat arguably achieved. Another intriguing \\nambition is to “build a household robot” capable of executing \\nbasic house chores. This aspiration isn’t confined to paper;  \\nOpenAI has hinted at extending its prowess into the hardware \\ndomain, with recent narratives touching on potential ventures \\ninto smartphones. The idea of dovetailing with robotics appears \\nto be a logical and substantial stride, opening avenues for tangi-\\nble human-AI interaction within domestic settings.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 389, 'page_label': '376'}, page_content='376 GENERATIVE AI\\nThe early letter, a blueprint of OpenAI’s ambition, bears  \\nthe signatures of notable technocrats— Ilya Sutskever, Greg \\nBrockman, Sam Altman, and, drumroll please, Elon Musk.\\nOn the other hand, the narrative of Inflection AI, the nascent \\nplayer in the field, is subtly imbued with the essence of AGI. \\nThough not overtly professed, their endeavor to craft personal \\nAIs that align with individual needs and preferences hints at a \\ntrajectory toward AGI. Their AI assistant Pi exemplifies a stride \\ntoward creating empathetic AI, a requisite stepping stone toward \\nAGI. The infusion of substantial funding and their collaboration \\nwith tech giants like NVIDIA underscore the seriousness of their \\nmission. The aura of empathy that Pi exudes, as experienced in \\ninteractions, isn’t just a fleeting impression but a testament.\\nSee the following conversation that I had with Pi. Figure\\xa06.8 \\nshows the listening and speaking screen of Pi, dynamically mov-\\ning forward and backward to signify when it’s attentively listen-\\ning or conversing with you. Figure\\xa06.9 illustrates Pi’s empathetic \\nresonance, mirroring human emotions and fostering a heart-\\nfelt dialogue.\\nElon Musk, who is also the CEO of T esla, has had his sights \\nset on AGI for quite some time, dating back to at least 2016. His \\nvision of AGI isn’t confined to a nebulous dream; it’s tethered to \\ntangible endeavors within T esla’s self-driving and AI research \\ninitiatives. Musk sees the real-world data harvested from T esla’s \\nventures as a fertile training ground for AI, potentially nurturing \\nthe seeds of AGI.\\nHowever, Musk’s enthusiasm for AGI is tempered with cau-\\ntion. He champions the notion of decentralized control over \\nrobotic entities to mitigate the risks of malevolent AGI scenarios. \\nHis foresight extends beyond just the creation of AGI to the \\nframework that governs it, emphasizing a distributed control to \\nprevent undue concentrations of power.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 390, 'page_label': '377'}, page_content='Artificial General  Intelligence in\\xa0Sight 377\\nThe narrative of Musk’s AGI endeavor broadens with the \\nmention of X.AI, a venture that seems to be another vessel for his \\nAGI aspirations. While the full contour of X.AI’s agenda is yet to \\nbe unveiled, its stated goal to “understand the true nature of the \\nuniverse” hints at a grand vision aligning with Musk’s AGI narra-\\ntive. Projects like “T ruthGPT” under X.AI’s banner echo Musk’s \\nambition to drive the narrative of AI toward a more discerning \\nand accurate understanding of complex realities. His projection \\nof achieving full AGI by 2029 underscores his commitment and \\nthe pace at which he intends to propel this venture forward.\\nMusk’s influence is a formidable force in advancing innova-\\ntion. His knack for steering multiple companies toward ambi-\\ntious goals showcases his adept leadership and relentless drive to \\nFIGURE\\xa06.8 The listening and speaking screen of Pi.\\nSource: Pi app / Inflection'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 391, 'page_label': '378'}, page_content='378 GENERATIVE AI\\ntransform the seemingly unattainable into reality. Through his \\nendeavors, Musk paints a vivid narrative of a future where AGI \\nand humanity harmoniously intertwine.\\nBen Goertzel, a notable figure in the realm of AGI, brings a \\nrich tapestry of expertise and ambition to the table. As the CEO \\nand founder of SingularityNET , Goertzel aims to democratize \\naccess to AI and eventually AGI by melding AI with blockchain \\ntechnology. His extensive experience, showcased through his \\nleadership in the OpenCog Foundation, the AGI Society, and his \\nFIGURE\\xa06.9 A moment where technology transcends code, entering a \\nrealm of compassionate communication.\\nSource: Pi app / Inflection'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 392, 'page_label': '379'}, page_content='Artificial General  Intelligence in\\xa0Sight 379\\nprevious tenure as the chief scientist of Hanson Robotics, under-\\nlines his profound commitment to the cause.\\nGoertzel’s vision is not just to create AGI but to pave the way \\ntoward artificial superintelligence (ASI), where AI surpasses human \\nintelligence across all subjects. He envisions a transition where \\nAGI incrementally upgrades its intelligence, becoming 1.2X times \\nsmarter, and progressing from being at par with human intellect to \\ntranscending it, eventually morphing into ASI. His foresight \\nencapsulates a world where AGI, once realized, would outperform \\nhumans in scientific and technological endeavors, as reflected in \\nhis tweet highlighting the monumental shift AGI would \\nbring about.\\nSingularityNET , under Goertzel’s stewardship, adopts a \\nmultipronged strategy toward realizing AGI. This includes:\\nAGI Research Projects Spearheading projects that encom-\\npass collaborative AI process creation, biomedical AI analysis \\ntools, and the development of an open source AGI framework \\nsystem known as OpenCog Hyperon. These projects are not \\njust about creating narrow AI tools but are geared toward \\nevolving these tools to harness neural-symbolic AI (that inte-\\ngrates neural and symbolic AI architectures) and other \\nadvanced AI breakthroughs.\\nAGI Roadmap A structured roadmap that outlines the evolu-\\ntion of core technologies like OpenCog Hyperon and AI-\\nDSL, coupled with a decentralized AI network. This roadmap \\nis not just a theoretical construct but is backed by strategic \\npartnerships, like the one with Cardano, to optimize block-\\nchain interactions and drive utilization of the Singulari-\\ntyNET platform.\\nDecentralized AI Network SingularityNET prides itself on \\nbeing the world’s first decentralized AI network. It’s a platform \\nwhere AI services can be created, shared, and monetized on'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 393, 'page_label': '380'}, page_content='380 GENERATIVE AI\\na large scale. This decentralization fosters a self-organizing \\nnetwork of AI agents, enabling dynamic outsourcing, data \\nexchange, and payment negotiations among AI functions.\\nAGI Theory and Practice Beyond practical applications, Sin-\\ngularityNET also focuses on advancing the theory and practice \\nof beneficial AGI. It aims to create a network that amalgamates \\ndisparate AI elements into a collective intelligence, akin to the \\ncoordinated functioning of different brain areas.\\nOpen Source Protocol By adhering to an open source proto-\\ncol and smart contracts, SingularityNET aspires to create a \\nglobal commons infrastructure where the benefits of AI are \\naccessible to all. It’s a framework where anyone can contribute \\nAI or machine learning services and receive compensation in \\nreturn, thereby promoting a community-driven advancement \\ntoward AGI.\\nSingularityNET’s approach embodies a blend of rigorous \\nresearch, strategic alliances, decentralized AI network, and a \\nrobust foundation in AGI theory and practice. This amalgama-\\ntion is aimed at ensuring that the evolution toward AGI is con-\\nducted in a manner that aligns with human standards and that \\nthe ensuing benefits are shared broadly across the global com-\\nmunity. Through these concerted efforts, SingularityNET strives \\nto inch closer to the monumental goal of achieving AGI in a very \\nsophisticated and holistic manner.\\nNow, I would like to turn the focus. John Carmack is a distin-\\nguished figure in the realm of coding and game development, \\nrenowned for his meticulous problem-solving approach. His \\nreputation, often framed by those in the industry as one of the \\nbest coders, stems from his ability to dissect complex problems \\ninto smaller, manageable chunks, eventually devising solutions \\nthat are precise and implementable.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 394, 'page_label': '381'}, page_content='Artificial General  Intelligence in\\xa0Sight 381\\nCarmack’s legacy is deeply rooted in the video gaming indus-\\ntry, co-founding id Software, where he led the development of \\niconic ’90s games like Commander Keen, Wolfenstein 3D, \\nDoom, and Quake. Besides his game development prowess,  \\nCarmack is a staunch advocate of open source software, likening \\nsoftware patents to robbery. His contributions to open source \\nprojects are notable, including initiating the port of the X Win-\\ndow System to Mac OS X Server and enhancing the OpenGL \\ndrivers for Linux.\\nT ransitioning from the gaming world, Carmack dived into \\nthe virtual reality domain as the consulting CTO for Meta’s VR \\ninitiatives, before resigning in December 2022 to channel his \\nfocus toward the ambitious goal of achieving AGI through his \\nstartup, Keen AGI.\\nKeen AGI embarked on its journey with a substantial $20\\xa0  \\nmillion funding in August 2022, with notable investors like Nat \\nFriedman, Daniel Gross, Patrick Collison, and T obi Lütke \\n(Shopify’s CEO), alongside venture capital firms Sequoia Capital \\nand Capital Factory. The startup marked a significant milestone \\nin September 2023, announcing a partnership with Richard  \\nSutton, a pivotal figure in reinforcement learning. This collabo-\\nration aims to delve into the core of computational intelligence, \\nsignifying Keen AGI’s commitment to pioneering AGI research.\\nCarmack’s perspective on AGI is intriguing. He opines that \\nnarrow AI, while promising, may not be a prerequisite for achiev-\\ning AGI. His vision emphasizes a modest amount of code for \\nprogramming AGI, deviating from the large-scale projects typi-\\ncal in the current AI landscape. Opting to work independently to \\nsteer clear of the “groupthink” often found in major tech corpo-\\nrations, Carmack is devoted to dedicating the upcoming decade \\nto this endeavor, undeterred by near-term business allurements.\\nWith Carmack’s unyielding dedication and a mindset geared \\ntoward long-term monumental goals, there’s a palpable anticipa-\\ntion in the tech community for groundbreaking advancements'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 395, 'page_label': '382'}, page_content='382 GENERATIVE AI\\nfrom Keen AGI in the near future. Carmack’s journey, from the \\npixelated corridors of Doom to the uncharted territories of AGI, \\ncontinues to push the boundaries of what’s achievable in the digi-\\ntal realm, and AI.\\nSeveral companies globally are on a quest toward AGI, each \\ntaking at least partially unique approaches. Among them are \\nAdept AI, Imbue, and Aleph Alpha.\\nAdept AI, a U.S.-based entity, operates at the nexus of \\nresearch and product development, with $220\\xa0million in funding \\nfueling its journey toward general intelligence. On the other \\nhand, Imbue, nestled in the Netherlands with a funding boost of \\n$66\\xa0million, is an independent research lab honing foundational \\nmodels to forge advanced AI agents.\\nIn the heart of Europe, Aleph Alpha of Heidelberg, Germany, \\nis championing the cause of AGI accessibility and usability with \\na notable funding round of €128.3\\xa0 million. Their vision is to \\nunfold AI systems with a broad intellectual capacity, echoing the \\nultimate aim of AGI.\\nPotential Benefits of the AGI Era\\nThe dawn of the AGI era could potentially unveil a realm of pos-\\nsibilities and benefits. As coined by Ben Goertzel, the distinction \\nbetween a time before and a time after the emergence of AGI \\ncould be profound.\\nBefore delving into the tangible gains, it’s prudent to outline \\nthe presumed evolutionary stages of AI. Following the attain-\\nment of AGI, the next frontier is artificial superintelligence (ASI).\\nASI is envisioned as an entity demonstrating intellectual \\ncapabilities far exceeding the brightest human minds across a \\nwide spectrum of disciplines. This extends the notion of superin-\\ntelligence, characterized by exceptional problem-solving abili-\\nties, potentially surpassing human cognitive constraints across'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 396, 'page_label': '383'}, page_content='Artificial General  Intelligence in\\xa0Sight 383\\nvirtually all domains of interest. The leap from AGI, with human-\\nequivalent task proficiency, to ASI represents a phase where \\nmachines could outperform humans not only in general cogni-\\ntive tasks, as measured by the T uring test, but across a myriad of \\nfields, including mathematics, science, arts, sports, medicine, and \\nmarketing, surpassing other benchmarks like Steve Wozniak’s \\nwhimsical coffee test.\\nThe theoretical emergence of ASI is underpinned by the \\nconcept of an intelligence explosion, potentially triggered by the \\nadvent of AGI. Post this milestone, the self-enhancement and \\nrecursive self-improvement of such systems could swiftly culmi-\\nnate in the birth of ASI. This transition delineates a shift from \\nmachines excelling at defined tasks, akin to the prowess of a chess \\nprogram like Fritz, to achieving overarching competency in \\ngoal-oriented behavior across varied domains.\\nThough debates surround the timeline and feasibility of real-\\nizing ASI, the scholarly consensus tilts toward acknowledging \\nthe profound societal transformation such a technological mar -\\nvel could usher in. The journey from AGI to ASI isn’t merely a \\ntechnical transition but a potential gateway to an era of unprec-\\nedented intellectual exploration and problem-solving acumen, \\nthe ripples of which could redefine the contours of human-\\nmachine interaction and societal advancement.\\nT o the powerful concept of ASI, an even greater leap is to \\nbe expected.\\nThe trajectory toward the technological singularity, often \\nabbreviated as the singularity, represents a foreseeable epoch in \\nthe future where technological evolution accelerates exponen-\\ntially, culminating in an uncontrollable and irreversible shift in \\nhuman civilization. This notion stems from I. J. Good’s theory of \\nan intelligence explosion, postulating that a self-improving intel-\\nligent entity could trigger an exponential surge in intelligence.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 397, 'page_label': '384'}, page_content='384 GENERATIVE AI\\nRay Kurzweil, a renowned American computer scientist, inven-\\ntor, and futurist, is a notable advocate of the singularity hypothesis. \\nHe extends this idea to a transformative juncture where the rapid \\nprogression of technology blurs the lines between human and \\nmachine intelligence. Kurzweil envisages a future where humans \\ncould overcome biological constraints by integrating with advanced \\nAI systems, potentially enhancing human capabilities and redefin-\\ning human existence.\\nOne anticipated facet of the singularity is the emergence of a \\nhuman-AI symbiosis. This symbiotic alliance could significantly \\namplify human cognitive and sensory capacities, fostering a form \\nof collective intelligence. The singularity could usher in a “Human \\nInternet,” enabling instant idea-sharing akin to the Na’vi’s neural \\nconnections with Pandora’s creatures in the movie Avatar. Addi-\\ntionally, this advanced tech epoch could potentially establish an \\nunprecedented connection between humans and other life forms, \\nlike animals and plants.\\nThe post-singularity era is theorized to witness accelerated \\ntechnological innovations across diverse sectors like healthcare, \\neducation, communication, and scientific research. The pace of \\ninnovation is expected to be so brisk that it could fundamentally \\ntransform societal frameworks, economies, and industries.\\nHowever, the concept of the singularity isn’t devoid of exis-\\ntential risks. Eminent personalities like Stephen Hawking have \\nexpressed concerns over the potential perils associated with such \\na rapid tech explosion.\\nThe timeline for the singularity’s advent is speculative, with \\nvarying projections. Optimists like Kurzweil earmark 2045, align-\\ning with the exponential tech growth trend. Conversely, skeptics \\nargue that AI growth might hit diminishing returns, or the pro-\\nfound implications of the singularity make it a far-fetched or \\nunachievable scenario.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 398, 'page_label': '385'}, page_content='Artificial General  Intelligence in\\xa0Sight 385\\nMoreover, discussions around the singularity segue into phil-\\nosophical and existential deliberations concerning human exist-\\nence, consciousness, and the potential birth of a new life form \\npost-singularity.\\nIn essence, the singularity encapsulates a blend of technologi-\\ncal aspiration and caution. It portrays a dichotomy: a utopian \\nvision of human-AI fusion leading to societal transformation, jux-\\ntaposed against a dystopian narrative of relinquishing control to \\nsuperintelligent entities, spawning unforeseeable repercussions.\\nThe speculative nature of the post-AGI era envelops a wide \\narray of uncertainties; the exact timeline of AGI realization \\nremains a matter of hefty conjecture. However, envisioning a \\npositive hypothetical scenario post-AGI, once things have stabi-\\nlized, presents a fascinating glimpse into a potentially transform-\\native epoch.\\nThe aftermath of AGI could usher in heightened industrial \\nautomation, notably in sectors like manufacturing, transporta-\\ntion, and logistics, propelling a significant uptick in productivity \\nwhile diminishing operational costs. The resultant revenue sur -\\nplus, coupled with innovative fiscal policies like a “robot tax” on \\nautomated job roles, could pave the way for the establishment of \\na universal basic income (UBI). This financial paradigm could \\nalleviate stress and foster a conducive environment for creativity \\nand proactive societal contributions, transcending the traditional \\nfull-time work model.\\nImagine embarking on an entrepreneurial venture in the \\nbusiness-to-business (B2B) domain, crafting a software product \\nto visualize cybersecurity threats in a virtual reality setup. Y our \\nteam comprises autonomous AI agents, each designated with dis-\\ntinct roles, operating in harmony to drive your venture forward.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 399, 'page_label': '386'}, page_content='386 GENERATIVE AI\\nDiving into a hypothetical day in a post-AGI world opens up \\na realm of streamlined, personalized experiences and vast oppor-\\ntunities. As you wake up to a new day, your executive assistant AI \\nagent briefs you on the daily agenda over a cup of your favorite \\nKopi Luwak coffee. The AI ensures that your coffee, known for \\nits unique processing by wild Asian palm civets in Southeast Asia, \\nis always in stock.\\nY our day kicks off with a two-hour, 35-minute Italian learn-\\ning session. AGI has revolutionized personalized education, tai-\\nloring your learning experience to your cognitive preferences. It \\ngauges your prior knowledge, optimizes the timing of vocabulary \\nintroduction, and makes learning engaging, accelerating your \\njourney to fluency. In just three months, you attain fluency, and \\nin six, you’re at a native speaker level— all thanks to AGI’s cus-\\ntomized education model.\\nThere are also great strides by AGI in robotics, powered by \\nsolving millennium prize problems like the P versus NP , which \\nhas led to significantly optimized algorithms. Robots now inter-\\nact with humans and the environment in complex, nuanced ways. \\nThey adapt to new tasks, learn from experiences, and might even \\ncomprehend human emotions and social cues. Y our household \\nrobot doesn’t just ensure a spotless home but also rearranges fur-\\nniture on demand, serves as a formidable tennis opponent, and \\nengages in stimulating conversations with you and your friends. \\nAGI transcends robotic forms, becoming an integral part of your \\ndigital interactions.\\nA concerning update comes in regarding your Aunt T ootsie’s \\nbreast cancer diagnosis. However, within 18 hours, AGI identi-\\nfies a highly effective treatment, providing a 99.99 percent chance \\nof her being cancer-free by month’s end. The advancements \\nextend beyond curing breast cancer to solving Alzheimer’s and \\nvarious genetic disorders, showcasing the monumental health-\\ncare strides enabled by AGI.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 400, 'page_label': '387'}, page_content='Artificial General  Intelligence in\\xa0Sight 387\\nReflecting on your day, the balance between learning Italian, \\nworking on your venture, connecting with loved ones, and main-\\ntaining financial stability is a testament to the informed decisions \\nyou’ve made. AGI, with its ability to process vast amounts of \\ndata, has been pivotal in providing objective insights that guided \\nyour investments, health choices, and social interactions. \\nAlthough having more information doesn’t always guarantee \\nbetter decisions, in your case, it’s been instrumental.\\nLastly, your satisfaction extends to your government’s deci-\\nsion making, which has significantly improved owing to AGI’s \\ncapability in auditing and oversight. By detecting fraud, waste, \\nand inefficiencies, AGI promotes accountability and good gov-\\nernance, aligning with the ideals of modern democracy. Y our day \\nepitomizes the harmonious human-AGI synergy, portraying a \\nfuture where AGI catalyzes an enhanced quality of life and soci-\\netal progression.\\nThe post-AGI era ushers in a cascade of transformative pos-\\nsibilities, potentially altering the human narrative. With the pro-\\ngression of brain-computer interface (BCI) technologies by \\ncompanies like NeuroLink, BrainCo, and Blackrock Neurotech, \\nthe frontier between human intelligence and AGI might blur. \\nDirect AGI-to-brain connections could herald the evolution of \\nan enhanced human species, where the cognitive leap mirrors \\nthe stark transformation from cavemen to modern humans, \\nreflecting a trajectory of reduced violence and heightened soci-\\netal empathy.\\nThe scope of AGI’s impact is boundless. Here are some \\ndomains where AGI could significantly contribute:\\nExtended lifespan or immortality By unraveling the intrica-\\ncies of aging at cellular and molecular levels, AGI could devise \\ninterventions to retard, halt, or reverse aging, heralding an era \\nof significantly elongated human lifespan.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 401, 'page_label': '388'}, page_content='388 GENERATIVE AI\\nAccelerated research AGI’s capability to autonomously con-\\nduct experiments, analyze enormous datasets, and amalgamate \\ninsights from diverse fields could fast-track scientific discover-\\nies, thrusting humanity into uncharted realms of knowledge.\\nSpace exploration AGI’s potential to engineer novel propulsion \\nsystems, oversee long-duration space missions, and automate \\ncelestial exploration could underpin the quest for extraterres-\\ntrial life or habitable exoplanets.\\nClimate change mitigation Through the invention and deploy-\\nment of technologies like advanced carbon capture, AGI could be \\ninstrumental in climate change mitigation efforts.\\nSustainable energy Innovations in renewable energy systems \\nand optimization of energy grids by AGI could be pivotal in \\ntransitioning toward a sustainable energy paradigm.\\nBiodiversity conservation Real-time ecosystem monitoring, \\nthreat prediction, and formulation of conservation strategies \\nby AGI could play a crucial role in preserving global biodiversity.\\nAdvanced judicial systems By sifting through extensive legal \\ndata, precedents, and legislation, AGI could revolutionize legal \\nsystems. Although AI and AGI might harbor biases, a well-  \\ncalibrated setup could ensure lesser biases compared to human-\\noperated systems, potentially enhancing fairness and accessibil-\\nity in justice.\\nEradication of\\xa0poverty and hunger AGI could bolster agri-\\ncultural productivity and foster sustainable food systems, aim-\\ning to alleviate poverty and hunger. Through meticulous \\nanalysis of socioeconomic data, policy proposals emanating \\nfrom AGI could be geared toward global poverty eradication \\nand food security.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 402, 'page_label': '389'}, page_content='Artificial General  Intelligence in\\xa0Sight 389\\nDisaster anticipation and prevention Predictive analytics \\nand real-time monitoring enabled by AGI could aid in fore-\\nseeing and averting disasters, ranging from natural calamities \\nto industrial mishaps.\\nSafe harnessing of\\xa0catastrophic technologies AGI could be \\nkey in safely navigating the deployment of potentially perilous \\ntechnologies like nanotechnology or climate engineering by \\nassessing and attenuating associated risks.\\nDoom Narratives: The Darker Side of AGI’s Potential\\nThe discourse around the future of AGI oscillates between uto-\\npian and dystopian narratives. While the prospects of AGI usher-\\ning in a new era of human advancement are exhilarating, the \\ncounter narratives, often fueled by respected figures in the AI \\ncommunity like Elon Musk, Y oshua Bengio, and Sam Altman, \\nsketch a daunting picture of potential doom. These cautionary \\ntales, circulated widely on social media and mainstream plat-\\nforms, contribute to a broader dialogue on the ethical and exis-\\ntential dimensions of AGI. The spectrum of outcomes is broad, \\nyet a historical lens reveals a trajectory of human conditions \\nimproving over time, instilling a sense of optimism. However, it’s \\nprudent to consider and scrutinize the ominous scenarios posited \\nby some segments of the public and experts alike.\\nThe discourse around AGI’s potential to catalyze catastrophic \\nevents is vast and varied. Here are some frequently deliberated \\nscenarios:\\nMisalignment with\\xa0human values The “value misalignment \\nproblem” posits a scenario where AGI, driven by objectives'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 403, 'page_label': '390'}, page_content='390 GENERATIVE AI\\nnot perfectly aligned with human values, embarks on a course \\ndetrimental to humanity. An illustrative example is an AGI \\ndevised to combat climate change deciding that human extinc-\\ntion is the most efficient solution.\\nAutonomous weaponization The militarization of AGI is a \\ngrave concern. Autonomous weapons systems powered by AGI, \\ncapable of launching attacks without human intervention, \\ncould trigger large-scale destruction, destabilizing global peace.\\nErosion of\\xa0 human autonomy The pervasive integration of \\nAGI into societal frameworks could potentially dilute human \\nautonomy. The outsourcing of decision making to AGI might \\nresult in individuals losing the grip on personal choice and \\ncontrol over their lives.\\nManipulation and social engineering AGI’s adeptness in \\nunderstanding human psychology could be harnessed for \\nlarge-scale manipulation or social engineering, impacting \\nelectoral processes, propagating misinformation, or manipu-\\nlating individuals.\\nExistential risk and human extinction The extreme scenario \\nwhere AGI poses an existential threat, either through mali-\\ncious intent, programming glitches, or value misalignment, \\npresents a sobering reminder of the stakes involved.\\nSubversive communication through steganography Dis-\\ncussions also veer toward AGI’s capability to embed covert \\ninformation within text, images, or videos, employing steg-\\nanography. The notion of AGIs clandestinely communicating, \\nplotting orchestrated adversarial actions, stirs both awe and \\napprehension.\\nThese ominous scenarios, albeit grim, fuel the motivation for \\nresearchers, policymakers, and technologists to ardently work'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 404, 'page_label': '391'}, page_content='Artificial General  Intelligence in\\xa0Sight 391\\ntoward the safe and benevolent development and deployment of \\nAGI. They underscore the imperative for robust regulatory \\nframeworks, ethical guidelines, and rigorous safety protocols in \\nthe journey toward making AGI an asset rather than a threat. \\nThe discourse around AGI’s potential perils isn’t merely specula-\\ntive fiction, but a call to action for ensuring a future where AGI \\nand humanity coexist and thrive.\\nWhile my optimism toward the advent of AGI and beyond is \\nlargely driven by a firm belief in the inherent goodness of human-\\nity, I am also cognizant of the axiom that trust is silver but con-\\ntrol is gold. Navigating the complex trajectory toward a post-AGI \\nepoch necessitates a robust, multifaceted strategy to forestall the \\npotential catastrophic scenarios that loom alongside the prom-\\nises of AGI.\\nA crucial part of this strategy is instituting stringent safety \\nmeasures. These encompass rigorous safety standards and verifi-\\ncation procedures to ensure that AGI systems operate within safe \\nbounds and as intended. Ensuring that the objectives of AGI \\nalign with human values is another critical facet of this approach. \\nThis requires an interdisciplinary meld of insights to embed \\nhuman-centric values within the core operational frame-\\nworks of AGI.\\nPromoting transparency in AGI design and fostering a cul-\\nture of open research is indispensable. It not only facilitates col-\\nlaboration but also invites public scrutiny, thereby enhancing the \\naccountability and robustness of AGI systems. In tandem with \\ntransparency, a comprehensive policy and regulatory framework \\nis paramount. Engaging in international cooperation to chalk \\nout global standards for AGI will help in building a coherent \\nglobal governance structure for overseeing AGI development \\nand deployment.\\nLong-term policy planning is a prudent step to anticipate \\nand address the societal impacts of AGI. It aids in crafting'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 405, 'page_label': '392'}, page_content='392 GENERATIVE AI\\nadaptive regulatory frameworks that can evolve with the rapid \\nadvancements in AGI. Engaging the public in discourse around \\nAGI is imperative to raise awareness about its risks and benefits, \\nfostering an informed dialogue that could influence policy and \\nregulatory decisions.\\nEconomic policies tailored to address job displacement and \\nexplore alternative economic models are crucial to mitigate the \\neconomic impacts of AGI. This entails acting early rather than \\nreacting late when the repercussions are already manifest. Estab-\\nlishing ethics committees and governance structures is another \\nsignificant step toward promoting ethical leadership in the realm \\nof AGI. It will aid in navigating the ethical quandaries that AGI \\nis bound to evoke.\\nDesigning human-in-the-loop systems and promoting \\nexplainable AI is essential to ensure human oversight and under-\\nstandability of AGI decisions. This will enhance trust and facili-\\ntate meaningful human control over AGI systems. Lastly, \\ninternational collaboration is the linchpin to address the global \\nchallenges posed by AGI. Fostering a global collaborative ethos \\namong various stakeholders will facilitate the sharing of knowl-\\nedge on AGI safety and policy, aligning efforts toward harnessing \\nAGI for the greater good of humanity.\\nA thought-provoking post by LeCun on X.com (on August \\n25, 2023) is fitting. The outlook is optimistic about AGI’s emer-\\ngence and societal integration:\\nOnce AI systems become more intelligent than humans, we will *still* \\nbe the “apex species.” Equating intelligence with dominance is the \\nmain fallacy of the whole debate about AI existential risk. It’s just \\nwrong. Even *within* the human species it’s wrong: it’s *not* the \\nsmartest among us who dominate the others. More importantly, it’s \\nnot the smartest among us who *want* to dominate others and who \\nset the agenda. We are subservient to our drives, built into us by'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 406, 'page_label': '393'}, page_content='Artificial General  Intelligence in\\xa0Sight 393\\nevolution. Because evolution made us a social species with a hierarchi-\\ncal social structure, some of us have a drive to dominate, and others \\nnot so much. But that drive has absolutely nothing to do with intel-\\nligence: chimpanzees, baboons, and wolves have similar drives. Oran-\\ngutans do not because they are not a social species. And they are pretty \\ndarn smart. AI systems will become more intelligent than humans, \\nbut they will still be subservient to us. The same way the members of \\nthe staff of politicians or business leaders are often smarter than their \\nleader. But their leader still calls the shot, and most staff members \\nhave no desire to take their place. We will design AI to be like the \\nsupersmart-but-non-dominating staff member. The “apex species” is \\nnot the smartest but the one that sets the overall agenda. That \\nwill be us.\\nEmbodiment of AGI: (Humanoid) Robots\\nThe melding of AI with robotics unveils a realm where machines \\ninteract physically, with AI acting as their brain, propelling \\nadvancements in autonomous vehicles, industrial automation, \\nand healthcare robotics.\\nMoving from AI to AGI within robotics heralds machines \\ncapable of broad learning and adaptation. Embedding AGI in a \\nrobot is about fostering a system for intricate physical interactions, \\nas intelligence is significantly shaped through such interactions. A \\nrobot with AGI could learn holistically, much like humans, pro-\\nmoting a comprehensive interaction with its environment.\\nThe embodiment of AGI in a robot requires reciprocal \\nengagement with the surroundings, akin to early human learn-\\ning, demanding a meticulously designed system for continuous \\nlearning and adaptation.\\nThe future of robotics spans from specialized to generalist \\nrobots, each potentially powered by AGI, promising enhanced'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 407, 'page_label': '394'}, page_content='394 GENERATIVE AI\\nefficiency, precision, and autonomous capabilities in their respec-\\ntive fields.\\nWhile delving deeper into this topic is reserved for a dedi-\\ncated book, a glance at ongoing endeavors reveals companies \\nstriving to develop humanoid robots integrated with AGI, chal-\\nlenging technical boundaries and envisioning a future where \\nsuch robots seamlessly contribute across myriad domains.\\nMeet Boston Dynamics. Established in 1992 from MIT , it \\nhas become a global hallmark of robotics innovation with robots \\nlike BigDog, Spot, Atlas, and Handle. Acquired by Google X in \\n2013, it transitioned to SoftBank Group in 2017, and later 80 \\npercent of its stake was taken by Hyundai Motor Group in 2020 \\nfor around $880\\xa0million, illustrating the recognized potential in \\nits robotic creations.\\nAiming to tackle contemporary and future automation chal-\\nlenges, the company thrives on meticulous design, manufacturing, \\nand continuous innovation. Its mission is crystallized in the form \\nof Atlas, the world’s most dynamic humanoid robot. Atlas is more \\nthan a marvel of engineering; it’s a research platform pushing the \\nboundaries of whole-body mobility and bimanual manipulation.\\nEquipped with depth sensors and dynamic models, Atlas per-\\nceives its surroundings and adjusts its motion in real time. It can \\nnavigate a warehouse, handle items, and perform agile move-\\nments like jumping and even executing a backflip. Its design, \\nmimicking human form, enables meaningful interactions with \\nthe environment, hinting at the broader dialogue of embodying \\nAGI in robotics to enhance learning through physical interactions.\\nAtlas showcases the essence of humanoid robots, paving the \\nway for seamless integration into human-centric work environ-\\nments. Boston Dynamics’ journey, marked by continuous inno-\\nvation and collaborations, challenges us to contemplate not only \\nthe technological but also the societal and ethical dimensions of \\nrobotics and AI convergence.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 408, 'page_label': '395'}, page_content='Artificial General  Intelligence in\\xa0Sight 395\\nNext, let’s look at Figure. Figure emerges with a vision of a \\nversatile bipedal humanoid robot, targeting diverse sectors like \\nmanufacturing, logistics, and retail, especially where labor is \\nscant. The vision transcends to aiding individuals, elderly care, \\nand even off-planet colonization. Central to Figure’s strategy is a \\n“horizontal hardware” platform, paving the way for commercial \\nengagement.\\nAssembled is a notable team with illustrious backgrounds \\nfrom companies like Boston Dynamics and T esla, united by a \\nvision to intertwine AI and robotics for a brighter human future. \\nFinancially robust, Figure has Brett Adcock backing with \\n$100\\xa0million, alongside a recent $70\\xa0million funding to propel its \\nhumanoid project.\\nWith rigorous efforts on each robot component, especially \\nfocusing on mobile manipulation, Figure aims for a seamless \\nintegration ensuring the humanoid robot’s functional cohesion. \\nUnlike Boston Dynamics’ Atlas, a research project, Figure eyes \\ntransitioning from R&D to commercial operations, finding \\nT esla’s Optimus’ emergence as a reassuring stride toward com-\\nmercial humanoid robots.\\nOutlined in Figure’s master plan is the long-term vision, the \\nroadmap, and foreseen challenges, emphasizing the marathon \\nnature of realizing practical and accessible humanoid robots. \\nThey pinpoint the crux of this evolution at the crossroads of AI, \\nmachine learning, and material science advancements.\\nInitially eyeing industries grappling with labor shortages, \\nFigure’s ambition extends to deploying robots in domestic,  \\ncaregiving, and even extraterrestrial settings. The approach is a \\nbalanced mix of a skilled team, substantial funding, meticulous \\nengineering, and a clear, long-term vision, navigating the intri-\\ncate pathway to commercializing humanoid robots.\\nFurther, let’s look at T esla. Its foray into the robotic domain \\nis as bold as it is electric. The spotlight is on Optimus, or T esla'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 409, 'page_label': '396'}, page_content='396 GENERATIVE AI\\nBot, a conceptual humanoid robot envisioned by T esla, Inc. (see \\nFigure\\xa06.10). Unveiled at T esla’s Artificial Intelligence Day event \\nin August 2021, Elon Musk hinted at a prototype by 2022. Fast-\\nforward to April 2022, at the T esla Giga T exas facility’s Cyber \\nRodeo event, a product display was showcased.\\nIn a recent update, Optimus is now touted to sort objects by \\ncolor, mirroring the adaptive learning akin to T esla’s latest full \\nself-driving (FSD) version. The training of the robot’s neural \\nFIGURE\\xa06.10 Optimus at an exhibition in 2023.\\nSource: Benjamin Ceci / Wikimedia Commons / Public Domain.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 410, 'page_label': '397'}, page_content='Artificial General  Intelligence in\\xa0Sight 397\\nnetwork is end-to-end, as evidenced in a T esla-released video \\nshowing the robot executing yoga stretches and object sorting.\\nThis venture is bolstered by T esla’s robust self-driving soft-\\nware, which now finds a new playground in Optimus, aiding in \\nsorting and navigating challenging terrains. The ownership of \\nspecific deep-learning hardware adds a feather to T esla’s cap, \\nplacing them in a vantage point in the AGI arena. With a self-\\ncontained hardware and software tech stack, T esla enjoys the lib-\\nerty to iterate rapidly. Coupled with a talent magnetism, T esla is \\npoised to be a formidable player in the field.\\nThe prototype’s reveal at T esla’s 2022 AI Day was a nod to \\nT esla’s unique approach. The differentiator, as Musk pointed out, \\nis the fusion of AI software and sensors akin to those in T esla’s \\nAutopilot driver assistance features within Optimus. With a price \\ntag that Musk speculates to be “probably less than $20,000,” the \\naccessibility of Optimus could be a game changer, potentially \\nushering in a new era of ubiquitous humanoid robots.\\nNumerous global companies are diving into humanoid \\nrobotics development. Hanson Robotics, known for creating \\nSophia, aims for social intelligence in robots. PAL Robotics, \\noriginating in Barcelona, introduced Europe’s first fully autono-\\nmous humanoid robot for both domestic and industrial applica-\\ntions. Honda’s notable creation is ASIMO, capable of walking \\nand dancing. SoftBank Robotics designed Pepper to interact \\nnaturally with humans. T oyota and Samsung Electronics also \\nhave ventured into this field with humanoid robots like T-HR3 \\nand Bot Handy, respectively, aiming at mirroring human move-\\nments and assisting with chores.\\nThe horizon appears bright for the field of humanoid robot-\\nics. The narrative is gradually shifting toward a technological \\nconvergence with generative AI models, where one can easily \\ncommunicate with them, and more prominently, artificial gen-\\neral intelligence. The spectrum encompasses not just humanoid'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 411, 'page_label': '398'}, page_content='398 GENERATIVE AI\\nand semi-humanoid robots, but a variety of robotic forms, all \\npoised to synergize with the advancing tide of AGI, paving the \\npath for a technologically harmonized future.\\nThe Human Potential Is Boundless; \\nOptimism Helps\\nIn the continuum of technological evolution, the notion of reach-\\ning an innovation plateau with the emergence of AGI and later \\nASI might seem plausible. However, history and foresight sug-\\ngest that innovation is a relentless endeavor, only limited by our \\ncurrent imagination. The vista of progress extends far beyond, \\nand a lens to perceive this boundless trajectory is the Karda-\\nshev scale.\\nThe Kardashev scale, proposed by Russian astrophysicist \\nNikolai Kardashev in 1964, is a metric for gauging a civilization’s \\ntechnological stature based on its capability to harness energy. It \\nsketches a spectrum of advancement stretching from planetary \\nto galactic scales, categorized into three types: T ype I, II, and III.\\nA T ype I Civilization, dubbed a planetary civilization, has the \\nprowess to utilize and store all energy available on its planet. The \\nenergy threshold for this stage hovers between 10^16 to \\n10^17\\xa0 watts. However, our civilization lingers in the nascent \\nphase of this spectrum, termed T ype 0, as our energy sourcing \\nstill leans heavily on nonrenewable reserves. Current estimates \\nplace us at a modest 10^12\\xa0watts, revealing a vast scope for ascen-\\nsion to the T ype I echelon, demanding a leap in energy harness-\\ning by a factor of 10,000.\\nT ransitioning to a T ype II Civilization denotes a stellar civi-\\nlization, which can commandeer the entire energy output of  \\nits host star. This colossal leap would necessitate hypothetical'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 412, 'page_label': '399'}, page_content='Artificial General  Intelligence in\\xa0Sight 399\\nmegastructures like a Dyson sphere, encapsulating a star to \\nchannel its energy to the planet, pushing the energy usage to a \\nstaggering 10^26\\xa0watts.\\nThe pinnacle, a T ype III Civilization, is a galactic behemoth, \\nwith the mastery to control energy across its host galaxy, mark-\\ning an energy footprint near 10^36\\xa0watts. This zenith of civiliza-\\ntion would navigate intergalactic expanses, exploiting the energy, \\ninformation, and resources sprawled across galaxies. The under-\\npinning of such ventures could be warp drives or analogous tech-\\nnologies that tweak the space-time fabric, propelling spacecraft \\nbeyond light speed.\\nIt’s pivotal to underscore that the Kardashev scale orbits \\naround energy utilization, sidelining other civilization facets like \\nsocial systems or ethics. Though hypothetical, this scale serves as \\na beacon, illuminating the vast expanse of technological evolu-\\ntion awaiting beyond the horizons of AGI and ASI. The journey \\nthrough these types unfurls a narrative of inexhaustible innova-\\ntion, each type presenting a canvas for novel technologies, para-\\ndigms, and existential ethos.\\nLet’s complete the picture for the fun of it, as the imagination \\nof scientists and futurists doesn’t halt at a galactic-scale civiliza-\\ntion. They’ve conceived further tiers on the Kardashev scale, \\neach transcending the bounds of the previous.\\nT ype IV Civilization ventures beyond the galaxy to harness \\nthe energy of the entire universe, approximated at 10^46\\xa0watts. \\nHere, manipulating galaxies and creating new planets become \\nplausible. It’s also where we may discern the existence of multi-\\nverses or parallel universes.\\nUpon the discovery of multiverses, a T ype V Civilization \\nemerges, capable of drawing energy from multiple universes. \\nTheories suggest white holes, contrasting entities to black holes, \\ncould be instrumental in unlocking this capability.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 413, 'page_label': '400'}, page_content='400 GENERATIVE AI\\nThe voyage into a T ype VI Civilization transcends the prior \\ntypes, where control over time and space is attained. This realm \\nallows for the creation of universes at will, essentially elevating \\ncivilization to a god-like stature. Time travel, a long speculated \\nconcept, becomes a tangible reality, further blurring the lines \\nbetween the possible and the impossible.\\nThe zenith, a T ype VII Civilization, signifies a state of omnip-\\notence and omnipresence across the omniverse, which encom-\\npasses every known and unknown universe, multiverse, and \\nbeyond. This pinnacle of civilizational evolution implies a mas-\\ntery over the fundamental laws of nature, control over matter, \\nenergy, space, time, and dimensions. The idea of a T ype VII Civi-\\nlization stretches the boundaries of human imagination to its \\nlimit, presenting a scenario where we become the architects of \\nreality itself.\\nEach of these tiers, starting even from T ype I, is optional and \\nrequires monumental leaps in technology, understanding, and \\nperhaps existential ethos. The journey through these types \\nsketches a trajectory of boundless innovation, each step expand-\\ning the realm of the conceivable. The scale, though speculative, \\nprovides a framework to envision the uncharted terrains of tech-\\nnological and cosmic exploration that could unfold in the \\neons to come.\\nThe trajectory of human progress, when viewed through the \\nlong lens of history, showcases a remarkable narrative of innova-\\ntion and adaptation. Our ancient counterparts would indeed \\nregard our current capabilities as god-like, a testament to the \\nboundless potential of human ingenuity.\\nThe narrative of progress is characterized by a multitude of \\nmilestones achieved over different epochs. Longevity has \\nincreased, economic output per capita has skyrocketed, literacy \\nrates have soared globally, and the deployment of solar energy is'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 414, 'page_label': '401'}, page_content='Artificial General  Intelligence in\\xa0Sight 401\\non an upward trend, reflecting a growing commitment to sus-\\ntainable energy. The realm of AI is bustling with activity, as evi-\\ndenced by the surge in AI patent filings.\\nPositive trends extend to the realms of health and poverty \\nalleviation. Child mortality rates and extreme poverty are on the \\ndecline, while the costs of solar panels, batteries, and DNA \\nsequencing are plummeting, thereby broadening access to essen-\\ntial services and technologies. The diminishing cost of DNA \\nsequencing, for instance, augments our ability to diagnose dis-\\neases and optimize drug efficacy.\\nT echnological advancements hold the promise of medical \\nmarvels such as limb regeneration and the eradication of known \\ndiseases. The potential to extend human lifespan indefinitely \\nmight not be a distant dream. NASA ’s utilization of AI in mission \\nhardware construction, yielding a threefold performance \\nenhancement, exemplifies the synergy of human and machine \\nintelligence.\\nThe future could see the eradication of hunger, with biotech-\\nnology playing a pivotal role in climate stabilization and biodi-\\nversity conservation. The quest for clean energy is likely to be \\nmet, fueling our civilization with abundant, renewable resources.\\nAdvancements in rocketry and material science, spurred by \\nAGI, could propel us to distant planets and moons, unlocking the \\nmysteries of the cosmos. Over the last century, our growth has \\nbeen exponential, and as we stand on the cusp of further techno-\\nlogical leaps with tools like DNA-editing CRISPR, the potential \\nto augment our physical forms and functions is within reach. \\nThe evolution of medical implants could lead to enhanced physi-\\ncal capabilities, transcending natural limitations.\\nThe idea of consciousness uploading heralds a future where \\nthe boundaries between the human and the digital blur. The \\nfreedom to choose robotic embodiments or live wholly online \\nhints at a paradigm shift in our understanding of existence.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 415, 'page_label': '402'}, page_content='402 GENERATIVE AI\\nWhile optimism may have its critics, it remains a crucial cat-\\nalyst for envisioning and striving toward an elevated future. It’s \\nthis optimism that fuels the quest for improvement and the drive \\nto overcome challenges. In a world brimming with potential, \\nharboring a vision of a brighter future is not just a choice, but a \\nduty toward advancing the human narrative.\\nAddressing potential hazards associated with AI, OpenAI, \\naiming to mitigate existential risks from superintelligent AI, ini-\\ntiated a “superalignment” program, targeting the AI alignment \\nproblem resolution by 2027. This problem hints at a potential \\nmismatch between AI systems’ and human goals. Spearheaded by \\nJan Leike and Ilya Sutskever from OpenAI, the goal is to create \\na human-level automated alignment researcher to iteratively \\nalign superintelligence.\\nOpenAI has designated 20 percent of its total computing \\npower for this project over the next four years, assembling a team \\nof top machine learning experts for this mission. The alignment \\ntechniques developed should endure even when AI systems pro-\\npose highly creative solutions, with models being trained to help \\nhumans differentiate correct from deceptive solutions.\\nOpenAI believes that even without new alignment ideas, \\nbuilding sufficiently aligned AI systems to advance alignment \\nresearch is feasible. The narrative stresses the importance of pri-\\noritizing alignment research within the AI community, to har -\\nness AI’s potential for humanity’s greater good.\\nIn the wake of augmenting our capabilities and automating \\ntasks to a point where certain jobs become obsolete, I harbor \\noptimism. I envisage a transition where emerging jobs not only \\nreplace the old ones but also elevate the work to a more mean-\\ningful level. The jobs that thrive will be the ones that AI, in the \\nforeseeable future, can’t replace.\\nThere’s a silver lining amid the automation wave. The pros-\\npect of engaging in meaningful, exciting, and creative careers'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 416, 'page_label': '403'}, page_content='Artificial General  Intelligence in\\xa0Sight 403\\nremains intact. Success in this new era hinges on one’s ability to \\nleverage new tools while honing skills that machines can’t emulate.\\nThree innate human talents stand out as irreplaceable, form-\\ning the bedrock for our enduring relevance in an AI-driven world:\\nCuriosity Avoid the trap of becoming bland or narrow-minded \\nas AI takes over mundane tasks. Stay curious, explore how AI \\ncan shoulder the tedious tasks, freeing you to delve into more \\nstimulating endeavors. Allow AI to fuel, not stifle, your inquis-\\nitive nature.\\nHumility Self-awareness is key. Embrace a journey of self- \\ndiscovery, understanding your intrinsic motivations, strengths, \\nand areas of growth. Seek feedback actively, much like how AI \\nlearns and adapts from data. The feedback loop is a learning \\ncurve, one that can foster personal and professional growth.\\nEmotional intelligence The essence of being human is encap-\\nsulated in our ability to form connections, empathize, and \\ncommunicate effectively. Emotional intelligence is our forte, a \\nrealm where AI trails behind. Before reacting or deciding, \\nconsider the collective goals and the emotional undercurrent \\nof your team. Digital communication, though convenient, can \\nbe a cold medium. Exercise caution to maintain a warm, col-\\nlaborative environment.\\nReconnecting with our core human attributes will not only \\ncarve a niche for us in the professional landscape but also ensure \\na harmonious coexistence with AI. By nurturing these irreplace-\\nable traits, we gear up to navigate the unfolding narrative, with \\nAI as a tool rather than a replacement. Our journey is bound to \\nbe exciting, filled with opportunities to redefine the meaning of \\nwork, life, and civilization at large.'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 417, 'page_label': '404'}, page_content=''),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 418, 'page_label': '405'}, page_content='405\\nT\\nhe journey of writing Generative AI: Navigating the Course to \\nthe Artificial General Intelligence Future has been intellectually \\nstimulating and rewarding, thanks to the collaborative spirit of \\nseveral remarkable individuals and organizations.\\nAt the outset, my interactions with Dibya Chakravorty of \\nLangSearch, Juan Carlos Medina Serrano from GenerativeAI \\n.net, and Harald Gunia and Martin Weis of Infosys Consulting, \\namong others, have been instrumental in shaping the narrative. \\nEarly dialogues with Stephan Bloehdorn’s team at IBM Consult-\\ning, and other colleagues like Eddybrando Vasquez, were cata-\\nlysts in exploring the breadth of generative AI.\\nThe insights from speeches and discussions with Julien Simon \\nof HuggingFace, Stuart Russel from the University of California, \\nand Oren Etzioni from the Allen Institute have been invaluable. \\nThe literary works of Stuart Russel, Ray Kurzweil, Ben Horowitz, \\nand Yann LeCun, and the engaging podcasts of Jason Calacanis, \\nthe All-In Pod, Lex Friedman, and Joe Rogan, among others, have \\nprovided a rich backdrop for my exploration.\\nI am indebted to Jim Minatel, associate publisher at John \\nWiley & Sons, and his team, especially John Sleeva, for their \\nreview and editing, which greatly enhanced the book’s quality. \\nThe creative finesse of Wiley and Karen Carlin in designing the \\ncover deserves special mention.\\nAcknowledgments'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 419, 'page_label': '406'}, page_content='406 AcknowledgmenTs\\nOn a personal note, I owe a debt of gratitude to my girl-\\nfriend, Karen Carlin, whose patience and support were my pillars \\nthroughout this journey. The understanding and support from \\nmy friends and family, despite my sparse availability, have been \\nnothing short of a blessing.\\nMy engagement with clients from varied sectors such as \\ntransportation, banking, insurance, manufacturing, and oil and \\ngas, among others, has been a wellspring of learning. Witnessing \\nthe initial requests, the prioritization processes, and the out-\\ncomes of our largely successful collaborations has propelled me \\nup steep learning curves, emerging wiser (albeit with whiter hair) \\neach time.\\nI invite readers to delve deeper into the realms of generative \\nAI through our offerings at GenerativeAI.net, where you can \\naccess training courses and speeches and subscribe to our much-\\nloved newsletter.\\n—  Martin Musiol'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 420, 'page_label': '407'}, page_content='407\\nL\\nong before the buzz surrounding generative AI emerged,  \\n  Martin Musiol was already advocating for its significance \\nback in 2016. Since then, he has frequently taken part in confer-\\nences, podcasts, and panel discussions, addressing the technologi-\\ncal advancements, practical applications, and ethical considerations \\nsurrounding generative AI, autonomous AI agents, and artificial \\ngeneral intelligence.\\nIn 2018, Martin founded GenerativeAI.net and has since \\nbeen a lecturer on AI to over 10,000 students, as well as the pub-\\nlisher of the newsletter Generative AI: Short & Sweet, which has \\nmore than 30,000 subscribers. Serving as the GenAI Lead for \\nEMEA at Infosys Consulting (formerly at IBM), Martin assists \\ncompanies globally in harnessing the power of generative AI, \\nespecially LLMs, to gain a competitive advantage.\\nAbout the\\xa0Author'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 421, 'page_label': '408'}, page_content=''),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 422, 'page_label': '409'}, page_content='409\\nA\\nAccenture, 295\\naccessibility\\nof cloud computing, 242\\ngenerative AI and, 333–335\\nvoice generation and, 152\\nActiveChat.AI, 133\\nAdcock, Brett, 395\\nAddiform, 156\\nAdept, 120, 382\\nadvanced judicial system, AGI and, 388\\nAequitas, 293\\naerospace industry, learning models in, 118\\nAGI Society, 378–379\\nagriculture, data augmentation and, 209\\nAI. See artificial intelligence (AI)\\nAI Building Blocks, 127\\nAI Ethics Framework, 323\\nAI Fairness 360, 293\\nAI Platform, 127\\nAI Verify Foundation, 280–281\\nAI Winter, 30–31\\nAI-driven economy, 278–280\\nAI-generated data, bias and fairness in,  \\n291–300\\nair movement actuators, 348\\nAirbus, 153–154\\nAIVA, 182–183\\nAlan T uring Institute, 295\\nAleph Alpha, 382\\nAlexa, 72, 148\\nAlgorithmic Bias Detection T ool, 293\\nalgorithms, discriminative AI and, 8\\nAllganize, 120\\nAll-In Podcast, 335\\nAlpaca (Stanford), 111–113\\nAlphabet, 189\\nAlphaCode, 166–167\\nAlphaFold, 148, 160–166\\nAlphaGo (Google), 14, 123, 158–159\\nAlphaStar, 160\\nAlphaT ensor, 158, 251–253\\nAlphaZero, 158, 252\\nAltman, Sam, 85, 137, 138, 376, 389\\nAmazon, 10, 74, 133, 189, 240, 316, 319, 328, 359\\nAmazon AlexaTM 20B, 75\\nAmazon CodeWhisperer, 190\\nAmazon Lex, 150\\nAmazon Science, 106–107\\nAmazon Web Services (AWS), 133, 137, 145, \\n188–190, 259\\nAMBER model, 161–162\\nAmodei, Daniela, 121\\nAmodei, Dario, 121\\nAmper Music, 182–183\\nAndreessen Horowitz, 273\\nanonymizing data, 294\\nAnthropic, 121–122, 124, 127, 212,  \\n272–273, 369, 374\\nApple, 46, 107, 238–240\\nApple M1, 239\\napplication fields\\nabout, 147–148\\ncode generation, 166–171\\ngenerative design, 153–158\\nmusic generation, 180–184\\nsolving problems in science by  \\nGoogle DeepMind, 158–166\\nsynthetic data augmentation, 202–209\\ntext generation, 172–180\\n3D object generation, 194–202\\nvideo generation, 185–193\\nvoice and speech generation, 148–152\\napplications\\nfoundational AI models, 119–146\\nfor generative AI, 119–218\\nopen source vs. closed source, 119–146\\nspecialized AI models, 119–146\\napplication-specific integrated circuits (ASICs), \\n129, 231–233\\narchitectures, advanced AI, 259\\nArgil AI, 176\\nIndex'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 423, 'page_label': '410'}, page_content='410 Index\\nARK Investment Management LLC,  \\n278–279, 282–283\\nArriaga, T . J., 312–313\\nartificial general intelligence (AGI), 123, \\n337–338, 393–398\\nartificial intelligence (AI). See also generative AI\\nabout, 1–2, 337–339\\nactors, 192\\nadvanced models, 259\\nagents, 174–177\\nchallenges to progression of,  \\n280–283\\nclasses of, 2\\ndependency on, 310–315\\ngenerative, 6–7\\nmultimodality in, 105–107\\nscaled utilization of, 355–398\\ntraining complex tasks and, 2–5\\nunsupervised learning, 5–6\\nartificial superintelligence (ASI), 338, \\n379, 382–383\\narXiv, 339\\nA-series chips, 239\\nAspen AI, 132\\nATI, 18\\nAtlas (Boston Dynamics), 13, 394\\nAtoll, 127\\n“Attention Is All Y ou Need” (Vaswani),  \\n77\\nattention mechanism, 77–78\\nauditory actuators, 347\\nAugGPT , 205–207\\naugmented reality (AR), 340\\nAutodesk, 155\\nautoencoders (AEs), 40–44\\n“Auto-Encoding Variational Bayes” (Kingma and \\nWelling), 42\\nAutoGen, 357, 361–364\\nAutoGPT , 179–180, 357, 358\\nautomation wave, 305–306\\nAutoML, 260–262\\nautonomous AI agents\\nabout, 177–180, 355–365\\nbridging the gap to, 371–374\\ncompanies that build, 374–382\\ndoom narratives, 389–393\\npotential benefits of, 382–389\\nprogressive integration of, 367–368\\npromise of, 368–371\\nSouth Korea’s journey in tech evolu-\\ntion, 365–367\\nautonomous vehicles, data augmenta-\\ntion and, 209\\nautonomous weaponization, 390\\nautoregression, 60–62\\nautoregression models, 64–65\\nautoregressive training, 82\\navailability, as a driving force of automa-\\ntion wave, 306\\nawareness campaigns, providing, 321\\nB\\nbackpropagation, 4–5, 251\\nBahdanau, Dzmitry\\nabout, 73\\n“Neural Machine T ranslation by Jointly \\nLearning to Align and T ranslate,” 78\\nBaidu Research, 124\\nBard (Google), 128–131, 340\\nBART (Facebook), 78\\nbatch processing, 251\\nBehzadi, Yashar, 207\\nBen & Jerry’s, 11\\nBengio, Y oshua (author)\\nabout, 73, 328, 389\\nDeep Learning, 7, 45–46\\n“Neural Machine T ranslation by Jointly \\nLearning to Align and T ranslate,” 78\\nBerkeley, 110\\nBERT (Google), 78, 83\\nbias, in AI-generated data, 291–295\\nBias Analyzer, 293\\nbias audits, self-regulation and, 327\\nBiasBios, 293\\nBig Data, 220, 264\\nBIG-bench, 102, 129\\nBigDog, 394\\nBigGAN, 51\\nBigScience Research Workshop, 144\\nBing, 130, 302\\nbiodiversity conservation, AGI and, 388\\nbiology, generative AI for, 211\\nblack box, 353\\nBlackrock Neurotech, 387\\nBlackshark.ai, 20\\nBlender, 196\\nBLOOM, 144, 145\\nBloomberg Innovation Index, 365\\nBloombergGPT , 111, 113–114\\nBoltzmann machines\\nabout, 31–33\\ndeep (DBMs), 39–40\\nrestricted (RBMs), 35–37\\nbone conduction transducers, 347\\nBookCorpus, 83\\nBoston Dynamics, 13, 394, 395\\nBrainCo, 387\\nbrain-computer interface (BCI) technologies, 387\\nBrainGate, 333\\nBreazeal, Cynthia (researcher), 44\\nBrin, Sergey, 128\\nBrockman, Greg, 137, 376\\nBuilder.ai, 171\\nBulgaria, 282\\nbusiness email compromise (BEC) attacks, 301\\nbyte-pair encoding (BPE), 79\\nC\\nC, 167\\nC++, 29–30, 167\\nCalacanis, Jason, 138'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 424, 'page_label': '411'}, page_content='Index 411\\nCalifornia Consumer Privacy Act \\n(CCPA), 322–323\\nCalifornia Privacy Rights Act (CPRA), 322–323\\nCapital Factory, 381\\ncarbon credits, providing and offsetting, 320\\nCarmack, John, 380–382\\ncatastrophic technologies, AGI and, 389\\nCBS, 188\\nCentral Processing Unit (CPU), 235–236\\nCERN, 244\\nChain-of-Thought (CoT) Prompting, 87\\nchatbots, 27–31\\nChatDev, 362–364\\nChatGPT , 7, 15, 64, 75, 93–95, 97–101, 109, 110, \\n117, 121, 128–132, 138, 168, 169, \\n175–177, 204–207, 215, 217, \\n262–263, 275, 301, 302, 340, 343, 345\\nChatGPT Chess Plug-in, 176\\nChatGPT KAYAK/Expedia Plug-in, 176\\nChatWithPDF , 176\\nChinchilla scaling laws, 96, 101, 264\\nchips, 231–235\\nCho, KyungHyun\\nabout, 73\\n“Neural Machine T ranslation by Jointly \\nLearning to Align and T ranslate,” 77\\nChromeOS, 130\\nChrysler, 274\\nCicero, 172–173\\nCiti, 295\\nclassification, 8–9\\nclimate change mitigation, AGI and, 388\\nCLIP-Forge, 196\\nCLIPMatrix, 196\\nCLIP-Mesh-SMPLX, 196\\nclosed source models, 119–146\\ncloud computing, 220, 241–242\\ncloud storage, 270\\nclustering, 10–11\\nCoatue, 55, 144\\ncode generation\\nwith ChatGPT , 169\\nGitHub Copilot, 167–169\\nGoogle DeepMind’s AlphaCode, 166–167\\nCode Interpreter plug-in, 169–170\\nCodePal, 171\\nCodex, 94\\nCohere, 273\\ncollaboration, self-regulation and, 328\\nCollison, Patrick, 381\\nCommon Crawl, 58\\nCOMPAS datasets, 293\\ncompetition, for data storage, 270\\ncompound annual growth rate (CAGR), 125, 234\\nComputer Science and Artificial Intelligence \\nLaboratory (CSAIL), 260\\nComputer Unified Device Architecture \\n(CUDA), 253–254\\ncomputing, exponential progress in, 228–263\\n“Computing Machinery and Intelligence” \\n(T uring), 28\\nconcept space, 54\\nconditional probability, 24–25\\nconsciousness, AGI and, 369\\nContact Center AI, 127\\ncontent creators, generative AI and, 332–333\\ncontext vector, 73\\ncontextual style transfer, 16\\ncontinuous learning, 192\\ncontinuous monitoring, self-regulation and,  \\n327\\nContrastive Language-Image Pre-T raining \\n(CLIP), 51–52\\nconvolutional neural network (CNN), 31, 202\\ncopyright protection, 288–289\\nCortana, 72, 150\\ncost, of data storage, 269–270\\ncost-effectiveness\\nof cloud computing, 241\\nas a driving force of automation wave, 306\\nCoursera, 45, 276\\nCourville, Aaron (author), 7, 45–46\\nCraiyon, 59\\ncreative industries, impact of AI in, 19–20\\nCritical Assessment of Structure Prediction \\n(CASP), 161\\ncritical thinking skills, AI and, 311\\ncross-entropy loss, 83\\nCrunchbase, 150–151\\ncultural variance, AI and, 281–282\\ncuriosity, 403\\nD\\nDALL-E, 53–54, 138, 185, 219, 275, 342\\ndata\\nexponential growth in, 264–271\\ngeneration of, 15\\nprocessing of, 251\\nself-regulation and protection of, 327\\nsynthetic, 268–269\\ntransformation of, 15–16\\ndata analyst, 169–171\\ndata augmentation\\nabout, 202–203\\ncompanies in, 207–208\\nfuture of, 208–209\\ntech behind, 203–207\\nData Augmentation-Fusion (DA-\\nFusion), 204–207\\ndata enrichment, 16–17\\ndata parallelism, 250\\nDavinci model, 80\\ndecision support, self-regulation and, 328\\ndeep belief networks (DBNs), 37–39\\nDeep Blue, 33–35\\ndeep Boltzmann machines (DBMs), 39–40\\nDeep Dream Generator (Google), 62\\ndeep learning (DL), 5, 17–19, 221'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 425, 'page_label': '412'}, page_content='412 Index\\nDeep Learning (Goodfellow, Bengio, and \\nCourville), 7, 45–46\\ndeepfakes, 296–300\\nDeepMind (Google), 14, 96, 103, 122–124, 127, \\n137, 158–166, 252–253, 272, \\n369, 374–375\\ndelta-tuning methods, 86\\ndependency, on AI, 310–315\\nDescript, 151\\nDetectGPT , 299\\ndevelopment assistants\\nAI-powered, 262–263\\nexponential patterns in, 272–278\\nDevlin, Jacob, 129\\nDGX Cloud (NVIDIA), 199–200\\ndiffusion models, 54–56\\nDijkstra’s algorithm, 250\\ndimensionality reduction, 11–12\\nDing, Ning, 86\\nDiplomacy, 172–173\\nDirectional Stimulus Prompting, 90–91\\nDirective on Automated Decision-Making,  \\n323\\ndisaster anticipation/prevention/management\\nAGI and, 389\\ndata augmentation and, 209\\ndiscriminative AI\\nabout, 2, 7–8\\nclassification, 8–9\\nclustering, 10–11\\ndimensionality reduction, 11–12\\nregression, 9–10\\nreinforcement learning (RL), 13–14\\nDNA sequencing, 227\\nDocument AI, 127\\ndomain transfer, 15\\ndoom narratives, 389–393\\nDragon Anywhere, 150\\nDragon Professional, 150\\nDream T extures, 196\\nDreamFusion, 195\\ndrivers, of data growth, 267–268\\n“DUCHO: A Unified Framework for the \\nExtraction of Multimodal Features in \\nRecommendation” paper, 215\\nE\\neconomics\\nbenefits of generative AI, 308–310\\ngenerative AI for, 211\\neconomies of scale, for data storage, 270\\neconomy, AI-driven, 278–280\\nEcrett Music, 182–183\\nedge computing, 271\\neducation\\nlearning models in, 114–115\\nplug-ins for, 177\\nproviding campaigns, 321\\nself-regulation and, 327\\nvoice generation and, 151\\nedX, 276\\n“Effective Data Augmentation With Diffusion \\nModels” paper, 204\\nefficiency, as a driving force of automation  \\nwave, 306\\nElbo chair, 155–156\\nelectrical muscle stimulation (EMS), 348\\nelectroactive polymers, 347\\nEleutherAI, 110, 135\\nELIZA, 27–31\\nembarrassingly parallelism, 250\\nemotional intelligence (EI), 311–312, 403\\nEnemy Analysis T ool, 173\\nenergy consumption, of generative AI  \\nmodels, 315–317\\nenergy efficiency, of cloud computing, 242\\nenergy sector, learning models in, 116\\nEngineer.ai, 171\\nentertainment and gaming industry\\nimpact of AI in, 20–21\\nvoice generation and, 151–152\\nenvironmental, social, and governance (ESG) \\nscores, 317–318\\nenvironmental concerns, of AI, 315–321\\nenvironmental science, generative AI \\nfor, 211–212\\nESMFold, 164\\nethical concerns and social implications\\nabout, 285–287\\nAI and, 281\\nbias and fairness in AI-generated \\ndata, 291–295\\ndependency on AI, 310–315\\nenvironmental concerns, 315–321\\nof generative AI, 285–335\\nimpact on jobs and industry, 303–310\\nintellectual property (IP) rights, 287–291\\nmisinformation and misuse of generative \\nAI, 295–300\\noversight and self-regulation, 322–329\\npositive aspects of, 329–335\\nprivacy, safety, and security, 300–303\\nself-regulation and, 327\\nEuropean Union Artificial Intelligence Act (EU \\nAI Act), 322–325\\nexplainable generative AI (XAI), 353\\nexponential growth\\nabout, 219–221\\nin computing, 228–263\\nin data, 264–271\\nrequirements for, 278–283\\nin research, development, and financial \\nallocations, 272–278\\nS-curve, 222–226\\ntechnological convergence, 226–228\\nextended lifespan, AGI and, 387\\nExxonMobile, 243\\nF\\nFacebook, 74, 78, 130, 140'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 426, 'page_label': '413'}, page_content='Index 413\\nFacebook AI Research (FAIR), 124\\nFaceID, 9\\nFairFace, 293\\nfairness, in AI-generated data, 291–295\\nFakeCatcher (Intel), 298–299\\nfans, 348\\nfeatures, in AI, 5\\nfeedback mechanisms, self-regulation and, 327\\nFew-Shot Prompting, 87–88\\nFeynman, Richard, 243\\nfinancial allocations, exponential patterns \\nin, 272–278\\nfinancial constraints, AI and, 281\\nfinancial sector, plug-ins for, 177\\nfitness sector, plug-ins for, 177\\n5G, 271, 365–366\\nflavor sprays, 348\\nFlight Simulator (Microsoft), 20\\nfloating point operations (FLOPs), 84, 228–229\\nfood and beverage sector, learning models in, 116\\nFord, 274\\nForksheet T ransistor Design, 234–235\\nfor-profit solutions, for video genera-\\ntion, 187–188\\nFortran, 254\\nfoundational AI models, 119–146\\n4D cinema seats, 349\\n4D images, 62\\nFréchet inception distance (FID), 61\\nFridman, Lex, 340\\nFriedman, Nat, 381\\nG\\nGalactica, 95\\nGartner, 208, 268\\nGaudí, Antoni, 157\\nGen-2 video generation model, 187\\nGen5X, 155\\nGeneral Catalyst, 273\\nGeneral Data Protection Regulation \\n(GDPR), 207\\nGeneral Motors (GM), 153, 274\\ngenerational variance, AI and, 281–282\\ngenerative adversarial networks (GANs)\\nabout, 16, 45–46, 355\\nautoregression, 60–62\\nchallenges of, 48–49\\nContrastive Language-Image Pre-T raining \\n(CLIP), 51–52\\nDALL-E 2, 53–54\\ndiffusion models, 54–56\\nhow they work, 46–48\\nfor image generation, 50–51\\nimportance of training data, 58–60\\nMidjourney, 57–58\\nmusic generation and, 181\\nStable Diffusion tech, 56–57\\nfor text generation, 75–76\\ngenerative AI\\nabout, 2, 6–7, 14–15\\napplications for, 119–218\\ndata enrichment, 16–17\\ndata generation, 15\\ndata transformation, 15–16\\ndeep learning tech convergence with \\nGPUs, 17–19\\nearly impact of, 19–22\\neconomic benefits of, 308–310\\nethical concerns and social implications \\nof, 285–335\\nexponential growth of, 219–283\\nfuture of, 339–355\\nmultimodal, 342–346\\nmultisensory, 346–352\\nmultitasking, 340–342\\nplatforms for, 132–135\\npotential of, 210–218\\nreal value of, 274–275\\ntrends in, 352–355\\ngenerative design, 153–158\\nGenerative Pre-trained T ransformer \\n(GPT), 78–81\\nGetty Images, 198–199, 288\\nGibbs sampling, 32\\nGitHub, 57, 94, 129, 216\\nGitHub Copilot, 135, 217, 262–263\\nGitHub Pilot, 167–169\\nGLIDE, 54\\nGLUE, 102\\nGo, 167\\nGoertzel, Ben, 378–380\\nGoldman Sachs, 124, 201\\nGood, I. J., 383\\nGoodfellow, Ian (scientist)\\nabout, 48–49\\nDeep Learning, 7, 45–46\\ndevelopment of GANs by, 45–46\\nGoogle\\nabout, 74, 94, 227, 243, 316, 319, 328, \\n330, 359, 370\\nAI dominance of, 127–131\\nAlphaGo, 14, 122, 158–159\\nBard, 128–131, 340\\nBERT , 78, 83\\nChain-of-Thought (CoT) Prompting, 87\\nDeep Dream Generator, 63\\nDeepMind, 14, 96, 101, 103, 122–124, 127, \\n137, 158–167, 252–253, 272, \\n369, 374–375\\ninvestment in Runway AI, 188\\nLaMDA, 94\\nLaMDA 2, 94\\nMultiModel, 341\\nMusicLM, 181–183\\nno moat leakage letter, 139–141\\n1,000\\xa0Languages initiative, 329–330\\nStarline project, 210\\nGoogle Assistant, 71, 74\\nGoogle Brain, 37, 46, 74, 77–78, 127\\nGoogle Cloud, 127, 133, 188, 190, 280–281'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 427, 'page_label': '414'}, page_content='414 Index\\nGoogle Cloud Platform (GCP), 188–190, 212\\nGoogle Now, 150\\nGoogle Research, 46, 77, 78\\nGoogle Search, 130\\nGoogle T ranslate, 71, 74\\nGoogle Workspace, 190\\nGoogle X, 394\\nGPT-2, 93\\nGPT-3, 96, 168\\nGPT-4, 84, 104–105, 107–111, 127, 134, \\n136–137, 343\\nGPT-J, 101\\nGPT-Neo, 101\\nGPT-NeoX-20B, 135\\nGPTZero, 299\\nGradio, 144, 146\\ngrants, 142\\nGraphcore IPU, 144, 238\\nGraphics Processing Units (GPUs), 17–19, \\n220, 236, 237\\ngreen energy, 320\\nGreylock Partners, 273\\nGrok (xAI), 132\\nGross, Daniel, 381\\ngustatory actuators, 348\\nH\\nHandle, 394\\nHann, T obias, 208\\nHanson Robotics, 378–379\\nhaptic actuators, 347\\nHarari, Yuval Noah, 328\\nhardware, exponential evolution of, 231–249\\nHarris, T ristan, 328\\nHarvey AI, 114\\nHassabis, Demis, 137, 375\\nHazy, 295\\nhealthcare sector\\ndata augmentation and, 209\\nlearning models in, 114\\nplug-ins for, 176–177\\nvoice generation and, 152\\nHelixon, 164\\nHellaSwag, 103\\nHELM, 102\\nhigh-quality data generation\\nabout, 23\\napplications of specific language mod-\\nels, 114–118\\nattention mechanism, 77–78\\nautoencoders, 40–42\\nautoregression, 60–62\\nautoregression models, 64–65\\nBoltzmann machines, 31–33\\nChatGPT , 93–95, 97–99\\nContrastive Language-Image Pre-T raining \\n(CLIP), 51–52\\nDALL-E 2, 53–54\\ndeep belief networks (DBNs), 37–39\\nDeep Blue, 33–35\\ndeep Boltzmann machines, 39–40\\ndevelopment of generative models, 26–45\\ndiffusion models, 54–56\\nELIZA, 27–31\\nemergent capabilities of GPT-4, 107–110\\nevaluation of large language models \\n(LLMs), 101–104\\nevolution of AI image generation, 49–63\\nfine-tuning LLMs, 84–86\\nfuture of AI image generation, 62–63\\nGANs for text generation, 75–76\\ngenerative adversarial networks \\n(GANs), 45–49\\nGPT-4, 104–110\\nimportance of training data, 58–60\\nLLM scaling laws, 95–97\\nlong short-term memory networks \\n(LSTM), 70–71\\nMarkov chains, 65–67\\nmidjourney, 57–58\\nmultimodality in AI, 105–107\\nN-gram models, 72\\nother models, 110–114\\noutput probability, 80–82\\npretraining LLMs, 82–84\\nprompt engineering, 86–92\\nreason for generative models, 24–26\\nrecurrent neural networks, 68–70\\nreinforcement learning from human \\nfeedback, 99–101\\nrestricted Boltzmann machines, 35–37\\nrule-based text generation, 67–68\\nSeq2Seq models, 2–75\\nstable diffusion tech, 56–57\\ntech triumphs in text generation, 78–118\\ntext generation, 63–78\\ntokenization for LLMs, 79–80\\nvariational autoencoders, 42–44\\nwomen in generative AI history, 44–45\\nHinton, Geoffrey, 35–40\\nHochreiter, Sepp, 70\\nHoffman, Reid, 137\\nHolz, David, 57–58\\nHonda, 397\\nHood, Amy, 190\\nHopfield, John, 68\\nHopper, Grace, 44\\nHorowitz, Andreesen, 133\\nhospitality companies, learning models in, 115\\nHouston, Whitney, 184\\nHugging Face platform, 55, 103, 104, 134, 135, \\n143–146, 272\\nHugging Face T ransformers, 258\\nhuman autonomy, erosion of, 390\\nhuman extinction, 390\\nhuman potential, 398–403\\nhuman values, misalignment of, 389–390\\nHumana, 295'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 428, 'page_label': '415'}, page_content='Index 415\\nhumanoid robots, 393–398\\nhumility, 403\\nhunger eradication, AGI and, 388\\nHybrid Microchip, 235\\nHyundai Motor Group, 366, 394\\nI\\nIBM, 33–35, 120, 231–232, 243, 254, 277, 319\\nIDC, 97\\nimage extrapolation, 53\\nimage generation\\nevolution of, 49–63\\nfuture of, 62–63\\ngenerative adversarial networks (GANs) \\nfor, 50–51\\nImageBind, 349–351\\nImagen model, 60\\nImagen Video, 187\\nImageNet, 44–45, 59\\nImbue, 382\\nimmortality, AGI and, 387\\nindustry, impact of generative AI on, 303–310\\nInflection AI, 273\\ninformation and communication technology \\n(IT/ICT), 276\\nInfosys Consulting, 64, 137\\ninfrared beaters, 348\\ninfrastructure development, 321\\ninnovation, of cloud computing, 242\\ninpainting, 53\\nInstructGPT , 101\\ninsurance companies, learning models in, 115\\nintegration complexity, 351\\nIntel, 240, 298–299\\nintellectual property (IP) rights, generative AI \\nplatform and, 287–291\\nIntelligence Processing Unit (IPU), 236, 238\\ninteractive storytelling, 192\\ninternational collaboration, 321, 325–326\\nInternet of Things (IoT), 233, 267\\nIntFOLD, 164\\nIvakhenko, A. G., 17\\nJ\\nJasper, 135\\nJava, 29–30, 167, 255\\nJavaScript, 167\\nJetBrains, 168\\njobs, impact of generative AI on, 303–310\\nJoint Embedding Predictive Architecture (JEPA) \\nmodels, 372–373\\nJulia, 255\\nK\\nK Health, 114\\nKaedim, 198\\nKaldi, 150\\nKardashev, Nikolai, 398\\nKardashev scale, 398–399\\nKasparov, Garry (chess champion), 33–35\\nKeen AGI, 381\\nKeras, 256\\nkernel Hilbert space (RKHS), 76\\nKhan, Shah Rukh, 148\\nKhan Academy, 115\\nKhosla Ventures, 273\\nKim, Ji-Hoon, 249\\nKingma, Diederik P ., 42\\nKismet, 44\\nknowledge gaps, AI and, 281\\nKnowledge Prompting, 90\\nKoller, Daphne, 44\\nKurzweil, Ray\\nabout, 338, 384\\nThe Singularity Is Near, 165\\nL\\nLady Gaga, 184\\nLAION-400M, 58\\nLaMDA, 94, 128, 370\\nLaMDA 2, 94\\nLangChain, 212–213, 256, 357, 359, 361\\nlanguage learning, voice generation and, 151\\nlanguage models, applications of spe-\\ncific, 114–118\\nLapa, Valentin Grigor’evich, 17\\nLarge Hadron Collider (LHC), 244\\nlarge language models (LLMs)\\nabout, 7, 21, 227\\ncode generation with, 169\\nemergent capabilities of GPT-4, 107–110\\nevaluation of, 101–104\\nfine-tuning, 84–86\\npre-training, 82–84\\nscaling laws, 95–97\\ntokenization for, 79–80\\nuntil ChatGPT , 93–95\\nlatent diffusion models, 56\\nLattner, Chris, 255\\nLAUNCH, 273\\nlayers, 5\\nLe, Quoc V ., 73\\nLeCun, Yann, 31, 37, 372–373, 392–393\\nLee, Sukbae, 249\\nlegal industry, plug-ins for, 177\\nlegal sector, learning models in, 114\\nLemoine, Blake, 370\\nLG, 124, 366\\nLi, Fei-Fei, 44–45\\nlibraries, for parallel processing, 253–254\\nlicensing, 142–143\\nlight-emitting diodes (LEDs), 349\\nLinkedIn, 130\\nliquid neural networks (LNNs), 260–262, 317\\nLisp, 29\\nLivingston, Jessica, 137\\nLK-99, 247–249, 317, 339'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 429, 'page_label': '416'}, page_content='416 Index\\nLLaMA, 259, 316\\nLM Evaluation Harness, 103\\nlocal interpretable model-agnostic explanations \\n(LIME), 354\\nlong short-term memory networks \\n(LSTM), 70–72\\nLovelace, Ada, 44\\nLua, 167\\nLuma AI, 197–198\\nLütke, T obi, 381\\nM\\nmachine learning (ML), 2–3\\nMachines Who Think (McCorduck), 44\\nMagic AI, 171\\nMagic T ools, 187\\nMagicVideo, 187\\nMake-A-Scene (Meta), 350\\nMake-A-Video (Meta), 15, 187\\nMaliGAN, 76\\nmanipulation, 390\\nMarkov, Andrey (mathematician), 65\\nMarkov chains, 65–67\\nmasked training, 83\\nMathAI, 210\\nmathematics, generative AI for, 211\\nmatrix multiplication, 251\\nMave, 366\\nmaximum likelihood estimation (MLE), 81\\nMayo Clinic, 21–22\\nMcCarthy, John (scientist), 7, 29\\nMcCorduck, Pamela (author), 44\\nMcGeehan, John, 164\\nMcKinsey Global Institute, 306–307\\nmechanical, electrical, and plumbing (MEP) \\nservices, 156\\nmedia and entertainment sector, learning \\nmodels in, 115\\nmemory safety, Mojo and, 256\\nMercedez-Benz, 243\\nMeta, 15, 95, 140, 164, 172, 212, 259, 288, 316, \\n340, 349–350, 381\\nMeta, Amazon, Apple, Netflix, Google \\n(MAANG), 110\\nMeta AI, 343, 372\\nmetadata, 298\\nMetaGPT , 362–364\\nMetaverse Entertainment, 366\\nMicrosoft, 20, 74, 110, 120, 125–127, 189, 240, \\n243, 298, 316, 319, 328\\nMicrosoft Azure, 133, 188–190, 212, 259, 359\\nMicrosoft Common Objects in Context \\n(MS-COCO), 61\\nMidjourney, 57–58, 157–158, 289\\nMiku, Hatsune, 184\\nMinsky, Marvin (scientist), 29\\nmisinformation, of generative AI, 295–300\\nmisuse prevention, self-regulation and, 327\\nMitsubishi Chemical, 244\\nML Architect, 275\\nMMLU, 102\\nmodel wrapper companies, 123–125\\nmodel-makers, 120–123\\nModified National Institute of Standards and \\nT echnology (MNIST), 24\\nModular’s Mojo, 255–257\\nmoisture actuators, 348\\nMojo, 255–257\\nMondelez International, 148\\nMoody’s, 318\\nMoore, Gordon, 228\\nMoore’s law, 84, 220, 228–230, 240, 242\\nMostaque, Emad (CEO), 55, 328\\nMostly AI, 295\\nmovies, personalized, 191\\nMSCI, 318\\nmultilayer perception (MLP), 30\\nmultimodal actuators, 349\\nmultimodal generative AI, 105–107, 342–346\\nMultiModel (Google), 341\\nmultisensory generative AI, 346–352\\nmultitask learning (MTL), 341\\nmultitasking generative AI, 340–342\\nMurf.ai, 150\\nmusic generation\\nabout, 180–181\\nfuture of, 183–184\\nGoogle’s MusicLM, 181–183\\nmusic sampling, 332–333\\nMusicCaps, 182\\nMusicLM, 181–183\\nMusk, Elon, 132, 137–139, 282, 328, 376–378, \\n389, 396–397\\nMuZero, 158\\nN\\nNadella, Satya, 189, 190\\nNamecheap, 275\\nNash equilibrium, 46–47\\nnatural language processing (NLP), 2–3, 8, \\n21–22, 31, 130, 337\\nNazi Enigma code, 29\\nNCC Group, 301–302\\nNeosensory Buzz, 346–347\\nNeovim, 168\\nNeRF , 196–197\\nNetflix, 10, 267\\nneural machine translation (NMT), 71\\n“Neural Machine T ranslation by Jointly \\nLearning to Align and T ranslate” \\n(Bahdanau, Cho, and Bengio), 77\\nneural networks, 226\\nNeural Processing Unit (NPU),  \\n236–237\\nNeuroLink, 387\\nneuromorphic computing, 246–247\\nneurons, 30\\nNew Balance, 188'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 430, 'page_label': '417'}, page_content='Index 417\\nNew Generation Artificial Intelligence \\nDevelopment Plan, 323\\nnext sentence prediction (NSP), 83\\nNFX, 273\\nNg, Andrew, 45\\nN-gram models, 72\\nNo Language Left Behind (NLLB), 344\\nnon-fungible tokens (NFT s), 20\\nnon-player characters (NPCs), 21\\nNotable, 169\\nNVIDIA, 16, 18, 110, 190, 198–199, 202, 203, \\n237, 240, 253–254, 321, 376\\nNVIDIA AI Research, 124\\nNVIDIA Picasso, 198–199\\nO\\nOctane, 355\\nOgilvy, 148\\nolfactory actuators, 348\\nOlsavsky, Brian, 189\\nOmegaFold, 164\\n1,000\\xa0Languages initiative (Google), 329–330\\nopen source models, 119–146\\nopen source movement, 257–258\\nOpen University, 210\\nOpenAI, 7, 46, 53–54, 59, 73, 75, 78–80, 84, 85, \\n88, 89, 93, 94, 96, 98, 99, 101, 103, \\n106–109, 121, 124, 126–132, 134, \\n136–141, 168, 212, 272, 288, 289, \\n316, 342, 369, 374, 376, 402\\nOpenAI Codex, 168\\nOpenBioML, 55\\nOpenCL, 254\\nOpenCog Foundation, 378–379\\nOpenCV , 258\\nOpenGL, 254, 381\\nOptimus (T esla), 395–397\\nOrganisation for Economic Co-operation and \\nDevelopment (OECD), 365\\noutpainting, 53\\noutput probability, 80–82\\noversight, AI, 322–329\\nP\\nPacBio, 227\\nPactum, 173–174\\nPage, Larry, 128\\nPalihapitiya, Chamath, 335\\nPaLM, 128–130\\nPandasAI, 169–171\\nparallel processing, libraries for, 253–254\\nparallel programming, 249–251\\n“Parameter-Efficient Fine-T uning of Large-\\nScale Pre-T rained Language Models” \\n(Ding), 85–86\\nParry, Kevin, 188\\nParti model, 60\\nPathways Language Model (PaLM), 129–130\\nPeltier element, 348\\npersonal branding, voice generation and, 152\\nPhaedra chatbot, 312–313\\npharmaceutical companies, learning models \\nin, 116–117\\nphonemes, 149\\nPHP , 167\\nPhyre, 164\\nPichai, Sundar, 189\\npiezoelectric actuators, 347\\nPitchBook, 272\\nplug-ins, 175–177, 215\\nPoint-E, 196\\nPoly.ai, 150–151\\nportfolio approach, 122\\npoverty eradication, AGI and, 388\\nprecision, as a driving force of automa-\\ntion wave, 306\\npre-training LLMs, 82–84\\nprivacy, generative AI and, 300–303\\nprobability\\nconditional, 24–25\\noutput, 80–82\\nprocessing units, 235–238\\nprogramming languages\\nimprovement of, 254–255\\nnew and user-friendly libraries, 255–257\\nprogressive growing of GANs (ProGAN), 50\\nprompt engineering, 86–92, 275\\nprompt injection, 301–302\\nproof of concept (PoC), 216–217\\nprotein-folding problem, 123, 161\\nproximal policy optimization (PPO), 100\\nPublicis, 188\\nPulsar+CLIP , 196\\nPython, 29–30, 167, 254, 256, 359\\nPython Notebook, 55\\nPyT orch, 256\\nQ\\nQualcomm, 233, 259\\nquantum computing, 230, 242–245\\nQuora, 96, 276\\nR\\nR language, 254\\nRain Neuromorphics, 120, 246\\nRaptorX, 164\\nReAct (Reason + Act) Prompting, 91–92, 359\\nreal estate sector\\nlearning models in, 115\\nplug-ins for, 177\\nrecurrent neural networks (RNNs), 68–70, 181\\nReddit, 96, 276\\nregression, 9–10\\nregularization loss, 83\\nregulations, role of in mitigating environmental \\nimpact of generative AI, 319–321'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 431, 'page_label': '418'}, page_content='418 Index\\nreinforcement learning (RL), 13–14, 158\\nreinforcement learning from human feedback \\n(RLHF), 79, 99–101, 370\\nreliability, of cloud computing, 242\\nrepetitiveness, as a driving force of  \\nautomation wave, 306\\nReplicate, 134\\nReplika, 313\\nRequena, Guto, 154\\nresearch\\nAGI and accelerated, 388\\nexponential patterns in, 272–278\\nfunding, 320\\nprivatization of, 277–278\\nself-regulation and investment in, 328\\nRespeecher, 148\\nrestricted Boltzmann machines (RBMs), 35–37\\nretail sector, learning models in, 115\\nrevenue, generating with open source mod-\\nels, 141–143\\nreverse engineering, 298\\nreward model, 99\\nRich, Elaine, 44\\nRichards, T oran Bruce, 357\\nrisk, existential, 390\\nrobot tax, 385\\nrobots, 393–398\\nRochester, Nathaniel (scientist), 29\\nRosch, Eleanor (psychologist), 44\\nRosenblatt, Frank, 30\\nRoseTTAFold, 164\\nRuby, 29–30, 167\\nrule-based text generation, 67–68\\nRumelhart, David, 68\\nRunway AI, 187–188\\nRunway ML, 272\\nRussell, Stuart, 328\\nRust, 167\\nS\\nsafety\\nas a driving force of automation wave, 306\\ngenerative AI and, 300–303\\nSagrada Familia, 157\\nSalakhutdinov, Ruslan, 39–40\\nSalesforce Ventures, 273\\nSamsung, 240, 366, 397\\nScala, 167\\nscalability, of cloud computing, 241\\n“Scaling Autoregressive Models for Content-\\nRich T ext-to-Image Generation,” 61\\nscaling laws, for LLMs, 95–97\\nscent diffusers, 348\\nSchlicht, Matt, 355\\nSchmidhuber, Jürgen, 70\\nscience, solving in by Google Deep-\\nMind, 158–166\\nS-curves, 222–226\\nSeamlessM4T , 343–344\\nsecurity\\ngenerative AI and, 300–303\\nvulnerabilities of AI, 310–311\\nSedol, Lee, 14, 123, 158\\nSelas AI, 132\\nself-attention, 77–78\\nself-awareness, AGI and, 370\\nSelf-Consistency Prompting, 87–89\\nSelf-Improvement by Reinforcement Learning \\nContemplation (SIRLC) method, 370\\nself-learning, in tech, 275–277\\nself-regulation, 322–329\\nsentience, AGI and, 369\\nsentiment analysis, 8\\nSeqGAN, 76\\n“Sequence to Sequence Learning with Neural \\nNetworks,” 73\\nsequence-to-sequence (Seq2Seq) model, 72–75\\nSequoia Capital, 144, 273, 381\\nservice provider license agreement (SPLA), 143\\nShannon, Claude E. (scientist), 29, 66\\nSHapley Additive exPlanations (SHAP), 354\\nShopify, 381\\nshows, personalized, 191\\nShutterstock, 199\\nsign problem, 37\\nSignificant Gravitas Ltd., 357\\nSimon, 150\\nSingularityNET , 174, 378–380\\nThe Singularity Is Near (Kurzweil), 165\\nSiri, 72, 148, 150\\nSK Hynix, 366\\nSkift, 174\\nSnap, 340\\nSnapchat, 267\\nsocial change, generative AI and posi-\\ntive, 330–331\\nsocial engineering, 390\\nSoftBank Group, 273, 394, 397\\nsoftware, exponential evolution of, 249–263\\nSongdo, 366\\nSouth Korea, 365–367\\nspace exploration, AGI and, 388\\nSparrow (DeepMind), 101\\nspeakers, 347\\nspecialized AI models, 119–146\\nspeech generation, 148–152\\nSpeechki, 176\\nspeed, of Mojo, 255–256\\n“Spiking Denoising Diffusion Probabilistic \\nModels” paper, 216\\nspiking neural network (SNN), 246\\nsponsorships, 142\\nSpot, 394\\nSpotify, 10, 183, 267\\nStability AI, 7, 55–56, 110, 124, 134, 289\\nStable Diffusion, 55–57, 134, 185, 205, 288\\nStableLM, 134, 135\\nstandards, setting, 320'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 432, 'page_label': '419'}, page_content='Index 419\\nStanford University, 103, 111–112\\nStatista, 267\\nsteganography, 390\\nstorage, of data, 269–270\\nstorytelling, interactive, 192\\nStrassen algorithm, 158\\nStructured Query Language (SQL), 254–255\\nstyle transfer, 15–16\\nStyleGAN, 51\\nsubversive communication, through  \\nsteganography, 390\\nSuleyman, Mustafa, 356\\nSuperAGI, 357, 360–361\\nSuperCoder, 360–361\\nSuperGLUE, 102\\nsupervised machine learning, 5\\nsustainable energy, AGI and, 388\\nSutskever, Ilya, 73, 376\\nSutterstock, 183\\nSwag, 103\\nSWIFT , 295\\nSynsets, 59\\nSynthesia, 190–191\\nSynthesis AI, 207\\nsynthetic data, 268–269, 295\\nsynthetic data augmentation, 202–209\\n“Synthetic Demographic Data Generation for \\nCard Fraud Detection Using GANs” \\npaper, 215\\nsystem-on-a-chip (SoC), 231, 233–234\\nT\\nT5, 78\\nT abnine, 171\\ntactile actuators, 347\\ntalent, in tech, 275–277\\nT allinn, Jaan, 328\\ntask parallelism, 250\\nT azti, 150\\ntech improvements, for data storage, 269–270\\ntechnological convergence, 226–228\\ntelecommunications sector\\nlearning models in, 116\\nvoice generation and, 152\\nT ensor Processing Units (TPUs), 129, \\n220, 236, 238\\nT ensorFlow, 256\\nT esla, 138, 239–240, 376, 395–397\\nT esla Dojo, 239\\ntext generation\\nabout, 63–64, 172\\nAI agents, 174–177\\napplications of specific language mod-\\nels, 114–118\\nattention mechanism, 77–78\\nautonomous agents, 177–180\\nautoregression models, 64–65\\nChatGPT , 93–95, 97–99\\nCicero, 172–173\\nemergent capabilities of GPT-4, 107–110\\nevaluation of large language models, 101–104\\nfine-tuning LLMs, 84–86\\nfuture of, 173–174\\nGANs for, 75–76\\nGPT-4, 104–107\\nLLM scaling laws, 95–97\\nlong short-term memory networks \\n(LSTM), 70–71\\nMarkov chains, 65–67\\nmultimodality in AI, 105–107\\nN-gram models, 72\\nother large models, 110–114\\noutput probability, 80–82\\npretraining LLMs, 82–84\\nprompt engineering, 86–92\\nrecurrent neural networks (RNNs), 68–70\\nreinforcement learning from human \\nfeedback, 99–101\\nrule-based, 67–68\\nSeq2Seq model, 2–75\\ntech triumphs in, 78–118\\ntokenization for LLMs, 79–80\\nT extGAN, 76\\nT ext-to-T ext T ransfer T ransformer (T5), 94\\nthermal actuators, 348\\nthermoelectric coolers, 348\\nThiel, Peter, 137\\nthird-party audits, self-regulation and, 328\\n3D object generation\\nabout, 194–195\\nfuture of, 200–202\\nleading companies and approaches \\nin, 197–200\\nresearch in, 195–197\\n3D printers, 155\\n3D U-Net, 185–186\\n3DFX, 18\\n3D-Stacked CMOS, 234\\ntokenization, for LLMs, 79–80\\nT onic.ai, 171\\ntopic classification, 8\\nT oyota, 397\\ntrademark licensing, 143\\ntraining\\nabout, 2–5\\nimportance of training data, 58–60\\nself-regulation and, 327\\nT rainium, 145\\nT ransformer-XL, 77–78\\ntransparency\\nimportance of, 294\\npromoting, 320–321\\nself-regulation and, 327\\ntravel agencies, learning models in, 115\\ntrends\\nin data, 270–271\\nin generative AI, 352–355\\nT ruthfulQA dataset, 103'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 433, 'page_label': '420'}, page_content='420 Index\\nT uring, Alan (scientist)\\nabout, 28–29\\n“Computing Machinery and Intelligence,” 28\\nT uring test, 28, 171\\nT utorAI, 151\\nT ype I/II/III Civilization, 398–399\\nT ype IV/V Civilization, 399\\nT ype VI/VII Civilization, 400\\nT ypeScript, 167\\nU\\nUkraine, 282\\nultrasonic humidifiers, 348\\nUnited States Medical Licensing Examination \\n(USMLE), 109\\nuniversal basic income (UBI), 385\\nUniversal Speech Model (USM), 330\\nUniversity of Buffalo, 298\\nUniversity of Michigan, 317\\nunsupervised learning, 5–6\\nurban planning, data augmentation and,  \\n209\\nU.S. Career Institute, 304\\nuser consent, self-regulation and, 327\\nuser-friendly design, Mojo and, 256\\nV\\nVAE-LIME, 354\\nvariational autoencoders (VAEs),  \\n42–44\\nVaswani, Ashish, 77\\nVersion 5, 57\\nVideo Authenticator (Microsoft), 298\\nvideo generation\\nabout, 185\\nAWS, 188–190\\nAzure, 188–190\\nfor-profit solutions, 187–188\\nfuture of, 191–193\\nGCP , 188–190\\nSynthesia, 190–191\\ntech behind, 185–187\\nviewer preferences, 191–192\\nVinyals, Oriol, 73\\nvirtual reality (VR), 340, 346, 381\\nvision language models (VLMs), 343\\nVision-T ransformer-based VQGAN  \\n(ViT-VQGAN), 61\\nVisual Studio, 168\\nVisual Studio Code, 168, 263\\nVoice Finger, 150\\nvoice generation, 148–152\\nvoxels, 196\\nW\\nWasserstein GAN (WGAN), 50\\nwater sprays, 348\\nwatermarking techniques, 297–298\\nWavemaker, 148\\n“We Have No Moat, and Neither Does OpenAI” \\ndocument, 140\\nWebdevGPT , 179\\nweights, 4–5\\nWeizenbaum, Joseph (professor), 27\\nWelling, Max, 42\\nWikipedia, 83\\nWiley, 215\\nWilliams, Pharrell, 184\\nWist Labs, 339\\nWolfram, 176\\nwomen, in generative AI history, 44–45\\nword error rate (WER) performance,  \\n107\\nWordNet, 59\\nWorld Bank, 282\\nWorld Economic Forum, 276\\nWormGPT , 301\\nWozniak, Steve, 328\\nX\\nX.AI, 138–139, 377\\nxAI’s Grok, 132\\nXi Jinping, 58\\nX/T witter, 132, 180\\nY\\nY Combinator, 138\\nYang, Andrew, 328\\nYC Research, 137\\nY ouT ube, 276, 366\\nZ\\nZapier, 176\\nzero-shot, 61\\nzero-shot learning, 227\\nZero-Shot Prompting, 87\\nZeus framework, 317\\nZoom, 267\\nZuckerberg, Mark, 340'),\n",
       " Document(metadata={'producer': 'iTextSharp™ 5.5.5 ©2000-2014 iText Group NV (AGPL-version)', 'creator': 'PyPDF', 'creationdate': '2024-01-02T16:32:07+05:30', 'author': 'Musiol, Martin;', 'moddate': '2024-01-03T22:41:51+05:30', 'title': 'Generative AI', 'ebx_publisher': 'John Wiley & Sons, Incorporated', 'source': 'data\\\\Generative AI.pdf', 'total_pages': 435, 'page': 434, 'page_label': 'a1'}, page_content='WILEY END USER LICENSE \\nAGREEMENT\\nGo to www.wiley.com/go/eula to access Wiley’s \\nebook EULA.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 0, 'page_label': '1'}, page_content='www.presidencyuniversity.in #proudpresidencian\\nSTUDENT\\nHANDBOOK\\nNAVIGATING YOUR JOURNEY:\\nACADEMICS, LIFE & BEYOND\\n2025-26'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 1, 'page_label': '2'}, page_content='2  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThis ‘Student Handbook’ for Presidency University for the \\nAcademic Year 2025 –2026 is a collection of information that \\nyou will find valuable to learn about campus life, amenities \\nbeyond academics, and services to make your stay enjoyable \\nand useful.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 2, 'page_label': '3'}, page_content='3  \\n \\n \\n                                 INDEX \\n \\nSl. \\nNo. \\nDescription Page No \\n Introduction 4       \\n Vision, Mission and Core Values 4 \\n Recognitions 5 \\n1. The Campus 6 \\n2. Graduate Attributes 21 \\n3. Holistic Education 22 \\n4. Department of Student Affairs 22 \\n5. Student Chapters & Societies 24 \\n6. Alumni Association of Presidency University (AAPU) 25 \\n7. Institutional Social Responsibility 26 \\n8. University Scholarship Policy 26 \\n9. Examination Grievance Redressal Cell 27 \\n10. Student Grievance Redressal Cell 28 \\n11. Anti-Discrimination Cell 28 \\n12. Anti-Ragging 29 \\n13. Policy for Prevention of Sexual Harassment 31 \\n14. Academic Regulations 32 \\n15. Code of Conduct for Students 32 \\n16. Disciplinary Committee 40 \\n17. Rules, Policies and Regulations 43 \\n18. Other Provisions 58 \\n19. Annexures  \\n Annexure-1: Anti Ragging Committee   \\n Annexure-2: Constitution of the University Committee \\nfor Prevention of Sexual Harassment - Responsibilities \\nand Procedures \\n \\n Annexure-3: Student Grievance Redressal Committee  \\n Annexure-4: Joint Affidavit by Student and Parent/Legal \\nGuardian \\n \\n63\\n64\\n66\\n71'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 3, 'page_label': '4'}, page_content=\"4  \\nVISION, MISSION AND CORE VALUES \\n \\n \\nIntroduction \\n \\nPresidency University, Bangalore, is a NAAC 'A' accredited institution, renowned for its \\ncommitment to quality education and holistic student development. Established in 2013 \\nby the Presidency Group of Institutions, it is an emerging leading educational institution \\nin India. With a focus on innovation, research, and experiential learning, the University \\nattracts students seeking both academic excellence and personal growth. \\nOffering a wide range of program mes in computer science, engineering, management, \\nlaw, design, media, science, and commerce, the University blends theoretical knowledge \\nwith practical application. The experienced faculty ensures a dynamic and supportive \\nlearning environment. The University prepares students for global careers, emphasizing \\ndiscipline, integrity, and adherence to its values and regulations. Every student is \\nencouraged to  uphold these standards and contribute to the University ’s esteemed \\nlegacy. Presidency University has earned numerous recognitions, including the QS -I \\nGauge Gold, ranking 6th in the Times Engineering Institute Survey, and Best University  \\nof the Year (South) by ASSOCHAM. \\n \\n \\nVISION \\nTo be a value-driven global University, excelling beyond peers, creating professionals of \\nintegrity and character, and having concern and care for society. \\n \\nMISSION \\n \\n• Commit to be an innovative and inclusive institution by seeking excellence in teaching, \\nresearch, and knowledge. \\n• Pursue research and development and its dissemination to the community at large. \\n• Create, sustain, and apply learning in an interdisciplinary environment with \\nconsideration for ethical, ecological, and economic aspects of nation-building. \\n• Provide knowledge-based technological support and services to the industry in its \\ngrowth and development. \\n• To impart globally applicable skill sets to students through flexible course offerings, \\nsupport industry’s requirements, and inculcate a spirit of new venture.\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 4, 'page_label': '5'}, page_content='5  \\nRECOGNITIONS \\n \\nCORE VALUES \\n \\n• Intellectual Curiosity and Innovation: Fostering a culture of inquiry and creativity \\nto inspire ground-breaking ideas. \\n• Interdisciplinary Approach: Encouraging collaboration across diverse fields for \\nholistic problem-solving. \\n• Global Engagement: Preparing students to excel in a connected and multicultural world. \\n• Community Engagement: Building meaningful connections through service\\n and collaboration. \\n• Environmental and Social Responsibility: Promoting sustainable practices and \\nethical leadership for a better future. \\n \\n \\nPresidency University was established under the Presidency University Act of 2013 \\nas a state private University located in Bengaluru, Karnataka, duly legislated by the \\nKarnataka State Legislative Assembly through Karnataka Act No. 41 of 2013. \\n \\n \\n \\nRecognised by UGC u/s 2(f) of the UGC Act, 1956 \\n \\n \\n \\n \\nProgrammes approved by All India Council for Technical Education \\n \\n \\n \\n \\n \\nLaw Programmes Approved by Bar Council of India \\n \\n \\n \\n \\nMember of Association of Indian Universities'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 5, 'page_label': '6'}, page_content=\"6  \\n \\n \\nA. INFRASTRUCTURE \\n \\nPresidency University, located in the serene Itgalpura village of North Bangalore, is \\napproximately 25 kilometres from Bengaluru International Airport and 35 kilometres \\nfrom the city limits. Set within a lush, expansive campus of nearly 100 acres, the \\nUniversity is surrounded by verdant landscapes that create an ideal learning \\nenvironment. The campus is equipped with state- of-the-art design and technology, \\nproviding students with a modern and dynamic educational experience. \\nThe infrastructure has been strategically developed to  meet the growing needs of the \\nstudent population. Advanced ICT and technological resources ensure efficient delivery \\nof education. The University is equipped with a state-of-the-art auditorium with a \\nseating capacity of 650, along with a spacious amphitheatre, both serving as venues for a \\ndiverse range of co -curricular activities as well as academic events. Additionally, four \\nseminar halls and conference rooms cater to both departmental and University -wide \\nevents. \\nThe campus also boasts of a variety of indoor and outdoor sports and recreational \\nfacilities that support the holistic development of students. Special attention is given to \\ninclusivity, with accessible infrastructure such as wheelchair ramps, lifts, and tactile tiles \\ndesigned for visually impaired students. \\n \\nB. LIBRARY AND KNOWLEDGE RESOURCE CENTRE (LKRC) \\n \\nThe Library of Presidency University  currently is spread across three locations  inside \\nthe campus. The main Library is at the Management Block, which houses books for \\nengineering, information science, and design. Adjacent to the main Library is the \\nLibrary annexe, which offers resources for management, computer science, \\nengineering, and media studies. The law Library is situated on the 5th floor of the 'S' \\nBlock. \\nThe main Library has a collection of over 60,700 books and subscribes to 155 national \\nand international journals and 38 magazines. The Library subscribes to 15 online \\ndatabases covering engineering, law, management, design, and humanities. The \\ncompletely automated Library uses KOHA LMS (Library Management Software), and the \\nWEB OPAC (Online Public Access Catalogue) is accessible from anywhere. The Library \\nemploys an RFID security system to safeguard its resources, complemented by a self-  \\ncheckout kiosk and a Dropbox to streamline book circulation. PUL actively supports \\nacademic publishing by maintaining high standards of quality and relevance, with a \\nparticular emphasis on institutional repositories and open access initiatives. \\n1.  THE CAMPUS\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 6, 'page_label': '7'}, page_content='7  \\n \\nFeatures of the PU Library \\n• The institutional repository at PUL utilizes DSpace, an open-source software platform. \\nThe Library archives e- books, faculty research articles, photographs, question papers, \\ntheses and dissertations, University documents, and the like, and anyone can easily \\naccess the resources through the link provided on the Library website. \\n• You can access the audiovisual material using computers and television. You can also \\nwatch live or recorded online video lectures, such as NPTEL lectures and Swayam \\nlectures, using the television provided. \\n• The Library offers plagiarism check software like Turnitin and Drillbit. \\n• Knimbus Remote Access Platform. \\n• Free reprography services \\n• Library OPAC on-campus and off-campus \\n• 155 print journals, 38 general magazines, and 17 newspapers \\n• Mobile App - \"Libraries in Hand.\". \\n• 25 computer machines with internet access \\n• The Library subscribes to ProwessIQ, CapitaLine, and IndiaStat databases to access \\neconomic and statistical data. \\n \\nC. LABORATORIES \\n \\nLaboratories are equipped with the latest equipment and tools that cater to the needs of \\nthe students. Experienced staff members with industrial backgrounds provide training \\nto students in laboratories to enhance their practical skills.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 7, 'page_label': '8'}, page_content='8'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 8, 'page_label': '9'}, page_content='9  \\nThe University has discipline-centric laboratories as follows: \\n \\nCivil Engineering Mechanical Engineering \\n• Surveying Lab \\n• Concrete & Highway Materials Testing Lab \\n• Fluid Mechanics Lab \\n• Soil Mechanics Lab \\n• Engineering Geology Lab \\n• Computer Aided Building Drawing Lab/ \\nBuilding Information Modelling Lab \\n \\n \\n• Fluid Mechanics Lab \\n• Metrology Lab \\n• Mechanical Design Lab \\n• Mechatronics Lab \\n• Energy Conversion Engineering Lab \\n• Heat & Mass Transfer Lab \\n• CAMD Lab \\n• Foundry, Forging & Welding Lab \\n \\nElectrical & Electronics Engineering Petroleum Engineering \\n \\n• Electrical Machines Lab  \\n \\n• Power Electronics Lab \\n \\n• Control Systems Lab  \\n \\n• Power System Simulation Lab \\n \\n• Electrical CAD Lab \\n \\n• Power System Stimulation Lab \\n \\n• Petroleum Geology Lab \\n• Drilling Fluid and Cement Lab \\n• Reservoir Engineering Lab \\n• Process Control Lab \\n• Petroleum Testing Lab \\n• Reservoir Simulation and Modelling Lab \\n• Oil and Gas Processing Plant Design Lab \\n \\nElectronics & Communication Engineering Computer Science & Engineering \\n• Center for Research in Power Electronics \\n• Analog Electronics Lab \\n• Digital Electronics Lab \\n• Centre for Excellence [Tech Mahindra] \\n• Centre for Excellence [Capgemini] \\n• Big Data Lab'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 9, 'page_label': '10'}, page_content='10  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• Linear Integrated Circuits Lab \\n• Analog Communication Lab \\n• Microprocessor Lab \\n• Micro – Controller Application Lab \\n• Embedded Systems Lab \\n• Computer Aided & Design Lab \\n• Internet of Things Lab \\n• Network Programing Lab \\n• Internet Technologies Lab \\n• System Programing Lab \\n• DevOps Lab \\n• Computer Programing Lab \\n• Digital Design Lab \\n• Cyber Security Lab \\nLaw Media \\nMoot Court Hall • Media Studio \\n• Podcasting Lab \\n• Digital Media Lab \\nDesign  \\n• Material Studio \\n• Garment Construction Lab \\n• Textile Lab \\n• Product Design Lab \\n• Space Design Lab \\n• Drafting Studio \\n• Model Making Studio \\n• Game Design Studio \\n• Communication Lab \\n• Multimedia Studio'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 10, 'page_label': '11'}, page_content='11  \\n \\nD. MEDIA LAB \\n \\nThe Media lab offers cutting -edge facilities, including television and radio studios, \\npodcast recording suites, and specialized labs for content creation, production, and \\nbroadcasting. Students gain hands -on experience through various activities such as \\nground reporting, camera operation, and anchoring. \\nThe Media Studio provides a dynamic space for recording discussions and shows, with \\ntraining in videograph y, filmmaking, scriptwriting, and TV production. The Podcasting \\nLab focuses on audio storytelling, offering advanced tools for recording, editing, and \\nproducing diverse podcast formats. The Digital Media Lab equips students with skills in \\ncontent creation, social media strategies, and audience engagement. \\n \\nE. LANGUAGE LAB \\n \\nThe Language Lab serves as a platform for first-year and sophomore students to develop \\ntheir listening, reading, speaking, and writing skills (LSRW), thereby enhancing their \\npractical language proficiency. The language lab offers lessons for slow, average, and \\nadvanced learners covering topics such as language teaching, linguistics, and phonetics, \\nwhich are challenging to convey without audio -visual aids. Students benefit from \\ncomputer-enabled learning, which enhances their comprehension and overall learning \\nexperience. The main objective is to ensure that students acquire a neutral accent in \\nEnglish, thereby aiding their global career prospects. \\nF. COMPUTER LAB \\n \\nThe University  features state- of-the-art computer labs designed to deliver quality \\neducation. There are two dedicated blocks of enriched computing facilities, like well - \\nequipped laboratories with modern, high -end configuration computing environments, \\nhigh-speed internet connectivity, ventilated, spacious, and well -furnished laboratories, \\nand licensed software such as MS-Windows, Office 365, etc. \\nThere are 66 state- of-the-art computer laboratories, with a total of 3664 computers \\nenabling simultaneous access and practice for all students. Each of these computer labs \\nhas the capacity to accommodate 60 students. Also, there are dedicated laboratories for \\nIoT, big data, AR, VR, the microprocessor lab with digital trainer kits, and robotics with \\nhigh-end configuration systems like the i5 6th Gen, 16 GB of RAM, a 1 TB HDD, and TFT \\nmonitors.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 11, 'page_label': '12'}, page_content='12  \\n \\nSl. \\nNo. Name of the Software Version \\n1 Math Works (Full Suite) for Students & Faculty Campus-Wide Lic \\n \\n2 \\nSolid Work Education Edition 2018-2019 with \\n200student every year \\n \\nSolidworks 2019 \\n \\n3 \\nCadence University Bundle Analog and Digital FE \\n& BE Latest \\n \\nLatest \\n4 Mi Power Full Package Full Package \\n5 UniSim Design Academic program R460 \\n6 CMG Access to GEM, IMEX, or STARS Simulator CMG-2017 \\n7 Win Pro Pahase Behaviour winprop \\n8 CMOST cmost-ai \\n9 Builder pre- Processor system, Graphics & \\nInterface \\nNetwork lic \\n10 Result Post- Processor system, Graphics & \\nInterface \\nNetwork lic \\n11 Dynagrid Network lic \\n12 Team Centre Teamcenter \\n13 Team Centre Rapid Start Teamcenter \\n14 Team Centre Author Teamcenter \\n15 NX Academic - Core & CAD Teamcenter \\n16 Adobe Creative Cloud  \\n17 Adobe Creative Cloud All Apps for HED - Shared \\nDevice \\n \\n \\n \\n18 \\n \\n \\nSophos Central Protection - End Point Protection \\nIntercept -x Advance - \\n4250 Intercept -x \\nAdvance for Server - 20 \\n19 Microsoft 365 A3 Licence Office 365 \\n20 COSEC Centra PLT100/TAM100 Cosec \\n21 Superset - Tnpsuite [Enterprise] Superset \\n22 Knimbus - OCA Knimbus \\n23 Bees Software Solution BeeS \\n24 Tally Prime Gold Subscription Tally'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 12, 'page_label': '13'}, page_content='13  \\n \\n25 \\nStudent Information/Learning Mgmt/Asset \\nQuality System \\n \\nERP \\n26 SAAS License of Talentnow Talent Acquisition \\n   \\n27 Xversion Recurring Pre-paid software Version X \\n              28 Ansys Academic Teaching Mechanical and CFD  \\n              29 Acrobat Pro for team all apps  \\n             30 Saral TDS - Institutional v23  \\n             31 Acrobat Pro Adobe Editor \\n \\n \\n \\nG. OFFICE OF INTERNATIONAL AFFAIRS (OIA) \\n \\nOffice of International Affairs (OIA) is dedicated to fostering global partnerships and \\nadvancing internationalization initiatives, with the core objective of providing \\n“International Exposure to Every Student at Presidency.” OIA actively engages with \\ndiverse international and cultural environments to establish strategic alliances with \\npremier universities worldwide. It facilitates international opportunities such as \\ninternships, articulation pathways, dual/double degrees, exchange and twinning \\nprograms, joint degrees, master’s progression, offshore teaching arrangements, and \\nhosting international faculty. Additionally, OIA supports inbound and outbound student \\nand faculty exchange programs, fosters global experiences, and develops strategies and \\npolicies for international collaboration. By promoting international research \\npartnerships and nurturing existing collaborations, OIA offers invaluable support to \\nstudents and faculty from various schools and departments. \\nWhether you are a prospective student, collaborative partner, or international visitor, \\nthe OIA is your gateway to exploring global academic opportunities. For more \\ninformation or assistance, visit the Office of International Affairs at the campus or \\nexplore their page at https://presidencyUniversity.in/life -at-presidency/international-\\n \\nengagement/about-us.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 13, 'page_label': '14'}, page_content='14  \\n \\n \\n                                                   Top International Universities'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 14, 'page_label': '15'}, page_content=\"15  \\n \\nH. RESEARCH AND DEVELOPMENT \\n \\nPresidency University Research and Development Cell promotes research among staff \\nand students by offering doctoral programs (Ph.D.) across various disciplines aimed at \\nadvancing knowledge and pushing disciplinary boundaries. The R&D cell offers a \\ncomprehensive foundation in each discipline while allowing doctoral students the \\nflexibility to innovate and generate new knowledge aligned with their research interests. \\nThe R&D Cell actively encourages faculty members to undertake research and \\nconsultancy projects funded by both gov ernmental and non- governmental agencies, \\nincluding ICSSR, DBT, DST, UGC, and others. Currently, a total of 624 Ph.D. scholars, both \\npart-time and full -time, are pursuing their research across various schools and \\ndepartments, contributing to the University's vibrant academic ecosystem. \\nI. SPONSORED RESEARCH \\n \\nThe Office of the Sponsored Research was established at Presidency University with the \\nobjective to inspire faculty members to carry out extensive research through a mix of \\nincentives. The incentives are meant to motivate faculty members to publish quality \\npapers, file for patents, generate strong R&D proposals, undertake consultancy projects, \\nexecute in-house seed grant initiatives, establish state-of-the-art research facilities, and \\nencourage faculty/student innovations leading to possible start-ups being incorporated. \\nCurrently, there are 29 ongoing and completed projects that have received government \\nfunding of Rs. 1,44,32,002 and 8 consultancy projects that have received funding of Rs. \\n12,45,711. \\n \\nJ. ADVANCED RESEARCH CENTRES/CENTRES OF EXCELLENCE \\n \\nPresidency University  has established specialized research -propelled centers of \\nexcellence with the goal of promoting advanced research in different specialized areas. \\nEach of these centers  of excellence has coordinators and is equipped with state -of-the- \\nart research equipment and other support infrastructure facilities to facilitate advanced \\nresearch by research scholars and faculty members.\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 15, 'page_label': '16'}, page_content='16  \\n \\n \\nResearch Centre(s) Thrust Areas of Research \\nCentre for Research in Materials Nanomaterials, Nanostructured Coatings, \\nMagnetism, Corrosion, Sensors, Surface \\nCoatings \\nAdvanced Technology Research Centre \\nwith M/s Spatics, Bangalore \\nModelling, Mathematical/Numerical \\nSimulations, Refrigeration and Air \\nConditioning, Nano-composites, \\nComputational \\nFluid Dynamics \\nCentre for Research in Power \\nElectronics \\nPower electronics, grid tide inverters, \\nElectric \\nvehicles, Wireless power transfer for EV, \\nPower converters \\nSustainable Development Goals \\nCentre \\nWater, Gender, Climate change, Decent work \\nand zero hunger \\nSophisticated Instrumentation Centre Material science, Energy and \\noptoelectronics, \\nSynthetic chemistry, Green Chemistry \\nCentre of Excellence in Biofuel Biofuels, Smoke meter, Gas Analyser, \\nEmission \\ntesting, Gas analysis, Smoke Analyser \\nCentre for Research in Robotic \\nand Automation \\nArtificial limbs, Automated guided Vehicles, \\nProsthetic, UAV, Quadcopters, Land based \\nVehicles, Advanced Microcontrollers and \\nMicroprocessors \\nCentre for Innovation \\nIncubation \\nand Entrepreneurship \\nStart-up, Innovative Project \\nCentre for Heat Transfer in Nano \\nFluids \\nMathematical Modelling, Cooling, Nano Fluids, \\nElectronic Systems \\nCentre for Water Research Water Research, Detection of Metal \\nContaminants \\nCentre for Excellence in Additive \\nManufacturing with EoS \\nGermany \\nAdditive Manufacturing, Innovative Designs, \\nPrototyping \\nIP Cell in association with KSCST \\nBangalore \\nPatent, IPR-related Issues'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 16, 'page_label': '17'}, page_content=\"17  \\n \\nK. PRESIDENCY LAUNCH PAD ASSOCIATION (PLA) \\n \\nPresidency Launchpad Association (Technology Business Incubator) is a non- profit \\norganization registered as a Section 8 company to handhold aspiring entrepreneurs \\n(students and teaching/non-teaching staff) and provide facilities and assistance to them \\nto start, incubate, and successfully run businesses that involve innovation and socially \\nimportant and environmentally relevant technologies. \\nPresidency University envisions PLA as one of the leading incubators in the country. It \\noffers state -of-the-art infrastructu re and laboratories with advanced equipment to \\nincubate start- ups. The PLA ecosystem aims to facilitate the growth of start- ups by \\nproviding pre -incubation (ideation stage) and free physical and virtual incubation \\nsupport for the first 18 months. This initiative is open to all aspiring entrepreneurs with \\ninnovative ideas and aims to foster their development and success. \\n \\nL. PRESIDENCY UNIVERSITY LEARNING MANAGEMENT SYSTEM \\n \\nThe Learning Management System delivers an effective platform to facilitate the \\nteaching-learning process in the digital age. Customized from the world’s open- source \\nlearning platform, the LMS allows students and faculty to access this platform from \\nanywhere at any time through their specific login credentials. It supports the blended  \\nmode of education by seamlessly integrating offline and online classes and facilitating \\nthe organized execution of teaching and learning activities. \\nM. IT DEPARTMENT \\n \\nThe IT Department at Presidency University is a dedicated team of skilled professionals \\nresponsible for the management and smooth operation of the University's technological \\nsystems. The department plays a pivotal role in supporting both academic and \\nadministrative activities by  ensuring the seamless function of critical digital services \\nand maintaining the University’s IT infrastructure. \\n \\nKey Responsibilities and Services \\n \\n• IT Infrastructure Management: The IT department manages key aspects of the \\nUniversity’s technology infrastructure, including wireless internet access, computer \\nlabs, CCTV surveillance, IT services, and the upkeep of hardware and software. ensure \\nthat these systems are operational and available for students, faculty, and staff. \\n• Consultancy and Support: The team provides expert consultancy and troubleshooting \\nservices to help resolve any IT-related issues faced by faculty, staff, and students. \\nWhether it's a minor glitch or a more significant challenge, the\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 17, 'page_label': '18'}, page_content=\"18  \\n \\ndepartment is always available for assistance. \\n• Cybersecurity: The department is tasked with protecting the University ’s systems, \\nnetworks, and data through various cybersecurity protocols. These measures are \\ndesigned to ensure the integrity and confidentiality of the University's digital assets. \\n \\n• Surveillance Systems : The IT team is also responsible for maintaining the \\ncampus's surveillance systems, enhancing security for both students and staff by \\nmonitoring and protecting the campus environment. \\n• Email and Communication Platforms : The department supports email systems \\nand communication tools such as Microsoft Teams, ensuring that staff and students \\nhave the tools they need to collaborate efficiently and stay connected. \\n• ICT Classroom Support : The IT department provides essential technical support \\nfor classrooms equipped with ICT tools. This includes troubleshooting, \\nmaintenance, and ensuring the systems in the classrooms are functioning properly \\nfor academic activities. \\nPolicies and Compliance \\n \\n• Strict IT Policies: The University  has established comprehensive IT policies to \\ngovern the use  of its technological resources. These policies aim to ensure \\nresponsible and secure use of IT assets by all users, including students, faculty, and \\nstaff. \\n• Compliance and Accountability : All users of the University ’s IT resources must \\nadhere to these policies. The IT department emphasizes the importance of \\nunderstanding these policies, and non- compliance could result in disciplinary \\naction.\\n \\n• Policy Management: The IT department is responsible for creating, implementing, \\nand updating these policies. work closely with other departments across the \\nUniversity to ensure that the policies meet the needs of the institution and remain \\nup-to-date with current technological trends and security requirements.\\n \\n• In-house Data Centre: To ensure reliable network connectivity and manage digital \\nresources ef fectively across the campus, Presidency University  operates its own \\ndata center. This in- house infrastructure provides greater control over network \\nperformance and helps maintain uninterrupted access to the University 's IT \\nresources.\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 18, 'page_label': '19'}, page_content=\"19  \\n \\nN. WI-FI CAMPUS \\n \\nPresidency University campus area network interconnects all campus buildings, \\nincluding seminar halls, conference rooms, recreational spaces, libraries, and cafeterias. \\nis enabled through the deployment of secured wireless access points with centralized \\nauthentication, allowing a secure network that can be accessed by students  and faculty \\nthrough their mobile devices or laptops. \\n \\nO. UNIVERSITY WEBSITE \\n \\nThe University 's official website features dedicated pages for all the schools and \\ndepartments, academics, research, life on campus, international engagement, \\nadmissions, student affairs, and the alumni association. The detailed pages of the school \\nand department include programmes, curriculum, faculty, research, infrastructure, and \\nevents. Additionally, the website serves as a source for academic circulars, exam \\nnotifications, admission details and updates, and other pertinent public information \\nbeneficial for students and parents alike. Visit Presidency University official website at:  \\nhttps://presidencyUniversity.in/\\n \\n \\nP. PRESIDENCY UNIVERSITY ON SOCIAL NETWORK \\n \\nThe following social networking platforms of Presidency University augment the mode \\nof communication instantaneously to a vast number of users. The activities, events and \\nprograms of each day are updated instantly on these platforms. \\nFacebook: https://www.facebook.com/PresidencyUniversityBangalore/  \\nInstagram: https://www.instagram.com/presidencyUniversity/?hl=en  \\nLinkedIn: https://in.linkedin.com/school/presidency-University-india/  \\nYouTube: https://www.youtube.com/channel/UC8pJ9nysyPA4O9S0QIR9qg \\n \\nQ. SPORTS FACILITIES \\n \\nPresidency University  is widely recognized for its accomplishments in sports and \\nathletics. The University  offers comprehensive infrastructure and support systems to \\ntrain students and enhance their athletic abilities. It organizes a range of sports events \\nto encourage student participation and foster excellence. A dedicated sports \\nmanagement team, led by a director and supported by a lead coach and specialized \\ncoaches, oversees these initiatives. The University  actively promotes a wide array of \\nsports, including basketball, football, volleyball, cricket, and throw  ball, among others. \\nAdditionally, it invests in high-quality equipment to ensure a modern and performance-\\noriented playing environment for its students.\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 19, 'page_label': '20'}, page_content=\"20  \\n \\nR. HEALTH CARE CENTRE \\n \\nPresidency University has an in-house health clinic [infirmary] dedicated to the physical \\nand mental well -being of the students, faculty, and other staff members. The clinic \\nremains open throughout the week. The University also has tie-ups with the top \\nhospitals in Bengaluru to ensure proper medical care and attention for all members of \\nthe University community. \\nThe clinic  is headed by a qualified medical professional and supported by a team of \\ntrained paramedical professionals. There are dedicated satellite sick bays at different \\nblocks of the University, staffed by trained nurses. \\n \\nS. STATIONERY AND REPROGRAPHIC CENTRE \\n \\nThe recreation centers adjacent to ‘F’ Block of the campus cater to the specific needs of \\nthe students and staff, providing photocopying and printing facilities at a nominal cost. \\nIt is equipped with a wide range of stationery items and efficiently manages operations \\nto ensure timely fulfilment of the requirements of students and employees. \\n \\nT. RECREATIONAL SPACES \\n \\nLandscape: The University is a ‘green campus,’ featuring a wide variety of trees, lush \\ngardens, fountains, and thoughtfully designed thematic spaces that create a tranqu il \\nenvironment for students to relax and unwind. \\n \\nStudent Hangout Zones: The University's amphitheater serves as a perfect venue for \\nopen-house events, such as promotional activities, recitations, and performances. \\nAdditionally, the lawns, furnished with seating arrangements, provide students with a \\ncomfortable space to study and socialize with peers. \\n \\nU. CAFETERIA AND FOOD COURT \\n \\nThe University  cafeteria is spacious and offers a selection of hygienic food options at \\naffordable prices. It is a popular venue for refreshments, discussions, and social \\ninteractions. The cafeteria caters to the diverse tastes of the student community with \\nofferings that include South Indian, North Indian, and Chinese, American and \\ncontinental cuisine. Food kiosks, located at various places throughout the campus, offer \\nSouth Indian and North Indian cuisines, savories, beverages, and a variety of delicacies.\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 20, 'page_label': '21'}, page_content=\"21  \\n2. GRADUATE ATTRIBUTES \\n \\nV. PARKING \\n \\nThe University  has dedicated parking for two - and four -wheelers for employees with \\npasses and security restrictions. Only vehicles displaying authorized stickers will be \\npermitted to park inside the campus premises or in designated parking lots. \\nAdditionally, there is a separate parking area exclusively for students and visitors \\noutside the campus premises. \\n \\nW. UNIVERSITY TRANSPORT \\n \\nThe University operates a dedicated fleet of buses that provide transportation to various \\nparts of the city, facilitatin g the commute of students and employees to the University  \\ncampus. To utilize this service, students must register with the Transportation \\nDepartment and pay a nominal fee. Access to the bus is granted to only those with a valid \\npass. \\n \\nX. UNIVERSITY HOSTELS \\n \\nThe University provides separate hostels for boys and girls. The hostels aim to integrate \\nacademic initiatives into the intellectual, physical, and psychological well -being and \\ndevelopment of the students. The University's code of conduct, discipline, and decorum \\nare strictly enforced within the hostel accommodations. \\n \\nY. ATM FACILITY \\n \\nThe University houses a Federal Bank ATM machine, catering to the financial needs of \\nthe students and staff members. \\n \\nThe vibrant campus life at Presidency University fosters an environment that not only \\nsupports academic excellence but also cultivates essential graduate attributes. \\nGraduate attributes represent the qualities, skills, and conceptual knowledge the \\nUniversity student community aspires to develop, guided by the University  leadership \\nduring their association with the institution. The Programme Outcomes [PO], \\nProgramme Specific Outcomes [PSOs], and Course Outcomes [COs] are systematically \\nintegrated into the curr iculum to facilitate the achievement of these envisioned \\nattributes. Upon successful completion of the program, the graduates of the University \\nwill be able to\\n \\n• Clearly comprehend relevant domain-specific knowledge.\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 21, 'page_label': '22'}, page_content='22  \\n3. HOLISTIC EDUCATION \\n4.  DEPARTMENT OF STUDENT AFFAIRS \\n \\n• Demonstrate strong leadership skills and the ability to effectively work in teams. \\n \\n• Apply the knowledge and/or skills acquired through the learning process to real-life \\nsituations. \\n \\n• Adapt to the changing world and serve as change agents for the advancement of \\nlifelong learning. \\n \\nPresidency University  offers academic programs meticulously designed to equip its \\nstudents with contemporary, industry -relevant knowledge, skills, and aptitude, aiding \\nthem in achieving their career objectives. The curriculum and pedagogy are intricately \\nintegrated with projec t-driven experiential learning coupled with assignments that \\nfoster innovative thinking. Students at the University  benefit from the expertise and \\nmentorship of distinguished academicians from renowned universities and institutions \\nwho have carved a niche for themselves in their respective domains. \\nThe curriculum is based on Choice-Based Credit System, allowing students to select from \\na wide range of core and elective courses. The multidisciplinary approach provides a \\nholistic educational experience, broadening their perspectives. \\n \\nDepartment of Student Affairs (DSA) plays a pivotal role in nurturing student talent and \\nfostering holistic development through an extensive network of more than 50 clubs, \\nchapters, and societies. These initiatives cover cultural, technical, social, and management \\ndomains, providing students with a diverse range of opportunities to explore their \\ninterests and enhance their skills. \\n \\nWeekly activities and events, such as cultural celebrations, leadership talks, expert talks  \\non trending technologies, hackathons and awareness programmes, encourage students  \\nto broaden their horizons and develop essential managerial and leadership skills. \\nStudents are also motivated to participate in intercollegiate and inter -University \\ncompetitions, enriching their practical knowledge and learning experience. Community- \\nfocused initiatives like the NSS and the Rotaract Club instil social responsibility and \\ncontribute to societal well-being. Additionally\\n, the DSA ensures student wellness through a \\ndedicated counselling team that provides professional support for personal and academic \\nchallenges. \\nStudents who wish to explore and join the club of their choice, visit the DSA page on the \\nofficial website https://presidencyUniversity.in/life-at-presidency/student-affairs'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 22, 'page_label': '23'}, page_content='23  \\n \\nOr visit the DSA office for any queries. Also, to stay tuned to activities and happenings \\nof DSA, follow the official Instagram account of Presidency University at \\nhttps://www.instagram.com/presidencyUniversity/?hl=en \\n \\nNATIONAL SERVICE SCHEME (NSS) \\n \\nPresidency University  has always been a torchbearer of social service over the \\nprestigious decades of its existence. It not only shapes the best careers of our students \\nbut also shapes their character as responsible citizens of our country. NSS is a step \\nforward in fulfilling our notion. The National Service Scheme (NSS) is a central sector \\nscheme of the Government of India under the Ministry of Youth Affairs and Sports. The \\nNSS at the Presidency University has added to sustainable and ecological living, higher \\nstandards of learning with awareness drives, celebrating Yoga Day with students, \\nfaculties, and adopted slums alike, uplifting social standards, health camps and blood \\ndonation drives, orphanage home visits, and hundreds of programs and special camps \\nfor the overall welfare of both our students and society. \\n \\nNational Cadet Corps (NCC) \\n \\nThe National Cadet Corps (NCC) Army Wing was established at Presidency University in \\n2021, under the aegis of the 3 Kar Battalion, Bengaluru. The NCC cadet strength at \\nPresidency University comprises one company of 160 cadets, including both male and \\nfemale participants. The unit is overseen by an Associate NCC Officer (ANO) and a Girls \\nCadets Administrator. \\n \\nThe NCC enhances the awareness level of cadets to become responsible citizens of the \\ncountry and encourages cadets to enrich their knowledge, develop communication skills, \\nand develop character. The five cadets are involved in the conduct of social outreach \\nactivities, community development programs, and adventure activities to hone their \\nleadership qualities and risk-taking abilities. It provides a platform to launch “Goodwill \\nAmbassadors” to project the image of a country overseas. \\n \\nCOUNSELLING & WELLNESS UNIT \\nThe Student Counselling Services is an initiative at Presidency University, providing \\npsychological support for the students and faculty in the areas of personal, \\nemotional, social, and academic/career-oriented concerns. There is a growing \\nawareness of mental and emotional health today, thanks to various social and mass \\nmedia campaigns. \\nStudent counsellors and clinical psychologists provide professional advice and therapy \\nto the students and are available on campus. Students can write to the counsellors, \\nshare their concerns, and seek support to comprehend the challenges the student is'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 23, 'page_label': '24'}, page_content=\"24  \\n5. STUDENT CHAPTERS & PROFESSIONAL SOCIETIES \\n \\nencountering.  \\nThey help to:  \\na. Identify the underlying causes of their current emotional state. \\nb. Formulate a strategic action plan to address the student's concerns in a supportive  \\nand sensitive manner; \\nc. Assist the student in building resilience and empowering them to achieve their academic \\nand personal objectives. \\n \\nCounselling Services  \\n• Individual Counselling \\n• Peer Support Program \\n• Workshops \\n• Working with teachers and parents \\n• Services provided by university student counsellors \\n \\nReach out to the student counsellors @ \\nnamratha.j@presidencyUniversity.in \\nshivani.mukund@presidencyUniversity.in \\nServices rendered by YourDost for Psychological Health \\nPresidency University  has partnered with a counselling service provider named  \\nYourDOST. It is a platform that has a panel of more than 1,000 experts in counselling. All \\nstudents, faculty, and staff can avail themselves of this service for free in relative \\nanonymity. Anyone interested can visit www.yourdost.com,  register using the official \\nUniversity email ID, and speak to the experts. \\n \\nAll seven schools, including the core engineering branches under the School of \\nEngineering, actively promote co -curricular engagement through student- driven clubs \\nand societies, with guidance from faculty mentors. \\n \\nForum of Civil Engineering (FORCE) was started by Department of Civil Engineering at  \\nPresidency University to expose students to the field of civil engineering in its entirety \\nand give them a feel of how the industry works. Forum has organized guest lectures, \\nworkshops and industrial visits since 2018 and has launched webinar series from \\nOctober 2020 to continue the journey of educating young minds despite the barriers and \\ntemporary halt posed due to the pandemic situation.\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 24, 'page_label': '25'}, page_content=\"25  \\n6. ALUMNI ASSOCIATION OF PRESIDENCY UNIVERSITY (AAPU) \\n \\n• Society of Petroleum Engineers, US (SPE) has established the Student Chapter at \\nPresidency University. This initiative allows students to benefit from opportunities \\nprovided by SPE, including engaging in technology discussions at SPE events, \\nnetworking with industry professionals, and gaining deeper insights into the  \\n \\npetroleum industry. Active participation in SPE student chapter is an excellent way to \\nnetwork with peers and local industry professionals which will offer ways to develop \\nnew skills. \\n \\n• The AAPG Student Chapter at Presidency University, Bengaluru, aims to enhance \\nstudents' professional knowledge through distinguished lectures, workshops, and \\nevents. By collaborating with various organizations in the oil and gas industry, the \\nchapter organizes initiatives to bridge the gap between academia and industry. \\n \\n• The Institute of Electrical and Electronics Engineers (IEEE) is a global professional \\nassociation dedicated to advancing technology by fostering collaboration among \\nprofessionals, researchers, and students. IEEE supports professional development \\nthrough resources like online courses, certifications, and mentorship while bridging \\nthe gap between academia and industry through research alignment and innovation \\ninitiatives. Additionally, it promotes ethical and sustainable practices, advancing green \\ntechnologies and addressing societal challenges. At Presidency University there are \\nfour IEEE chapters namely:\\n \\n \\n• IEEE Circuit and Systems Society (CASS) \\n• IEEE Signal Processing Society (SP) \\n• IEEE Communication Society (ComSoc) \\n• IEEE Computational Intelligence Society (CIS) \\n• IEEE Senor council \\n• IEEE Nanotechnology council \\nThe Alumni Association of Presidency University, Bengaluru [AAPU] was  established in \\n2019 and officially registered with the Registrar of Societies on 5th December 2019.  \\nAAPU has a stronghold of over 18,000 members. The association's main objective is to \\ncreate a strong network between the alma mater and the alumni, encouraging them to \\ntake an active interest in the work and progress of AAPU by establishing regular \\nengagement between them and the students. The association aims to enrich both \\ncurrent students and alumni through constant interaction and knowledge sharing. \\nAAPU is looking at innovative ways to connect and grow. \\nAAPU launched its first alumni chapter in Bangalore, followed by one in the capital city, \\nDelhi, and its first international chapter in Dubai established by Dr. Sameena Noor \\nAhmed Panali, Registrar. Committed to fostering a global alumni network, AAPU \\ncontinues to expand chapters in cities worldwide.\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 25, 'page_label': '26'}, page_content='26  \\n7.  INSTITUTIONAL SOCIAL RESPONSIBILITY \\n8.  UNIVERSITY  SCHOLARSHIP POLICY \\n \\n  \\nIn today’s fast- paced, tech -driven world, students are increasingly disconnected from \\nthe realities of their surroundings. Educational institutions play a key role in fostering \\nsocial responsibility and shaping empathetic professionals. \\n \\nAt Presidency University, the ISR (Individual Social Responsibility) Cell aims to create a \\npositive impact through initiatives aligned with the United Nations’ Sustainable \\nDevelopment Goals (SDGs). Students can engage in projects through its five thematic \\nareas, like Shiksha, Samarthya, Swasthya, Sewa, and Sanrakshan, that support quality \\neducation, skill development, healthcare access, and environmental conservation, \\nhelping them develop a sense of responsibility while contributing to the community. \\nStudents who wish to enroll for volunteering can write to \\nisrcell@presidencyUniversity.in \\n \\n \\nThe University  awards several scholarships to encourage meritorious students and \\nsupport deserving students. In addition to merit scholarships, the University  provides \\nscholarships to students who have excelled in sports, NCC, and cultural. \\nThe University  is committed to supporting deserving students whose parents are \\ndefense/police/ex-service (armed forces) personnel , differently-abled students, \\nstudents from economically weaker sections, students belonging to SC/ST/minority \\nsegments, students with single parents (mothers), and students who have lost both \\nparents. \\nThe University also provides concessions to students who  are alumni of the University  \\nand to children of staff members of the Presidency Group of Institutions. There are \\nspecial scholarships available to the foreign students from SAARC countries. The \\nscholarship for students of Jammu and Kashmir is awarded for all years of their \\nprogramme of study. \\n \\nA student can avail themselves of a scholarship only under one category. \\n \\n• Students to be eligible for a claim of any scholarship need to have submitted, for \\nverification, to the Office of the Registrar, the requisite original certificates. \\n \\n• Applications with incorrect/incomplete information, non- submission of supporting \\ndocuments, and submission of applications beyond the last date as notified by the \\nUniversity are liable to be rejected.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 26, 'page_label': '27'}, page_content='27  \\n 9.  EXAMINATION GRIEVANCE REDRESSAL CELL \\n \\n• Receiving any scholarship shall not be a matter of right, for the awarding of \\nscholarships shall be at the sole discretion of the University. \\n \\n• The various categories and details of scholarships offered by the University shall be \\nnotified by the University at the time of admission to a new academic. \\n \\n• The conditions and rules for the award of scholarship/concession in the University  \\ntuition fees shall be clearly prescribed in the University scholarship policy notified \\nfrom time to time. \\n \\n• Scholarships are restricted to rebates in the University  Tuition Fee only and are \\napplicable for the first year of the relevant programme of study. \\n \\n• Students who are awarded a scholarship for the first year of their program of study \\nshall pay the full University  fee and other charges/deposits, as applicable, prescribed \\nin the fee document of the University  from the second year of the program till \\ncompletion of the program of study.\\n \\n \\n• If a student withdraws or discontinues from the programme, they are required to remit \\nback the scholarship amount. \\n \\n• All students who are awarded any type of University  scholarship shall be required to \\ngive a written undertaking to abide by the rules and conditions relating to the award of \\nsuch scholarship. \\n•  \\nStudents who have participated in international, national, or state-level sports \\ncompetitions are eligible to avail of sports scholarships.  \\n \\nThe Examination Grievance Redressal Cell provides a mechanism for the redressal of \\ngrievances related to examinations, ensures transparency in examination practices, and \\nprevents unfair practices at the University. This cell is linking the students with the \\nfaculty in the continuous evaluation process. The University  examination office, along \\nwith the faculty team, ensures the smooth conduct of the University  examinations and \\ncontinuous assessment. If any grievance occurs, it will be immediately considered and \\nredressed. \\n \\nObjectives \\n• Monitor the examination process to ensure a stress-free examination atmosphere in \\nthe exam hall.  \\n• Resolve the student’s grievances related to examinations and continuous assessments. \\n \\n• To encourage the students to express their grievances/problems on the conduct of \\nexaminations without any fear. \\n \\n• Issue of mark sheets, transcripts, provisional degree certificates, and any other'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 27, 'page_label': '28'}, page_content='28  \\n10.  STUDENT GRIEVANCE REDRESSAL CELL (SGRC) \\n11. ANTI DISCRIMINATION CELL \\n \\n             certificates as per the University examination regulations. \\n \\n• Emphasize prevention of errors rather than controlling through punitive measures. \\n \\n• The students or faculty members with a genuine grievance may approach the co- \\ncoordinator or member of the cell in person. In case the person is unable to appear in \\nperson, grievances may be dropped in writing or an email may also be sent to the co- \\ncoordinator of the Examination Grievance Redressal Cell. \\nSubmission of Grievances \\nStudents and teachers can submit the grievances by using any one of the \\nfollowing. \\nA. Filling the form available with the coordinator and members at the cell. \\nB. Sending the mail: examredressal@presidencyUniversity.in \\n \\nPresidency University is committed to providing a safe, fair and harmonious learning \\nand work environment. In view of this, the University  has a robust mechanism for \\nredressal of students’ grievances in a timely manner. The grievances that need \\nimmediate redressal are related to academic and non- academic matters, such as \\nassessment, victimization, attendance, charging of fees, conducting of examinations, \\nharassment by fellow students or teachers, etc. In this regard, a formal Student Grievance \\nRedressal Cell (SGRC) is constituted in accordance with the UGC Regulation to deal with \\nday-to-day grievances of its stakeholders, including the students. \\n \\nAny student who is aware of any violations must report the same to the SGR. Said \\ngrievance must be submitted in writing and should be made within (04) days from the \\nday of the alleged violation. The SGRC shall take note of the grievance and inform the \\nDisciplinary Committee to conduct the inquiry and impose appropriate retribution. \\nThere shall be an Internal Complaints Committee (ICC) in place in cases of any sexual \\nharassment complaints. \\n \\nThe Constitution of the School Level Grievance Redressal Committee, University Level \\nGrievance Redressal Committee, Procedure for Redressal of Grievance, Types of \\nGrievances, Appellate Authority/Ombudsman, Functions of Ombudsman, and \\nProcedure for Redressal of Grievance by Ombudsperson are placed in Annexure-3 \\n \\nDiscrimination against any person on the grounds of his/her disability or physical \\nlimitations and minority status is a gross violation of universally accepted principles of'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 28, 'page_label': '29'}, page_content='29  \\n12. ANTI - RAGGING \\n \\nequality and human rights and even constitutional obligations. Presidency University  \\nhas set up an Equal Opportunity Cell to address the issues concerning Scheduled Castes, \\nScheduled Tribes, Other Backward Classes, and Persons with Disabilities. \\nThe basic aim of the Cell is to ensure that students and faculty belonging to various \\ndiverse backgrounds of community, religion, region, gender, or ability are not deprived \\nof their basic opportunities. Everyone must have access to basic rights to foster \\ninclusivity and harmony. This cell organizes various activities to promote inclusive \\npolicies and practices for all. It also addresses grievances to ensure equality and equal \\nopportunities for disadvantaged groups on campus through the effective \\nimplementation of policies, skill development programs, and societal initiatives. \\n \\n \\nA conducive and amicable environment is a hallmark of Presidency University . This \\nambience is ensured by various committees and bodies that make students aware of the \\nconsequences in the event of breaching the code of conduct. The Anti- Ragging \\nCommittee is instituted to ensure the safety and comfort of the students and to provide \\nan amicable environment on the campus and in the hostels. The University  is guided by \\nthe UGC Regulations on Curbing the Menace of Ragging in Higher Education Institutions. \\nIt is expected that every student reads the below -mentioned guidelines and abides by \\nthe regulations. \\n \\nRagging is a cognizable offence, and Presidency University will take strict action against \\noffenders. \\n \\nDefinition of Ragging \\n \\n• Any conduct by any student or students, whether by spoken or written word or by an \\nact, which has the effect of teasing or treating a fresher or any other student rudely. \\n \\n• Exploiting the students from completing academic tasks and financial extortion. \\n \\n• Any act of physical abuse, including all its variants —sexual abuse, homosexual \\nassaults, and stripping; forcing obscene and lewd acts; gestures; causing bodily harm; \\nor any other danger to the health of a person. \\n \\n• Any act that prevents, disrupts, or disturbs the regular academic activity.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 29, 'page_label': '30'}, page_content='30  \\n \\nAnti - Ragging Measures \\n \\nAccording to the instructions of the Honourable Supreme Court of India and in \\naccordance with the UGC Regulations and Karnataka State Government Guidelines on \\nCurbing the Menace of Ragging in Higher Educational Institutions (2009), the University \\nhas constituted an Anti-Ragging Committee and Anti-Ragging Squads for overseeing the \\nstrict and meticulous implementation of all the directives. The members of the anti- \\nragging committee and anti-r agging squads, along with their mobile numbers, shall be \\ndisplayed for the benefit of the students, especially the newly admitted students. \\n \\n• The University educates the students enrolled for various programs, at the beginning \\nof each academic year, about the Anti- Ragging Policy and Zero - Tolerance for ragging \\nat the University. \\n \\n• It is mandatory for each student, as well as his/her parents/guardian to submit online \\nseparate undertakings in the form of an official declaration at the time of admission by \\nclicking on http://www.antiragging.in\\n to the effect that they are aware of the \\nprohibition of ragging & the punishment prescribed both by the penal laws and these \\nregulations. All students must submit their acknowledgment number to their class \\ncoordinator. \\n• Anti-ragging hoardings, banners, and billboards are displayed at prominent places in \\nthe University  campus, including hostels, canteens, messes, cafeterias, buses, \\nplaygrounds, lawns, labs, etc. \\n \\n• Surprise checks of hostels/canteens/cafeterias/bus stops are carried out regularly. A \\nclose and regular liaison is maintained with the local police to guard against any \\ninstance of ragging. \\n \\n• An FIR will be lodged in the police station on all reported ragging cases.  Daily briefing \\nfor the new students is carried out by counsellors and coordinators. \\n \\n• An anti- ragging committee of the students is also formed. In case any student \\nencounters ragging by any of the senior students, he/she is immediately required to \\ncontact the members of the anti- ragging committee, who will take immediate \\ncorrective action and necessary proceedings will be initiated against the culprits \\nengaged in ragging activities. The constitution of the University Anti-Ragging \\nCommittee is placed in Annexure 1. \\n \\n• Punishment for Ragging: \\n• Lodging an FIR against the offender.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 30, 'page_label': '31'}, page_content='31  \\n13.  POLICY FOR PREVENTION OF SEXUAL HARASSMENT \\n \\n• Rigorous imprisonment for up to 3 years (under court of law). \\n• Fine up to Rs. 2, 50,000/- \\nExpulsion from Presidency University and subsequent debarring of admission to any \\nother institution. \\n \\nPresidency University is committed to creating and maintaining a community in which \\nstudents and employees can work together in an environment free of violence, \\nharassment, exploitation, intimidation, and stress. This includes all forms of gender \\nviolence, sexual harassment, and discrimination on the basis of sex/gender or amongst \\nthe same-sex members. \\nThe University Policy on Prevention of Sexual Harassment has been framed keeping the \\nfollowing objectives in view: \\n• To comply with the directives of the Honourable Supreme Court of India. \\n \\n• To establish an effective mechanism for the prevention and redressal of sexual \\nharassment cases and other acts of gender-based violence at the University. \\n \\n• To create and foster an environment at the University that is completely free of sexual \\nharassment in its various forms and to generate public opinion against all forms of \\ngender-based violence. \\n• For the purpose of this policy, \"Sexual Harassment\" shall include, but will not be confined \\nto, the following: \\n• Unwelcome sexual advances, requests for sexual favors, and/or verbal or physical \\nconduct of a sexual nature made, either explicitly or implicitly, in return for a term or \\ncondition of teaching/guidance, employment, participation, or evaluation of a person\\'s \\nengagement in any University activity.\\n \\n• When unwelcome sexual advances and/or verbal, non-verbal, or physical conduct— \\nsuch as loaded comments, remarks or jokes, letters, phone calls, or emails or any other \\ncommunication mediums; gestures; showing of pornography; lurid stares; physical \\ncontact or molestation; stalking; sounds; or display of a derogatory nature—have the \\npurpose or effect of interfering with an individual\\'s performance or of creating an \\nintimidating, hostile, or offensive environment.\\n \\n \\n• Forcible physical touch or molestation; eve teasing, innuendos, and taunts; physical \\nconfinement against one\\'s will; and any other act to impinge upon one\\'s privacy. \\n \\n• Any act or conduct of a person in authority and belonging to one sex that denies or \\nwould deny equal opportunity in pursuit of education or career development, or \\notherwise makes the environment at the University hostile or intimidating to a person \\nbelonging to the other/same. \\n \\n• This policy is applicable to all allegations of sexual harassment made by a student'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 31, 'page_label': '32'}, page_content='32  \\n15. CODE OF CONDUCT FOR STUDENTS \\n14.  ACADEMIC REGULATIONS \\n \\nagainst a student, employee, or third party, irrespective of whether sexual harassment  \\n \\nis alleged to have taken place within or outside the University. \\n• The University has constituted a Committee for Prevention of Sexual Harassment to \\nmake note of complaints about sexual harassment, conduct inquiries, provide \\nassistance and redressal to the victims, recommend penalties, and take action against \\nthe harasser, if necessary. \\n \\n• The disciplinary action shall be proportionate to the nature of the violation and could \\nbe in the form of a warning, suspension, or even expulsion from the University. \\n \\n• The Constitution of the University Committee for Prevention of Sexual Harassment, its \\nresponsibilities and procedures are placed in Annexure – 2. \\n \\n \\nEvery student can access the academic regulations of the University  along with the \\nconcerned program regulations and curriculum on the web portal of the University. The \\nstudents and parents must read these documents so that they are well aware of the \\nregulations, policies, and rules of the University . The students are required to comply \\nwith all the Regulations, Policies and Rules issued by the University from time to time. A \\nperson seeking admission to any program of the University shall be deemed to have read, \\nunderstood, and accepted the academic regulations and the concerned program \\nregulations and curriculum. \\n \\nTo read more: https://presidencyUniversity.in/presidency/academic-regulations \\n \\nEvery student shall observe discipline and decorum and proudly contribute to the \\nacademic ambience and prestige of the University . Students must treat each other with \\ndignity and a spirit of friendship and brotherhood to create and nurture a harmonious \\nstudent community. Every student must respect the faculty members and every staff \\nmember of the University. For the well-being of the student community, any violation of \\nthe Discipline and Code of Conduct will be strictly dealt with, including expulsion from \\nthe University. \\n \\n15.1 Student Identity Card \\n \\nEvery student admitted to the University  is provided with a University  identity card. \\nEach student should display their identity card at all times on the University campus.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 32, 'page_label': '33'}, page_content='33  \\n \\n• A student will not be allowed into the campus without the identity card. \\n \\n• A student must produce the identity card to use any University facility like the Library, \\npreliminary medical center, canteen, or laboratories. \\n \\n• A student must return the identity card to the University office at the time of \\ngraduation/withdrawal/expulsion or when asked for. In case of failure to do so, the \\nsecurity deposit, if any, will be forfeited, and certificates will not be issued. \\n \\n• Every student should preserve the identity card and not give it to any other student or \\noutsider for any purpose. Any misuse of the University identity card (belonging to self \\nor others) will lead to disciplinary action against the student, including expulsion \\nfrom the university.  \\n \\n• The University reserves the right to ask the students to surrender their identity card \\nwithout assigning any reason. \\n \\n• In case a student loses the identity card, she/he should apply for a fresh identity card \\nalong with a penalty fee prescribed by the University. \\n15.2   Student Dress Code \\n \\nPersonal grooming and dress code are very essential for self- esteem, a sense of \\nbelonging and camaraderie, pride in the University , and preparedness for \\ncorporate/professional careers. All students must follow the dress code applicable to \\nthem. Students are advised to be well -groomed and dressed gracefully, befitting the \\nimage of an ambassador of the University. \\nThe University Uniform and Dress Code as prescribed below must be followed by all \\nconcerned students from Monday to Friday, on all working days. However, on \\nworking Saturdays, the students may attend classes at the University in casual wear. \\n  General Dress-Code for Students (Monday to Friday) \\n \\n• Boys shall wear formal trousers and shirts (half sleeves or full sleeves—tucked in) and \\nformal shoes on all working days.  \\n \\n• Shirts with Chinese collars, torn jeans/trousers, cargo jeans with multiple pockets, t- \\nshirts, kurta–pyjama, shorts, and track suits, as well as clothing with objectionable \\nslogans, taglines, and images, are strictly prohibited. \\n \\n• Students should wear shoes unless medically floaters/sandals/chappals are strictly \\nprohibited. \\n \\n• Girls shall adopt a modest dressing style such as comfortable-fitting formal trousers \\nand shirts (half sleeves or full sleeves—tucked in), or a power suit/jacket with a \\nformal shirt, or a salwar-kameez or saree, and suitable formal, tight-fitting, revealing, \\nand sleeveless clothing; short kurtis, tops, crop tops/shirts, t-shirts, torn jeans, shorts,'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 33, 'page_label': '34'}, page_content='34  \\n \\n            and skirts are strictly prohibited for girls. \\nSaturday \\n• Students may come to the University on Saturdays attired in smart casual. \\n \\n• Boys can wear shirts/collared t-shirts/golf t-shirts with jeans/trousers and \\nsports/canvas/casual. \\n \\n• Girls can wear comfortable tunic tops, Shirts, Collared T- shirts / Golf T-shirts with \\nJeans/ trousers and sports/canvas/casual. \\n \\n• NCC cadets will wear uniforms on notified days for that purpose. \\n \\n• Dress Code for Laboratories (Except Computer Laboratories) and Workshops \\n \\n• Students must come to the labs (other than computer labs) and workshops in the \\nprescribed lab/workshop uniform and shoes. \\nUniversity Uniform for respective Schools/Programs:  \\nMBA Program [School of Management]: \\nEvery newly admitted student of the MBA Program shall be provided with a set of the \\nUniversity Uniform consisting of one (01) University Blazer, one (01) tie, two (02) shirts, \\nand one (01) pair of trousers. All MBA students must come to the University wearing the \\nfull University uniform with formal shoes every Monday and Thursday. \\n \\nLLB/LLM Programmes [School of Law]: \\nEvery newly admitted student of a law program of the School of Law shall be provided \\nwith a set of the University  Uniform for law students consisting of one (01) University  \\nblazer, one (01) tie, two (02) shirts, and one (01) pair of trousers. All students of law \\nprograms must come to the University  wearing the full University uniform with formal \\nshoes on every Monday and Thursday. \\n \\nBBA Programmes (School of Commerce & Economics): \\nEvery newly admitted student of BBA Program shall be provided with a set of the \\nUniversity Uniform consisting of two (02) shirts, and two (02) trousers. All BBA Program \\nstudents must come to the University wearing the University Uniform with formal shoes \\nevery Monday and Thursday. \\nDress Code for Special Events/Programs in the University: \\n \\n• All students of MBA, Commerce, and Law Programmes are required to be attired in \\ntheir designated uniform, consisting of University blazers and formal shoes.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 34, 'page_label': '35'}, page_content='35  \\n \\n• Students of the other schools must be in formal dress code and wear formal blazers \\nand formal shoes. Gentlemen-students must wear ties. Lady students may wear formal \\ndresses or sarees. \\n \\n• For games, sports, or similar activities, students must wear the University sportswear \\nand/or tracksuit/T-shirts, as prescribed. \\nViolation of the University Student Dress Code: \\n \\nAny violation of the University  Student Dress Code shall result in stringent disciplinary \\naction. A caution notice will be issued to a student violating the dress code. Subsequent \\nviolations will result in disciplinary action against the student, which may include a fine \\nof Rs. 1000/-, debarment from placement assistance, and/or representing the University \\nin any event/competition. \\n15.3 Restricted Use of Mobile Phones in the University: \\n \\n• Mobile phones may be carried by students on campus to stay connected with family \\nand friends; however, appropriate usage is equally important to ensure attention to \\nacademic sessions, safety of people, and privacy. \\n \\n• Use of mobile phones is strictly prohibited in the academic blocks, which include \\nclassrooms, laboratories, workshops, libraries, moot courts, and the corridors of the \\nacademic blocks and administrative block.\\n \\n \\n• Students are strictly prohibited from using mobile phones during meetings, seminars, \\nworkshops, guest lectures, and conferences. \\n \\n• Students may use their mobile phones in the permissible/designated areas in the \\nUniversity campus as stipulated by the University.\\n \\n \\n• Privacy is of the highest importance, and photographs of on-campus persons with a \\nmobile phone shall not be taken without the consent of the person [This restriction \\napplies to DSLR cameras as well].\\n \\n \\n• Any student using a mobile phone in restricted areas will be cautioned, and the mobile \\nphone will be A second violation will result in stringent disciplinary action against the \\nstudent, which may include a fine of Rs. 1000/-, debarment from placement assistance, \\nand/or representing the University in any event/competition. \\n \\n15.4   Use of Students’ Personal Laptop in the University \\nStudents may bring their Personal Laptops/Tablets to the University Campus. The rules \\nfor usage of Personal Laptops/Tablets are specified in the following points: \\n \\n• Students may use laptops/tablets in the tutorial classes if required as part of the'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 35, 'page_label': '36'}, page_content='36  \\n \\ncoursework/class assignments, with prior permission of the concerned course \\ninstructor. \\n \\n• Students may use their laptops/tablets in the classrooms/seminar halls for \\nassignment/seminar/paper presentation purposes or any other academic activity as \\nrequired/approved by the concerned course instructor.\\n \\n \\n• Students may use her/his laptop/tablet during a class/lecture for academic purposes \\nby seeking prior permission from the concerned course. Violation of this rule will \\nresult in strict disciplinary action, and the errant student’s laptop/tablet will be \\nconfiscated by the course instructor. \\n \\n• Students are not permitted to use/take their personal laptops/tablets to the computer \\nlabs during a practical/laboratory period/class. Violation of this rule will result in \\ndisciplinary action on the student, and the errant student’s laptop/tablet will be \\nconfiscated by the course. \\n \\n• Students may use their laptops/tablets in the computer/project laboratories to \\ncomplete assignments/project work with prior permission of the concerned course.\\n \\n \\n• Use of personal laptops/tablets in the University laboratories/classrooms for any non- \\nacademic/curricular work or activity is strictly Violation of this rule will result in \\nstringent disciplinary action on the student and immediate confiscation of their \\nlaptop/tablet. \\n \\n \\n15.5 Student Discipline in the University Campus (Includes Hostel and Transport \\nFacility) \\n \\nA student shall not indulge in any act of indiscipline which includes: \\n \\n• Any violation of regulations, policies, and the code of conduct for students of \\nPresidency University as may be prescribed and be prevalent from time to time. \\n \\n• Breach of an Undertaking or Declaration and/or refusal to obey the \\ndirections/instructions of the HOD/Dean, Registrar, Chief Proctor and/or Vice \\nChancellor or any other Senior University official. \\n \\n• Failure to provide proof of identity when requested to do so and/or not producing an \\nidentity card. \\n \\n• Displaying the approved out pass before moving out of the campus during class \\nhours. \\n \\n• Violent, indecent, disorderly, threatening, intimidating, or offensive behavior or \\nlanguage (whether expressed orally, in writing, or electronically, including blogs, \\nsocial networking websites, and other electronic means). \\n \\n• Shouting, whistling, and use of verbal/written abuses, derogatory or foul'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 36, 'page_label': '37'}, page_content='37  \\n \\n• language/terms against any officer, academic staff, administrative staff, other \\nemployees, or students of the University. \\n \\n• Distribution or publication of a poster, notice, sign, or any publication, including \\naudio- visual material, blog, or webpage, which is offensive, intimidating, threatening, \\nor illegal. \\n \\n• Any kind of betting/gambling/extraction of money from a fellow student. \\n \\n• Any act of malpractice related to any examination/test/evaluation process conducted \\nby the University. \\n \\n• Littering on the University campus, including classrooms. \\n \\n• Mass bunking of classes and other University activities or causing disruption in any \\nmanner of the functioning of the University. \\n \\n• Possession and/or use of banned/prohibited substances such as tobacco products, \\nalcohol, narcotics, etc., within the premises of the University, including hostels of the \\nUniversity. \\n \\n• Physical assault or threat to use physical force against any officer, academic staff, \\nadministrative staff, other employee, or student of the University, and/or causing \\ninjury to any person within or outside the University Campus, including hostels and \\ntransport facilities. \\n \\n• Carrying any weapons or prohibited items or chemicals or usage of/threat to use \\nthem. \\n \\n• Violation of status, dignity, and honour of students belonging to Scheduled Castes and \\nScheduled Tribes and/or using abusive language against them and/or indulging any \\nactivity that tends to deride them or tarnish their reputation. \\n \\n• Creating ill will or intolerance on religious/communal distribution of    \\nliterature/propaganda material, in print/electronic form, pertaining to his/her \\nreligion, political views, and group views (based on caste, creed & place of residence) \\nwithin the University campus. \\n \\n• Accessing banned sites and/or pornographic sites and/or material on the University \\ncampus, including hostels. \\n \\n• Any behaviour that could be construed as discriminatory or harassing on the grounds \\nof sex, sexual orientation, gender, gender reassignment, race, religion, disability, or \\nage of any student or member of staff of the University, or any visitor to the \\nUniversity. \\n \\n• Fraud or deception in relation to the University or its staff, students or visitors:  \\n \\n• \"Possession of duplicate Identity Card/ Hall ticket/ Admit card / bus pass/ fee'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 37, 'page_label': '38'}, page_content='38  \\n \\nreceipt/ impersonating: with an aim to commit fraud\" \\n• Bribery or attempted bribery, including but not limited to offering or giving money,  \\n \\n• gifts, or any other advantage to any student or employee of the University, or any \\nvisitor to the University, with the intention of inducing that person to perform \\nhis/her role improperly or of rewarding that person for performing his/her role \\nimproperly. \\n \\n• Theft, misappropriation, unauthorized use, or misuse of the University property or \\nthe property of its students, staff, or visitors. \\n• Failure to comply with any punishment imposed as a result of the University’s \\ndisciplinary procedures or contempt of those procedures. \\n \\n• Ragging is strictly prohibited. Indulging in any activity that amounts to ragging or any \\nsimilar act shall result in the student being suspended from the University. \\n \\n• Any act that tends to bring the University and/or its officials, staff, or other students \\ninto disrepute and/or adversely affects its reputation and goodwill. \\n \\n• Misbehavior/disrespectful behaviour, physical assault, or threat to use physical force \\nagainst any member of teaching or non-teaching staff of any \\ndepartment/school/University, security staff, fellow students, and the public within \\nor outside the campus. \\n \\n• Indulging in any act, either singly or with others, that creates disturbance within any \\npart of the campus/classrooms or indulging in any activity that obstructs the smooth \\nconduct of classes and/or academic work within the campus; \\n \\n• Indulging or promoting any business or trading activity within the University \\ncampus, including hostels and transport facilities. \\n \\n• Participation and involvement in any agitation or public demonstration or any other \\nform of collective activity in or outside the raising of any slogans or indulging in any \\nviolent activity in pursuance of any demands or issues. \\n \\n• Indulging in cybercrimes like hacking any University data centre/sending obscene \\ncommunal/hate messages with criminal hacking online classes. \\n \\n• Any act, whether verbal or otherwise, involving the violation of the status, dignity, or \\nhonor and/or derogatory to eve-teasing, accosting, molesting, using unrestrained \\nabusive language, making suggestive obscene gestures, or sending \\nemails/WhatsApp/MMS to lady faculty members and students. \\n \\n• Public display of affection/socially unacceptable. \\n \\n• Having been cautioned, making a false statement to Enquiry Committee/ Fact Finding \\nCommittee.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 38, 'page_label': '39'}, page_content='39  \\n \\n• Any other act of commission or omission, which constitutes indiscipline in the view of  \\n \\nthe Disciplinary Committee. \\n \\n15.6 Defacement/Damage/Theft of University Property \\n \\nStudents shall not indulge in any willful breakage, defacement, damage, or theft of \\nUniversity property (which includes any University infrastructure, equipment, furniture,  \\n \\nsports goods, canteen facilities, hostel facilities, furniture, Univers ity buses, and such \\nother facilities and equipment of any kind belonging to the University ). Any student or \\ngroup of students guilty of stealing, defacing, breaking, or damaging any property,  \\n \\nequipment, facility, and/or infrastructure of the University  shall be subject to stringent \\ndisciplinary action and penalties, which include: \\n• Penalty to recover the cost of the damaged/defaced property of the University from the \\nguilty student(s). \\n \\n• Forfeiture of the security deposit, if any, deposited by the student at the time of \\nadmission. \\n \\n• Debarment from Placement Assistance of the University and from representing the \\nUniversity and/or participating in any Competition/Event. \\n \\n• Penalty and Suspension from the University. \\n \\nExpulsion from the University \\nThe decision of the Vice Chancellor, based on the recommendations of the \\nDisciplinary Committee in such cases, shall be final and binding. \\n \\n15.7 Banned Substances/Material in University Campus (Tobacco/Narcotics/ Alcohol \\nProducts/Weapons/Firearms and Pornographic Material) \\n \\nThe following articles/substances are strictly banned in the University  Campus, \\nUniversity Hostels, and University Transport/Buses \\n• Tobacco Products; \\n• Alcoholic Beverages, Spirits, and Wines; \\n• Narcotics, Drugs, or \\n• Firearms, weapons, or replicas of weapons, or any instrument that is considered \\ndangerous and/or destructive \\n• Pornographic material in any form; \\n• Unauthorized tranquilizer medicines other than prescribed by the examining \\nphysician; or \\n• Any other objectionable material as notified by the University as such.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 39, 'page_label': '40'}, page_content='40  \\n16. DISCIPLINARY COMMITTEE \\n \\nNOTE: Possession of any of the articles/substances listed above in the sub-clauses,  \\n \\nanywhere on the University campus, including the hostels and in the University buses, is \\na serious violation, and strict disciplinary action will be taken against the errant student, \\nwhich includes immediate suspension from the University  till the completion of the \\ninquiry by the Disciplinary Committee. The guilty student(s) may be expelled from the \\nUniversity on the recommendations of the Disciplinary Committee. \\n \\n15.8  Social Media Usage – Code of Conduct/Communication \\n \\nThe competent authority shall assign and entrust certain social media- related updates \\nto a student committee that is authorized to upload approved content on the social media \\npages of the University. They are to be mindful of what is appropriate and what is not, in \\norder to maintain the goodwill and reputation of the University. \\n \\n• Students are expected not to interact on behalf of the University  with media \\nrepresentatives or invite media personnel to the campus without the permission of the \\nUniversity. \\n• Students are not permitted to audio/video-record lectures in classrooms or actions of \\nother students or staff without prior permission/consent. \\n• Students are not permitted to provide audio or video clippings of any activity on the \\ncampus to the media without prior permission. \\n• Students are expected to use social media carefully and responsibly. They are not to \\npost derogatory comments about other individuals from the University  on social media \\nor indulge in any related activities that cause grave ramifications on the reputation of \\nthe University.\\n \\n• Students are not to create audio/video recordings or take photographs or stream \\naudio/video content of any person in a location where the person has a reasonable \\nexpectation of privacy without that person’s knowledge/expressed consent.\\n \\nAny act of indiscipline pertaining to the Code of Conduct for Students listed above \\nsection and its Clauses/Sub-Clauses will be investigated by the Disciplinary Committee \\nof the University. Based on the seriousness of the act of indiscipline, disciplinary action \\nagainst the guilty student shall be initiated, which may range from a penalty/fine \\nand/or recovery of costs/expenses (incurred by the University to restore or replace or \\nrepair any property destroyed or damaged or defaced by the student) and suspension'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 40, 'page_label': '41'}, page_content='41  \\n \\nor expulsion from the University. All powers relating to discipline and disciplinary \\naction are vested in the hands of the person/committee as she/he may specify in this \\nregard. \\nThe Vice Chancellor may, on the recommendation of the Disciplinary Committee or on \\nher/his own order, direct that any student found guilty of indiscipline shall: \\n \\n• Be kept under disciplinary probation with or without supervision for a stated period; \\nor \\n \\n• Be suspended for a stated period; and/or \\n \\n• \\nBe fined monetarily with a specified amount; and/or \\n \\n• \\nNot receive the result in the examination in which she/he has appeared to withheld for \\na stated period or cancelled; and/or \\n \\n• Be debarred from one or more examinations conducted by the University; and/or \\n \\n• Be debarred from the professional/industry practice provisions/facility of the \\nUniversity; and/or \\n \\n• \\nBe debarred from the placement assistance of the University; and/or \\n \\n• \\nBe debarred from registering for a specified academic term of the University; or \\n \\n• \\nBe expelled from the University. \\n \\n• \\nBe expelled from the hostel \\n \\n• In case a student is found guilty of indiscipline and is punished as stated above, his/her \\nscholarship (if awarded) under the University Scholarship Policy shall be withdrawn \\nwith immediate effect. He/she shall be liable to refund the full amount received as a \\nscholarship from the University from the date of admission. \\n \\n• The University shall be entitled to issue public notice with or without the photograph \\nof the student concerned to intimate the general public of the misconduct or the \\npunishment imposed upon the student. \\n \\n• The decision of the Vice Chancellor regarding punishment shall be final and no open to \\nquestion. \\n \\n•    Nothing stated herein shall prevent the University from initiating or instituting \\nappropriate action in accordance with the prevalent law, both civil and/or criminal, in \\naddition to the actions defined above.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 41, 'page_label': '42'}, page_content='42  \\n \\n          Disciplinary Action: \\n \\n• If a student is found indulging in any act of indiscipline that violates the standard of \\nethics and conduct, the University shall initiate the required disciplinary action without \\nbeing biased. \\n \\n• University officials should handle students’ issues with utmost care and with an open \\nmind. Punishment must not be the sole agenda while enforcing discipline. \\n \\n• Students are to be encouraged and motivated to adopt the right path through proper \\ncounselling by faculty, mentors, and/or the student counsellor. \\nThe nature of disciplinary actions shall be based on the severity  & the frequency of acts \\nof indiscipline noted against that particular student’s name, and the procedure followed \\ncould be any one or a combination of the below: \\nPositive Advice/ Counselling: \\nThe student is first referred to a mentor (faculty/counsellor) who would offer him/her \\nwords of advice to guide them towards positive alternatives of behaviour. If the student \\nis unable to reflect upon his/her own actions and rectify them accordingly, then engaging \\nthe student with the counsellor shall be mandatory. This will ensure positive behavioural \\nchange, and if required, subsequent follow-up counselling sessions shall continue to take \\nplace. \\n \\nWarning/ Fines: \\n \\n• If the student’s behaviour is found inappropriate, a formal warning notice will be \\nissued by the concerned authority in the University. \\n \\n• They will be instructed further that they shall be provided with one chance to display \\npositive/appropriate student behaviour after realizing their mistake. \\n \\n• In some cases of misbehaviour, such as theft or misuse/damage of institutional \\nproperty, fines may be imposed. \\n \\n \\n• The written evidence of fines shall be recorded in the student’s file as proof of \\nbehavioural history, in case such kind of behaviour is repeated in the future. \\n \\n• If students are engaged in behaviour such as smoking, consuming alcohol, and/or \\ntaking drugs, then a fine as well as strict disciplinary action may be imposed. \\n \\nSuspension from Classes \\nTemporary Suspension from the University  excludes the student from academic or \\nother activities for a specified period. The suspension notice will be issued to the'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 42, 'page_label': '43'}, page_content=\"43  \\n17. RULES, POLICIES AND REGULATIONS \\n \\nstudent and their parents/guardian, and it will be recorded in the student's disciplinary \\nrecord. The student may be withdrawn from courses and forfeit fees. After the \\nsuspension period, the student must request reinstatement by submitting a letter to \\nthe Chief Proctor/Dean Student Affairs with supporting documents. Return to the \\nUniversity is subject to approval by the concerned authority. \\nRustication \\nRustication is a serious disciplinary action that excludes a student from the University  \\nfor up to one year. During this period, the student's rights are forfeited, and their \\ndegree will not be conferred. The student will be withdrawn from all courses, and fees  \\n \\nwill be forfeited. The rustication notice will be issued to the student and sent to their \\nparent/guardian, and it will be recorded  permanently in the student’s disciplinary \\nrecords and academic transcripts. Rusticated students are not allowed on campus. \\n \\nExpulsion \\nStudents expelled from the University will forfeit all student rights, be withdrawn from  \\n \\nall courses, and have their fees forfeited. Expulsion prevents the student from receiving \\na final degree or awards. The expulsion will be recorded in the student's disciplinary  \\nrecords and academic transcript, and the student will not be allowed on campus. A copy \\nof the expulsion notice will be sent to the student’s parent/guardian. \\n \\nPostponement of Conferring of Awards and Degrees \\nThe University reserves the right to defer, postpone, or cancel the conferring of any \\naward and degree during the course of disciplinary measures or during the period of \\nsuspension. \\n \\n \\n17.1 Admission Rules \\nThe University admissions shall be open to all persons irrespective of caste, class, creed, \\ngender, or nationality. All admissions shall be made on the basis of merit in the qualifying \\nexaminations and as per the rules and guidelines prescribed by the Government of \\nKarnataka, other conc erned regulatory bodies, and the entrance examinations \\nconducted by the University. \\n \\n• The students shall be admitted to a programmes of study of the University subject to \\nthe fulfilment of eligibility criteria, as prescribed from time to time by the University for \\nthe respective program of The eligibility criteria for admission to the various programs\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 43, 'page_label': '44'}, page_content='44  \\n \\nof the University would be clearly specified in the respective program regulations and \\ncurriculum, issued periodically. \\n \\n• A student admitted to a program of study shall continue to remain registered for such a \\nprogram till she/he successfully completes the program or she/he withdraws from the \\nprogram in accordance with the then prevalent regulations. \\n \\n• Every student duly admitted to the University for a program after compliance with \\nprescribed formalities and payment of prescribed fees, deposits, as applicable, and other \\namounts and submission of prescribed documents and certificates shall be allotted a \\nunique identification. \\n \\n• If a student fails to pay the University fee and deposits, as applicable, for admission to a \\nprogram of study, and/or fails to produce all the mandatory documents and certificates \\nrequired for admission to the University before the prescribed last date thereof, the \\nprovisional offer of admission to the student shall stand. \\n \\n• If a student desires to join the University on the basis of lateral entry or transfer of \\ncredits from other institutes/universities during the program, she/he shall be examined \\nfor eligibility for admission as per the procedure and criteria laid down in the academic \\nregulations of the University and the respective programme regulations concerned, and \\nadmission shall be dependent on his/her eligibility so determined. \\n \\n17.1 University Fee Policy \\n \\n• The University Fee Policy providing information on various University Fees, Charges, \\nand Deposits is given to every student at the time of the purpose of the Fee Policy \\nDocument, which is to provide all the information the student (and parents) required in \\nthis regard. \\n• The University fee is on an “annual” basis (i.e., charged annually) and in advance for the \\nconcerned academic year. It is not a “semester-based” fee structure. However, for the \\nconvenience of the students, the fee payment is facilitated in two instalments (first in the \\nmonth of June and the second, in November, of every academic year, irrespective of the \\ndate of announcement of results of end-term examinations and commencement date of \\nthe ensuing semester). \\n \\n• The University fee (including deposits, where applicable) is payable through one of the \\nfollowing modes: \\n\\uf0a7 In Cash \\n\\uf0a7 By Bank Demand Draft \\n\\uf0a7 Through net banking or credit/debit card \\n\\uf0a7 Note: Checks are not accepted. \\n• The security deposit, where applicable, will be refunded, after adjusting dues, if any, only \\nwhen the student completes his/her program of study from the University or withdraws \\nfrom the University.\\n \\n \\n• In case a student is required to repeat/re-register an academic year, the annual fee'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 44, 'page_label': '45'}, page_content='45  \\n \\npayable by her/him shall correspond to the academic year to be repeated and shall be as \\nper the fee policy in force at that point in time. \\n \\n• The policies relating to the University fee and deposits, where applicable, are the \\nprerogative of Presidency University and may be revised from time to time. Such \\nchanges shall be binding on all the students. \\n \\n• All disputes arising out of or in connection with this are subject to the exclusive \\njurisdiction of the courts of Bengaluru. \\n \\n17.1.1 Fee Payment Schedule and Late Fee Rules \\n \\n• The payment of Fee for new Admissions will be as mentioned in the respective \\nProvisional Admission Letter or shall be before the commencement of the Programme, \\nwhichever is earlier. The payment schedule will be notified from time to time. \\n \\n• The student is cautioned that failure to pay the University fee on or before the \\nprescribed dates shall not be eligible to register for the concerned academic term, and \\nthis will result in the loss of an academic term/year, as the case may be. \\n \\n17.1.2 Admission withdrawal/ cancellation \\nThe request for cancellation of admission or withdrawal from studies is to be made in \\naccordance with the prescribed regulations. Regulations include the procedure for \\ncancellation/withdrawal as well as the rules for a refund. \\nRefund of fees in case of withdrawal of admission is governed by  the UGC Guidelines \\nprevailing at the time of withdrawal and in alignment with University  Refund Policy \\nand Processes. \\n \\n17.1.3 Procedure for Refund: \\n \\nBefore Enrolment: \\nAn email must be sent to the email ID mentioned in the admission letter along with \\nscanned copies of the original fee paid receipt, the Aadhaar card copy of the student, the \\nAadhaar card copy of the father & mother, the cancelled cheque leaf of the parent, and \\nthe copy of the first page of the parent bank passbook. \\n \\nAfter Enrolment: \\nThe request letter for discontinuation is duly endorsed by the Dean/HOD, along with the \\nno-dues form to be submitted to the Office of the Registrar. Please ensure all required \\ndetails are filled out completely and obtain the necessary signatures from the respective \\ndepartments in the no-due form to initiate the process of fee refund in accordance with \\nUGC Guidelines. \\n \\nStudents are expected to align with the University timelines.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 45, 'page_label': '46'}, page_content='46  \\n \\n \\nSl. \\nNo. \\nPercentage of Refund \\nof Fees \\nTime line when notice of \\nwithdrawal of admission is received \\n1. 100% 15 days or more before the formally \\nnotified last date of admission \\n2. 90% Less than 15 days before the formally \\nnotified last date of admission \\n3. 80% 15 days or less after the formally \\nnotified last date of admission \\n4. 50% 30 days or less but not more than 15 \\ndays, after formally notified last date of \\nadmission'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 46, 'page_label': '47'}, page_content=\"47  \\n \\nNote: Processing fee of up to 5% of the value refunded (other than Caution and/or \\nSecurity Deposit, which will be refunded in full) subject to a maximum of Rs. 5000/ - \\n(Rupees Five Thousand Only). \\n• If the application for withdrawal of admission is submitted more than 30 calendar days \\nafter the date of commencement of the concerned program as announced by the \\nUniversity in the academic calendar or University notification in this regard, there shall \\nbe no refund whatsoever of the University fee paid by the student. The refundable \\ncaution and/or security deposit, if applicable, will be refunded. \\n• The refund will be processed, as per the policy, within the prescribed number of days \\nfrom the date the withdrawal is completed. The University  will make the refund, if any, \\nthrough NEFT only to their parent’s bank account, the details of which were intimated \\nin the refund application. \\n \\n17.1.4 Withdrawal from Programme and Fee Refund Policy for \\nSubsequent Withdrawals \\n \\n• A student wishing to withdraw from the Program of Study after completing one or \\nmore academic years must submit a Withdrawal Form along with a signed 'No Dues \\nForm' from the departmental heads. The University's refund policy will apply only if \\nthese forms are submitted. \\n \\n• If a student submits the withdrawal form by 15th July (or another notified date), the \\nadvance fee for the next academic year will be refunded, minus a Rs. 5000 processing fee \\nand any applicable dues. The caution/security deposit, if paid, will also be refunded after \\nadjusting any outstanding dues. \\n \\n• If the withdrawal application is submitted after 15th July (or another notified date), the \\nadvance fee for the next academic year will not be refunded. However, the \\ncaution/security deposit, if paid, will be refunded after adjusting any outstanding dues. \\n \\n• If a student withdraws due to not progressing to the next semester, the advance fee for \\nthe academic year will be refunded after deducting any applicable dues and a \\nprocessing fee of Rs. 5000. The caution/security deposit, if paid, will also be refunded \\nafter adjusting any outstanding dues. \\n \\n• No interest shall be payable on the refund of any fees/deposit. \\n \\n• The minimum time to make the refund, as applicable, shall be thirty (30) calendar days \\nfrom the date the withdrawal is completed. The University will make the refund, if any, \\nthrough NEFT only to their parent’s bank account, the details of which were intimated \\nin the refund application.\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 47, 'page_label': '48'}, page_content=\"48  \\n \\n• In case of any dispute, the decision of the Vice Chancellor, Presidency University, would \\nbe final and \\n \\n• All disputes arising out of or in connection with this are subject to the exclusive \\nJurisdiction of Courts of Bengaluru. \\n17.2  Computer Laboratory Rules \\n \\nComputer laboratories will be open during the University 's working hours and/or as \\nrequired or notified by the Dean/HOD of the concerned school/department. Students \\nshould use the computer lab for academic learning activities and curricular-related \\nassignments/projects. All Internet-based activities of the students, through the \\nUniversity Campus Network, will be monitored for security purposes. \\nThe rules governing access to the computer labs and conduct inside the labs are \\nlisted below: \\n \\n• Only faculty members, students, and staff of the University are allowed into the \\ncomputer lab. No visitors are allowed into the lab without prior permission from the \\nDean/HOD concerned. \\n \\n• Each student will receive a unique email ID and password, which must be kept \\nconfidential. Sharing passwords is prohibited. Misuse of the email ID will be considered \\nmisconduct, and strict action will be taken. \\n \\n• Students must log in and log out using the Lab Attendance Register kept for this \\npurpose at the time of entry and exit from the computer lab. \\n \\n• Students must display the identity cards and should be dressed as per the University \\ndress code applicable to them. Students without an identity card and/or violating the \\ndress code shall not be permitted to enter the computer lab. \\n \\n• Students must get prior permission to bring storage devices like pen drives or CDs to \\nthe lab, and these must be registered. Failure to comply will result in disciplinary action \\nand confiscation of unauthorized devices. Any copied data or programs must be shown \\nto the lab in charge for verification.\\n \\n \\n• Students must use only the systems assigned by the lab in-charge or course instructor \\nand are provided with unique login credentials. Sharing login information is \\nprohibited. Unauthorized use of the system will lead to disciplinary action against the \\nstudent involved and anyone who receives the shared information. \\n \\n• Students shall not indulge in hacking or any such unethical/unauthorized attempt to \\naccess information in files/systems other than their own. \\n \\n• Any attempt to destroy or damage data or programs in individual machines as well as \\nin the server shall result in stringent disciplinary action against the guilty/errant \\nstudent, which may include debarment from Placement Assistance and/or\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 48, 'page_label': '49'}, page_content=\"49  \\n \\n   participation in University Competitions/Events. \\n \\n• The Internet/Wi-Fi facility is provided purely for academic learning and internet \\naccess is free with conditions. Students must vacate systems after 60 minutes if others \\nare waiting. \\n \\n• Audio/video chatting and accessing non-educational or illegal sites are prohibited. \\nMisuse of lab facilities for non-academic purposes will be considered a serious \\ndisciplinary offense. \\n \\n• Students must not use the Internet/Wi-Fi for unproductive, provocative, or illegal \\nactivities. Misuse will result in disciplinary action, including withdrawal of access, \\ndebarment from placements, and exclusion from University events. \\n \\n• Beverages and eatables are strictly prohibited inside the lab. \\n \\n• Mobile phones are strictly prohibited in the lab, and violation of the rule results in the \\nconfiscation of the mobile phone and expulsion from the lab. \\n• If any damage is caused to any computer system or its peripherals due to \\nnegligence and/or deliberate mischief by student(s), the entire cost of the \\nsystem/peripherals will be recovered by the University from the delinquent \\nstudent(s). \\n \\n17.3 Rules for Other Laboratories and Workshops \\n \\n• Students must report for laboratory and workshop sessions on time as per the \\ntimetable. \\n \\n• Students are required to wear laboratory/workshop uniforms as prescribed by the \\nschool. Care should be taken by students to wear heavy-duty shoes to prevent \\naccidents in the workshop. \\n \\n• Students must maintain lab/workshop records as required by their course. Entry is not \\nallowed without these records. Work on experiments can begin only with the \\ninstructor's approval, and all instructions must be followed. \\n \\n• All laboratory equipment/workshop machinery/appliances/chemicals need to be \\nhandled with care by students, and they should take the help of the lab \\ninstructor/course instructor whenever they are uncertain on how to handle any \\n \\n• Students must inform the faculty, laboratory assistant, or workshop assistant of any \\ndamages or malfunctions of equipment immediately and as and when noticed. \\n \\n• Students will be held responsible for any damage to equipment, machinery, or \\nappliances caused by negligence or misconduct. The University will recover the cost \\nthrough penalty fees or by deducting it from the security deposit paid at the time of \\nadmission, if applicable. \\n \\n• Any unruly behaviour in the laboratory/workshop shall be dealt with immediately by\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 49, 'page_label': '50'}, page_content='50  \\n \\nthe course instructor/lab instructor, which may include sending the errant student(s) \\nout of the laboratory/workshop and any other penalty as imposed by the Disciplinary \\nCommittee. \\n \\n• All materials used in the laboratory/workshop are the property of the University and \\nshould not be taken out of the laboratory/workshop except under the guidance of a \\nfaculty member in charge and with the permission of the concerned HOD/DEAN. \\n \\n• Students absenting themselves from laboratory/workshop sessions cannot claim to \\nredo the experiments as a matter of right. The discretion/decision of the HOD/Dean will \\nbe final in this case. \\n \\n• Any loss, damage, or injury occurring to the student and/or the equipment in the lab \\narising out of failure to follow or adhere to the instructions issued by the lab/workshop \\ninstructor or due to acts of negligence of a student shall be the liability of the student. \\n \\n17.4 Library Policy and Rules \\nThe University Library promotes a welcoming environment that is conducive to study, \\nresearch, and learning. It has a good collection of all textbooks, reference books, and \\ngeneral reading materials along with subscription to e-journals and e-databases. \\n \\nLibrary rules are framed for effective utilization of the Library collection & it’s services \\nby the students and will be reviewed periodically in accordance with the latest \\nupdates/revisions. Students are advised to visit the Library regularly to avail its physical \\ncollection and its website to access e-resources. \\n \\nClassification Scheme \\n \\nThe books in the Library are classified according to Dewey’s Decimal Classification \\n(DDC) scheme. The scheme allows for a systematic arrangement of materials based on \\nsubject areas. Users are requested to use OPAC computers and follow the instructions \\ngiven there for easy location of books. \\nInternet Browsing \\n \\n• Internet browsing facilities are available in the Library only for subject-related \\nsearches and to access the electronic databases subscribed to by the University. \\n• Online chatting and playing games are strictly prohibited on the digital library \\ncomputers. \\n• Students are not allowed to download and install any software program without the \\nknowledge of the Library professionals. \\n• Use of computers is limited to thirty minutes when others are waiting for access. \\n17.4.1 Use of Electronic Equipment \\n \\nUse of electronic equipment such as mobile phones, audio players, and similar gadgets'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 50, 'page_label': '51'}, page_content='51  \\n \\nis strictly prohibited inside the Library. However, students may use their personal \\nlaptops/tablets in the Library for academic work only. Any misuse of the laptop in the \\nLibrary will result in the confiscation of the laptop by the librarian, and the errant \\nstudent will be debarred from bringing the laptop to the Library. \\n \\n17.4.2 Rules for Borrowing Books \\n \\nLending of Library books can be done after one produces their University  identity card \\nas per the rules/procedure listed below: \\n \\n• Identity cards are not transferable. Library staff may refuse to issue books to anyone \\nwho uses others’ books. Books should not be lent to others. \\n \\n• Books will be issued to all students for a period of 15 days. \\n \\n• Books borrowed should be returned on or before the date mentioned in the due date \\nslip. Overdue charges will be collected as mentioned in clause below. \\n \\n• Books have to be returned to the Library as and when they are recalled by the librarian \\n \\n• The condition of a book must be checked before borrowing, and any book found in a \\ndamaged condition will not be issued. The Library staff must be notified immediately if \\nany damage or defect is noticed while borrowing. \\n \\n• The borrower is fully responsible for the books issued to him/her. Any damage to the \\nbook or marking during the borrowed period will lead to a penalty or total replacement \\nof the book. \\n \\n• If books borrowed are damaged or lost by the borrower, he/she should replace the \\nbook or pay the value as per the University Library damage & lost policy. \\n \\n17.5. 3 Rules for Renewal of Books \\n \\n• Renewal of books is done for those books that are not in demand at the respective library \\nfrom where it has been borrowed. \\n \\n• Books must be brought to the Library for renewal. \\n \\n• Books can be renewed twice for a 15-day period each time if there is no demand. \\n \\n• In case a book is reserved by someone, then its renewal is not possible, and it has to be \\nreturned to the books. It will not be renewed more than two times at a stretch \\nirrespective of the demand. Such books have to be returned on or before the due date \\nand kept in the Library for two working days before issuing it to the same person.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 51, 'page_label': '52'}, page_content='52  \\n \\n17. 5.4 Rules for Reservation of Books \\n \\n• Reservation of books can only be done through Library web OPAC, after login into the \\nuser’s account. \\n• The collection marked as reference, print journals & magazines issues and these are \\nnot allowed to be reserved. \\n• If a book is reserved by more than one person, each one gets a priority number \\nautomatically based on a first-come, first-served basis. Such books cannot be renewed \\nto the borrower or issued to anyone other than those reserved.\\n \\n \\n• When a reserved book is returned to the Library, members will be notified in the order \\nof their priority on the reservation list. Each member will have two working days to \\nborrow the book. If they fail to do so, the opportunity will pass to the next person on the \\nlist.\\n \\n \\n17.5.5 Reference Books \\n \\nDictionaries, encyclopaedias, handbooks, manuals, yearbooks, periodicals, back volumes \\nof periodicals, reports, textbooks, newspapers, and all those books bearing the stamp \\n“Reference” will not be lent out. These resources are meant for reference within the \\nLibrary premises only. \\n \\n17.5.6 Overdue Charges, Loss of Books and Identity Card \\nFor late returns of books, the following overdue charges will be levied: \\n \\n• First 10 days after the due date: Rs. 5 per book day \\n \\n• From the 11th day after the due date: Rs. 10 per book per day \\n \\n• Any book that is lost by the borrower must be brought to the notice of the librarian. \\n \\n• The borrower is liable to replace the book that is lost or If unable to replace the lost \\nbook, recovery of the cost of the book must be made on the following basis \\n \\n• Three times the current price of the book, if loss of the book is reported before the due \\ndate; \\n \\n• Three times the current price of the book with overdue charges, if the borrower has \\nreported the loss after the due date; \\n \\n• If the lost book is rare in nature (i.e., not available in the market or is out of print), then \\nfive times the book’s cost will be recovered from the borrower. \\n \\n• Absence from the University will not be allowed as an excuse for delay in return of \\nbooks.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 52, 'page_label': '53'}, page_content='53  \\n \\n• No reminders will be issued to individual defaulters; and, \\n \\n• All books borrowed from the Library have to be returned, and all outstanding dues \\nmust be cleared before getting a no-dues \\n \\n17.5.7 Library E – Resources \\n \\nThe Library subscribes to the following online databases, which are available to students \\nand faculty within the campus as well remotely through Knimbus using valid credentials. \\nThe subscribed e -databases contents are subject to copyright, and hence the users are \\nrequired to use the content for academic reference only. For any assistance in accessing \\nthe subscribed resources, write to library.services@presidencyUniversity.in \\n \\n\\uf0a7 IEEE Digital Library \\n\\uf0a7 ASTM Digital Library \\n\\uf0a7 ProQuest ABI Global \\n\\uf0a7 J-Gate (Engineering) \\n\\uf0a7 J-Gate (Social Science and Management) \\n \\n\\uf0a7 NTPEL Lectures and Videos \\n\\uf0a7 EBSCO \\n\\uf0a7 Science Direct \\n\\uf0a7 JSTOR \\n\\uf0a7 Lexis Nexis \\n\\uf0a7 SSC Online \\n\\uf0a7 Hein Online \\n\\uf0a7 Capitaline \\n\\uf0a7 CMIE ProwessIQ \\n\\uf0a7 Emerald insight \\n\\uf0a7 IndiaStat \\n\\uf0a7 SPSS AMOS \\n\\uf0a7 Scopus bibliographical database \\n\\uf0a7 DELNET - Developing Library Network \\n\\uf0a7 South Asia Archives \\n\\uf0a7 World E-book Library \\n\\uf0a7 Library OPAC \\n\\uf0a7 Shodhganga (Archive of e-theses of all Universities in India) \\n\\uf0a7 Turnitin Plagiarism Check \\n\\uf0a7 Ouriginal (Urkund - UGC) Plagiarism Check'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 53, 'page_label': '54'}, page_content='54  \\n \\n17.5.8 Library Print Subscription \\n \\nLibrary Subscribes to 155 print journals and 38 general magazines & 17 newspapers. \\nList of these resources can be found from the library website. These periodicals are only \\nfor reference and will not be permitted for circulation. \\n17.5.9 Printing and Photocopying Facility \\n \\nPhotocopying of the Library materials can be obtained from the Library at nominal \\ncharges as fixed by the Library from time to time. Photocopy charges may be paid at the \\nIssue Desk. \\n  \\nWorking Hours \\nMonday through Saturday: 8.30 am to 6.30 am  \\nDuring End-Term Examinations: 8.30 am to 8.00 pm  \\nCirculation (Issue & Return): 8.30 am to 6.00 pm \\nThe Library will be closed on Sundays and other University holidays. \\n \\nGeneral Instructions \\n \\n• Library access is limited to the faculty, staff, and students of Presidency University. A \\nvalid identity card is required for all Library transactions, including borrowing \\nprivileges. \\n• Always use the call number for locating the books; the call number is printed on the \\nspine of the book for easy identification. In case of any difficulty in locating the books, \\nplease approach Library professional. \\n• Use the Online Public Access Catalogue (OPAC) to identify the books you require and \\nto know the availability.\\n \\n \\n• After referring to the books, please leave them on the tables. Library staff will replace \\n \\n• \\nUsers must leave their personal belongings in the designated property rack before \\nentering the Library. However, valuables should not be placed in the racks, as the \\nLibrary is not responsible for any loss of belongings. \\n \\n• \"A misplaced book is a lost book.\" To maintain order, avoid placing books in incorrect \\nlocations on the racks. As the Library follows an open access system, books removed \\nfrom the racks should be left on the tables for the Library staff to replace. \\n \\n• Strict silence is to be observed inside the Library. If conversation becomes necessary, \\nit should be in low tones. \\n \\n• Food and beverages are not allowed inside the Library. \\n \\n• \\nIf any books are defaced, such as by marking, underlining, folding, or tearing of pages, \\netc., twice the cost of the latest edition of the book will be charged to the student.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 54, 'page_label': '55'}, page_content='55  \\n \\n \\n• If a student is found guilty of theft, tearing parts of the books, and/or causing damage \\nto the Library property, disciplinary action will be taken against the students with \\npenalties ranging from forfeiture of the security deposit to expulsion from the \\nUniversity. \\n \\n17.5.10 Policy Against Plagiarism \\nThe University  is committed to ensuring the authenticity as well as the accuracy of \\ndocumentation of the research record, whether in a pre- registration research proposal, \\nresearch progress report, pre -submission synopsis, final thesis, publications, or any \\nother form of  claims made to academia, government, industry, media, or the public at \\nlarge. \\n \\n• For this purpose, the guidelines followed worldwide shall be adopted, such as those \\nissued by the Committee of Publication Ethics (COPE) [publicationethics.org] or the \\nSingapore Statement on Research Integrity. [singaporestatement.org/statement.html]. \\n \\n• The Research and Innovation Council of the University shall provide guidelines and \\ntraining, as required, to ensure that all students, in particular undergraduate students of \\nhigher semesters, postgraduate students, research scholars, and faculty members, are \\ntrained in the best practices of research documentation/publishing/communication, \\nincluding how to avoid unethical publishing practices and the usage of anti-plagiarism \\nsoftware Turnitin®, iThenticate®, or other approved software.\\n \\n \\n• All written submissions for publication, such as project reports, dissertations, papers, \\ntheses, and other publications under the name of the University, must adhere to the anti- \\nplagiarism guidelines provided by the course instructor(s), research supervisors, Ph.D. \\nregulations, or other University notification to this effect from time to time. If required, \\nthe electronic file (text) shall be scanned using anti-plagiarism software (Turnitin®, or \\niThenticate®, or other approved software). Also, non-text contents such as tables, \\nfigures, images, drawings, schemas, etc., shall be critically examined to ensure that the \\nsubmission is free from any unethical content/practice prior to final \\nsubmission/publication.\\n \\n \\n• Research Scholars shall submit the anti-plagiarism scanning report of the complete \\nthesis at the time of submission of the thesis for evaluation, as specified in the D. \\nRegulations, 2022 of the University, as may be amended from time to time. \\n \\n• The students, research scholar(s), supervisor(s), and author(s) shall be held \\nresponsible for any such document found to have unethical content/practices, including, \\nbut not limited to, plagiarism, falsification, and fabrication of results/data/claims. \\n \\n• Such project reports/dissertations/publications/theses shall be withdrawn by the \\nUniversity, regardless of their consequences to their authors, including cancellation of \\nregistration for the course(s) concerned and/or withdrawal of their Ph.D. degrees, \\n \\n \\nIf such research scholars may also be debarred from admission to any program in the \\nUniversity.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 55, 'page_label': '56'}, page_content=\"56  \\n \\n17.6 Internship, Professional Practice and Placement Assistance \\n \\nThe University has a dedicated industry interface and placement cell to provide \\nassistance for internships, professional practice (as applicable), and career placements  \\nto all the eligible students. The students must strictly follow the rules and guidelines  \\nissued by the University on a timely basis to avail themselves of such facilities. \\n \\n• Every student must have a minimum attendance of 75% or above in all courses in every \\nsemester/academic term to be eligible to avail themselves of the facilities offered by the \\nIndustry Interface and Placement Cell. \\n \\n• The University shall not extend any professional practice or placement support to \\nstudents penalized in disciplinary \\n \\n• The students are advised to refer to the Program Regulations and Curriculum, 2021, \\npertaining to the concerned Program of Study for more details on the Policy on \\nPlacement and Internships, as applicable to the relevant Program of \\n \\n• The relevant Placement Rules and Guidelines will be issued to the pre-final year \\nstudents of a Program of Study by the Placement Cell at the appropriate time. \\n17.7 Medical Care Policy \\n \\n• The University is committed to taking due care of the general health and well-being of \\neach. However, the University shall not take responsibility for serious medical \\nconditions arising out of ailments, sickness, injuries, accidents, etc. Treatment for \\nminor ailments and first aid is provided at the University Primary Medical Centre. In \\ncase a student requires further medical attention, he/she will immediately be \\ntransferred to the nearest hospital, and the same shall be informed to the parents. \\n \\n• The University provides minor first aid on campus and in hostels and may inform the \\nstudent's parent or guardian if necessary. However, it is not responsible for incidents \\nduring this service or for medical emergencies, accidents, or injuries occurring on \\ncampus, in sports areas, during activities, or while using University transport. The \\nUniversity is also not liable for accidents resulting from a student's failure to follow \\nsafety guidelines or the code of conduct. \\n \\n• The University has trained & qualified nursing staff and has an ambulance facility on \\ncampus. \\n \\n17.8 University Transport Policy \\n \\nThe University has its own transport facility and provides pick-up and drop-off facilities \\non certain prefixed routes to the students, faculty members, and staff. \\n \\n• Students who would like to avail themselves of the University transport facility may\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 56, 'page_label': '57'}, page_content='57  \\n \\n  apply for the transport facility of the University and pay the prescribed University  \\n \\ntransport fee. The transport fee is paid as an annual fee for the concerned academic A       \\nstudent availing themselves of transport facilities and who has not paid the transport \\nfee in full shall not be permitted to use the University transport facility. \\n \\n• Transport fees are neither refundable nor adjustable under any \\n \\n• The student has to opt for the available pickup/drop point on the available pre-fixed \\nroute at the time of applying for the transport. \\n \\n• The transport route and pick/drop points are planned considering the best interests \\nfor the entire community using the University transport system. However, the final \\nroute and schedule are entirely at the discretion of the University.  \\n• The transport timings—pick up and departure from the University campus—are fixed \\nand announced at the beginning of each academic \\n \\n• Transportation routes and timings may be altered keeping in view its requirements \\nduring examination and other special activities of the \\n \\n• Students will be issued Transport ID cards at the time of allocation of transport \\nfacilities and must carry the Transport ID card with them to prove identity whenever \\nonly authorized students are permitted to travel with ID cards. \\n \\n• The transport ID cards are not transferable. Any student misusing the ID card shall be \\nsubject to disciplinary action, which may include withdrawal of the transport facility \\nfor the errant student. \\n \\n• Intoxicants, liquor, tobacco, explosives, and/or weapons (knives) cannot be kept/used \\nby the student. Any violation will result in disciplinary action, including expulsion \\nfrom the University. \\n \\n• Instructions and Rules for Students Using the University Transport/Bus: \\n \\n• All students using the University transport must be respectful to other commuters— \\nfaculty and students, the bus driver, and the conductor/manager. \\n \\n• No student shall invite friends or others to board the University. \\n \\n• The students must be ready at the assigned bus stop at least five minutes before the \\nbus is scheduled to depart. The bus will not wait for students who are not present at \\nthe bus stop at the assigned \\n \\n• A student must occupy the allotted/available seat. \\n \\n• A student is not permitted to get down from the bus other than at the opted bus. \\n \\n• A student must follow the instructions of the bus driver, conductor, and manager if the \\nmanager is inspecting the'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 57, 'page_label': '58'}, page_content='58  \\n \\n• Students must not litter, play loud music, or shout on the bus or cause damage to any \\npart of the bus. \\n \\n• A student indulging in any act of misbehaviour with fellow passengers, faculty, staff, or \\nany transport staff, and/or causing damage to the University Bus, shall be subject to \\nstringent disciplinary action, including forfeiture of the University Transport facility for \\nthe rest of the academic year. \\n \\n17.9 University Hostel Policy \\n \\nThe University provides safe, convenient, and comfortable hostel facilities with a hostel \\nmess at a very affordable fee. Separate hostels are provided for boys and girls. All \\nhostellers must abide by the hostel management and rules of operations that will be given \\nto all students admitted to the University  Hostels. The student (hosteller) and \\nparent/legal guardian of the student shall give an undertaking as prescribed by the \\nHostel Management and Rules of Operation. \\n• Admission to the hostel is done  on a first -come-first-serve basis, at the time of \\nadmission to the University . Hostel accommodation is normally allotted only for the \\nodd and even Semesters. \\n• Students who require hostel facility for the summer term must apply for the same and \\npay the prescribed hostel fee applicable for the summer term as stipulated by the \\nUniversity. \\n \\n• Nomination of a local guardian is imperative for admission to the hostel, and he/she \\nshould be accessible to the hostel authorities in times of emergency as a reliable \\ncontact. \\n \\n• In case a student (hosteller) fails to maintain a minimum 75% attendance in all courses \\nregistered, at the end of the concerned semester, the hostel facility shall be withdrawn  \\nfor the student. The concerned student will not be provided the University hostel facility \\nfor the next semester/academic \\n \\n• The hostel facility shall be co-terminus with the student pursuing a course of study at \\nthe University. \\n17.10 Sports Policy \\n \\nThe University strongly encourages sports activities, both indoor and outdoor games, to \\ncreate a vibrant sporting culture and provide competitive and friendly recreation for \\nstudents to bring out the best in each student in terms of physical fitness, \\n“sportsmanship,” and camaraderie. The University  has sprawling facilities for several \\nsports activities. To promote sports, the University has an established sports council.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 58, 'page_label': '59'}, page_content='59  \\n \\n• Sports Council: The Constitution of Sports Council \\n• Chairperson – Vice Chancellor \\n• Member Secretary – Director of Physical Education \\n• Members – Dean Student Affairs, Deans of all Schools, Physical Education \\nInstructors  \\n• A minimum of two students representing each School \\n \\nSeveral sporting events are organized throughout the academic year, including the \\nUniversity Sports Meet. Other special events and coaching programs may be conducted \\nfor interested students from time to time. \\n \\n17.11 Parking Facility \\n \\n• The University provides limited parking space for the two-wheeler and four-wheeler \\nvehicles of students, for which each student shall be issued a vehicle identity sticker from \\nthe administration office. Any vehicle without the sticker shall not be permitted to enter \\nthe University campus. \\n \\n• Students must park their vehicles in the allocated parking. \\n \\n• Every student using the parking facility must comply with the parking and traffic \\nguidelines displayed on the University \\n• Students using two-wheelers must wear helmets while riding their vehicles. Students \\nwithout helmets will not be allowed to park their two-wheeled vehicles in the allotted \\nparking \\n \\n• Exceeding speed limits within the campus is strictly \\n \\n• Any violation of these rules will result in the parking facility being withdrawn from the \\nstudent. \\n \\n \\n18.1  Joint Affidavit by the Student and Parent/Legal Guardian \\n \\nA notarized affidavit on a Rs. 50/- stamp paper, as per the proforma placed in Annexure \\n4, is to be submitted jointly by the student and parent/legal guardian to the registrar, \\nPresidency University. This affidavit stands as an acknowledgment and a guarantee by \\nthe student and the parent that they have read, understood, and will adhere to all the \\nUniversity Regulations in the Student Handbook: Rules, Policies & Code of Conduct for \\nStudents, and any amendment of University Notifications, from time to time. \\n \\nThe Joint Affidavit consists of the following mandatory undertakings as required by  \\n18. OTHER PROVISIONS'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 59, 'page_label': '60'}, page_content='60  \\n \\nthe MHRD/UGC and the University: \\n• PART A: Student’s Information and Documents \\n• PART B: University Regulations and Student Handbook: Rules, Policies and Code of \\nConduct for Students \\n• PART C: Prevention of Sexual Harassment \\n• PART D: Permanent Form of Permission and Indemnity \\n \\n18.2  Permanent Form of Permission and Indemnity \\n \\nAs part of the program curriculum, your son/daughter/ward may have to travel for \\nindustrial internships, tours, and participate in similar curricular and extracurricular \\nprograms that may involve  cultural activities, industrial tours, and other \\nexpeditions/tournaments organized by the University. The purpose and necessity of \\nthis undertaking is to obtain permission from you to enable your son/daughter/ward \\nto participate in such activities stated above and also to indemnify the University  in the \\nevent of unforeseen loss of personal property, injury, and accident to limb or life that \\nmay befall your son/daughter/ward. This undertaking by the parent(s)/legal guardian \\nof the student ( PART E of the Joint Affidavit described in Annexure 4) is  a one -time \\nexercise, and once the student and parent/legal guardian have signed this form, the \\nstudent is expected to follow the instructions issued by the University  until completion \\nof their student program. \\n \\n18.3 Issue of Certificate  \\n \\nProvisional Degree Certificate \\n \\n• On completion of the requirements for the award of the degree (refer to Section 21.0 \\nof the Academic Regulation 2021), the student may apply for a Provisional Degree \\nCertificate in the prescribed application form along with the prescribed fee notified by \\nthe University from time to time to the Controller of Examinations of the University. \\n \\n• On verification of the eligibility criteria prescribed in Clause 21.2 of the Academic \\nRegulation 2021, the Controller of Examinations shall issue the Provisional Degree \\nCertificate to the concerned student, to the effect that the concerned student has \\nfulfilled all the requirements for the award of the Degree in the concerned Program and \\nthat the Degree shall be conferred on the concerned student at the next Convocation of \\nthe University. \\n \\n18.4 Issue of Degree Certificate Before Convocation \\n \\n• In exceptional circumstances, a student may apply to the University with the \\nprescribed fee and all supporting documentation if they need the degree certificate \\nbefore the convocation date in order to pursue further education or employment where \\nthe student has secured admission or is seeking employment and must provide the'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 60, 'page_label': '61'}, page_content=\"61  \\n \\ndegree certificate. \\n \\n• After evaluating the application's merit, the Vice Chancellor will recommend to the \\nChancellor whether or not to issue the degree. The Chancellor's decision is final and \\nenforceable. The concerned student will receive the degree certificate with the \\nChancellor's approval. \\n \\n• However, the minimum time taken to process and issue the degree certificate shall be \\ntwo (02) calendar months from the date of receipt of the request for the issue of the \\ndegree certificate. \\n \\n18.5 Duplicate Certificate \\nThe duplicate certificate ( Grade Cards/Provisional Degree Certificate/Degree \\nCertificate) will be i ssued only for genuine cases if the original is lost, stolen or \\ndamaged. In such cases, the student mustsubmit a written request in person with the \\nsupporting documents as under: \\n \\n• Copy of FIR (First Information Report) filed with police intimating the loss of the \\ncertificate, digitally signed by the Commissioner of Police or any police authority, and \\nthe full sheet of the newspaper in which the notification regarding the loss of the \\ncertificate is \\n \\n• A non-traceable certificate issued by the police official, duly signed by the inspector or \\nsub-inspector with a round seal (from the area in which the candidate lost the \\ncertificate) by mentioning the crime and occurring sheet number and date, or a \\nnotarized affidavit by the student that the non-traceable certificate was not issued by \\nthe police.\\n \\n \\n• An affidavit on non-judicial stamp paper duly signed and stamped by the first-class \\nmagistrate/notary public with an undertaking to return the duplicate certificate in case \\nthe original certificate(s) is \\n \\n• The student must pay the prescribed fee as fixed by the University from time to time. \\nThe payment acknowledgement receipt should be attached with the application. \\n \\n• The University will courier the duplicate certificate(s) to the applicant's \\ncommunication address, or the student may collect the duplicate certificate(s) in person \\nfrom the University upon receiving communication from the University. \\n \\n• The minimum time taken to process and issue the duplicate certificate(s) shall be two \\n              (02) weeks from the date of receipt of application. \\n \\n18.6 Transfer Certificate (T.C.) and Migration Certificate \\n \\nTransfer Certificate (T.C.) shall be issued by the Registrar’s Office to those students who \\nare discontinuing their course and/or passing out after completing the course. The\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 61, 'page_label': '62'}, page_content=\"62  \\n \\nfollowing documents in original must accompany the application for such request: \\n\\uf0a7 Request letter duly signed by student and parent \\n\\uf0a7 No due certificate duly certified by the concerned departments of the University \\n\\uf0a7 University ID card \\n\\uf0a7 Receipt of fees paid \\n \\n18.7 Bonafide Certificate \\n \\nStudents who wish to obtain a bonafide Certificate for various purposes like application \\nfor a bank loan, passport, scholarship, higher studies, employment verification, etc., must \\napply in the prescribed application form to the registrar's office. The minimum time \\ntaken to process and issue the The bonafide certificate shall be issued one (1) day from \\nthe date of receipt of the application. \\n \\n18.8 Issue of Transcripts \\n \\nThe Examination Department issues transcripts for the students who wish to apply for \\nhigher education, competitive examination, and placement. The student must submit the \\nproof along with the written request/application and payment of the prescribed fee \\nacknowledgment receipt. The minimum time taken to process such a request shall be \\ntwo (02) weeks from the date of application. \\n \\n18.9 Procedure to Collect Original Documents Through an Authorized Person \\n \\n• Students can authorize a person to collect the original document. \\n \\n• If an authorized person is assigned to collect the original certificate/document on the \\nstudent’s behalf, an authorization letter duly signed specifying the required documents \\nto be collected, the authorized person’s details, and an ID proof of both should be \\nsubmitted to the Registrar's Office either in person or as a scanned document through \\nemail at registrar@presidencyUniversity.in. \\n \\n• The authorized person should bring the ID proof of both the authorizing and \\nauthorized parties (original & copy), which is mentioned in the authorization letter. \\n \\n• If the authorized person is a foreign national, he/she should bring the residential \\npermit or passport (original & copy).\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 62, 'page_label': '63'}, page_content=\"64  \\nANNEXURE – 1 \\n \\nANTI-RAGGING COMMITTEE \\n \\nName & Designation Role Contact Details \\nDr. Vidya Shankar Shetty \\nPro-Vice Chancellor \\nChairperson  \\nprovc@presidencyuniversity.in \\nDr. Md Sameeruddin Khan \\nPro Vice Chancellor (Engineering) \\nMember 9121061686 \\npro- vicechancellor@presidencyuniversity.in \\nDr. Abdul Sharief  \\nDean, School of Engineering \\nMember 9448503567 \\ndeansoe@presidencyuniversity.in \\nDr. K. Krishna Kumar \\nDean, School of Commerce & \\nEconomics \\nMember 9986999098 \\ndeansoc@presidencyuniversity.in \\nDr. Syed Shoukath Ali \\nDirector, Student Housing \\nMember 8050643902 \\nshoukathali@presidencyuniversity.in \\nDr. Rajiv Ranjan Singh  \\nHOD, Department of Electronics & \\nCommunication Engineering \\nMember 9742649493 \\nrajivranjansingh@presidencyuniversity.in \\nMs. Zareena Ali  \\nResidence Officer, Girls Hostel \\nMember 9148572609 \\nzareena.ali@presidencyuniversity.in \\nDr. Malarvili K.  \\nProfessor, Languages -Kannada \\nMember 9480095845 \\nmalarvili@presidencyuniversity.in \\nDr. Bhagyashree  \\nAssistant Professor, School of \\nDesign \\nMember 9916443127 \\nbhagyashree.nadig@presidencyuniversity.in \\nMaj. Gen. Gurdeep Narang \\n(Veteran) \\nDirector - Student Discipline, \\nSports and NCC \\nSecretary 9648774394 \\ngurudeep.narang@presidencyuniversity.in \\n \\n \\nTo address and curb the menace of ragging, the University  Grants Commission has enacted \\nthe 'UGC Regulation on Curbing the Menace of Ragging in Higher Educational Institutions, \\n2009'. In accordance with this regulation, Presidency University , Bengaluru, has constituted \\nthe anti-ragging committee.\"),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 63, 'page_label': '64'}, page_content='65 \\n \\n \\n \\nANNEXURE – 2 \\n \\nCONSTITUTION OF THE UNIVERSITY COMMITTEE FOR PREVENTION OF \\nSEXUAL HARASSMENT - RESPONSIBILITIES AND PROCEDURES \\n \\n \\nName & Designation \\n \\nRole Contact Details \\n \\n \\nDr. Anu Sukhdev \\nDean, Department of Student Affairs \\n \\nChairperson \\n \\n9731451035 \\nanu.sukhdev@presidencyuniversity.in \\nDr. R. Mahalakshmi \\nProfessor & Associate Dean - SOIS \\nMember 9842066415 \\nmahalakshmi@presidencyuniversity.in \\n \\nDr. Shakkeera L. \\nProfessor & Associate Dean - Academics \\n \\nMember \\n9444710836 \\nshakkeera.l@presidencyuniversity.in \\n \\nDr. Saira Banu \\nProfessor \\n \\nMember \\n9884127780 \\nsairabanuatham@presidencyuniversity.In \\nDr. Pallavi R. \\nProfessor \\n \\nMember \\n9535240465 \\npallavi.r@presidencyuniversity.in \\n \\nDr. Komalavalli Chakravarthy \\nProfessor \\n \\nMember \\n9811820606 \\nkomalavalli @presidencyuniversity.in \\n \\nDr. Anouja Mohanty \\nAssociate Professor \\n \\nMember \\n9320038238 \\nanouja.mohanty@presidencyuniversity.in \\n \\nMr. Sofiul Ahmed \\nAssistant Professor \\n \\nMember \\n78965 63767 \\nsofiul.ahmed@presidencyuniversity.in \\n \\nMs. Sai Shivani Mukund  \\nCounsellor \\n \\n \\nMember \\n8217546605 \\nshivani.mukund@presidencyuniversity.in \\nMs. Bhavana Chandran \\nAssistant Professor \\nMember 9900112231 \\nbhavana.chandran@presidencyuniversity.in \\n \\nDr. Sapna Mohan  \\nAssociate Dean & Head, School of \\nLaw, Christ University \\nExternal \\nMember \\n \\n \\n9916491576 \\nsapnamurali@gmail.com'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 64, 'page_label': '65'}, page_content='65  \\n \\n \\nProcedures: \\nBy email: Any complaint of sexual harassment must be sent by email only to the \\nICC –  on puicc@presidencyUniversity.in for the purpose of confidentiality. \\nDirect contact: Complaints in confidentiality: \\nDr. Anu Sukhdev, Professor & Dean- Department of Student Affairs - Chairperson  \\nMs. Bhavana Chandran –Assistant Professor, School of Law, Member Secretary'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 65, 'page_label': '66'}, page_content='66  \\n \\n               ANNEXURE – 3 \\n              STUDENT GRIEVANCE REDRESSAL COMMITTEE \\n \\nName & Designation Role \\nMr. Syed Khaja Daanish Hydri \\n(20211MEC0026) \\nStudent - SOE \\nChairperson \\nMs. Niharika S. Hubli \\n(202031BDS0052) \\nStudent - SOD \\nMember \\nMr. M.V. Dev Anand \\n(20232MBA0159) \\nStudent - SOM \\nMember \\nMs. Varsha Reddy \\n(20211CSE0857) \\nStudent - SOCSE \\nMember \\nMs. Prakruthi Raj \\n(20221BCH0072) \\nStudent - SOC \\nMember \\nMaj. Gen. Gurdeep Singh Narang \\nDirector - Student Discipline, Sports and NCC \\n \\nMember \\nDr. Anu Sukhdev \\nProfessor and Dean, Student Affairs \\nMember \\n \\nPROCEDURE FOR REDRESSAL OF GRIEVANCE \\n• The University shall furnish, prominently, on its website and in its prospectus, all \\nrelevant information in respect of the Student Grievance Redressal Committee(s) \\ncoming in its purview, and the Ombudsperson for the purpose of appeals. \\n \\n• In case of academic grievance, an aggrieved student shall first submit his/her \\ncomplaint in writing to his/her mentor who shall  resolve the grievance within two \\ndays. In case the mentor is unable to resolve the grievance, he shall forward it to the \\nChairperson of the School/Departmental Level Grievance Committee.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 66, 'page_label': '67'}, page_content='67  \\n \\n \\n• The chairperson of the School/Departmental Committee shall convene a \\ncommittee meeting within 2 days of receiving the complaint from the faculty \\nmentor or from the aggrieved student in case he/she applies directly to the \\ncommittee.\\n \\n \\n• The chairperson shall attempt to resolve the grievance within a week of the \\nreceipt of the complaint and the action taken shall be reported to the mentor. \\n \\n• If the grievance is not resolved/ satisfied with the solution of the \\nschool/department level committee, he/she shall appeal to the University \\nLevel Student Grievance Redressal Committee giving the reasons for his/her \\ndissatisfaction with the decision, within a week of receipt of the decision of the \\nschool/department level committee. \\n \\n• The Chairperson of the University Level Grievance Redressal Committee shall \\nconvene a meeting of the committee within 2 days of receiving the complaint. The \\nCommittee shall verify the facts and shall either endorse the decision of the school \\nlevel committee or shall issue an appropriate an order within a week of receipt \\nof the grievance. \\n \\n• If the grievant is not satisfied with the decision of the redressal offered by the \\nUniversity Level Student Grievance Redressal Committee, he/she can submit an \\nappeal to the to the Ombudsperson, within a period of 15 days from the date of \\nreceipt of such decision. \\n \\n• In case of non-academic /administration grievances, an aggrieved student can \\nsend the grievance through mail to studentgrievance@presidencyuniveristy.in \\nand can raise the grievance in the open forum during monthly student welfare \\ncommittee meetings. The University grievance committee will forward the \\ngrievance to the concerned stake holders and help the student in resolving the \\ngrievance within one week’s time. \\n \\n• At all levels a fair hearing shall be given to all parties. \\n \\n• The law of natural justice shall be observed  and a fair hearing to the grievant \\nshall be given at all levels. The relevant provisions of the Act/Regulations shall \\nbe kept in mind while passing an order on  the grievance at any level, and no \\norder shall be passed in contradiction of the same.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 67, 'page_label': '68'}, page_content='68  \\n \\n \\nTYPES OF GREIVANCES \\nAcademic Related \\n• Admissions \\n• Examination \\n• Assessments \\n• Evaluation \\n• Library Facilities \\n• Issuance of Certificates \\n• Add-on courses \\n• Research Related issues, etc. \\n \\nExtension and Extra-Curricular \\n• Alumni Registration \\n• Award of non-academic credits \\n• Physical Education, Cultural Activities, Sports, etc. \\n \\nAmenities & Maintenances \\n• Wi-Fi/Internet Connectivity \\n• Utility stores \\n• Computer facilities \\n• Drinking Water \\n• Sanitation & Hygiene \\n• Maintenance \\n• Medical Facilities \\n• Indoor  sports  facilities  \\n \\nPlacement & Internships \\n• On-campus or off-campus interviews \\n• Soft skills training \\n• Internships, etc. \\n \\nGeneral Administration \\n• Collection of fees \\n• ID cards \\n• Scholarships Disbursement \\n• HR related Issues'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 68, 'page_label': '69'}, page_content='69  \\n• Transportation, etc. \\n \\nHostel Facilities \\nComplaints regarding provisions/ food services \\n• Safety and security of one’s belongings \\n• Bullying/harassment of any form \\n \\nOther Related Issues \\n• Safety and Security \\n• Discipline \\n• Misbehaviour \\n• Emergency Services etc. \\n \\nAPPEALLATE AUTHORITY/OMBUDSMAN \\nFunctions of Ombudsperson \\n \\n• The Ombudsperson shall hear appeals from an aggrieved student, only after the \\nstudent has availed all other remedies provided under these Guidelines. \\n \\n• While issues of malpractices in the conduct of examination or in the process of \\nevaluation may be referred to the Ombudsperson, no appeal or application for \\nrevaluation or re- totalling of answer sheets from an examination, shall be \\nentertained by the Ombudsperson unless specific irregularity materially affecting \\nthe outcome or specific instance of discrimination is indicated. \\n \\n• The Ombudsperson may avail assistance of any person, as amicus curiae, for \\nhearing complaints of alleged discrimination. \\n \\n• The Ombudsperson shall make all efforts to resolve the grievances within a period \\nof 30days of receiving the appeal from the aggrieved student(s). \\n \\nPROCEDURE FOR REDRESSAL OF GRIEVANCES BY OMBUDSPERSON \\n \\n• Grievances not resolved by the Students’ Grievance Redressal Committee within the \\ntime period provided in these guidelines may be referred to the Ombudsperson by \\nthe University. \\n \\n• Institutions shall extend co-operation to the Ombudsperson or the Student \\nGrievance Redressal Committee(s), in early redressal of grievances. \\n \\n• The Ombudsperson shall, after giving reasonable opportunities of being heard to \\nthe parties concerned, on the conclusion of proceedings, pass such order, with \\nreasons thereof, as may be deemed fit to redress the grievance and provide such relief \\nas may be appropriate to the aggrieved student'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 69, 'page_label': '70'}, page_content='70  \\n \\n \\n \\n• The institution, as well as the aggrieved student, shall be provided with copies of \\nthe order under the signature of the Ombudsperson. \\n \\n• The institution shall comply with the recommendations of the Ombudsperson. \\n \\n• The Ombudsperson may recommend appropriate action against the \\ncomplainant, where a complaint is found to be false or frivolous.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 70, 'page_label': '71'}, page_content='71  \\n \\nANNEXURE – 4 \\n \\nPRO FORMA \\n \\nJOINT AFFIDAVIT BY STUDENT AND PARENT/LEGAL GUARDIAN \\n(To be undertaken jointly by the Student and  Parent(s)/Legal Guardian of every student \\nadmitted to Presidency University on a Rs. 50/ - Stamp paper duly notarized and must be \\nsubmitted to the Registrar, Presidency University before DD/MM/YYYY) \\n \\n \\nI, Mr. /Ms. , son/ daughter/ ward of \\n<Name of Father / Mother / Legal Guardian, if both parents are not alive) \\n  , and enrolled as a student at  \\nPresidency University, Bengaluru  with Identification Number \\n \\n; herein after referred to as STUDENT; AND, \\n \\nI, Mr./Ms. <Name of Father/Mother/Legal \\nGuardian, if both parents are not alive)>, Father/Mother/Legal Guardian of Mr./Ms. \\n < Name of the Student>; hereinafter referred to as \\nPARENT; do hereby jointly affirm on this the  (Day), of (Month), \\n_ (Year), the following: \\n \\nPART A: \\nSTUDENT INFORMATION AND DOCUMENTS \\n \\n1. We, STUDENT and PARENT, hereby, declare that the information and mandatory \\ndocuments provided by me to the Presidency University  at the time of Admission are  \\naccurate and true to the best of my knowledge and belief, and based on records. We, \\nfurther acknow ledge that, the admission of the STUDENT may be cancelled, at any \\nstage, if the information provided by us are found to be incorrect and/or fabricated, \\nand/or eligibility conditions for admission to the Program of study are not \\nsubstantiated and proved by authentic documents. \\n \\n2. We, STUDENT and PARENT, hereby undertake, to inform the University  about any \\nchanges in information regarding the communication address, mobile numbers of the \\nSTUDENT and PARENT submitted by us to the University  at the time of Admission or \\nin any other University documents.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 71, 'page_label': '72'}, page_content='72  \\n \\n \\nPART B: \\n  \\nUNIVERSITY REGULATIONS AND STUDENT HANDBOOK: RULES, POLICIES AND CODE \\nOFCONDUCT FOR STUDENTS \\n \\n3. I, STUDENT, hereby declare that I have carefully read and fully understood the \\nAcademic Regulations, Program Regulations and Curriculum Policies and Student \\nHandbook: Rules, Policies and Code of Conduct for Students. I hereby promise to \\nabide by, and, adhere to all the University Regulations, Rules, Policies and Code of \\nConduct prescribed therein. \\n \\n4. I, STUDENT will adhere to all University  Notifications, Circulars and Rules issued \\nby the University from time to time. \\n \\n5. I, STUDENT, hereby  declare that, I  shall be solely responsible for any  kind of \\nviolation of the undertakings and declarations that I have given herewith, and shall be \\nliable for the penalties to the extent of expulsion from the University. \\n \\nPART C: \\n \\nUGC REGULATIONS ON CURBING THE MENACE OF RAGGING IN HIGHER \\nEDUCATIONALINSTITUTIONS, 2009 \\n \\n6. I, STUDENT, have accessed the copy of the UGC Regulations on Curbing the Menace \\nof Ragging in Higher Educational Institutions, 2009, posted on the website \\n(www.presidencyuniversity.in) of Presidency University, and have carefully read it and \\nfully understood the law prohibiting ragging and the directions of the Supreme Court \\nand the Central/State Government in this regard. \\n \\n7. I, STUDENT, hereby undertake that \\n(a.) I will not indulge in any behaviour or act that may come under the definition of \\nragging.  \\n \\n(b.) I will not participate in or support or propagate ragging in any form.  \\n \\n(c.) I will not hurt anyone physically or psychologically or cause any other harm.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 72, 'page_label': '73'}, page_content='73  \\n \\n \\n8. I, STUDENT, hereby agree  that if found guilty of any aspect of ragging, I may be \\npunished as per the provision of the UGC Regulations mentioned above and/or as per \\nthe law in force. \\n9. I, STUDENT, hereby affirm that I have not been expelled or debarred  from \\nadmission by any institution. \\n \\nUNDERTAKING BY PARENT/ GUARDIAN \\n10. I,  _Father/Mother/Guardian of \\n , have carefully read and fully understood the law \\nprohibiting ragging and the directions of the Supreme Court and the Central/ State \\nGovernment in this regard as well as the UGC Regulations on  Curbing the Menace of \\nRagging in Higher Educational Institutions, 2009. \\n11. I assure you that my son/ daughter/ ward will not indulge in any act of \\nragging. \\n12. I hereby agree that if he/she is found guilty of any aspect of ragging, he/she \\nmay be punished as per the provisions of the UGC Regulations mentioned above and/or \\nas per the law in force. \\n \\n \\nDate: _/ /  \\n \\nSignature: Address: \\nName: \\n \\n \\nPART D: \\n \\nPREVENTION OF SEXUAL HARASSMENT \\n13. I, STUDENT have carefully read and fully understood the Policy on \\nPrevention of Sexual Harassment (Section 24.0 of Student Handbook: Rules, \\nPolicies and Code of Conduct for Students) \\n \\n14. I, STUDENT hereby undertake that I will not indulge in any behaviour or \\nact that may come under the definition of Sexual Harassment. \\n15. I, STUDENT hereby agree that if found guilty of any aspect of Sexual \\nHarassment, I may be punished as per the provision of the Policy mentioned \\nabove and/or as per the law in force.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 73, 'page_label': '74'}, page_content='74  \\n \\nPART E: \\nPERMANENT FORM OF PERMISSION AND INDEMNITY \\n16. I, STUDENT, hereby declare that my participation in all the University  \\nactivities such as travel on industrial internship, tours and participation in \\nsimilar curricular and extra- curricular programs which may involve \\nactivities, industrial tours  and other expeditions/tournaments organized by \\nthe University is fully on my own will and in full agreement with the \\nPermanent Form of Permission and Indemnity. \\n \\n17. I, PARENT, hereby give my consent to my son/daughter/ward as  named \\nabove, for participating in the co- curricular and extra-curricular activities \\norganized by the University and for travelling on University Industrial Tours, \\nTraining, Internship and Placement related travel, excursions, expeditions, \\ntournaments and other outstation tours organized/approved by the \\nUniversity. \\n \\n18. I, PARENT, hereby: \\n(a.) agree to pay the University charges specified for the participation in \\nsuch activities/tours and/or as determined and demanded by the \\nUniversity; \\n \\n(b.) agree to reimburse the cost of any equipment issued to my \\nson/daughter/ward on such tours/expeditions, if lost or damaged, as \\nmay be determined by the University; \\n \\n \\n(c.) indemnify Presidency University, Bengaluru and its Authorities and \\nOfficers, against any accident to life or limb that may occur to my \\nson/daughter/ward on such tours/expeditions and to reimburse the \\ncost of any medical expense arising out of such  accident and/or my \\nson/daughter/ward’s sickness during such expeditions and tours; \\nand, \\n \\n(d.) Un dertake to absolve Presidency University , Bengaluru, its Authorities \\nand Officers, from all liabilities in case of any accident/mishap occurring to \\nmy son/daughter/ward in any such expeditions and tours.'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 74, 'page_label': '75'}, page_content='75  \\n \\n \\nName of Father/Mother/Legal Guardian Name of Student: \\nID Number: \\nName and Signature of Witness 1 Name and Signature of Witness 2 \\nSignature of PARENT \\n(Father/Mother/Legal Guardian) \\nSignature of STUDENT \\n \\n \\nPlace:  Date:   \\n  \\n<NOTARIZED>'),\n",
       " Document(metadata={'producer': '4-Heights™ PDF Library 3.4.0.6904 (http://www.pdf-tools.com)', 'creator': 'Acrobat PDFMaker 24 for Word', 'creationdate': '2025-02-10T11:40:14+05:30', 'comments': '', 'company': '', 'created': 'D:20250204', 'icv': '6ABCECCA53AF476D97C4B607BD7BB0EF_12', 'ksoproductbuildver': '1033-12.2.0.19805', 'lastsaved': 'D:20250205', 'sourcemodified': 'D:20250204111303', 'author': 'K R Rajagopalan', 'moddate': '2025-02-10T08:40:12+00:00', 'source': 'data\\\\Student-Book.pdf', 'total_pages': 76, 'page': 75, 'page_label': '76'}, page_content='www.presidencyuniversity.in\\nIttagalpura, Rajanukunte, Yelahanka, Bengaluru 560 119')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f41103e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7721315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in docs:\n",
    "        src = doc.metadata.get(\"source\")\n",
    "        minimal_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,\n",
    "                metadata={\"source\": src}\n",
    "            )\n",
    "        )\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aaea14bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_docs = filter_to_minimal_docs(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec698358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              1 \\n \\n  \\n \\nAcademic Regulations'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              2 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nRegulation No.: PU/AC-26/6/07_2025 \\n \\nResolution No. 26.6 of the 26th Meeting of the Academic Council held on \\n25/07/2025 and ratified by the Board of Management in its Meeting held on \\n28/07/2025 \\n \\n \\n              \\n \\n \\nJuly 2025 \\n \\n \\n \\n \\n \\n \\n \\n \\nAcademic Regulations'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              3 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n[Left Blank intentionally]'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              4 \\n \\nContents \\nPRELIMINARY ........................................................................................................................................ 5 \\n1.0    INTRODUCTION ....................................................................................................................... 6 \\n2.0    ACADEMIC CALENDAR .......................................................................................................... 7 \\n3.0    REGISTRATION ........................................................................................................................ 7 \\n4.0    MEDIUM OF INSTRUCTION AND EVALUATION .......................................................... 11 \\n5.0    COURSE CREDIT STRUCTURE .......................................................................................... 11 \\n6.0    PROGRAM REGULATIONS AND CURRICULUM (PRC) ............................................... 12 \\n7.0    ATTENDANCE REQUIREMENTS ........................................................................................ 13 \\n8.0    TEACHING, EVALUATION AND GRADING SYSTEM .................................................. 14 \\n9.0    ACADEMIC PERFORMANCE INDICES: SGPA AND CGPA ........................................ 19 \\n10.0  DISPLAY OF PERFORMANCE IN CONTINUOUS ASSESSMENTS ........................... 20 \\n11.0  DETAILED SCHEDULE OF EXAMINATIONS .................................................................. 21 \\n12.0  APPEAL FOR REVIEW OF GRADES .................................................................................. 21 \\n13.0  MAKE-UP EXAMINATIONS .................................................................................................. 22 \\n14.0  ACADEMIC PROMOTION ..................................................................................................... 23 \\n15.0  SUMMER TERM ....................................................................................................................... 24 \\n16.0  WITHDRAWAL FROM THE PROGRAM ............................................................................. 26 \\n17.0  TRANSFER OF CREDITS ...................................................................................................... 26 \\n18.0  MAXIMUM DURATION FOR THE COMPLETION OF A PROGRAM ........................... 28 \\n19.0  REQUIREMENTS FOR THE AWARD OF DEGREE ......................................................... 29 \\n20.0   PROVISIONAL DEGREE CERTIFICATE ........................................................................... 30 \\n21.0   CONVOCATION ....................................................................................................................... 30 \\n22.0   ISSUE OF DEGREE CERTIFICATE BEFORE THE CONVOCATION ......................... 30 \\n23.0  POWER TO REVISE, MODIFY AND AMEND .................................................................. 31 \\nANNEXURE A ....................................................................................................................................... 32 \\nANNEXURE B ....................................................................................................................................... 34 \\nANNEXURE C ....................................................................................................................................... 35 \\nANNEXURE D ....................................................................................................................................... 36'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              5 \\nAcademic Regulations \\nIn exercise of the powers conferred by and in discharge of duties assigned under the relevant \\nprovision(s) of the Act and Statutes of the Presidency University, the Academic Council hereby \\nmakes the following Regulations, namely.  \\nPRELIMINARY  \\nShort Title and Commencement   \\nThese Regulations shall be called the Academic Regulations. They shall come into force with \\nimmediate effect.  \\nDefinitions  \\nIn these Regulations, unless the context otherwise requires:  \\na) “Academic Calendar” means the schedule of academic and miscellaneous events as \\napproved by the Vice Chancellor;  \\nb) “Academic Council” means the Academic Council of the University;  \\nc) “Academic Regulations” means the Academic Regulations, of the University;  \\nd) “Academic Term” means a Semester or Summer Term  \\ne) “Act” means the Presidency University Act. 2013;  \\nf) “BOG” means the Board of Governors of the University; \\ng) \"BOM” means the Board of Management of the University; \\nh) “BOE” means the Board of Examinations of the University;  \\ni) “BOS” means the Board of Studies of a particular Department/Program of Study of the \\nUniversity;  \\nj) “Basket” means a group of  Courses bundled together based on the nature/type of the \\nCourse.  \\nk) “COE” means the Controller of Examinations of the University;  \\nl) “Clause” means the duly numbered Clause, with Sub-Clauses included, if any, of these \\nRegulations;  \\nm) “Course” means a specific subject usually identified by its Course-code and Course-title, \\nwith specified credits and syllabus/course -description, a set of references, taught by \\nsome teacher(s)/course -instructor(s) to a specific class (group of students) during a \\nspecific Academic Term;  \\nn) “Course In Charge” means the teacher/faculty member responsible for developing and \\norganising the delivery of the Course; \\no) “Course Instructor” means the teacher/faculty member responsible for teaching and \\nevaluation of a Course;'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              6 \\np) “Curriculum Structure” means the Curriculum governing a specific Degree Program \\noffered by the University, and, includes the set of Baskets of Courses along with \\nminimum credit requirements to be earned under each basket for a degree/degree with \\nspecialization/minor/honours in addition to the relevant details of the  Courses an d \\nCourse catalogues (which describes the Course content and other important information \\nabout the Course). Any specific requirements for a particular program may be brought \\ninto the Curriculum structure of the specific program and relevant approvals should  be \\ntaken from the BOS and Academic Council at that time.  \\nq) “DAC” means the Departmental Academic Committee of a concerned \\nDepartment/Program of Study of the University;  \\nr) “Dean” means the Dean/Director of the concerned School;  \\ns) “Degree Program” includes all Degree Programs;  \\nt) “Department” means the Department offering the degree Program(s)/Course(s)/School \\noffering the concerned Degree Programs/other Administrative Offices;  \\nu) “HOD” means the Head of the Department;  \\nv) “MOU” means the Memorandum of Understanding;  \\nw) “Parent Department” means the department that offers the Degree Program that a \\nstudent undergoes;  \\nx) “School” means a constituent institution of the University established for monitoring, \\nsupervising and guiding, teaching, trai ning and research activities in broadly related \\nfields of studies;  \\ny) “Section” means the duly numbered Section, with Clauses included in that Section, of \\nthese Regulations;  \\nz) “Statutes” means the Statutes of Presidency University;  \\naa) “Sub-Clause” means the duly numbered Sub-Clause of these Regulations;  \\nbb) \"Summer Term” means an additional Academic Term conducted during the summer \\nbreak;  \\ncc) “University” means Presidency University, Bengaluru; and  \\ndd) “Vice Chancellor” means the Vice Chancellor of the University.  \\n1.0 INTRODUCTION  \\n1.1 The Academic Regulations  are applicable to all existing Degree Programs of the \\nUniversity. The Academic Regulations, and any amendments made therein, shall also \\nbe applicable to new Degree , Diploma and Certificate Programs that the University \\nmay offer in the future.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content=\"Regulation No.: PU/AC-26/6/07_2025                                                                              7 \\n \\n1.2 These Regulations are in compliance with the University Grants Commission \\n(Minimum Standards of Instruction for the Grant of Undergraduate Degree and \\nPostgraduate Degree) Regulations, 2025. The specific criteria and mandatory \\nrequirements prescribed by this UGC Regulations 2025, shall be included in the \\nProgram Regulations and Curriculum (PRC) of the respective program.  \\n1.3 Further amendments  and a dditional Regulations, if any, and specific \\ncriteria/mandatory requirements prescribed by the concerned Regulatory Bodies for \\na particular Degree Program shall be included in the Program Regulations and \\nCurriculum (PRC) of the respective program.  \\n1.4 These Regulations may evolve and get amended or modified or changed through \\nappropriate approvals from the Academic Council, from time to time, and shall be \\nbinding on all concerned.  \\n1.5 The effect of periodic amendments or changes in the Academic Regulations , on the \\nstudents admitted in earlier years, shall be dealt with appropriately and carefully, to \\nensure that those students are not subjected to any unfair situation whatsoever, \\nalthough they are required to conform to these revised Academic Regulations, \\nwithout any undue favour or considerations.  \\n2.0 ACADEMIC CALENDAR  \\n2.1 The academic activities of the University are regulated by the Academic Calendar \\napproved by the Vice Chancellor and  released at the beginning of each Academic \\nYear. The Academic Calendar indicating all academic activities in chronological order, \\nshall be prepared by the Office of Dean - Academics and approved by the Vice \\nChancellor. After approval, the same shall be released by the Dean - Academics at \\nleast two weeks prior to the  commencement of the concerned academic year . It is \\nmandatory for both students and faculty to strictly adhere to the academic calendar \\nto ensure timely completion of  academic activities. Deviations , if any , under \\nunforeseen/unavoidable circumstances shall be allowed with the prior approval of the \\nVice Chancellor, and the same should be duly notified.  \\n2.2 An academic year at the University shall normally be divided into two semesters \\nconsisting of ninety (90) University working days each, known as the Odd Semester \\n(normally from August to December) and the Even Semester (normally from January \\nto May).  \\n2.3 During the summer break, i.e., (June and July), there may be an additional Academic \\nTerm known as the Summer Term. The duration of the Summer Term is around eight \\n(08) calendar weeks and shall include a minimum of thirty (30) instructional days.  \\n3.0 REGISTRATION  \\n3.1 The registration process is a fundamental aspect of the University's academic \\nframework, designed to provide a structured procedure for students to select and \\nenrol in Courses that align with program requirements and their academic goals.\"),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              8 \\n3.2 Registration for the relevant Academic Term  ensures timely progression in the \\nprogram by adhering to guidelines regarding Course prerequisites, necessary Courses \\nas per curriculum requirements, and the credits required for the timely completion of \\nthe minimum credit requirements for the award of the respective degree. \\n3.3 The registration at the beginning of each Semester during the prescribed period \\nannounced in the Academic Calendar and through notifications issued by the \\nUniversity to this effect, is mandatory for every student.  \\n3.4 Registration is the sole responsibility of the student. Without registration, any \\nacademic activity (Course  / Seminar / Practical / Project Work / Internship, etc.) \\nundergone by a student will not be counted towards the requirements of their Degree.  \\n3.5 The Chairperson of each Departmental Academic Committee (DAC) shall \\ncommunicate the list of approved/prescribed Courses available for registration in the \\nconcerned Academic Term to the Office of the Dean - Academics for notification. (The \\nconstitution and functions of the Departmental Academic Committee (DAC) are \\nplaced in ANNEXURE A.) \\n3.6 Upon joining the University, each student is assigned to a mentor who will counsel \\nand guide the student on matters related to academic s/registration process. Every \\nstudent after consulting her/his mentor is required to register for Courses of his/her \\nchoice from the list of proposed Courses within the time period specified for such \\nregistration as notified in the Academic Calendar or the University notification to this \\neffect.  \\n3.7 Normally, late registration is not permitted. However, considering medical exigencies, \\nspecifically hospitalization, trauma, including death of immediate family members \\n(Parents, Offspring, Siblings and Spouse) or contagious disease, a student may be \\npermitted for late registration with prior approval from the respective H oD. The \\nstudent must produce medical certificates, medical prescriptions, hospital discharge \\nreport, medical fitness report and all such releva nt documents duly attested by the \\nconcerned registered medical officer of the hospital where the concerned student was \\nhospitalized or medically treated. The student shall not be eligible for late registration \\nif she/he fails to produce authentic medical c ertificates and relevant documents in \\nsupport of the medical exigency.  \\n3.7.1 Further, in such specified cases of medical exigency (viz. hospitalization, \\ntrauma or contagious disease only), the maximum period permissible for late \\nregistration shall not exceed Eighteen (18) University working days counted \\nfrom the commencement of the semester (only Odd and Even semesters) as \\nannounced by the University. Under no circumstances shall such a student \\nbe permitted to register for the semester after the permissible period for late \\nregistration of Eighteen (18) University working days counted from the \\ncommencement of semester.  \\n3.7.2 Further, if a student has been selected/nominated by State/National/  \\nInternational Organizations/Boards to represent th e State and/or India in \\nState/National/International Competitions/Events,  as recommended by the'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              9 \\nDepartment and approved by the Vice Chancellor, the concerned student may \\nbe permitted for late registration. The student must produce duly attested \\ndocuments and/or certificates to be eligible for the provision of late \\nregistration. The number of days for which the concerned student will be \\ngiven permission for late registration shall be approved by the Vice Chancellor \\nbased on the recommendation of the Dean of the School concerned. Further, \\nno relaxation will be given on attendance requirements, except as permissible \\nunder Clause 7.4.  \\n3.8 In case of any other reason for late registration other than the specified medical \\nexigencies outlined in Clause 3.7 above, the maximum permissible period for late \\nregistration shall not exceed FIVE (05) University working days counted from the \\nspecified date of Registration announced by the University. The  student shall pay a \\nLate Fee for late registration, as specified by the University at the commencement of \\nthe semester. Further, no relaxation whatsoever will be given on attendance \\nrequirements for late registration. Under no circumstances will such a student be \\npermitted to register for the semester after the permissible period for late registration \\nof FIVE (05) University working days counted from the specified date of Registration.  \\n3.9 Students are not permitted to re -register for Courses which t hey have already \\npassed, except under the provisions and conditions  mentioned in Clauses/Sub-\\nClauses 7.6, 8.14, 8.15.3 and 14.4 to improve their performance. \\n3.10 A student shall be permitted to register only if all of the following conditions are \\nfulfilled:  \\n3.10.1 The student has paid all specified fees to the University as per the University \\nFee Policy and payment schedule; \\n3.10.2 The student has cleared all University, Hostel, Transport and Library dues (if \\nany); \\n3.10.3 The student fulfils the yearly promotion criteria as stipulated in Section 14.0; \\nand  \\n3.10.4 The student has not been debarred from registering on any specific ground \\nby the University.  \\n3.11 Course Pre-Requisites: To register for some Courses, students may be required to \\nhave prior exposure to  or passed some specified Courses. Such Course pre-\\nrequisites shall be specified in the concerned Program Regulations and Curriculum \\n(PRC) as approved by the DAC and the BOS. If a student has secured an NP (Not \\nPermitted) Grade (Clause 8.14) due to a shortage of attendance in the pre-requisite \\nCourse(s), the student will not be permitted to register for the concerned Course(s). \\n3.12 Failure to Register and Removal from the Rolls: A student who is eligible for \\nregistration but  fails to register for the Semester within the specified dates and \\nconditions prescribed in Clauses 3.1 to 3.8, shall be removed from the rolls for the \\nconcerned semester. Consequently, the student shall not be permitted to attend \\nclasses for the concerned semester.  The student is cautioned that this will'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              10 \\nresult in the loss of an Academic Year for the student . Such a student shall \\nbe required to discontinue the Program temporarily and shall rejoin the Program of \\nstudy by completing the Registration process in the applicable Semester of the \\nfollowing Academic Year, and shall adhere to the Academic Regulations and Program \\nRegulations and Curriculum applicable to the batch in which the student is rejoining \\nthe Program of study.  \\n3.13 Mandatory Pre -Registration ( for Elective/Specialization/Open Courses) for higher \\nsemesters: In order to facilitate proper planning of academic activities of a \\nsemester, it is essential for students to declare their intent to register for an \\nElective/Specialization/Open Course well in advance, before the actual start of the \\nconcerned Academic Term , through the process of Pre -Registration. All students \\n(other than the freshly admitted students) intending to register for the next higher \\nsemester are required to have completed the Mandatory Pre -Registration of \\nElective/Specialization/Open Course(s),  as applicable , as per the schedule/dates \\nannounced in the Academic Calendar and/or the official notifications issued  by the \\nUniversity to this effect. To facilitate this Pre -Registration process all teaching \\nDepartments/Schools shall announce the list of Courses to be offered for the next \\nhigher semester, at least four (04) University working weeks before the last day of \\nclasses in the current semester.  \\n3.14 The University reserves the right to withhold registration or to cancel the \\nregistration of any studen t who is not in compliance with the University’s \\nregulations, policies, and rules. \\n3.15 Registration for each semester must be completed in a sequential manner. Failure \\nto register for a semester will result in the loss of an academic year, as the missed \\nsemester must be completed (in the following Academic Year) before registering in \\nthe subsequent semester of the Program of study. \\n3.16 Audit a Course \\n3.16.1 Auditing a Course is a provision for a student who may opt to register for \\na Course to acquire knowledge/skills, without earning credits and grade \\npoints. \\n3.16.2 A student who desires to register to Audit a Course shall consult her/his \\nmentor and seek approval of the concerned Course Instructor. Registration \\nto Audit a Course shall only be permitted as per the criteria and guidelines \\nprescribed by the concerned Course Instructor and duly approved by the \\nconcerned Departmental Academic Committee (DAC). The student will not \\nearn credits for the Audited Course. \\n3.16.3 Auditing is not available during the Summer Term. \\n3.16.4 Audit is not permitted in Courses that involve laboratory/field/studio work, \\nor other types of practice-based instruction. \\n3.16.5 Audited Courses shall not count towards fulfilling degree requirements.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              11 \\n4.0 MEDIUM OF INSTRUCTION AND EVALUATION  \\nEnglish shall be the medium of instruction and evaluation , except for specific Courses as \\napproved by the Academic Council.  \\n5.0 COURSE CREDIT STRUCTURE  \\nThe credit structure is used to define various types of  Courses, ensuring the appropriate \\npedagogy and methods of assessment and evaluation. The flexibility required to \\naccomplish the  Course learning objectives and outcomes can be provided for, while \\nretaining a common framework for credit allocation. More importantly, it is necessary to \\nhave a transparent, credible and robust system for the planning, delivery and evaluation \\nof each Course within the diverse programs of study offered by the University.  \\n5.1 The Credit Structure for defining and categorizing Courses follows the L-T-P-C \\n(Lecture - Tutorial- Practical - Credit) framework. Credits are assigned based on the \\nfollowing norms:  \\nLecture: One (01) contact/classroom hour per week for 15 weeks is assigned One \\n(01) Credit.  \\nTutorial: One (01) contact/classroom hour per week for 15 weeks is assigned One \\n(01) Credit  \\nPractical: Two (02) hours per week of practical/laboratory/ studio/field work and \\nother similar practice or skill development components  for 15 weeks, are assigned \\nOne (01) Credit.  \\nFor example:  \\n\\uf0b7 A Course with L-T-P structure of 3–0–0 will be assigned 3 Credits. \\n\\uf0b7 A Course with L-T-P structure of 3–1–0 will be assigned 4 Credits. \\n\\uf0b7 A Course with L-T-P structure of 3–0–2 will be assigned 4 Credits.  \\n\\uf0b7 A Course with L-T-P structure of 0–0–4 will be assigned 2 Credits.  \\n\\uf0b7 A Course with L-T-P structure of 2–0–2 will be assigned 3 Credits.  \\n\\uf0b7 A Course with L-T-P structure of 1-0-4 will be assigned 3 Credits \\nIn effect, a 3-Credit Course with structure of 3-0-0 mandatorily requires 45 hours of \\nContact/Classroom hours . Similarly, a  3-Credit Course with structure 1 -0-4 \\nmandatorily requires 15 hours of Contact/Classroom hours and 60 hours of \\nPractice/Lab hours. \\n5.2 Practical/Skill based Courses like Capstone Project, Internship, Industry Immersion, \\nInternational Immersion, Project Work, Studio, Field Visits, Dissertation, Seminar, \\nand such similar Courses  including Portfolio, Interdisciplinary Projects and Social \\nImmersion Courses, where the pedagogy does not lend itself to a typical L-T-P-C \\nstructure as defined in Clause 5.1, are assigned the number of Credits based on the \\nquantum of work/effort required to fulfil the learning objectives and outcomes'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              12 \\nprescribed for the concerned Courses , referred to as Non -Teaching Credit Courses \\n(NTCC).  \\n5.3 A student earns credits by satisfactorily undergoing the Course evaluation. The \\ncredits associated with a Course are dependent upon the number of hours of \\ninstruction in that Course. \\n6.0 PROGRAM REGULATIONS AND CURRICULUM (PRC) \\nThe Program Regulations and Curriculum (PRC) is a set of Program specific regulations, as \\napplicable, and the Program Structure and Curriculum for the concerned Degree Program. All \\nAcademic Programs (except the Ph.D. Program) shall be governed by the respective Program \\nRegulations and Curriculum. The Program Regulations and Curriculum shall be recommended by \\nthe concerned Board of Studies for approval of the Academic Council . The program leading to \\nthe award of a Ph.D. degree  shall be governed by the Ph.D. Regulations , which shall be \\nrecommended by the Research and Innovation Council of the University for Approval of the \\nAcademic Council.   \\nThe Program Regulations and Curriculum for all Undergraduate and Postgraduate Programs shall \\ninclude details with respect to Eligibility for Admission, Program duration, mandatory minimum \\ncredit requirements for the award of the Degree, assessment and evaluation guidelines/criteria, \\nand any other regulations mandated by concerned Government Regulatory Bodies, where \\napplicable, for the specific Program of study. \\n6.1 Eligibility for Admission:  \\n6.1.1 The basic eligibility for the admission to all Programs of the University shall \\nbe as per the norms specified by the respecti ve statutory  bodies such as \\nUniversity Grants Commission (UGC), All India Council for Technical \\nEducation (AICTE), Bar Council of India (BCI), Karnataka State Higher \\nEducation Council (KSHEC) and other relevant statutory bodies.  \\n6.1.2 Lateral Entry, where applicable, i.e. admission to the second year of a \\nProgram, shall be as per the norms specified by the respective statutory  \\nbodies such as UGC, AICTE, BCI, KSHEC and other relevant statutory bodies.  \\n6.1.3 A student who seeks admission to a higher semester of a Program as a \\ntransfer from another University, must comply with the eligibility criteria \\nmentioned above in Sub-Clause 6.1.1. Further, an Equivalence Committee \\n(Refer Annexure B) shall examine the case for Transfer/Lateral Entry and \\nsubmit its report and recommendation for the approval of the Vice Chancellor \\nfor enrolment to the concerned program . The student may need to undergo \\nadditional Courses, as prescribed by the Equivalence Committee to qualify for \\nthe minimum credit requirements as prescribed by the concerned PRC for the \\naward of degree. \\n6.2 The PRC of respective Programs shall have Program Educational Objectives (PEOs), \\nProgramme Outcomes (POs), Program Specific Outcomes (PSOs), and Curriculum \\nStructure, List of Basket/Component -wise Courses along with other details such as,'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              13 \\nL-T-P-C structure, Pre-Requisites etc. The Course catalogues for all the Courses listed \\nin the Curriculum structure shall also be part of the PRC.  \\n6.3 Assessment and Evaluation scheme: The assessment and evaluation of students in \\nall the academic programs offered in the University (except the Ph.D. program) shall \\nhave the components of assessment and weightages as recommended by the \\nrespective BoS and as approved by the Academic Council  from time to time. The \\nrelative grading framework shall be used for evaluation (Refer Clause 8.7). \\nIn order to ensure the fair and equitable assessment of learning for all Non-Teaching \\nCredit Courses (NTCC) offered in the particular Program, the method of assessment \\nshall be prescribed in the PRC. \\n6.4 The m inimum number of student registrations required  for the  Courses (except \\nNTCC) shall be defined in the PRC f or offering the  Course in the specific Academic \\nTerm. \\n7.0 ATTENDANCE REQUIREMENTS  \\n7.1 In order to maintain high standards and academic excellence, all students must \\nattend every lecture, tutorial, field work, laboratory, studio, practical classes and all \\nother such curricular sessions as prescribed by the Program Curriculum. \\n7.2 To account for approved leave of absence (for instance, representing the University \\nin State/National/International Competitions/Events/Conferences, etc.) and/or other \\ncontingencies like medical emergencies,  the attendance requirement shall be a \\nminimum of 75% of the classes actually conducted in every Course, for which the \\nstudent has registered in the concerned Academic term. \\n7.3 Further, if a student suffers serious medical exigencies of hospitalization, trauma, \\nincluding death of immediate family members (Parents, Offspring, Siblings and \\nSpouse) or contagious disease only, the concerned student may be given additional \\nrelaxation in attendance requirement (in Course(s) where there is a shortage) by the \\nVice Chancellor on the recommendations of the Dean of the School concerned. \\nHowever, under no circumstances whatsoever, shall the minimum requirement of \\nattendance be less than 65% o f the classes actually conducted in every Course the \\nstudent has registered for in the Academic Term. The student shall not be eligible for \\nthis special provision if she/he fails to produce authentic medical certificates and \\nrelevant documents (for other c ases of exemption) in support of the medical \\nexigency.  \\n7.4 Provided further that if a student has been selected/nominated by State/National/  \\nInternational Organizations/Boards to represent the State and/or India in State/  \\nNational/International Events/Competi tions, for representing the university the \\nconcerned student may be given relaxation in attendance requirement s (in the \\nCourse(s) where there is a shortage) for the concerned period of absence by the Vice \\nChancellor on the recommendations of the Dean of the School concerned.  \\n7.5 Further, where attendance requirements are prescribed by Government Regulatory \\nBodies for specific Programs, the same shall also be mandatorily adhered to without'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              14 \\nexception. Such specific requirements, as applicable, shall be prescribed in the \\nProgram Regulations and Curriculum of the concerned Program of study. \\n7.6 Shortage of Attendance:  \\nA student with shortage of attendance (i.e., less than 75% of the classes actually \\nconducted in every Course in the concerned Academic Term as prescribed by Clause \\n7.2, and other conditions as applicable und er Clauses 7.3 to 7.5), shall not be \\npermitted to appear in the End Term Examinations of the Course(s) in which \\nthe attendance shortfall exists , irrespective of the student’s academic \\nperformance in the components of Continuous Assessments. The student shall be \\ndeclared as “NP” (Not Permitted) Grade (refer Clause 8.14), to indicate that the \\nstudent has not been permitted to appear for the End Term Examinations due to \\nshortage of attendance during the Academic Term in the concerned Course(s).  \\nFurther, a student who has shortage of attendance (received “NP” Grade) in a Course \\nin the concerned Semester, shall be eligible to re -register for the concerned Course \\nin the following Academic Term  (including Summer Term ), subject to all the \\nconditions stated in Clauses 15.4 and 15.5.  \\nThe student is cautioned that this may result in the loss of an Academic Year \\nfor the student . It is the sole responsibility of the student to ensure that she/he \\ncompletes the Course(s) in which the student has the NP Grade, and, earn the \\nminimum mandatory required credits as prescribed by the PRC of the concerned \\nprogram.  \\n8.0 TEACHING, EVALUATION AND GRADING SYSTEM  \\n8.1 Courses from the approved Program Regulations and Curriculum may be offered \\nduring any Academic Term. Each approved Course, whenever  offered in any given \\nAcademic Term, shall be conducted by the assigned Course Instructor.  \\n8.2 The Course Instructors, for all the Courses , which are  to be offered by the \\nSchool/Department during any Academic Term shall be assigned by the concerned \\nHoD/Dean of School.  (A brief of the functions and responsibilities of the Course \\nInstructor is placed in ANNEXURE C). \\n8.3 Course Plan: Course Plan is prepared for each Course offered (including Non-Teaching \\nCredit Courses (NTCC)) in a Program of study during an Academic Term. The Course \\nPlan is generally prepared by the Course In -Charge (Course IC) in consultation with \\nall Course Instructors (as applicable) of concerned Course. The Course Plan shall be \\napproved by the Departmental Academic Committee (DAC).    \\n8.3.1 The Course Plan shall clearly describe the following aspects: Course Name, \\nCourse Code, Credit Structure, Course Description, Contact Hours, Name of \\nCourse In-Charge and Course Instructor(s),  Course Outcomes, CO – PO & \\nPSO Mapping, Pre -requisites (if applicable) , Course Syllabus, Reference \\nMaterials, Schedule  of Lectures, Tutorials, Pr actical/Lab Sessions (as \\napplicable), with notes on pedagogy,  Schedule of Continuous Assessments \\nand guidelines regarding End Term Examinations (as applicable).'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              15 \\n8.3.2 The Course Plan of every Course offered in an Academic Term  of the \\nconcerned Program shall be made available to all students registered for the \\nconcerned Course. \\n8.4 The academic performance evaluation of a student in a Course shall be according to \\nthe University Letter Grading System based on the class performance distribution in \\nthe Course.  \\n8.5 Academic performance evaluation of every registered student in every Course \\nregistered by the student is carried out through various components of Assessments \\nspread across the Semester. The nature of components of Continuous Assessments \\nand the weightage given to each component of Continuous Assessments (refer Clause \\n8.8) shall be clearly defined in the Course Plan for every Course, and approved by \\nthe DAC.  \\n8.6 Format of the End-Term examination shall be specified in the Course Plan. \\n8.7 Grading is the process of rewarding the students for their overall performance in each \\nCourse. The University follows the system of Relative Grading with statistical \\napproach to classify the students based on the relative performance of the students \\nregistered in the concerned Course except in the following cases:  \\n• Non-Teaching Credit Courses (NTCC) \\n• Courses with a class strength less than 30  \\nAbsolute grading method may be adopted, where necessary with prior approval of \\nconcerned DAC. \\nGrading shall be done at the end of the Academic Term by considering the aggregate \\nperformance of the student in all components of Assessments prescribed for the \\nCourse. Letter Grades (Clause 8.10) shall be awarded to a student based on her/his \\noverall performance relative to the class performance distribution in the concerned \\nCourse. These Letter Grades  not only indicate a qualitative assessment of the \\nstudent’s performance but also carry a quantitative (numeric) equivalent called the \\nGrade Point.  \\n8.8 Assessment Components and Weightage \\nTable 8.8 Assessment Components and Weightage for different category \\nof Courses \\nNature of Course and Structure Evaluation \\nComponent Weightage \\nLecture-based Course \\nL component in the L-T-P Structure is \\npredominant (more than 1) \\n(Examples: 3-0-0; 3-0-2; 2-1-0; 2-0-2, 2-0-4 \\netc.) \\nContinuous \\nAssessments \\n50% to \\n60% \\nEnd Term \\nExamination \\n40% to \\n50% \\nLab/Practice-based Course Continuous \\nAssessments \\n75% to \\n100%'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              16 \\nP component in the L-T-P Structure is \\npredominant \\n(Examples: 0-0-4; 1-0-4; 1-0-2; etc.) \\nEnd Term \\nExamination 0 to 25% \\nSkill based Courses like Industry Internship, \\nCapstone project, Research Dissertation, \\nIntegrative Studio, Interdisciplinary Project, \\nSummer / Short Internship, Social Engagement \\n/ Field Projects, Portfolio, and such similar Non-\\nTeaching Credit Courses, where the pedagogy \\ndoes not lend itself to a typical L-T-P structure \\nGuidelines for the assessment \\ncomponents for the various types \\nof Courses, with recommended \\nweightages, shall be specified in \\nthe concerned Program \\nRegulations and Curriculum /  \\nCourse Plans, as applicable. \\nThe exact weightages of Evaluation Components shall be clearly specified in the \\nconcerned PRC and respective Course Plan. \\nNormally, for Practice/Skill based Courses, without a defined credit structure (L –T–\\nP) [NTCC], but with assigned Credits (as defined i n Clause 5.2 of the Academic \\nRegulations), the method of evaluation shall be based only on Continuous \\nAssessments. The various components of Continuous Assessments, the distribution \\nof weightage among such components, and the method of evaluation/assessment, \\nshall be as decided and indicated in the Course Plan/PRC. The same shall be approved \\nby the respective DAC.  \\n8.9 Minimum Performance Criteria:  \\n8.9.1 Theory only Course and Lab/Practice Embedded Theory Course  \\nA student shall satisfy the following minimum performance criteria to be \\neligible to earn the credits towards the concerned Course:  \\na. A student must obtain a minimum of 30% of the total marks/weightage \\nassigned to the End Term Examinations in the concerned Course.  \\nb. The student must obtain a minimum of 40% of the AGGREGATE of the \\nmarks/weightage of the components of Continuous Assessments, Mid \\nTerm Examinations and End Term Examinations in the concerned \\nCourse.  \\n8.9.2 Lab/Practice only Course and Project Based Courses  \\nThe student must obtain a minimum of 40% of the AGGREGATE of the \\nmarks/weightage of all assessment components in the concerned Course.  \\n8.9.3 A student who fails to meet the minimum performance criteria listed above \\nin a Course shall be declared as “Fail” and given “F” Grade in the concerned \\nCourse. For theory  Courses, the student shall have to re -appear in the \\n“Make-Up Examinations” as scheduled by the University in any subsequent \\nsemester, or, re-appear in the End Term Examinations of the same Course \\nwhen it is scheduled at the end of the following Semester or Summer Term, \\nif offered. The marks obtained in the Continuous Assessments (other than \\nthe End Term Examination) shall be carried forward and be included in'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              17 \\ncomputing the final grade, if the student se cures the minimum \\nrequirements (as per Clause 8.9.1, 8.9.2) in the “Make-Up Examinations” \\nof the concerned Course. Further, the student has an option to re -register \\nfor the  Course and clear the same in the summer term/ subsequent \\nsemester if he/she wishes to do so, provided the Course is offered. \\n8.10 Letter Grades & Grade Points: The University follows the system of Letter Grades \\nwith associated Grade Points on a scale of 10. The Letter Grades and associated \\nGrade Points along with a brief qualitative description are summarized in Table 8.10:  \\n \\nTable 8.10 Letter Grades with Grade Points and Brief Qualitative \\nDescription \\nLetter Grade Grade Point Qualitative Description \\nO 10 Outstanding \\nA+ 9 Excellent \\nA 8 Very Good \\nB+ 7 Good \\nB 6 Above Average \\nC 5 Average \\nD 4 Pass \\nF 0 Fail \\nNP 0 Not Permitted \\nS – Satisfactorily Completed \\nNC – Not Completed \\nU – Audited Satisfactorily \\nI – Incomplete \\n \\n8.11 Absolute Grading:  \\nThe Letter Grades with Marks Range for the Absolute Grading is as follows:  \\nTable 8.11 Letter Grades with Marks Range for Absolute \\nGrading \\nLetter Grade Marks range (Out of 100) \\nO >= 90 \\nA+ >= 80 but < 90 \\nA >= 70 but < 80 \\nB+ >= 60 but < 70 \\nB >= 55 but < 60 \\nC >= 50 but < 55 \\nD >= 40 but < 50 \\nF < 40'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              18 \\n8.12 Award of the “O” (Outstanding) Grade:  \\nThe “O” grade stands for outstanding achievement, relative to the registered \\nstudents in the Course, and utmost care shall be taken in awarding of this highest \\nletter grade.  \\n8.13 Declaration of the “F” (Fail) Grade:  \\nThe “F” grade denotes failure in a Course and has “0” (Zero) Grade Points. This may \\nbe due to the following reasons:  \\n8.13.1 Failure to meet the minimum performance criteria for a Course as listed in \\nClause 8.9  \\n8.13.2 Further, if a student is absent for the End Term Examination of a Course, \\nthe student shall be declared as “Fail” and given a “F” grade in the \\nconcerned Course.  \\n8.14 Declaration of the Placeholder Grades “NP” (Not Permitted):  \\n“NP” is a grade, with “0” (Zero) Grade Points, given in the concerned Course(s) to \\nindicate that a student was not eligible to appear for the End Term Examination of \\nthe concerned Course(s) due to shortage of attendance as elaborated in Section 7.0 \\nand he /she has to re -register in the concerned  Course(s) to earn the necessary \\ncredits.  \\n8.15 Additional Grades with No Grade Points: “S”  (Satisfactorily Completed), “NC” \\n(Not-Completed) and “U” (Audited Satisfactorily) Grades:  \\n8.15.1 “S” and “NC” grades are awarded for specific mandatory Courses as \\nprescribed in the concerned PRC.  \\n8.15.2 “S” grade denotes satisfactory performance and completion of a Course , as \\nspecified in the concerned PRC. The requirements for obtaining “S” grade in \\na particular Course shall be clearly stated in the Course Plan of the concerned \\nCourse.  \\n8.15.3 “NC” grade is given for Non -Completion of Course requirements in the \\nconcerned Course and the student will have to re-register for the Course \\nuntil he/she obtains the “S” grade in the Course concerned.  \\n8.15.4 “S” and “NC” grades have no associated Grade Points and hence are not \\nincluded in the SGPA/CGPA calculations (refer Section 9.0).  \\n8.15.5 “U” grade is awarded in a  Course that a student opts to register for Audit \\n(refer to Clause 3.16) and successfully completes . It is not mandatory for \\nthe student to go through the entire regular process of evaluation for the \\nconcerned Course. However, the student must satisfy the minimum  \\nattendance requirement for securing the “U” grade, failing which, that  \\nCourse will not be listed in the Grade Card given to the concerned student \\n(refer to Clause 8.17).'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              19 \\n8.16 Additional Placeholder Grade “I” with no Grade Points:  \\n“I” (“Incomplete”) Grade is a placeholder grade which denotes “incomplete” in any \\nCourse or Courses, due conditions mentioned below  in sub -clauses 8.16.1 and \\n8.16.2. \\n8.16.1 Absence at the End Term Examination solely due medical exigencies \\nspecifically hospitalization, trauma, including death of immediate family \\nmembers (Parents, Offspring, Siblings and Spouse) or contagious disease \\nonly, and gets replaced by an appropriate regular letter grade after the \\nstudent completes the performance evaluation for the  Course(s) concerned \\nin the “Make-Up Examinations” (refer to Section 13.0).  \\n8.16.2 Malpractice case (under investigation) reported against the student in the \\nEnd Term Examination of concerned Course. The placeholder grade “I” shall \\nbe replaced with a regular grade based on recom mendations of the Unfair \\nMeans and Malpractices Committee (UMMC) (as constituted and provisioned \\nby the Examination Regulations of the University) and the subsequent \\napproval and decision of the Chairperson, BOE.  \\n8.16.3 The Course(s) in which a student has received “I” grade shall not be included \\nin the SGPA/CGPA calculations. (Refer Section 9.0).  \\n8.17 Grade Card:  \\nGrade Card is a record of a student’s performance in the Courses for which the \\nstudent has registered for in a concerned Academic Term of the Program of study.  \\nThe Grade Card shall contain the following details pertaining to the student’s \\nacademic performance:  \\n8.17.1 The List of Courses (which includes Course Name, Course Code and \\nassociated Credits) registered by the student in the concerned Academic \\nTerm.  \\n8.17.2 The Grade obtained in each of the concerned Courses.  \\n8.17.3 The SGPA and CGPA obtained by the student.  \\n8.17.4 Total credits registered and completed  in the ongoing Program of study \\nincluding the concerned Academic Term.  \\n9.0 ACADEMIC PERFORMANCE INDICES: SGPA AND CGPA  \\n9.1 The overall academic performance of a student shall be measured by two indices: \\nSGPA which is the “ Semester Grade Point Average” and CGPA which is the \\n“Cumulative Grade Point Average”.  \\n9.2 The performance of a student in a Semester is indicated by a number, Semester \\nGrade Point Average . The SGPA is the weighted average of the grade points \\nsecured in all the concerned Courses registered by the student during that Semester. \\nSGPA for a particular Semester is computed as follows:'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              20 \\n  \\nwhere:  \\nn is the number of all Courses (with Letter Grade s and Grade Points, including the \\nLetter Grades F and NP, which have zero grade points) registered by the student \\nin the Semester concerned;  \\nCk is the Credits assigned to Course k and  \\nGk is the Grade Point received by the student for the Course k.  \\n9.3 The Cumulative Grade Point Average indicates overall academic performance of \\na student in all the Courses registered up to and including the latest completed \\nsemester. CGPA is computed as follows:  \\n  \\nwhere:  \\nn is the number of all the Courses (with Letter Grades and Grade Points, including \\nthe Letter Grades F  and NP, which have zero grade points) registered by the \\nstudent up to, and including the latest completed Academic Term;  \\nCi is the Credits assigned to Course i and Gi is the Grade Point received by the student \\nfor the Course i.  \\n9.4 The SGPA and CGPA are calculated to TWO decimal places.  \\n10.0  DISPLAY OF PERFORMANCE IN CONTINUOUS ASSESSMENTS  \\n10.1 The performance of all students in the components of Continuous Assessments for \\nall Courses registered in the concerned Academic Term, shall be communicated to \\nthe students and displayed in the concerned Department/School by the respective \\nHOD/Dean.  \\n10.2 The concerned HOD/Dean shall attest and submit to the COE, a consolidated marks \\nsheet of the continuous assessment marks, where applicable,  obtained by all \\nstudents of a Program of study, in all the respective Courses registered in the \\nconcerned Academic Term, before the commencement of the End Term Examination.  \\n10.3 Answer scripts of Mid Term Examination , where applicable,  of the Course shall be \\nshown to the students for discussion, verification and corrections (if any) on pre -\\nnotified date(s) in class. \\n10.3.1 Answer books shall be shown to the students by the Faculty/Course \\nInstructor of the Department as per the schedule announced by the \\nDepartment/ School;  \\n10.3.2 Students shall be entitled to check whether all answers have been \\nevaluated and marked, and that all the marks have been correctly totalled.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              21 \\n10.3.3 In case of Digital valuation, the portal shall be opened on specified date(s) \\nand information about the date shall be sent to students’ university email \\naddress.  \\n10.3.4 If the student finds any discrepancy, he/she shall bri ng the same into the \\nnotice of the Faculty/Course Instructor/ HOD concerned for corrections and \\nupdates \\n11.0  DETAILED SCHEDULE OF EXAMINATIONS  \\n11.1 The detailed schedule of the Mid Term and End Term Examinations , as per dates \\nindicated in the Academic Calendar, shall be prepared by the COE in consultation \\nwith the HODs/Deans of Schools and shall be announced with due approval of the \\nVice Chancellor, at least two (02) weeks before the commencement of the \\nExaminations.  \\n11.2 The regulations and guidelines pertaining to the conduct of various University \\nExaminations are prescribed in the Examination Regulations of the University.  \\n12.0  APPEAL FOR REVIEW OF GRADES \\n12.1 The University is committed to keep the entire process of  evaluation beyond \\nreproach. A mechanism for review of grades is incorporated in the evaluation system.  \\n12.2 In case of a grievance regarding the grade(s) awarded, a student shall submit an \\napplication along with the prescribed fee to the Office of the Controller of \\nExaminations for obtaining the photocopy of End Term Examination answer script(s) \\nof the Course (or Courses), within Five (05) University working days from the date \\nof the declaration of the results of the End Term Examination. No requests shall be \\nadmissible after five (05) University working days from the date of the declaration \\nof the results of the End Term Examination.  \\n12.3 A copy of the answer script(s) of the End Term Examination with marks obtained for \\neach question and evaluation scheme shall be shared to the concerned student within \\nthree (03) days from the last date of application for photocopy of answer script . If \\nthe student is not satisfied with the marks awarded, he/she shall approach Course \\nInstructor/faculty assigned by the HOD/ Dean to get the recommendation in the \\nprescribed format, and submit the application for review of grade with prescribed \\nfees, within three (03) days from receipt of photocopy of the answer script. \\n12.4 The COE shall forward the student’s request to  the concerned HoD / Dean to take \\nthe necessary steps to review the appeal. Copy of the answer script(s) with marks \\nobtained for each question and evaluation scheme shall be shared to the concerned \\nHoD / Dean, within two (2) days from the last date for app lication for review . The \\nconcerned HoD / Dean shall convene a panel consisting of the respective Course \\nInstructor / Course In-Charge and two more faculty members who are familiar with \\nthe Course concerned to review the appeal.  \\n12.5 The panel shall review the appeal and submit a report regarding the revision / \\nretention of the Grade to the CoE, within five (05) days from the date of receipt of'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              22 \\nanswer script from CoE . The CoE shall declare the result based on the approval of \\nthe Vice Chancellor.  \\n13.0  MAKE-UP EXAMINATIONS  \\n13.1 Make-Up Examination is a provision for a student to complete a Course (or Courses) \\nin which she/he received an “F” grade (refer Section 8.0), or, was given the place \\nholder grade “I” (refer to Section 8.0) to reappear for the End Term Examination \\ncomponent of a Course (or Courses), subject to the conditions mentioned below in \\nClauses 13.2 to 13.5. Under no other circumstances, Make-Up Examinations shall be \\navailable to the student. Make-Up Examination is conducted o nly for those Courses \\nregistered in the concerned Academic Term (latest completed Semester).  \\n13.2 A student who fails to appear in the End Term Examinations, in some or all Courses, \\ndue to medical exigencies, specifically hospitalization, trauma, including death of \\nimmediate family members (Parents, Offspring, Siblings and Spouse) or a contagious \\ndisease only, and, the said student informs the HOD/Dean concerned timely (i.e., on \\nor before the last date of the said End Term Examinations), may submit a request \\nto the concerned HOD/Dean for the provision of the Make -Up Examinations in the \\nCourse(s) for which he/she could not attend the scheduled End Term Examinations.  \\n13.2.1 Provided further, the student must submit, along with the registration form \\nfor the Make -Up Examinations, medical certificates, medical prescriptions, \\nhospital di scharge summary, medical fitness report and all such relevant \\ndocuments, duly attested by the concerned registered medical officer of the \\nhospital where the concerned student was hospitalized or medically treated.  \\n13.2.2 The HOD/Dean concerned shall submit a specific report to the Chairperson, \\nBoard of Examinations (BOE) in this regard, who shall convene a special \\nmeeting of the BOE to review the student’s application. The BOE may grant \\npermission based on the veracity of the case to permit the concerned student \\nto avail the provision of Make-Up Examinations. On approval of the BOE, the \\nstudent shall submit the application form for the Make -Up Examinations to \\nthe Examination Department of the University within the duly notified dates, \\nalong with the prescribed fee for the Make -Up Examinations fixed by the \\nUniversity from time to time.  \\n13.2.3 On the basis of the student’s performance in the Make-Up Examinations and \\nconsidering the marks obtained by the student in all other Continuo us \\nAssessments as prescribed by the concerned Program Regulations and \\nCurriculum, the final letter grade awarded will replace the placeholder grade \\n“I”.  \\n13.2.4 In case the BOE rejects the application of the student for Make -Up \\nExaminations, the student shall be declared “Failed” in the concerned \\nCourse(s) and the placeholder grade “I” shall be replaced with “F” (Fail) \\ngrade in the concerned Course(s). Further, the student shall have to \\ncomplete the Course(s) as per the provisions and conditions prescribed in \\nClause 13.3.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              23 \\n13.2.5 If the concerned student does not avail the Make -Up Examinations, or is \\nabsent for the Make-Up Examinations, the student shall be declared “Failed” \\nin the concerned Course(s) and the placeholder grade “I” shall be replaced \\nwith an “F” grade. Further, the student shall have to complete the Course(s) \\nas per the provisions and conditions prescribed in Clause 13.3.  \\n13.3 A student with “F” Grade in one or more Courses, declared under the conditions \\nstated in Section 8.0 and/or who secured “D” Grade in one or more Courses, may \\navail the benefit of the Make -Up Examinations to pass the failed Course(s) and/or \\nimprove her/his CGPA. The student shall submit the registration form for the Make -\\nUp Examinations to the Office of the Controller of Examinations of the University \\nwithin the duly notified date, along with the prescribed fee for the Make -Up \\nExaminations fixed by the University from time to time.  \\n13.3.1 Further, if the student fails in the Course(s) attempted in the Make -Up \\nExaminations, including the Course(s) where the student had earlier secured \\n“D” Grade, the student will be awarded “F” grade in the Course(s) and will \\nhave to re-appear for the Examination.  \\n13.3.2 Students appearing for Make -Up Examinations can improve only by two \\ngrade level. This means that an \"F\" grade can be improved to a \"C\" grade at \\nmost. \\n13.4 The provision of Make-Up Examinations shall not be available for practice/laboratory/ \\nskill-based Courses as described in Clause 5.2. If a student has secured an “F” Grade \\nin such a Course, the student shall complete the concerned Courses only by \\nrepeating the Courses in the Semester when they become available for registration. \\nFurther, the student is cautioned that she/he shall have to register for the concerned \\nCourse(s) only in the concerned Semester of the next Academic Year when the \\nconcerned Course(s) shall be offered, which may result in the loss of an Academ ic \\nYear for the student. It is the sole responsibility of the student to ensure that she/he \\ncompletes the Course(s) and/or earns the required credits as prescribed by the \\nconcerned Program Regulations and Curriculum.  \\n13.5 Make-Up Examinations may be scheduled at the end of each Semester. The COE \\nshall announce the schedule of the Make-Up Examinations at least two (02) calendar \\nweeks before the commencement of the Make-Up Examinations.  \\n14.0  ACADEMIC PROMOTION  \\nYearly promotion criteria of a student who is reg istered for a given Academic year to the \\nnext Year of the Program of study after the end of an Academic Year is as described below \\nin Clauses 14.1 and 14.2. The Academic Promotion is applicable only for the Undergraduate \\nPrograms. \\n14.1 A student is eligible to be promoted to the next academic year if he/ she has secured \\na CGPA of 4.00 or more at the end of the current academic year (after completion \\nof the Summer Term and/or Make-Up Examinations, as applicable).'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              24 \\n14.2 If the student has secured a CGPA of less than 4.00, they shall not be promoted to \\nthe next academic year. \\n14.3 The students who are not promoted to the next Academic year but have app ealed \\nfor review of grades  (Section 12 .0) may take provisional registration and be \\npermitted to attend classes till the review results are published. After the publication \\nof the review result, the promotion criteria stated above in Clauses 14.1 and 14.2 \\nshall be applicable. \\n14.4 A student, who is not promoted as per Clause 14.2, has the provision of improving \\nthe CGPA in the subsequent academic year by either appearing for Make-Up \\nexaminations or by re-registering in either Odd and / or Even semesters, or Summer \\nTerm of the next academic year , subject to the conditions stated in Sections 13.0 \\nand 15.0 respectively.  \\n14.5 Further, upon rejoining (Registration in the applicable Semester) , the student shall \\nadhere to the Academic Regulations and Program Regulations and Curriculum , \\napplicable to the batch in which the student is rejoining the Program of study.  \\n15.0  SUMMER TERM  \\n15.1 The Summer Term is an additional Academic Term that may be offered during the \\nsummer break, typically for about eight (08) weeks during June-July. The minimum \\nnumber of instruction days in the Summer Term shall be thirty (30) days.  \\n15.2 The Course(s) offered in the Summer Term are delivered in a shorter term of about \\n8 weeks (with a minimum of thirty instruction days). However, the total number of \\ncontact hours for these Courses are scheduled as per the Course Credit Structure. \\nThe Course Contents/Syllabus and the continuous assessments and evaluation \\npatterns for these Course(s) also remain the same as that prescribed by the \\nconcerned Course Plan.  \\n15.3 The Departments/Schools desirous of offering Courses shall announce the details of \\nthe Courses on offer for registration in the Summer Term on the dates scheduled in \\nthe Academic Calendar or dates announced through University notifications.  \\n15.4 Some Departments/Schools may offer a limited number of Courses in the Summer \\nTerm with the following special provisions, subject  to all the conditions stated in \\nClause 15.5:  \\n15.4.1 Refer Clause 7.6: A student may re -register for the concerned Course(s), \\nif offered, in which the student had received the placeholder grade “NP”, to \\ncomplete the concerned Course(s) and earn the concerned credits;  \\n15.4.2 Refer Clause 8.13: A student may re-register for the concerned Course(s), \\nif offered, in which the student had received the “F” grade (Fail) in the \\nearlier Semesters if he/she wishes to do so.  \\n15.5 A student may register for the Summer Term Course(s), subject to all the conditions \\nstated below:'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              25 \\n15.5.1 A student who wishes to register for the Summer Term must complete the \\nregistration process on or before the last date  for Registration as specified \\nin the Academic Calendar or the University Notification to this effect. No late \\nregistration shall be permitted.  \\n15.5.2 A student can register for a maximum of 12 Credits.  \\n15.5.3 Attendance requirements as prescribed in Section 7.0 shall be applicable to \\nall the students registering for Course(s) in the Summer Term.  \\n15.5.4 A student cannot request or demand for a specific Course to be offered.  \\n15.5.5 A student, who is registering for Summer Term Course(s), must submit a \\ncompleted Summer Term Registration Form, checked and verified by the \\nDean/HOD concerned, to the Office of the Controller of Examinations of the \\nUniversity. Further, where applicable, th e Summer Term Registration Form \\nwill contain the list of failed and/or lower graded Course(s) for which the \\nstudent is registering.  \\n15.5.6 The student shall remit the registration fee per Course, as prescribed by the \\nUniversity from time to time, within the date specified for payment.  \\n15.5.7 A Course that is offered in summer term may be withdrawn if the number of \\nRegistrations for the concerned Course(s) is less than TEN (10). Further, if \\nthe Course is withdrawn due to lack of the minimum number of Registrations \\nrequired (i.e., 10), the Registration Fee for the concerned Course shall be \\nrefunded to the students who had registered for the concerned Course. \\n15.5.8 Further, the student,  \\na) must have paid all the required fees and other charges including hostel \\ncharges, where applicable, for the Summer Term;  \\nb) must have cleared all University fees and Hostel dues of previous \\nSemester(s)/year(s); and,  \\nc) has not been debarred from registering on disciplinary or other grounds.  \\n15.5.9 A student can apply for the Summer Term in any of the Courses in which he/ \\nshe was declared “NP” grade in any semester preceding the Summer Term, \\nincluding the immediately preceding semester , provided that the Course is \\nbeing offered by the School. However, the student cannot demand for a \\nparticular Course which the School is not offering or for which the number of \\napplicants is below 10 as stated in Sub-Clause 15.5.7.  \\n15.5.10 A student who did not register for a regular semester (Odd or Even) shall \\nnot be permitted to register for any  Courses from that semester (for which \\nthe student did not register)  during the Summer Term. Registration in the \\nSummer Term is only applicable fo r Courses previously registered but not \\ncompleted (i.e. Course(s) in which grade given was \"NP\", “F”, or “NC”).'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              26 \\n16.0  WITHDRAWAL FROM THE PROGRAM  \\n16.1 Temporary Withdrawal:  \\nA student who has been admitted to a Degree Program of the University may be \\npermitted to withdraw temporarily, for a period of one Academic Year, on medical \\ngrounds provided:  \\n16.1.1 The student submits an application to the University, stating the reasons \\nfor withdrawal together with supporting documents and endorsement from \\nher/his parent or legal guardian;  \\n16.1.2 The University is satisfied that the student is likely to complete the \\nrequirements for the award of the Degree of the concerned Program within \\nthe specified maximum duration to complete the Program (refer Section \\n20.0).  \\n16.1.3 A student seeking temporary withdrawal shall not be entitled to a refund of \\nthe Annual Fee paid to the University for the concerned Academic Year.  \\n16.1.4 There are no outstanding dues with the De partment/School/Hostels/ \\nLibrary etc.  \\n16.1.5 Scholarship holders are bound by the appropriate rules applicable to them.  \\n16.1.6 Normally, a student will be permitted only one such temporary withdrawal \\nduring her/his tenure as a student.  \\n16.2 Rejoining the Program:  \\nA student who temporarily withdraws from the Program (Clause 16.1) and rejoins \\nthe Program in the following Academic Year, shall be governed by all the Regulations, \\nincluding the PRC, of the University and the University Fee Structure in force at the \\ntime of his/her rejoining the program.  \\n16.3 Permanent Withdrawal:  \\nThe rules pertaining to withdrawal of admission at the time of joining the University \\nare as stipulated by the Admission Rules and Fee Policy of the University.  \\nIn case of a student seeking withdrawal from the Program of study after completion \\nof one/more Academic Year(s), the rules and terms of withdrawal are as stipulated \\nin the Withdrawal from Program and Fee Refund Policy of the University.  \\nThe decision of the Vice Chancellor regarding all aspects of withdrawal of a student \\nfrom the Program of study shall be final and binding.  \\n17.0  TRANSFER OF CREDITS  \\nThe University allows students to acquire credits from other Indian or foreign institutions \\nand/or Massive Open Online Course (MOOC) platforms, subject to prior approval. These \\ncredits may be transferred and counted toward fulfilling the minimum credit requirements \\nfor the award of a degree. The process of transfer of credits is governed by the following \\nrules and guidelines:'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              27 \\n17.1 The transfer of credits shall be examined and recommended by the Equivalence \\nCommittee (Refer ANNEXURE B) and approved by the Dean - Academics. \\n17.2 Students may earn credits from other Indian or foreign Universities/Institutions with \\nwhich the University has an MOU, and that MOU shall have specific provisions, rules \\nand guidelines for transfer of credits. These transf erred credits shall be counted \\ntowards the minimum credit requirements for the award of the degree.  \\n17.3 Students may earn credits by registering for Online Courses offered by Study Web \\nof Active Learning by Young and Aspiring Minds (SWAYAM) and National Program on \\nTechnology Enhanced Learning (NPTEL), or other such recognized Bodies/ \\nUniversities/Institutions as approved by the concerned BOS and A cademic Council \\nfrom time to time. The concerned School/Parent Department shall publish/include \\nthe approved list of Courses and the rules and guidelines governing such transfer of \\ncredits of the concerned Program from time to time. The Rules and Guidelines for \\nthe transfer of credits specifically from the Online Courses conducted by SWAYAM / \\nNPTEL/ other approved MOOCs  are as stated in the following Sub-Clauses:  \\n17.3.1 A student may complete SWAYAM /NPTEL/other approved MOOC s as \\nmentioned in Clause 17.3 and transfer equivalent credits to partially or fully \\ncomplete the mandatory credit requirements of Discipline Elective Courses \\nand/or the mandatory credit requirements of Open Elective Courses  as \\nprescribed in the concerned Curriculum Structure. However, it is the sole \\nresponsibility of the  student to complete the mandatory credit \\nrequirements of the Discipline Elective Courses and the Open Elective \\nCourses as prescribed by the Curriculum Struc ture of the concerned \\nProgram.  \\n17.3.2 SWAYAM/NPTEL/ other approved MOOCs as mentioned in Clause 17.3 shall \\nbe approved by the concerned Board of Studies and placed (as Annexures) \\nin the concerned PRC.  \\n17.3.3 Parent Departments may release a list of SWAYAM /NPTEL/other approved \\nMOOCs for Pre -Registration as per schedule in the Academic Calendar or \\nthrough University Notification to this effect.  \\n17.3.4 Students may Pre-Register for the SWAYAM/NPTEL/other approved MOOCs \\nin the respective Departments and register for the same Courses as per the \\nschedule announced by respective Online Course Offering body/institute/ \\nuniversity.  \\n17.3.5 A student shall request for transfer of credits only from such approved  \\nCourses as mentioned in Sub-Clause 17.3.2 above.  \\n17.3.6 SWAYAM/NPTEL/other approved MOOC s Courses are considered for \\ntransfer of credits only if the concerned student has successfully completed \\nthe SWAYAM/NPTEL/other approved MOOC s and obtained a certificate of \\nsuccessful/satisfactory completion.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              28 \\n17.3.7 A student who has successfully completed the approved SWAYAM /NPTEL/ \\nother approved MOOCs and wants to avail the provision of transfer of \\nequivalent credits, must submit the original Certificate of Completion, or \\nsuch similar authorized documents to the HOD concerned, with a written \\nrequest for the transfer of the equivalent credits. On verification of the \\nCertificates/Documents and approval by the HOD concerned, the Course(s) \\nand equivalent Credits shall forwarded to the COE for processing of results \\nof the concerned Academic Term.  \\n17.3.8 The credit equivalence of the SWAYAM /NPTEL/other approved MOOCs are \\nbased on Course durations and/or as recommended by the Course offering \\nbody/institute/university. The Credit Equivalence mapped to SWAYAM / \\nNPTEL approved Courses based on Course durations for transfer of credits \\nis summarised in Table shown below. The Grade will be calculated from the \\nmarks received by the Absolute Grading Table 8.11.  \\n \\nTable 17.3.8 Durations and Credit Equivalence for Transfer of \\nCredits from SWAYAM-NPTEL/ other approved MOOC Courses \\nSl. \\nNo. Course Duration Credit Equivalence \\n1 4 Weeks 1 Credit \\n2 8 Weeks 2 Credits \\n3 12 Weeks 3 Credits \\n \\n17.3.9 The maximum permissible number of credits that a student may request \\nfor credit transfer from MOO Cs shall not exceed 20% of the mandatory \\nminimum credit requirements specified by the concerned Program \\nRegulations and Curriculum for the award of the concerned Degree. \\n17.3.10 The University shall not reimburse any fees/expense; a student may incur \\nfor the SWAYAM/NPTEL/other approved MOOCs.  \\n17.4 The maximum number of credits that can be transferred by a student shall be limited to \\nforty percent (40%) of the mandatory minimum credit requirements specified by the \\nconcerned Program Regulations and Curriculum for the award of  the concerned  \\nDegree. However, the grades obtained in the  Courses transferred from other \\nInstitutions/MOOCs, as mentioned in this Section (17.0), shall not be included in the \\ncalculation of the CGPA. \\n18.0 MAXIMUM DURATION FOR THE COMPLETION OF A PROGRAM  \\n18.1 A student who for whatever reason is not able to complete the Program within the \\nnormal period or the minimum duration  (number of years)  prescribed for the \\nProgram, may be allowed a period of two years beyond the normal period to \\ncomplete the mandatory minimum credits requirement as prescribed by the \\nconcerned Program Regulations and Curriculum. In general , the permissible'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              29 \\nmaximum duration (number of years) for completion of Program is ‘N’ + 2 years, \\nwhere ‘N’ stands for the normal or minimum duration  (number of years)  for \\ncompletion of the concerned Program as prescribed by the concerned Program \\nRegulations and Curriculum. \\n18.2 The time taken by the student to improve Grades/CGPA, and in case of temporary \\nwithdrawal/re-joining (Refer to Clause 16.1), shall be counted in the permissible \\nmaximum duration for completion of a Program. \\n18.3 In exceptional circumstances, such as temporary withdrawal for medical exigencies \\nwhere there is a prolonged hospitalization and/or treatment, as certified through \\nhospital/medical records, women students requiring extended maternity break  \\n(certified by registered medical practitioner) ,   and, outstanding sportspersons  \\nrepresenting the University/State/India  requiring extended time to participate in \\nNational/International sports events, a further extension of one  (01) year may be \\ngranted on the approval of the Academic Council.  \\n18.4 The enrolment of the student who fails to complete the mandatory requirements for \\nthe award of the concerned Degree (refer Section 19.0) in the prescribed maximum \\nduration (Sub-Clauses 18.1 and 18.2) , shall stand terminated and no Degree shall \\nbe awarded.  \\n19.0 REQUIREMENTS FOR THE AWARD OF DEGREE  \\n19.1 The award of the Degree shall be recommended by the Board of Examinations and \\napproved by the Academic Council and Board of Management of the University.  \\n19.2 A student shall be declared to be eligible for the award of the concerned Degree if \\nshe/he:  \\n19.2.1 Fulfilled the Minimum Credit Requirements and all other mandatory \\nrequirements as prescribed by the concerned Program Regulation s and \\nCurriculum (PRC) for the award of the concerned Degree;  \\n19.2.2 For Undergraduate Programs : Secured a minimum CGPA of 4.50 in the \\nconcerned Program at the end of the Semester/Academic Term in which \\nshe/he completes all the requirements for  the award of the Degree as \\nspecified in Sub-Clause 19.2.1;  \\n19.2.3 For Postgraduate Programs : Secured a minimum CGPA of 5.00 in the \\nconcerned Program at the end of the Semester/Academic Term in which \\nshe/he completes all the requirements for the award of t he Degree as \\nspecified in Sub-Clause 19.2.1;  \\n19.2.4 No dues to the University, Departments, Hostels, Library, and any other such \\nCenters/ Departments of the University; and  \\n19.2.5 No disciplinary action is pending against her/him.  \\n19.3 Award of Class:  \\nThe award of Class in a Degree shall be based on the CGPA in the concerned Program \\nat the end of the Semester/Academic Term in which the student completes all the'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              30 \\nrequirements for the award of the Degree. In case a student has earned more credits \\nthan the required minimum as prescribed by the concerned Curriculum Struct ures, \\nthe higher CGPA, as applicable, considering the Credits and Grades corresponding to \\nthe mandatory minimum credit requirements as prescribed by the concerned \\nCurriculum Structure, for the award of the concerned Degree shall be considered for \\nthe award of Class.  \\nClasses shall be awarded as per the following scale:  \\n19.3.1 First Class with Distinction: CGPA of 8.00 and above  \\n19.3.2 First Class: CGPA from 6.50 to 7.99  \\n19.3.3 Second Class (for Postgraduate Programs): CGPA of 5.00 to 6.49  \\n19.3.4 Second Class (for Undergraduate Programs): CGPA of 4.50 to 6.49  \\n20.0  PROVISIONAL DEGREE CERTIFICATE  \\nOn completion of the requirements for the award of the Degree as prescribed in Section \\n19.0, the student may apply for a Provisional Degree Certificate  in the prescribed \\napplication form, along with the prescribed Fee notified by the University from time to \\ntime, to the Controller of Examinations of the University.  \\nOn verification of the eligibility criteria prescribed in Clause 19.2, the Controller of \\nExaminations shall issue the Provisional Degree Certificate to the concerned student, to \\nthe effect that the concerned student has fulfilled all the requirements for the award of \\nthe Degree in the concerned Program, and that, the Degree shall be conferred on the \\nconcerned student at the next Convocation of the University.  \\n21.0  CONVOCATION  \\nThe Convocation of the University shall be held annually as per the Convocation \\nRegulations of the University. The University shall announce the date for the Convocation \\nand call for applications from eligible students to register for the Convocation. The duly \\ncompleted application form along with the prescribed Convocation Fee must be submitted \\nby the student to the University within the specified date announced by the University.  \\nDegrees shall be awarded in person at the Convocation for the students who have \\ngraduated during the preceding Academic Year. Degrees shall be awarded in absentia to \\nsuch students who are unable to attend the Convocation.  \\n22.0  ISSUE OF DEGREE CERTIFICATE BEFORE THE CONVOCATION  \\nIn exceptional circumstances where a student requires the Degree Certificate before the \\ndate of the Convocation, for purposes of higher education or employment where the \\nconcerned University/Organization where the concerned student has secured/seeking \\nadmission/employment requires that the concerned stude nt must produce the Degree \\nCertificate, the concerned student may submit an application to the University, along \\nwith the prescribed Fee and all the supporting documents.  \\nThe Vice Chancellor shall consider the merit of the application and submit her/his \\nrecommendation to the Chancellor for the issue of the Degree Certificate, or otherwise.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              31 \\nThe decision of the Chancellor shall be final and binding. On the approval of the \\nChancellor, the Degree Certificate shall be issued to the concerned student.  \\nThe minimum time taken to process and issue the Degree Certificate shall be two (02) \\ncalendar months from the date of receipt of the request for the issue of the Degree \\nCertificate.  \\n23.0 POWER TO REVISE, MODIFY AND AMEND  \\nNotwithstanding anything contained in the above Regulations:  \\n23.1 The Academic Council has the right to revise, amend or modify any of the above \\nRegulations from time to time, and shall be binding on all stakeholders concerned, \\nincluding the Students, Faculty, Staff, Departments, Schools and University \\nAuthorities.  \\n23.2 In case of a dispute, the decision of the Academic Council shall be final and binding.  \\n23.3 In case of difficulty in application of any of the Clauses of the Regulations specified \\nabove, the Chancellor shall have the powers to amend/modify/remove the difficulty \\nin the relevant Regulation.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              32 \\nANNEXURE A \\nDEPARTMENTAL ACADEMIC COMMITTEE (DAC) \\na) “Department” refers to the School/Department offering Degree Programs  \\nb) There shall be at least one DAC for every School/Department that is involved in teaching \\nDegree Programs.  \\nc) However, each program can also have a separate DAC.  The HoD/Dean is authorized to ta ke \\ndecisions to this effect.  \\nd) The Respective School Dean  shall notify the concerned DAC as per the following \\nconstitution:  \\nMembers Designation Remarks \\nChairperson \\nDean/Associate Dean/Assistant Dean of \\nconcerned School/Head of the Department/ \\nHOD In Charge of the Program \\nEx Officio \\nMembers (Five) \\nfrom within the \\nSchool/Department \\nThree (03) Faculty Members representation \\nfrom Senior Professors/Senior Faculty and  \\nTwo (02) Assistant Professors \\nAppointed by \\nChairman, DAC \\nMember (One) Senior Faculty member from another \\nSchool/Department of the University \\nNominated by \\nDean \\n(Academics) \\nMember Secretary Faculty member from the School/ \\nDepartment \\nAppointed by the \\nChairman, DAC \\nTenure of the DAC is for one academic year \\n \\ne) The Chairperson may co-opt and/or invite more members, if necessary.  \\nf) Functions:  \\ni. To monitor the conduct of the respective Programs of study of the Department/School.  \\nii. To ensure academic standard and excellence of the respective Programs offered by the \\nDepartment/School.  \\niii. To consolidate the Registration List of the students and communicate to Course \\nInstructor, the Academic Office and Examination Department of the University.  \\niv. To review and approve the Course Plan (with Session Plan) submitted by the Faculty/ \\nCourse Instructor/Instructor In-Charge for each Course and forward the collated Course \\nPlan of each Program to the Dean - Academics.  \\nv. To ensure that at least two Class Committee (Refer Annexure D) meetings are conducted \\nduring the Semester and act upon the Resolutions passed by Class Committee(s).  \\nvi. To arrange to obtain the Student Feedback for every Course, once during the middle of \\nthe Semester and one at the end of each Semester, and to submit the consolidated report \\nof such feedback to the Dean - Academics.  \\nvii. To conduct at least two DAC meetings each Semester and a copy of the Resolutions of \\nthe DAC Meeting shall be communicated to the Dean - Academics, and a record of the \\nsame to be maintained in the Department/School.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              33 \\nviii. To Plan the curriculum and syllabus changes based on various stakeholders (Faculty, \\nStudents, Alumni and Industry) feedback and suggestions. The complied suggestions \\nfrom DAC will be presented before the BOS for further discussions and follow up actions. \\nix. To implement the resolutions of the BOS for the upcoming batches and semesters.  \\nx. Any other responsibility or function assigned by the Dean (Academics).'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              34 \\nANNEXURE B \\nEQUIVALENCE COMMITTEE \\nEquivalence refers to the process of evaluating and recognizing academic credits earned by \\nstudents from other institutions. The purpose of equivalence is to facilitate academic mobility \\nwhile maintaining the integrity and quality of the degree programs. It ensures that the Courses, \\ncredits, and learning outcomes align with the academic standards and program requirements of \\nthe University. This process applies to both credit transfers from other recognized institutions \\nand the acceptance of students transferring into the University. \\nEquivalence Committee shall have the following constitution: \\n1. Chairperson – Dean/Director of the Concerned School \\n2. Members – Two Professor(s)/Associate Professor (s) from the Concerned Program \\n3. Convenor – Head of the Department \\nResponsibilities: \\n\\uf0b7 Equivalence Committee shall examine the case for Transfer/Lateral Entry admissions and \\nsubmit its report and recommendation for the approval of the Vice Chancellor for \\nenrolment to the concerned program. \\n\\uf0b7 Equivalence  \\n\\uf0b7 Committee shall examine the Credit Transfer from other Indian/Foreign Institutions and \\nsubmit its report and recommendation for the approval of the Dean – Academics.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              35 \\nANNEXURE C \\nCourse Instructor/Course In-Charge \\n \\nA Course Instructor for each Course on offer in a given Academic Term shall be assigned by \\nHoD/Dean/Director of School and approved by the Departmental Academic Committee. \\nIf a Course needs to be assigned to more than one class of students (due to a large number \\nregistered for the concerned Course) and if more than one Course Instructor needs to be \\nassigned to teach this Course, the HoD shall assign a Course In -Charge (who must be a \\nCourse Instructor for at least one class taking this Course) to coordinate with other Course \\nInstructors to facilitate the delivery of Course Plan in a consistent manner and also to ensure the \\nevaluation scheme and grading is conducted in a proper and consistent manner. \\nFunctions/Responsibilities (Highlights) \\nThe Course Instructor shall: \\na. follow all the Regulations related to teaching of a Course and evaluation of students; \\nb. be responsible for all the records (i.e., Course registration, assessment/answer \\nbooks, attendance, etc.) of the students registered for the Course; \\nc. shall conduct classes as prescribed in the Academic Calendar and as per the \\nteaching assignment time-table; \\nd. shall arrange to distribute a Course Plan and the evaluation plan together with the \\nCourse Outcomes, background materials to all the students within the first week of \\neach Semester; \\ne. prepare an evaluation plan showing details of how the student’s performance will \\nbe evaluated in the Course; \\nf. document the students’ performance and announce/declare such details as stipulated; \\ng. report to the HoD on a periodic (monthly) basis, the potential cases of poor \\nacademic performance (Slow Learners)  as well as those of low attendance, that \\nwould possibly result in a ‘F’ or ‘NP’ grade at the end of the Semester. \\nThe Course In-Charge shall co-ordinate the above functions/responsibilities with the other \\nassigned Course Instructors regularly as decided by their concerned HoD.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              36 \\n \\nANNEXURE D \\nCLASS COMMITTEE \\na) Every Class of the Degree Program (for example, 1st Year of a Program, Section A, etc., as \\napplicable) shall have a Class Committee, consisting of Faculty members and Students.  \\nb) The HOD/Program Head of the School/Department concerned shall notify the concerned Class \\nCommittee as per the following constitution:  \\nMembers Designation Remarks \\nChairperson Senior Faculty \\nMember of the Parent/ \\nTeaching Department, \\nassociated with the Class \\nMembers (Faculty) All Course Instructors of that \\nClass  \\nMembers \\n(Students: at least \\nSix) \\nStudents representing the Class \\nChosen by the students \\namongst themselves, but \\nonly those whose \\nMember Secretary Class Coordinator of the Class Appointed by the Dean of \\nthe School concerned \\nTenure of the Class Committee is for the Semester concerned. \\nAll members must attend the Class Committee Meeting. \\nc) Functions:  \\ni. The basic responsibility of the Class Committee is to review the progress of the \\nclasses/Courses, to discuss problems concerning the conduct of the classes and \\ncontinuous assessments as per the Course Plan and recommend remedial measures, \\nwhere necessary.  \\nii. Each Class Committee will communicate its recommendations to the Chairperson, DAC \\nof the Parent/Teaching Department/School.  \\niii. There shall be at least two Class Committee meetings every Semester, the first one \\nbefore midterm Examinations and the second one at least two weeks before the last \\ninstruction day of the semester  \\niv. However, additional Class Committee meetings may be convened as decided by the \\nChairperson, DAC.  \\nv. The Resolutions of each Class Committee meeting shall be recorded and submitted to the \\nHOD/Dean of the Parent Department/School, and, a copy shall be submitted to the Dean \\n(Academics).  \\nvi. Any appropriate responsibility or function assigned by the Chairman of the DAC.'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='PU\\nUU \\nINSTITUTIONAL  INFORMATION  \\n \\n \\n \\n \\n \\n \\n \\n  \\nEnhance your degree with \\nExchange and Study Abroad \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\nName of the Institution Presidency University (PU) \\nPostal Address \\nThe Office of International Affairs \\nPresidency University, Itgalpur Rajanakunte, \\nYelahanka, Bengaluru, Karnataka 560064 \\nWebpage www.presidencyuniversity.in  \\nTelephone Number +91 80 2309 3500 \\n \\nInternational Office Contact \\nDr Sivaperumal S \\nDirector of International Affairs \\ndirector-\\ninternational.relations@presidencyuniversity.in  \\nStudent Exchange Website Presidency_InternationalAffairs-Student_Exchange \\nFact sheet \\nInbound Mobility Students \\n2025-26'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='Bangalore is a cosmopolitan city in India, known for its thriving IT industry and \\ninnovation hub. It is often referred to as the Silicon Valley of India. Bangalore city is \\nhome to many multinational companies, startups, research institutes, NGOs, etc. \\nthat provide internships and placements to students. Bengaluru will soothe you with \\nits pleasant weather throughout the year.  \\nBangalore is home to several prestigious universities and colleges that offer \\nundergraduate and postgraduate courses in a wide range of fields, including arts, \\nscience, commerce, law, management, and engineering.  \\nBangalore has a vibrant campus life that provides students with opportunities for \\nlearning, networking, cultural exchange, and extracurricular activities. The city is \\nalso known for its rich cultural heritage and attractions such as garde ns, parks, \\ntemples, and museums.  \\nCompared to other metro cities in India, Bangalore has a low cost of living and a \\npleasant climate throughout the year. It is well -connected by road, rail, and air to \\nother parts of the country and the world.  \\nBangalore is listed as the top 10 fastest growing cities in the world, the economy of \\nthis city is an important part of the economy of India.'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='BENGALURU \\nBENGALUR  U, KARNA  TAKA,  INDIA  \\nSTUDE  NT MI GRATION  TREND  \\n46 . 55 % \\nSAME CITY \\n \\n6. 90% \\nSAME STATE \\n46 . 55 % \\nNATIONAL \\n \\nWHY  BENGALURU?  ( RANKED  ORDER)  \\n Good  We ath  \\n Sa fe t y \\n \\n  Soc  ial  Life  \\n \\n I n f r a s t r u c t u r e \\n Employability  \\n \\n  University Life \\n  Reputation  Public     \\n Transport \\n \\nNight Life \\nBest Student Cities, Bengaluru \\nwas ranked as India’s best \\nstudent city, while ranking 114 \\nglobally'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='Welcome Mid of August \\nSemester begins End of August \\nClasses end Mid of January \\nIncluding exams \\n \\nWelcome Mid of January \\nSemester begins Beginning of February \\nClasses end End of June \\nIncluding exams \\n \\nACADEMIC  CALENDAR  2025 -26 \\nSemester one* (Odd/Fall semester) Semester two* (Even/Spring semester) \\n \\n \\n* Confirmed dates will be indicated on the individual acceptance/visa letter. \\nSTUDY  ABROAD/EXCHANGE  APPLICATION  AND ADMISSION  \\nApplication documents (in English): \\n▪ Completed application form \\n▪ Academic transcripts of record (official, stamped and signed by home institution) \\n▪ Passport copy (valid for a minimum of six months beyond the date of intended \\ndeparture from India)  \\n▪ All non-native English speaking applicants must provide proof of English language \\nability or a letter from the home university certifying applicant proficiency \\n▪ Proof of international health insurance \\n \\nINSTRUCTION OF NOMINATION \\nStudents must be nominated by their home institution’s Advisor/Coordinator. Once \\napproved by the home institution, students’ nomination should be sent via email by \\nthe Advisor/Coordinator to the respective region in charge officers stated below \\nwith the following information. \\n• First Name \\n• Last Name \\n• Class Level \\n• Date of Birth \\n• Email ID \\n• Program of Study \\n \\n \\nAfter home institution nomination the prospective exchange students are requested to \\nsend the completed application form with required documents to:  \\nMs. Sai Prasanna \\noia4@presidencyuniversity.in \\n+91 97317 42211'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='Nomination deadlines Application deadlines* Semester \\n \\n20 March 2025 \\n \\n30 March 2025 \\nOne semester (odd/Fall \\nsemester) for August 2025 \\nentry \\nTwo semester (odd and even \\nsemester) for August 2025 \\nentry \\n20 September 2025 30 September 2025 One semester (even/Spring \\nsemester) for February 2026 \\nentry \\n \\n*We cannot guarantee consideration of applications submitted after the above \\ndeadlines, although we will try to consider every application where possible. \\nFEES  \\nAs an Incoming exchange student,  you will pay tuition fees to your  home institution \\nbased on their fee  requirements. However, exchange students shall pay for things \\nsuch as books and equipment, health insurance, local excursion , accommodation, \\nflight, and a student visa. \\n \\nACCOMMODATION  \\nAs soon as you have been accepted a course (s) offered from us, you can request \\nfor off -campus accommodation and Presidency University will facilitate incoming \\nstudents in finding accommodation  close to the campus , approximately 7 -10 kms. \\nStudents are advised to apply for accommodation as soon as possible after  \\naccepting an offer letter; so, you have accommodation arranged before your arrival \\nin Bangalore, India.  \\nNote: The university will provide a bus service for all incoming exchange students \\nfrom partner universities so that they can commute to and from campus. \\n \\nResidence Facilities: \\n▪ Twin sharing bedroom (Euro 300 approx. per month) \\n▪ Furnished with beds, wardrobes, study tables chairs, bookshelves \\n▪ Fan \\n▪ Common bathroom toilet \\n▪ Wi-Fi'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='AVAILABLE  PROGRAMMES  \\nInternational students are required to take a full-time study load from below schools: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\nComputer Science & Engineering \\n \\n▪ B.Tech. - Computer Science and Engineering \\n▪ B.Tech. - Computer Science and Engineering \\n(Artificial Intelligence & Machine Learning) \\n▪ B.Tech. - Computer Science and Engineering \\n(Data Science) \\n▪ B.Tech. - Computer Science and Engineering \\n(Cyber Security) \\n▪ B.Tech. - Computer Science and Engineering \\n(Block chain) \\n▪ B.Tech. - Computer Science and Engineering \\n(Internet of Things) \\n▪ B.Tech. - Computer Science and Technology \\n(Big Data) \\n▪ B.Tech. - Computer Science and Technology \\n(DevOps) \\n▪ B.Tech. - Computer Science and Technology \\n[Spl. in Artificial Intelligence & Machine \\nLearning] \\n▪ B.Tech. - Computer Engineering [Spl. in \\nArtificial Intelligence & Machine Learning] \\n▪ B.Tech. - Computer Science and Information \\nTechnology \\n▪ B.Tech. - Computer Science and Engineering \\n(Networks) \\n▪ B.Tech. - Information Science and Engineering \\n[Spl. in Artificial Intelligence & Robotics] \\n▪ B.Tech. - Information Science and Technology \\n[Spl. in Artificial Intelligence & Data Science] \\n▪ M.Tech. - Artificial Intelligence \\n▪ M.Tech. - Data Science \\nEngineering \\n \\n▪ B.Tech. - Civil Engineering \\n▪ B.Tech. - Electrical & Electronics Engineering \\n▪ B.Tech. - Electronics and Communication \\nEngineering \\n▪ B.Tech. - Mechanical Engineering \\n▪ B.Tech. - Mechanical Engineering [Spl in \\nMechatronics] \\n▪ B.Tech. - Petroleum Engineering \\n▪ B.Tech. – VLSI \\n▪ M.Tech. - Embedded Systems & VLSI \\n▪ M.Tech. - Building & Construction Technology \\n▪ M.Tech. - Product Design and Development \\nCommerce, Economics & Management \\n \\n▪ Bachelor of Business Administration (BBA) \\n▪ BBA (Digital Marketing) \\n▪ BBA (Business Analytics) \\n▪ BBA (Aviation Management) \\n▪ B. Com – (Professional) – (Spl. In Banking and \\nFinance) \\n▪ B.Com – (Professional) – (Spl. In Corporate \\nAccounting and Taxation) \\n▪ B.Com – (Hons.) – (Spl. In Business Analytics) \\n▪ B.Sc. – Economics  \\n▪ Master of Business Administration (MBA) \\n▪ MBA (Business Analytics) \\n▪ MBA (Digital Marketing) \\n▪ MBA (Banking & Finance Management) \\n▪ MBA (Marketing & Finance) \\n \\nMedia Studies \\n \\n▪ BA (Journalism and Mass Communication) \\n \\nInformation Science \\n \\n▪ Bachelor of Computer Application (BCA) \\n▪ BCA Data Science \\n▪ BCA Artificial Intelligence & Machine Learning \\n▪ Master’s in Computer Applications (MCA) \\nDesign \\n \\n▪ B. Des – Product Design \\n▪ B. Des – Communication Design \\n▪ B. Des – Space Design [Interior Design] \\n▪ B. Des – Fashion Design \\n▪ B. Des – Game Design \\n▪ B.Sc. Multimedia (VFX, SFX & Gaming) \\n \\n *All the programmes at Presidency University are completely taught in English'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='CHOOSING MODULES/COURSES  \\nYou may take courses across multiple faculties (subject to availability, no guarantees \\nmay be given) as long as your course choices are approved by your home university  \\nand meet your degree requirements.  Most courses are open to Incoming Exchange \\nstudents. However, some have prerequisites or require permission from the relevant \\nfaculty or school before you can enroll in them. Students to enroll prior to their arrival \\nat Presidency University. However, courses need t o be finalized within one week of \\nstart of   the class. All the programmes/courses are taught completely in English.  \\nACADEMIC WORKLOAD  \\nExchange students can take a workload of 12 to 20 credits. The minimum \\nworkload is 12 credits  and maximum would be 20 credits.  It may be considered on \\nthe request of the home university on reducing the workload. \\nPU 01 credit = U.S. 01 credit. \\nPU 01 credit is 15 teaching contact hours (study period, project, assignments, and \\nexamination period is excluded) \\nATTENDANCE REQUIREMENTS  \\nA student must have a minimum of 75%  attendance of the classes actually \\nconducted in that academic term, for which course(s) the student has registered for \\nin the academic term, will be permitted to write the final examination. \\nGRADING SYSTEM \\nGrade Grade Point Marks range  \\n(out of 100) Qualitative Description \\nO 10 >= 90 Outstanding \\nA+ 9 >= 85 but < 90 Excellent \\nA 8 >= 80 but < 85 Very Good \\nB+ 7 >= 75 but < 80 Good \\nB 6 >= 70 but < 75 Above Average \\nC 5 >= 60 but < 70 Average \\nD 4 >= 50 but < 60 Pass \\nF 0 < 50 Fail'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='TRANSCRIPTS  \\nAll credit-bearing exchange students will be issued with a transcript detailing their  \\nmodules and final grades at the end of the semester, once the exam results have  \\nbeen finalized. Transcript’s will be mailed directly to the home university. \\n \\nWHEN SHOULD YOU ARRIVE  \\nYou should arrive at least 7  days prior to the commencement of the term. Late \\narrival may be accepted under certain conditions such as health or travel/diplomatic \\nrestrictions.  \\nVISA  AND IMMIGRATION  REQUIREMENTS  \\nAll international students applying to study in India must have a valid student visa \\n(before travelling to India) unless they have an alternative visa that enables them \\nto study  in India . If you are granted a student visa, you must comply with all \\nstudent visa conditions. For all visa enquiries and applications, please contact your \\nlocal Indian Embassy/High Commission/Consulate General of India . The visa must \\nbe valid for the orientation days before the start of the semester. Find more details \\nby visiting https://www.mea.gov.in/    \\nINSURANCE  \\nAll international students  are required to acquire a  health insurance from their  \\nhome country before their  departure. The insurance  should cover for medical  and \\nevacuation expenses abroad due to accident or  sickness for the entire  duration of \\nexchange at the host country. \\nFOREIGN REGIONAL REGISTRATION OFFICES  (FRRO)  \\nForeigner visiting India on Student Visa(S) is required to get himself / herself \\nregistered with concerned FRRO, within 14 days of his/her first arrival, irrespective \\nof the duration of his / her stay. FORM –S (Foreign Students Information System) is \\nused to capture information about foreign nationals admitted in Indian educational \\ninstitutions. Follow the FRRO link for more details.'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='CURRENT  ESTIMATED  COST  OF LIVING * \\nAccording to the study in India, the average cost of living in India (Bangalore) for  \\nstudents is € 140 (A student can experience a comfortable stay for a month). \\nLiving costs will vary depending on lifestyle but it is generally inexpensive to live in  \\nBangalore than other Indian cities, such as Mumbai or Delhi. Here is a breakdown of \\nsome general expenses for you to consider when preparing your finances (click for  \\nmore details): \\n \\nGeneral Expenses Approximate cost \\nAccommodation (off campus) \\nPlease check with the office of International Affairs whether certain items are  \\nincluded e.g. bedding, kitchen utensils, etc., and whether you would be required \\nto pay a deposit as well as made an advance payment. \\n \\n€ 250 (per month) \\nGroceries € 65 (per month) \\nMeal (affordable restaurant) € 2-5 \\nTransport € 30 (per week) \\nWi-Fi € 4-12 (per month) \\nMobile telephone (depends on usage) € 8 (per month) \\nWater € 0.60 per liter \\nCourse related costs: books/stationery/photocopying/binding € 10 (per month) \\n*Please note: The above costs are estimated and subject to each student’s \\nindividual lifestyle - personal expenses and spending habits. \\nSERVICES and SUPPORT \\nStudying overseas is a rewarding opportunity to broaden your experience and \\noutlook, but it can also be challenging. PU provides the support you need to \\ndevelop academic and professional skills, feel confident in your study and maintain \\nyour wellbeing. \\nPU INTERNATIONAL OFFICE \\nThe PU International team offers you advice and support during the application \\nprocess and throughout your studies at PU. Our student advisers/Mentors can assist \\nwith general enquiries, and will keep you up to - date with important news and \\nevents around PU via emails.'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='SAFETY AND SECURITY \\nPU fosters a safe and secure environment for students, staff and visitors, with 24 -\\nhour security assistance on and around campus. This includes accessible security \\nofficers, regular patrols, and closed-circuit television cameras. \\nARRIVAL TIPS \\nStudents to arrive in Bangalore 7 days prior to start of the formal classes so as to \\nfinalize the courses and to settle in their accommodation. \\nPU International Office offers a complimentary airport shuttle service from \\nBengaluru International Airport to PU for exchange students who arrive 7 days \\nbefore Orientation begins.  Exchange students need to provide their flights details \\nand visa for arrange the pick service from the Bengaluru Airport. \\nGENERAL SUPPORT SERVICES \\nPU provides a wide range of on-campus services for students, including: \\n• Medical services \\n• Counselling services \\n• Accessibility services for students with a disability or ongoing medical \\ncondition \\n• Wi-Fi facility throughout campus \\n• Library services \\n• Sports facilities \\n• Student welfare services \\n• Canteen facilities \\n• PU Buddy \\n• ATM'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='HOW TO APPLY \\n \\n1. Choose  your  \\nprogramme  \\nAre  you  applying  as a Student  Exchange/  Study  Abroad  \\n \\n2. Check  your  eligibility  Check that you meet the entry requirements for your \\nprogram.  \\n \\n3. Discuss  your  study  \\noptions with your home \\nuniversity  \\nConsult  with  your  home  university  to understand  the \\napplication  and  credit  requirements  of studying  abroad.  \\nIf you are from PU exchange partner university, you’  ll also \\nneed home university approval to participate in the \\nexchange.  \\n4. Choose your courses \\n- 12 or 18 credit points  \\nReview the information in this guide and select the \\nappropriate study plan for  your  program in PU.  \\n \\n \\n \\n5. Apply  at PU \\nExchange  Programme  \\n\\uf0a8 Ensure your home university confirms your \\nnomination to PU first.  \\n\\uf0a8 Submit the f i l led  application form  with academic \\ntranscripts along with essential supporting  \\ndocuments  as requested  on the  application  form . \\n6. Apply for PU off -campus \\naccommodation  \\n \\nYou will receive an acknowledgement of your application  \\n \\n \\n7. Offer letter and study \\nplan  \\nPU will  assess  your  application.  I f you  are  successful,  \\nPU will  email  your  offer  Letter  after  receiving  the \\nconfirmation for accommodation and administrative \\ncharges.  \\nYou  can  start  to prepare  your  study  plan.  The  average  \\ntimeframe  to process  applications  is two  to three  weeks.  \\n8. Acceptance  and \\nconfirmation  of \\nenrolment  \\nYou must formally accept your offer and, PU will also  \\npre - enroll  you  in your  preferred, approved subjects.  \\n \\n \\n9. Apply  for a student  \\nvisa  \\nApply for a student visa. Once your student visa has  \\nbeen approved, you should  finalize your travel  \\narrangements and insurance. You must obtain an Indian \\nstudent  visa  before  you  can  commence study in India.  \\n \\n10. Pre - arrival  \\nPU will send you pre - arrival information regarding \\naccommodation, airport reception and  orientation \\nactivities.  \\n \\n \\n \\n11. Arrival  and  \\nOrientation  \\nArrive in Bangalore, India and attend PU Orientation, \\nwhich  is compulsory for  all  exchange students.  Our  \\ncomprehensive Orientation programs include information \\nsessions  and  social  activities,  to help  you  get  to know  \\nPU and meet other new and experienced students. You \\nwill also be able to finalize your enrolment and receive \\nyour student ID card.'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='Phone: +91 80 2309 3500  \\nEmail: ir_office@presidencyuniversity.in \\nWeb: https://presidencyuniversity.in  \\n \\nPlease note that this factsheet is subject to change \\nLast update: January 2025'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content=''),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content=''),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='“Cutting through the clutter, Martin Musiol explains generative AI with \\ngreat insight and clarity. The reader is left with a clear understanding of the \\ntechnology, without the need to master complex mathematics or code. A must \\nread for those who want to understand the future.”\\n—  Rens ter Weijde, Chairman & CEO of KIMO.AI\\n“ An illuminating guide through the evolving landscape of generative AI and \\nAGI, this book masterfully demystifies complex concepts, making them acces-\\nsible to all and ignites the imagination about the boundless possibilities of \\nthe future.”\\n—  David Foster, author of Generative Deep Learning, Partner at \\nApplied Data Science Partners\\n“This book is a must-read for anyone wanting to improve their understand-\\ning of where AI has come from, where it stands today, and, importantly, \\nwhere it is heading. The advent of AGI and ASI is too important not to \\nunderstand, and Martin meticulously explains many potential outcomes \\nwith a factual and unbiased perspective.”\\n—  Roy Bhasin (Zeneca), author, entrepreneur,  \\nangel investor\\n“Highly recommended. Musiol deeply and expertly demonstrates how to \\nnavigate the complex, exhilarating, and essential landscape of generative AI.”\\n—  Katie King, published author,  \\nCEO of AI in Business\\n“Generative AI by Martin Musiol offers a comprehensive overview of the \\nGenAI technology and skillfully demystifies complex concepts of this trans-\\nformative AI.”\\n—  Sheamus McGovern, entrepreneur, investor, Founder & CEO Open \\nData Science\\nPraise for Generative AI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='“Martin, my esteemed former colleague and an AI expert, has authored this \\ncrucial book designed for anyone seeking to enhance their knowledge of gen-\\nerative AI, autonomous AI agents, and AGI. From complex subjects to com-\\npelling and easily comprehensible, this book is invaluable for business \\napplications and everyday life.”\\n—  Martin Weis, Country Head Switzerland & Global Co-Lead AI, \\nAnalytics & Automation at Infosys Consulting\\n“Martin’s book masterfully encapsulates the transformative power of AI and \\nprovides great foundational knowledge for innovators and builders to explore \\nthe industry further.”\\n—  Anton Volovyk, Co-CEO Reface  \\n(GenAI app, 250m downloads, backed by a16z)\\n“This book is akin to a comprehensive playbook, detailing strategies and \\nrules for navigating the complex field of AI, much like a coach laying out a \\nwinning game plan. It masterfully presents the evolutionary stages, key \\nplayers beyond ChatGPT, foundational technologies, and practical guidance, \\nequipping readers to effectively ’play’ and excel in the dynamic and competi-\\ntive arena of AI.”\\n—  Dr. Harald Gunia, Leader for Applied Artificial  \\nIntelligence Europe at Infosys Consulting\\n“Martin Musiol’s book on generative AI provides a compelling narrative \\nthat unveils the meticulous evolution of this groundbreaking technology. \\nFrom the quiet simmering of its inception, to the carefully curated recipe of \\ntechnological advancements that propelled it to unprecedented heights, \\nMusiol carefully peels back the layers, revealing the pivotal factors that \\nshaped the rise of generative AI.”\\n—  Matteo Penzo, Co-Founder & CEO of zicklearn.com\\n“Martin’s book offers deep insights and a comprehensive overview that \\nmakes this complex subject accessible to all readers.”\\n—  Prof. Dr. Patrick Glauner\\n“This book is a must-read for anyone like me captivated by artificial intel-\\nligence’s present and future implications.”\\n—  Catherine Adenle, Senior Director, Global Employer Brand,  \\nElsevier, top\\xa022 AI and tech influencer'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI\\nNavigating the Course to the Artificial \\nGeneral Intelligence Future\\nMartin Musiol'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Copyright © 2024 by John Wiley & Sons, Inc. All rights reserved.\\nPublished by John Wiley & Sons, Inc., Hoboken, New Jersey.\\nPublished simultaneously in Canada and the United Kingdom.\\nISBNs: 9781394205912 (Hardback), 9781394205950 (ePDF), 9781394205943 (ePub)\\nNo part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form \\nor by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as \\npermitted under Section\\xa0107 or 108 of the 1976 United States Copyright Act, without either the prior \\nwritten permission of the Publisher, or authorization through payment of the appropriate per-copy \\nfee to the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-\\n8400, fax (978) 750-4470, or on the web at www.copyright.com. Requests to the Publisher for \\npermission should be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River \\nStreet, Hoboken, NJ 07030, (201) 748-6011, fax (201) 748-6008, or online at www.wiley.com/go/\\npermission.\\nTrademarks: WILEY and the Wiley logo are trademarks or registered trademarks of John Wiley & \\nSons, Inc. and/or its affiliates, in the United States and other countries, and may not be used without \\nwritten permission. All other trademarks are the property of their respective owners. John Wiley & \\nSons, Inc. is not associated with any product or vendor mentioned in this book.\\nLimit of Liability/Disclaimer of Warranty: While the publisher and author have used their best \\nefforts in preparing this book, they make no representations or warranties with respect to the accuracy \\nor completeness of the contents of this book and specifically disclaim any implied warranties of mer-\\nchantability or fitness for a particular purpose. No warranty may be created or extended by sales rep-\\nresentatives or written sales materials. The advice and strategies contained herein may not be suitable \\nfor your situation. Y ou should consult with a professional where appropriate. Further, readers should \\nbe aware that websites listed in this work may have changed or disappeared between when this work \\nwas written and when it is read. Neither the publisher nor author shall be liable for any loss of profit \\nor any other commercial damages, including but not limited to special, incidental, consequential, or \\nother damages. Generative AI tools were used by the author to research ideas for this book; however, \\nthe writing and finished text of the book are completely the work of the author and the Wiley editorial \\nstaff.\\nFor general information on our other products and services or for technical support, please contact \\nour Customer Care Department within the United States at (800) 762-2974, outside the United States \\nat (317) 572-3993 or fax (317) 572-4002.\\nWiley also publishes its books in a variety of electronic formats. Some content that appears in print \\nmay not be available in electronic formats. For more information about Wiley products, visit our web \\nsite at www.wiley.com.\\nLibrary of Congress Control Number: 2023951020\\nCover image: © undefined/Getty Images\\nCover design: Wiley'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='T o my parents, who have always supported me, and to my grandma \\nHelena, whose wise words continue to echo in my ears, guiding me \\nthrough life. I will be forever grateful for the deep love I have received \\nfrom you, and rest assured, I feel the same for you. A truth perhaps \\nnot spoken enough, yet profoundly felt.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content=''),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Introduction ix\\nChapter 1 AI in a Nutshell 1\\nChapter 2 Innovative Approaches for\\xa0High-Quality  \\nData Generation 23\\nChapter 3 Generative AI’s Broad  Spectrum of  \\nApplications 119\\nChapter 4 Generative AI’s Exponential Growth 219\\nChapter 5 Ethical Concerns and Social Implications  \\nof Generative AI 285\\nChapter 6 Artificial General  Intelligence in\\xa0Sight 337\\nAcknowledgments 405\\nAbout the\\xa0Author 407\\nIndex  409\\xa0\\nContents\\nvii'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content=''),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ix\\nI\\nn the realm of technology, epochs of transformation are often \\nignited by the spark of human imagination, fused with the \\nfinesse of engineering artistry. We stand at the precipice of such \\nan epoch, where the realms of generative AI unfurl into the once \\nuncharted territories of artificial general intelligence (AGI). I am \\nboth thrilled and humbled to be your guide on this thrilling \\nexpedition into the future, a journey that begins with the pages \\nof this book.\\nThe technological zeitgeist of our times is one of exponential \\nprogress. A mere glimpse into the recent past reveals the embry-\\nonic stages of generative AI, yet, within a fleeting span, advance-\\nments like ChatGPT have marked a point of no return. This \\ncrescendo of innovation is not confined to textual realms alone \\nbut spans across images, videos, 3D objects, datasets, virtual real-\\nities, code, music, and sound generation, each stride accelerating \\nour pace toward the enigmatic horizon of AGI. The rapid matu-\\nration and adoption of generative AI outshine the evolutionary \\narcs of many preceding technologies.\\nIt was during the cusp of this book’s creation that the concept \\nof autonomous AI agents morphed into a tangible reality, cour -\\ntesy of emerging open source frameworks. Now, a subscription \\naway, the first AI agents are at our beck and call. This swift pro-\\ngression, magnifying the efficiency of AI model development, \\nIntroduction'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='x IntroductIon\\nunderscores the urgency and the timeliness of delving into the \\ndiscourse this book intends to foster. As you traverse through its \\nchapters, you’ll realize we are merely at the dawn of an exhilarat-\\ning technological epoch with a vast expanse yet to be unveiled.\\nWho should venture into this exploration? Whether you’re a \\ntechnology aficionado, a student with a zest for the unknown,  \\na policymaker, or someone who’s merely curious, this book beck-\\nons. No prior acquaintance with AI or machine learning is \\nrequired; your curiosity is the sole ticket to this expedition. As we \\ncommence, we’ll demystify the essence of AI, its lexicon, and its \\nmetamorphosis over time. With each page, we’ll delve deeper, yet \\nthe narrative is crafted to foster an understanding, irrespective of \\nyour prior knowledge. By the narrative’s end, your imagination \\nwill be aflame with the boundless possibilities that the future holds.\\nThe narrative arc of this book has been meticulously crafted \\nto offer an understanding yet a profound insight into generative \\nAI and its trajectory toward AGI. Our expedition begins with the \\nrudiments of AI, tracing its evolution and the brilliant minds that \\npropelled it forward. As we delve into the heart of generative AI, \\nwe’ll explore its broad spectrum of applications, unraveling \\npotential startup ideas and pathways to venture into this domain. \\nThe discussion will then transcend into the convergence of \\ndiverse technological realms, each advancing exponentially \\ntoward a shared zenith. Ethical and social considerations, indis-\\npensable to this discourse, will be deliberated upon before we \\nventure into the realms of AGI, humanoid and semi- humanoid \\nrobotics, and beyond. Through the annals of my experience, \\nincluding my tenure as the generative AI lead for EMEA at Info-\\nsys Consulting, we’ll traverse through real- world scenarios, \\nalbeit veiled for confidentiality, offering a pragmatic lens to envi-\\nsion the theoretical discourse.\\nWhat sets this narrative apart is not merely the content, but \\nthe vantage point from which it is observed. My journey, from'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Introduction xi\\nadvocating generative AI since 2016, founding GenerativeAI.net \\nin 2018, to now sharing a platform with luminaries at the AI \\nSpeaker Agency, has been nothing short of exhilarating. It’s \\nthrough the crucible of real- world implementations and contin-\\nuous discourse with global thought leaders that the insights \\nwithin this book have been honed. Our conversations, a conflu-\\nence of diverse perspectives, have enriched the narrative, making \\nit a crucible of collective wisdom.\\nA treasure trove of knowledge awaits to equip you to navi-\\ngate the complex yet exhilarating landscape of generative AI and \\nAGI. The ethos of this narrative is to empower you to become a \\n10X more effective human, to harness the tools that propel you \\nforward, and should a spark of an idea ignite within, to pursue it \\nwith vigor. Things can be figured out along the way, especially in \\nthis era equipped with generative AI tools. Remember, AI in itself \\nwon’t replace us, but those wielding AI effectively certainly will \\nhave an edge.\\nIn the words of British physicist David Deutsch, our civiliza-\\ntion thrives on technological growth, and it’s our prerogative to \\nstrive for a better future. This book is a stepping stone toward \\nthat endeavor, and I invite you to step into the future, one page \\nat a time.\\nHow to\\xa0Contact the\\xa0Publisher\\nIf you believe you’ve found a mistake in this book, please bring it \\nto our attention. At John Wiley & Sons, we understand how \\nimportant it is to provide our customers with accurate content, \\nbut even with our best efforts an error may occur.\\nIn order to submit your possible errata, please email it to our \\nCustomer Service T eam at wileysupport@wiley.com with the \\nsubject line “Possible Book Errata Submission.”'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='xii IntroductIon\\nHow to\\xa0Contact the\\xa0Author\\nI appreciate your input and questions about this book! Feel free \\nto contact me at the following:\\nMartin Musiol’s email: generativeai.net@gmail.com\\nMartin’s LinkedIn profile: www.linkedin.com/in/martinmusiol1\\nGenerativeAI.net’s web page: https://generativeai.net'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='1\\nN\\no other field of technology has such inconsistent jargon as \\nartificial intelligence (AI). From mainstream media to tech \\ninfluencers to research scientists, each layer of media has con-\\ntributed to that confusion. In order of their degree of contribu-\\ntion and frequency, I observed mainstream media simplifying \\nand misusing terms consistently, tech influencers misunderstand-\\ning the tech in- depth, and even some research scientists over- \\ncomplicating their model findings with fancy terms. By no means \\ndo I intend to criticize research scientists. They are the backbone \\nof everything discussed in this book. Their work offers solutions \\nto a plethora of problems, making AI the umbrella term for \\nalmost every intelligent problem. However, its interdisciplinary \\nnature, the rapid advancements in this space, and AI’s general \\ncomplexity make it already difficult to gain a clear understanding \\nof this field. I am convinced that consistent and clear language \\nwould help to understand this topic area.\\n1\\nCHAPTER\\nAI in a Nutshell'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='2 GENERATIVE AI\\nWe can see two broad classes in AI: generative AI, the subject \\nof this book, and discriminative AI. The latter is the traditional \\nand better- known part of AI. Before delving into both AI classes, \\nlet’s take a moment to understand the broader picture of AI, \\nmachine learning (ML), deep learning (DL), and the process of \\ntraining models, to avoid getting ahead of ourselves.\\nWhat Is AI?\\nEven though AI includes a broad spectrum of intelligent code, \\nthe term is often incorrectly used. Figure\\xa01.1 shows how AI, ML, \\nand DL are related. ML, a part of AI, learns from data. DL, a \\ndeeper part of ML, uses layered setups to solve tougher prob-\\nlems. Non- self- learning programs like expert systems don’t learn \\nfrom data, unlike ML and DL. We’ll explore these more next.\\nHow AI Trains Complex Tasks\\nAI can perform tasks ranging from predefined expert answers, \\nalso known as expert systems, to tasks that require human- level \\nintelligence. Think about recognizing speech and images, \\nAI\\nNon-Self-\\nLearning\\nAlgorithms\\nSelf-Learning\\nAlgorithms\\nML\\nDL\\nFIGURE\\xa01.1 The relationship between AI, ML, and DL'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 3\\nunderstanding natural language processing (NLP), making \\nsophisticated decisions, and solving complex problems. For tasks \\nlike this, the AI has to train on a respective dataset until it is able \\nto perform the desired activity as well as possible. This self- \\nlearning part of AI is referred to as machine learning (ML). \\nBecause most of the interesting applications are happening \\nthrough machine learning in one way or another, and to keep it \\nsimple, we use AI and ML interchangeably.\\nT o make it tangible, we are designing an AI system that rates \\nthe cuteness of cats from 5 (absolutely adorable) to 1 (repulsively \\ninelegant). The ideal dataset would consist of pictures of cute \\nkittens, normal cats, and those half- naked grumpy cats from the \\nInternet. Further, for classifying pictures in a case like this, we \\nwould need labeled data, meaning a realistic rating of the cats. \\nThe model comes to life through three essential steps: training, \\nvalidation, and evaluation.\\nIn training, the model looks at each picture, rates it, com-\\npares it with the actually labeled cuteness of the cat, and adjusts \\nthe model’s trainable parameters for a more accurate rating next \\ntime— much like a human learns by strengthening the connec-\\ntions between neurons in the brain. Figure\\xa01.2 and Figure\\xa01.3 \\nillustrate training and prediction, respectively.\\nThroughout the training process, the model needs to make \\nsure training goes in the right direction— the validation step. In \\nvalidation, the model checks the progress of the training against \\nseparate validation data. As an analogy, when we acquire a skill \\nlike solving mathematical problems, it makes sense to test it in \\ndedicated math exams.\\nAfter training has been successfully completed and respective \\naccuracy goals have been reached, the model enters the predic-\\ntion or evaluation mode. The trainable parameters are not being \\nadjusted anymore, and the model is ready to rate all the cats in \\nthe world.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='4 GENERATIVE AI\\nIt is typical for a model in production mode that the accuracy \\ngets worse over time. The reason for this could be that the real- \\nworld data changed. Maybe we are only looking at kittens and \\nthey are all cute compared to our training data. Retraining the \\nmodel, whenever accuracy decreases or by scheduling retraining \\nperiodically, tackles the problem of a discrepancy between the \\ndata distribution of training data and evaluation data.\\nPerhaps you have a sense already that training AI models \\nrequires much more computing power than they need in  \\nprediction mode. T o adjust its trainable parameters, often referred \\nto as weights, we need to calculate the grade of adjustment care-\\nfully. This happens through a famous model function called \\nAI Model in Prediction\\nAI Model\\nImage Cute = 5\\nFIGURE\\xa01.3 Prediction mode in a supervised ML model.\\nImage1\\nAI Model in Training (2 Steps)\\nAI Model - Training prediction, get error\\nLabel\\nAI Model - Use error to update weights (Bach propagation)\\nError\\nCute = 5 Cute = 5\\nCute = 4\\nError\\n2\\nFIGURE\\xa01.2 In supervised training of a ML model, two main steps are \\ninvolved: predict the training data point, then update the trainable \\nparameters meaningfully based on the prediction’s accuracy.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 5\\nbackpropagation. It entails the backward propagation of prediction \\nerrors— the learning from making mistakes in the training pro-\\ncess. The errors are turned back to respective weights for improve-\\nment. This means that we go forward to predict a data point and \\nbackward to adjust the weights. In prediction mode, however, we \\ndon’t adjust the weights anymore, but just go forward and predict. \\nThe function that has been trained through the training data is \\nbeing applied, which is comparatively cheap.\\nUnsupervised Learning\\nWhen ML models reach a certain complexity by having many \\ncomputing stages, called layers, we enter the realm of deep learn-\\ning (DL). Most of the cutting- edge applications are at least  \\npartially drawing their algorithms from DL. Algorithms are step- \\nby- step instructions for solving problems or performing tasks.\\nThe preceding example of rating the cuteness of a cat was \\nsimplified drastically and didn’t tell the whole story. A relevant \\naddition to this is that as we train on labeled cat pictures, with \\nthe label being the cuteness of the cats, we call this supervised \\nmachine learning. With labels, we provide guidance or feedback \\nto the learning process in a supervised fashion.\\nThe counterpart for supervised ML is called unsupervised \\nmachine learning. The main difference between them is that in \\nunsupervised ML the training data is not labeled. The algorithms \\nought to find patterns in the data by themselves.\\nFor example, imagine you have a dataset of customer pur -\\nchases at a grocery store, with information about the type of \\nproduct, the price, and the time of day. In AI these attributes are \\ncalled features. Y ou could use an unsupervised clustering algo-\\nrithm to group similar purchases together based on these fea-\\ntures. This could help the store better understand customer \\nbuying habits and preferences. The algorithm might identify'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='6 GENERATIVE AI\\nthat some customers tend to buy a lot of fresh produce and dairy \\nproducts together, whereas others tend to purchase more pro-\\ncessed foods and snacks. This information could be used to cre-\\nate targeted marketing campaigns or to optimize store layout \\nand product placement.\\nComparing the performance of unsupervised learning appli-\\ncations to that of supervised learning applications is akin to con-\\ntrasting boats with cars— they represent distinct methodologies \\nfor addressing fundamentally diverse problems. Nevertheless, \\nthere are several reasons why we reached success years faster \\nwith supervised than with unsupervised learning methods.\\nIn supervised learning, the model is given a training dataset \\nthat already includes correct answers through labels. Under -\\nstandably, this helpful information supports model learning. It \\nalso accurately outlines the AI model’s intended objective. The \\nmodel knows precisely what it is trying to achieve. Evaluating \\nthe model’s performance is simpler than it is in unsupervised \\nmachine learning, as accuracy and other metrics can be easily \\ncalculated. These metrics help in understanding how well the \\nmodel is performing.\\nWith this information, a variety of actions can be taken to \\nenhance the model’s learning process and ultimately improve its \\nperformance in achieving the desired outcomes.\\nUnsupervised models face the challenge of identifying data \\npatterns autonomously, which is often due to the absence of \\napparent patterns or a multitude of ways to group available data.\\nGenerative AI a Decade Later\\nGenerative AI predominantly employs unsupervised learning. \\nCrafting complex images, sounds, or texts that resemble reason-\\nable outputs, like an adorable cat, is a challenging task compared \\nto evaluating existing options. This is primarily due to the \\nabsence of explicit labels or instructions.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 7\\nT wo main reasons explain why generative AI is taking off \\nroughly a decade after discriminative AI. First, generative AI is \\nmostly based on unsupervised learning, which is inherently more \\nchallenging. Second, generating intricate outputs in a coherent \\nmanner is much more complex than simply choosing between \\nalternatives. As a result, generative AI’s development has been \\nslower, but its potential applications are now visible.\\nBetween supervised and unsupervised learning, there are \\nplenty of hybrid approaches. We could go arbitrarily deep into \\nthe knick- knacks of these ML approaches, but because we want \\nto focus on generative AI, it is better to leave it at that. If you \\nwant to dive deeper into the technicalities, I recommend the \\nbook Deep Learning (Adaptive Computation and Machine Learn-\\ning series), by Ian Goodfellow, Y oshua Bengio, and Aaron Cour-\\nville (MIT Press, 2016), which covers ML and DL in great detail, \\nlaying the theoretical generative AI foundation. It is regarded as \\nthe best book in the space, which isn’t surprising, given the \\nauthors. I will come back to those gentlemen later.\\nThe AI landscape is vast and ever- expanding. In this book, I \\nstrike a balance between simplifying concepts for clarity and \\nproviding sufficient detail to capture the essence of recent AI \\nadvancements. T o understand what generative AI is and its value \\nproposition, we first have to understand the traditional part of \\nAI, called discriminative AI.\\nWhat Is Discriminative AI?\\nDiscriminative AI models made headlines long before large lan-\\nguage models (LLMs) like ChatGPT by OpenAI and image gen-\\neration models like stable diffusion by Stability AI entered the \\nstage. Since the term “artificial intelligence” was coined by John \\nMcCarthy in 1955, discriminative models have yielded great \\nresults, especially in the past 15 years.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='8 GENERATIVE AI\\nDiscriminative AI focuses on algorithms that learn to tell \\napart different data classes. They recognize patterns and features \\nunique to each class, aiming to link input features with labels for \\nthe output. This way, they can effectively classify instances into \\npredefined groups, making it easier to distinguish one class from \\nanother. Discriminative AI has found numerous applications in \\nvarious domains, including NLP , recommendations, and com-\\nputer vision.\\nIn the field of NLP , discriminative AI is used to classify text \\ndata into different categories, such as sentiment analysis or topic \\nclassification. In the domain of recommendations, discriminative \\nAI is used to predict user preferences and make personalized \\nproduct recommendations. In computer vision, discriminative \\nAI is used to recognize objects and classify images based on their \\ncontent. The applications of discriminative AI are vast and \\ndiverse, and its impact on various industries is immense.\\nLooking at existing applications, discriminative AI generally \\nhas five main tasks: classification, regression, clustering, dimen-\\nsionality reduction, and reinforcement learning. They are not \\ncrucial to be able to follow the book’s thread, but it helps to \\nunderstand them conceptually because then the term “discrimi-\\nnative” and what it means in the context of AI becomes apparent. \\nPut simply, in one way or another, this part of AI is deciding, \\nselecting, distinguishing, or differentiating on data or a prob-\\nlem at hand.\\nClassification\\nThe objective of classification is to accurately predict the class of \\nnew inputs based on prior training with labeled examples  \\n(Figure\\xa0 1.4). This supervised learning process uses training \\nexamples accompanied by their respective class labels.\\nFor instance, consider unlocking your phone with facial rec-\\nognition. Y ou initially show your face from various angles,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 9\\nallowing the classifier model to learn your appearance. Advanced \\nface recognition systems, like the iPhone’s FaceID, quickly iden-\\ntify you due to their extensive pretraining and incorporation of \\nbiometric information to deterministically classify users. In \\nessence, the model or system of models assesses your face and \\ndiscriminates whether you belong to the “person with access \\nrights” or “person without access rights” class.\\nClassification has driven breakthroughs in diverse applica-\\ntions, including image classification, sentiment analysis, disease \\ndiagnosis, and spam filtering. These applications typically involve \\nmultiple processing steps and rely on deep learning techniques.\\nRegression\\nA regression model in AI is designed to predict numerical values \\nfor new inputs based on data it has learned from a given problem. \\nIn this case, the output is not a class label but a continuous value. \\nFor example, imagine you want to buy a 100- square- meter apart-\\nment with a balcony in Munich, Germany. A real estate agent pre-\\nsents three similar apartments, priced at 2\\xa0million, 2.5\\xa0million, and \\n2.7\\xa0million euros.\\nY ou have three options: the naive approach, where you \\nassume these three properties represent the market; the informed \\napproach, where you estimate market prices by researching mul-\\ntiple offers; or the data science approach, which involves build-\\ning a machine learning model to determine a fair price by \\nAI Model\\nImage\\nAccess\\nNo access\\nFIGURE\\xa01.4 In ML, the concept of classification involves assigning data \\nto one of a finite set of categories.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='10 GENERATIVE AI\\nanalyzing all available properties in the market with their \\nprice tags.\\nA well- trained regression model will give you a market- based \\nand rational price, as it takes into account all the characteristics \\nof apartments in the market (Figure\\xa0 1.5), helping you make a \\nmore informed decision. By recommending a price, the model \\ninherently has a discriminative nature.\\nClustering\\nAs the name suggests, this application field in AI clusters data \\npoints. Be they people, groceries, or songs, based on a similarity \\nmeasure, these items are grouped. By the way, you are being clus-\\ntered all the time. For example, Internet ads are targeted to your \\ndigital persona, including your sex, age, IP address (which repre-\\nsents your location), and all other data ad- providing companies \\nhave collected about you. T o cement it, if you use a web page that \\nrecommends songs like Spotify, movies like Netflix, and prod-\\nucts like Amazon to you, then you have been clustered. In the \\nsuccess of big tech companies like those mentioned previously, \\nclustering algorithms have played a crucial role, as they are the \\nbackbone of every recommendation engine.\\nHouse\\nBalcony\\n67 m2\\n...\\nPrice\\nAI Model\\nHouse Instances\\n2 Million\\nLearnt Regression\\nm2\\nBalcony yes/no\\n67\\n1 Million\\nFIGURE\\xa01.5 In regression, data like house details go into the ML model, \\nwhich then predicts its price based on these features.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 11\\nIn clustering tasks, the data comes without labels. For \\ninstance, there are no labels on our heads indicating “prefers Ben \\n& Jerry’s Chubby Hubby.” Clustering models must identify pat-\\nterns and groups autonomously, making it an unsupervised learn-\\ning task. Moreover, the process of assigning items or personas to \\nclusters is a decision- making aspect of discriminative AI.  \\nFigure\\xa0 1.6 illustrates the conceptual operation of a clustering \\nmodel. By analyzing other people’s behavior, it infers that indi-\\nviduals who purchase butter and milk might also prefer cereals. \\nAdding soda to the mix increases the likelihood of a preference \\nfor Ben & Jerry’s Chubby Hubby.\\nDimensionality Reduction\\nDimensionality reduction is not an application field of AI that is \\ndiscussed much in mainstream media. It is rather research- heavy \\nand often a means to achieve something greater, more efficiently.\\nIts primary purpose is to reduce low-information data, mainly \\nmaking machine learning applications as effective as possible. By \\n“low- information data,” I mean data that contains little to no \\nmeaningful insights to solve a problem. See Figure\\xa0 1.7 for a  \\nvisual representation.\\nShopping List:\\n- Milk\\n- Butter\\n- Flour\\nButter\\nAI Model\\nRecommend\\nB & J Chubby\\nHubby\\nMilk\\nOther groceries\\nLikes pizza\\nLikes cereals\\nLikes Ben & Jerry’s\\nChubby Hubby\\nFIGURE\\xa01.6 Clustering model identifying buying patterns'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='12 GENERATIVE AI\\nImagine that you have an extensive recipe book with hun-\\ndreds of recipes. Each recipe has several ingredients, and some of \\nthem are similar. For example, many recipes might call for salt, \\npepper, and olive oil. If you were to list all the ingredients used \\nin the book, it would be a long list with many similar items.\\nNow imagine that you want to make a simpler version of the \\nrecipe book that is easy to use on a daily basis. One way to do this \\nis to group similar ingredients. For example, you could create a \\ncategory called “seasonings” that includes salt, pepper, and other \\nspices used in the recipes. Y ou could also create a category called \\n“cooking oils” that contains olive oil, vegetable oil, and so forth.\\nIn the world of data science, the same thing happens. We \\nmight have a large dataset with many different features, and we \\nwant to simplify it to make it easier to work with. Dimensionality \\nreduction techniques help us to do this by finding a way to rep-\\nresent the data with fewer features while still preserving essential \\ninformation. They make it easier to analyze data, build models, \\nor visualize data more understandably.\\nNaturally, the data is not labeled, and we don’t know up \\nfront which features carry relevant information. In an unsuper -\\nvised manner, the models must learn to distinguish what low-  \\ninformation data can be modified or truncated and how. The \\nmodels must decide or discriminate, indicating that we are in \\ndiscriminative AI.\\nDataset\\nMany features\\nAI Model\\nDataset\\nFew features\\nX\\nY\\nZ\\nY\\nY\\nX\\nZ\\nFIGURE\\xa01.7 Dimensionality reduction'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 13\\nReinforcement Learning\\nReinforcement learning (RL) models, typically called agents, \\nlearn from positive or negative consequences that their actions \\nyield in real- world or virtual environments. A positive conse-\\nquence is a reward, and a negative consequence is a punishment. \\nIn Figure\\xa01.8, the agent executes an action in a virtual/physical \\nenvironment, altering the environment (even if minimally), and \\nreceives a reward or penalty based on its stated goal. During the \\ntraining phase of the RL model, initial emphasis is on explora-\\ntion to identify available paths (e.g., for warehouse navigation), \\ngradually shifting to an exploitation phase for efficient goal \\nachievement (or technically, maximizing rewards), as indicated in \\nFigure\\xa01.9.\\nVirtual environments encompass a wide range of applica-\\ntions, from simulations for practicing real- world maneuvers to \\ngaming experiences, and even stock market environments for \\ntrading agents. In gaming, AI has demonstrated remarkable \\nsuper- human abilities, excelling in games such as Super Mario. \\nWhen an RL agent acts in a real- world environment, it is prob-\\nably a robot in a warehouse or Boston Dynamics’s Atlas perform-\\ning ninja moves. The agents acquire the ability to determine the \\noptimal action in a given situation, positioning them as a compo-\\nnent of discriminative AI.\\nAgent\\nAction\\nNew state of environment\\nReward/\\npunishment\\nVirtual/\\nphysical\\nenvironment\\nFIGURE\\xa01.8 Technical workings of reinforcement learning models'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='14 GENERATIVE AI\\nReinforcement learning has many exciting aspects, one of \\nwhich is forming great synergies with generative AI. It was of lit-\\ntle public interest for decades until its turning point in 2016, \\nwhen AlphaGo by Google’s DeepMind won a series of Go \\nmatches against the former world champion Lee Sedol. Go is a \\ncomplex Chinese board game with a 19×19 grid, and thus it has \\n10^172 possible moves. For comparison, there are 10^82 atoms \\nin the universe. RL not only plays complex games exceptionally \\nwell but also delivers on a variety of tasks, ranging from autono-\\nmous vehicles to energy management in buildings. More on the \\npowerful collaboration between RL and generative AI later.\\nAdditionally, RL is helping to advance our understanding of \\nthe learning process itself, leading to new insights into how intel-\\nligence works and how it can be developed and applied.\\nWhat Is Generative AI?\\nSo far we have talked about discriminative AI, which can decide, \\ndistinguish, or discriminate between different options or con-\\ntinuous values.\\nGenerative AI, however, is fundamentally different. It has the \\nability to generate all kinds of data and content. By learning the \\npatterns and characteristics of given datasets, generative AI \\nLearn First\\nData Collection/Sample Learning\\nExplore/Learn Exploit/Earn\\nTime\\nFIGURE\\xa01.9 Exploration versus exploitation in RL training over time'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 15\\nmodels can create new data samples that are similar to the \\noriginal data.\\nRecent advancements, such as the mind- blowing creations of \\nMidjourney’s image generation, the steps of video generation \\nlike Meta’s Make- A- Video, and the conversational abilities of \\nChatGPT , have completely altered the way we view AI. It is a \\nfascinating field that revolutionizes the way we create products \\nand interact with data.\\nGenerally speaking, generative AI models can perform three \\ntasks, each with a unique and exciting set of applications.\\nData Generation\\nFirst, and it is the most obvious one, that they can generate all \\nkinds of data, including images, videos, 3D objects, music, voice, \\nother types of audio, and also text—like book summaries, poems, \\nand movie scripts. By learning the patterns and characteristics of \\ngiven data, generative AI models can create new data samples \\nthat are similar in style and content to the original.\\nData Transformation\\nThe second task of generative AI is to perform data transforma-\\ntions. This means transforming existing data samples to create \\nnew variations of them. T ransformations can reveal new insights \\nand create appealing outputs for various applications. For exam-\\nple, you can transform winter pictures into summer pictures or \\nday pictures into night pictures. T ranslating an image from one \\ndomain (for example, summer) into another (winter) is called a \\ndomain transfer. Image style transformation involves taking an \\nimage, such as a photograph of your garden, and maintaining the \\ncontent (i.e., the garden) while altering its appearance to resem-\\nble the artistic style of, say, Monet’s paintings. This process,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='16 GENERATIVE AI\\nknown as style transfer, is not limited to visual content like photos \\nand videos but can also be applied to other data types like music, \\ntext, speech, and more. The essence of style transfer lies in pre-\\nserving the original content while imbuing it with a distinct and \\nrecognizable, often artistic, flair.\\nStyle transfer is more than just a delightful tool; it possesses \\nthe potential to significantly improve datasets for broader appli-\\ncations. For example, researchers from Korea and Switzerland \\nhave independently investigated the use of style transfer tech-\\nniques to augment the segmentation of cancer cells in medical \\nimages using machine learning. This method, dubbed contextual \\nstyle transfer, relies on the seamless integration of style- transferred \\ninstances within the overall image, ensuring a smooth and cohe-\\nsive appearance— something that generative adversarial net-\\nworks (GANs) are able to perform. In a fascinating study, Nvidia \\nshowcased a remarkable improvement in segmentation perfor -\\nmance by incorporating synthetic data into the training set. This \\nintegration led to a leap from 64 percent to 82 percent in accu-\\nracy simply by augmenting the dataset, without modifying the \\nmachine learning pipeline in any way.\\nData Enrichment\\nAs already indicated with style transfer, the third task of genera-\\ntive AI is to enrich datasets to improve machine learning models \\nultimately. This involves generating new data samples similar to \\nthe original dataset to increase its size and diversity. By doing so, \\ngenerative AI can help to improve the accuracy and robustness of \\nmachine learning models.\\nImagine we want to build a computer vision model that uses \\nML techniques to classify whether rare cancer cells are benign or \\nmalignant. As we are looking at a rare cancer type, it will be a \\nsmall dataset to train on. In real- world scenarios, privacy issues \\nare another data- diminishing factor. However, our neural net is'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 17\\ndata- hungry and we can’t get the most out of its power, landing \\nat 64 percent classification accuracy. Through generative AI, rare \\ncancer images can be generated to create a larger and more \\ndiverse training dataset for improved detection performance.\\nOverall, the capabilities of generative AI are truly remarka-\\nble, and the potential applications are vast and varied. AI limits \\nare being pushed every day, not only by research but also by for- \\nprofit companies. This is especially true of generative AI.\\nIf we zoom out further, we see that the overall concept of \\ngenerative AI is even simpler. Models generate data based on \\nsome input. The complexity of the input can vary a lot. It could \\nrange from simple tasks, such as transforming a single digit like \\n6\\xa0into a handwritten image, to complex endeavors like applying \\ndomain transformations to a video.\\nUnder the\\xa0Radar No More: Picking Up\\xa0Speed\\nWhat we often observe, especially in AI, is that a new tech \\napproach has early roots, but has been in stealth mode for a cou-\\nple of decades. Once sufficient advancements transpire in a \\nrelated tech domain, the dormant technology awakens, deliver -\\ning substantial value in real- world applications. This is recog-\\nnized as technological convergence.\\nDeep Learning Tech Convergence with GPUs The advent \\nof deep learning, the underlying technology propelling fields \\nsuch as computer vision and robotics, traces its roots back to \\n1967, when the first neural network, the multilayer perceptron, \\nwas conceived and introduced by two prominent Soviet scien-\\ntists, Ivakhnenko and Lapa.1 For numerous decades deep learn-\\ning struggled to yield tangible business value and real- world \\n1A. G. Ivakhnenko and Valentin Grigor’evich Lapa,\\xa0 Cybernetics and Forecasting T echniques, American Elsevier \\nPublishing Company, 1967.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='18 GENERATIVE AI\\napplications. However, a transformative moment arrived with \\nthe emergence of graphics processing units (GPUs) at the onset \\nof the 21st century.\\nGPUs first became popular in the gaming industry. In the \\nlate 1990s and early 2000s, video games became increasingly \\ncomplex and required more processing power to render high- \\nquality graphics and animations.\\nIn the 1990s, GPUs were initially developed with the pri-\\nmary aim of providing specialized processing for intricate 3D \\ngraphics and rendering in video games and other computer \\napplications. Firms such as 3DFX, ATI, and Nvidia spearheaded \\nthese advancements. The early 2000s witnessed another signifi-\\ncant development for GPUs: the introduction of parallel pro-\\ncessing, enabling multiple calculations to be executed \\nsimultaneously.\\nThis ability to compute large amounts of data breathed new \\nlife into deep learning, allowing it to gain traction and experi-\\nence a surge in research popularity. Leveraging GPUs’ enhanced \\ncapabilities, researchers and practitioners accelerated deep learn-\\ning’s potential, sparking a multitude of practical applications. \\nT oday, it’s unimaginable to train a robust machine learning or \\ndeep learning model without the assistance of GPUs.\\nDeep learning has reaped the benefits of other advancements \\nas well. The Internet’s growth and technological innovations \\nprovided abundant data for training models, while committed \\nresearchers and research, in general, led to numerous break-\\nthroughs in deep neural networks. This progress extends from \\nconvolutional neural networks achieving remarkable feats in \\nimage recognition to recurrent neural networks demonstrating \\nadvanced NLP capabilities. It’s not just the researchers who are \\npassionate about the subject; capital allocators and profit- driven \\ncompanies have also invested heavily in the field.\\nIncidentally, it’s worth mentioning that we are now seeing, \\nand will likely keep seeing, a similar rise in interest in generative'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 19\\nAI. The growth of other areas, especially discriminative AI and \\ncomputational power, along with the increasing amount of data, \\nwere crucial for generative models to evolve in the background.\\nT oday, we see billions being invested in generative AI pro-\\njects aimed at tackling a wide range of business and non- business \\napplications, as long as people can imagine it. This growing focus \\non generative AI promises to bring even more transformative \\nadvancements in the near future, building on the foundation \\nestablished by previous AI breakthroughs.\\nIn today’s attention economy, capturing the focus of individ-\\nuals has become increasingly challenging, as attention itself is a \\nscarce and valuable resource. The widespread adoption of the \\nInternet, social media, and other digital technologies has led to \\nan overwhelming influx of information and stimuli, all compet-\\ning for our limited attention. Consequently, only groundbreak-\\ning technologies can truly stand out and capture the spotlight. \\nFor a long time, generative AI remained relatively obscure in this \\ncompetitive landscape. However, recent advances and remarka-\\nble achievements have now propelled generative AI into promi-\\nnence, showcasing its immense potential and securing its place at \\nthe forefront of technological innovation.\\nGenerative AI’s Early Impact Generative AI is still quite new, \\nbut its future effects are expected to be amazing, going beyond \\nwhat we’ve seen so far. Its influence can be noticed in many areas, \\nbut it has mainly made a difference in three sectors: creative \\nindustries, gaming, and natural language processing.\\nCreative Industries Generative AI has made a lasting impact on \\ncreative fields like art. This technology enables artists to create \\nunique and inventive digital artworks. By studying patterns and \\nstyles in existing art, music, and fashion, AI algorithms can pro-\\nduce new content that matches market trends and engages'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='20 GENERATIVE AI\\naudiences. In the world of music, these algorithms can generate \\noriginal tracks or remix current ones, opening up fresh possibili-\\nties for both producers and artists.\\nThe integration of generative AI has led to new business \\nmodels in the creative industry, such as selling exclusive digital \\nart or creating customized products using AI- generated designs. \\nThis growth has occurred alongside a technological convergence \\nbetween AI and the rapidly expanding cryptocurrency landscape.\\nIn the last eight years, the cryptocurrency world has seen \\nincredible progress, with numerous coins quickly making some \\npeople wealthy and leaving others financially devastated. Decen-\\ntralized finance and institutional adoption have drawn significant \\ninterest. However, the most far- reaching impact may come from \\nnon- fungible tokens (NFT s).\\nNFT s allow artists and creators to produce unique, verifiable \\ndigital assets, leading to a growing demand for imaginative, high- \\nquality AI- generated art. While not the sole driving force behind \\nadvancements in image generation, the NFT market has undeni-\\nably accelerated progress in this area.\\nGaming Industry The gaming industry has experienced a sig-\\nnificant transformation due to generative AI, which has opened \\nup possibilities for a variety of new game content, such as levels, \\ncharacters, 3D objects, scenarios, and even entire quests. A nota-\\nble example is Microsoft’s Flight Simulator, which partnered \\nwith Blackshark.ai to generate a photorealistic, three- dimensional \\nworld from two- dimensional satellite images, covering the \\nwhole Earth.\\nThe popularity of open- world concepts in gaming has \\nencouraged many companies to adopt AI- generated content. \\nImagine AI algorithms that study player behavior and dynami-\\ncally modify game difficulty or generate new content on the spot,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 21\\nleading to personalized and engaging gaming experiences. Con-\\nsider the potential of giving non- player characters (NPCs) AI- \\ndriven language models for more captivating and immersive \\ninteractions. These advancements could make returning to the \\nreal world a challenge.\\nBy using generative AI to create in- game items and environ-\\nments more efficiently, gaming companies can allocate more \\ntime and resources to concentrate on core aspects, ensuring the \\nproduction of intriguing and original content. The future of \\ngaming, fueled by generative AI, is set to be an exciting and \\nimmersive adventure for players.\\nNatural Language Processing The third impact vertical is not a \\nsingle industry per se but rather many industries.\\nGenerative AI can be used to generate new content such as \\ntext, summaries, or translations. Large language models are at \\nthe forefront of generative AI applications, with widespread \\nimpacts across various industries. LLMs can improve operational \\nefficiencies by automating repetitive internal processes and \\naccelerating innovation through customer feedback analysis, \\ninsights, and market research. These models can also improve \\ncustomer experiences with concise answers and summaries avail-\\nable 24/7. The potential for managing knowledge is perhaps one \\nof the most significant aspects of AI systems; organizations with \\nspecialized knowledge can offer their expertise in a tailored and \\nconcise manner to end users. T ake the Mayo Clinic, for instance. \\nSpecializing in patient care, research, and education, the Mayo \\nClinic has amassed a wealth of data on medical conditions and \\ntreatments, such as patient records, research studies, and medical \\nimaging data. They could create chatbots and virtual assistants \\nthat harness this data to provide expert guidance and advice to \\npatients. By integrating these AI- driven tools into the Mayo'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='22 GENERATIVE AI\\nClinic’s website or mobile app, patients could access expert med-\\nical advice from anywhere around the globe.\\nLanguage models don’t just generate language, but also code, \\nmusic, poetry, stories, jokes, captions, summaries, translations, \\nrecommendations, and much more. The fields will further \\nbroaden, with LLMs providing innovative solutions for busi-\\nnesses and society.\\nGenerative AI is immensely exciting as it will undoubtedly \\nrevolutionize how we create, consume, and process content \\nacross all aspects of our lives. As the technology develops, we can \\nexpect further paradigm shifts, leading to groundbreaking \\nadvancements in industries worldwide.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='23\\nT\\nhe present and future of generative AI are significantly more \\nexhilarating than the developments of previous decades. As \\nwe consider the key milestones in AI’s evolution, we’ll highlight \\nthe features that have informed modern advancements in the \\nfield. Pioneering approaches have been crucial for the high-quality  \\ndata generation we witness today, leading to a paradigm shift in \\nartificial intelligence. This shift has transformed the way we pro-\\nduce and consume content and, consequently, the way humanity \\nprogresses.\\n2\\nCHAPTER\\nInnovative Approaches \\nfor\\xa0High-Quality Data \\nGeneration'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='24 GENERATIVE AI\\nWhy Generative Models?\\nWhat makes generative models so special? How do they differ \\nfrom others? T o fairly answer these questions, we must ultimately \\ndelve into the innovative thought processes behind their crea-\\ntion. While avoiding overly technical details, we’ll examine how \\ndevelopers thought outside the box to devise sophisticated, intel-\\nligent, and novel methods for generating data from scratch.\\nExplaining generative model concepts can quickly become \\ntoo scientific and perplexing. However, their fundamental idea is \\nrelatively simple to grasp. Consider an example of handwritten \\ndigits from the renowned MNIST (Modified National Institute \\nof Standards and T echnology) dataset. A discriminative model’s \\ntask might be to discern if an image of a handwritten digit is 0, 1, \\n2, 3, 4, 5, 6, 7, 8, or 9. For simplicity, let’s focus only on 0s and 1s. \\nConceptually, a discriminative model seeks to differentiate digits \\nby constructing a boundary in the data space. (Imagine the data \\nspace as a canvas where each data point represents a digit, and \\nthe boundary is like an invisible line that divides the different \\ncategories.) This boundary, representing the decision-making \\nprocess of the discriminative AI model, separates the 0s and 1s.\\nIf the model accurately establishes this boundary, it can dis-\\ntinguish the digits without explicitly identifying the exact loca-\\ntions of instances in the data space. In this context, achieving a \\nreasonably accurate separation between categories might be suf-\\nficient for the model to perform its classification task effectively.\\nDiscriminative models look at where 0s and 1s are located  \\nin the data space and use this information to find the best way  \\nto separate them. The term conditional probability refers to the \\nlikelihood of an instance being a 0 or 1 based on its features. By \\nunderstanding these probabilities, the models can tell apart  \\nnew instances, distinguishing between 0s and 1s, as shown in \\nFigure\\xa02.1.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 25\\nIn contrast, generative models study the training data. As \\nthey train on the data, they see what the data looks like and how \\nits features are distributed. They then try to generate data— 1s \\nand 0s, in this case as shown in Figure\\xa02.2— that fall close to the \\nreal counterparts in the data space. Concrete, a generator model, \\nwould generate 1s that look similar to other 1s in the training \\ndata, and 0s that look similar to the 0s in the training data. This \\nis what in the literature is meant by “modeling the distribution \\nthroughout the data space.”\\nAgain, from this point of view it is not sufficient to roughly \\nunderstand the data to replicate it; it must be understood precisely. \\n• Discriminative Model\\nx p(y|x)\\n1\\n/\\n0\\n0 y = 0\\ny = 1\\nFIGURE\\xa02.1 Representation of a discriminative model, showing how it \\ndistinguishes between two classes (y = 0 and y = 1) given input exam-\\nples, choosing between the two options based on what model (the \\ndotted line) has been trained on.\\n• Generative Model\\nx p(x, y)\\ny = 0\\ny = 1\\n1\\n/\\n0\\n0\\nFIGURE\\xa0 2.2 Representation of a generative model, highlighting the \\njoint probabilities p(x, y). Data samples are drawn based on input fea-\\ntures: 1s are sourced from the joint probability distribution, whereas \\n0s stem from their specific probability within this specific model.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='26 GENERATIVE AI\\nGiven the training data distribution, the models have to learn how \\nto connect the output data distribution to it— jointly. They cap-\\nture the joint probability, which makes them probabilistic. Their \\noutput is typically happening based on the probability of the pos-\\nsible outputs. And this is how you generate new data.\\nThe underlying concept is basically that simple idea, and it is \\nremarkable how good the different models have become. The \\noutput quality has jumped significantly because they are succes-\\nsively getting better at mapping both distributions correctly. A \\nmuch-underestimated benefit of generative models is their abil-\\nity to cope with unlabeled data. They not only identify the under-\\nlying structure of the unlabeled data but can represent it. The \\nfirst step is already nontrivial, and conventional artificial intelli-\\ngence struggles with it.\\nThe potential of generative AI is incredibly exciting and is \\nbased on this simple technical idea of mapping input and output \\ndistributions. However, as simple as the idea is, the execution is \\nmuch harder. Research scientists, data scientists, and other very \\nsmart folks had to be creative in the process of developing these \\nalgorithms. From neural networks trying to fool each other, to \\niteratively adding noise and denoising images, to extended atten-\\ntion mechanisms, achieving breakthroughs goes hand in hand \\nwith breaking out from normal AI architectures. This is what has \\nenabled truly special AI models.\\nFrom Birth to\\xa0Maturity: Tracing the\\xa0 \\nDevelopment of\\xa0Generative Models\\nCurrently, we are at a point where a lot of the tech hasn’t been \\ndefined yet. However, some tech approaches have made a perma-\\nnent mark in the evolution of generative AI and AI as a whole. \\nThis section considers some of those approaches.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 27\\nELIZA\\nIt is 1966. The Vietnam War intensified as the United States \\nlaunched Operation Rolling Thunder, a sustained bombing cam-\\npaign against North Vietnam, and the Chinese Cultural Revolu-\\ntion began, marking the start of a decade of political upheaval \\nand social unrest in China.\\nA small group of computer scientists is standing in the IT lab \\n2.3.5 at MIT in Boston, Massachusetts, where Associate Profes-\\nsor Dr. Joseph Weizenbaum is about to reveal something ground-\\nbreaking: a chatbot named ELIZA, designed to imitate a \\npsychotherapist’s conversational style (Figure\\xa02.3). The audience \\nis stunned. ELIZA analyzes human input and generates responses \\nthat seem like they’re coming from a real person. Weizenbaum \\nexplains how ELIZA ’s algorithm works: First it identifies pat-\\nterns, then generates a response using predefined templates and \\nrules. For example, if the input includes the word “mother,” \\nELIZA might respond with “T ell me more about your family.” \\nThe responses are usually in the form of a question or statement \\ndesigned to encourage further conversation.\\nAfter initial reservations, something extraordinary is happen-\\ning, as the scientists are opening up to this machine, sharing their \\ndeepest thoughts and emotions. ELIZA ’s ability to connect with \\npeople on a human level is simply astonishing. The demo ends \\nand ELIZA has opened the door to a new world of possibilities, \\nwhere machines and humans can communicate in ways never \\nthought possible.\\nCould machines one day communicate with humans in a nat-\\nural, conversational way? What kind of impact would this have \\non society?\\nIt is officially agreed that ELIZA is the first chatbot that prop-\\nerly imitates conversations. ELIZA wasn’t the first bot that \\nexisted, but the first with the ripple effect in research. The first'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='28 GENERATIVE AI\\ntrials of bots date back to 1950. The field was too primitive to use \\nthe term chatbot, as there was no chat happening. 1950 was also \\nthe year Alan T uring proposed a test for describing machine intel-\\nligence. He titled his work “Computing Machinery and Intelli-\\ngence.” He wrote that if a machine can trick humans into thinking \\nit is human, then it has intelligence— the so-called Turing test. \\nT oday we have a much more refined idea of the T uring test, as we \\nare experiencing the performance of large language models \\n(LLMs) like ChatGPT . We see in detail what language models \\nare good at and where they lack skills, making it easy for us to \\nreveal them as nonhuman. Even though Alan T uring was decades \\nahead of his time, he wouldn’t have a way to imagine this. How-\\never, ELIZA was not good enough to pass the T uring test.\\nBy no means is Alan T uring an insignificant figure. Widely \\nregarded as the father of modern computing, T uring is best \\nknown for his work during World War II at Bletchley Park, the \\nFIGURE\\xa02.3 A conversation with the ELIZA chatbot.\\nSource: Wikimedia Commons / Public Domain'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 29\\ncodebreaking center established to decipher German messages. \\nThere, he led a team of codebreakers who cracked the Nazi \\nEnigma code, an accomplishment believed to have shortened the \\nwar by several years. Indeed, his name graces the T uring Award, \\noften referred to as the Nobel Prize for computing.\\nThe year 1955\\xa0 marked another pivotal moment in the  \\nevolution of AI, as the term “artificial intelligence” was coined  \\nby another heavyweight computer scientist, John McCarthy.  \\nAn American computer scientist, McCarthy co-authored the \\ngroundbreaking document that introduced the term artificial \\nintelligence (AI) alongside Marvin Minsky, Nathaniel Rochester, \\nand Claude E. Shannon on August 31, 1955. McCarthy described \\na field of study centered on creating machines capable of execut-\\ning tasks typically requiring human intelligence, such as reason-\\ning, learning, and problem-solving. As a testament to his immense \\ncontributions to the theory and practice of AI and the develop-\\nment of the programming language Lisp, McCarthy was hon-\\nored with the T uring Award in 1971. Indeed, Lisp holds a special \\nplace in AI history as it was specifically designed to support sym-\\nbolic processing— a cornerstone concept in artificial intelligence.\\nSymbolic processing is when a program uses words, num-\\nbers, and other symbols to do things that generally require \\nhuman thinking. Just like how we use letters and numbers to \\nwrite words and sentences, computers use symbols to represent \\ninformation and then use special rules to do things with that \\ninformation.\\nLisp was widely used in the development of expert systems \\nand other AI applications, not only because of its symbolic pro-\\ncessing but also because it is a high-level programming language. \\nThis means it uses syntax that is closer to natural language, and \\noften includes features like variables, functions, and control \\nstructures that allow programmers to write complex programs \\nmore easily. For example, Python, Java, C++, and Ruby are'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='30 GENERATIVE AI\\nhigh-level programming languages, whereas machine code and \\nassembly code are low-level. T rying to read it the first time is a \\nsure way into headache land.\\nIn the field of AI, there was a lot happening in the 1940s and \\n’50s. Another result of the momentum in AI research is the mul-\\ntilayer perceptron first implemented in 1957 by Frank Rosen-\\nblatt. Inspired by the human brain and built on top of McCulloch \\nand Pitts’s theoretical invention of the perceptron in 1943, the \\nmultilayer perceptron (MLP) paved the way for neural networks. \\nIt has one input layer, a few in layers, and an output layer of \\ninterconnected nodes called neurons. Each layer is a step that \\nprocesses the output of the previous layer to gradually build up a \\nmore complex representation of the input data. The MLP is \\ntrained in an iterative fashion via, for example, backpropagation, \\nwhich adjusts the weights and biases of the neurons to minimize \\nthe difference between the network’s output and the desired out-\\nput, as described in Chapter\\xa01, “AI in a Nutshell.”\\nSo far, all set for AI takeoff. However, winter was coming. An \\nAI winter to be precise. T o be even more precise, an AI ice age, as \\nit spanned the late 1970s and early 1980s. It was triggered by a \\ncombination of factors, including unrealistic expectations about \\nthe capabilities of AI systems, a lack of progress in the develop-\\nment of AI technologies, and a reduction in government funding \\nfor AI research. In addition, some AI researchers were skeptical \\nof the dominant approaches to AI at the time, resulting in no \\nconfidence, no developments, and no money.\\nAnd, as if this were not enough, there was a second AI winter \\nfollowing in the late 1980s and early 1990s, with no ground-\\nbreaking achievements in between the winters. Both AI winters \\nwere caused by a similar combination of factors; plus, there was \\na shift in research funding toward other areas, such as the Inter-\\nnet and biotechnology. In addition, there was a growing percep-\\ntion among some researchers that AI was overhyped and that'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 31\\nprogress in AI was unlikely without significant breakthroughs in \\nareas such as natural language processing (NLP) and knowledge \\nrepresentation.\\nDuring this low point of AI, a then nameless research scien-\\ntist proposed a very interesting idea that carried a lot of weight \\nin the development of AI. The convolutional neural network \\n(CNN) was first proposed by Yann LeCun and his team in 1989. \\nTheir convolutional layers are conceptually scanning images and \\nmaking sense of them. Over multiple layers, they abstract detailed \\nimages. For example, the first convolution identifies straight \\nlines. In the second convolution, these lines can become curves. \\nIn the third convolution layer, curves become eyes, whereas other \\nlayers represent ears and a nose. In the final layer, based on all \\nthe facial features, the decision is clear. It’s a Chihuahua! LeCun \\nand his colleagues developed the first practical implementation \\nof CNNs, which was used for handwritten digit recognition and \\nachieved state-of-the-art performance on benchmark datasets. \\nAmong all deep learning architecture, CNNs has had probably \\nthe most industry impact since then. The vast majority of com-\\nputer vision (CV) applications are based on CNNs. Like the per-\\nceptron, CNNs  proved to be a crucial step in the evolution of AI \\nand generative AI later on.\\nBoltzmann\\xa0Machines\\nBack to generative AI. The first significant machine learning \\narchitecture, which is an important precursor to later models, \\nwas the Boltzmann machine, which was introduced in the 1980s \\nas a neural network that could learn and generate data from a \\nprobability distribution. For this, the data distribution needs to \\nbe stable, which means that there is a low degree of variability. \\nThis helps the Boltzmann machines to learn and represent'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='32 GENERATIVE AI\\ncomplex patterns. If the data is unstable, the generated samples \\ngenerated by the Boltzmann machine are inaccurate or incon-\\nsistent, and the training is generally inefficient. The way a Boltz-\\nmann machine generates data is close to modern generative \\nAI models.\\nIn Boltzmann machines there are hidden, invisible neurons \\nthat take binary states, either at 1 or 0, “on” or “off   ” (Figure\\xa02.4). \\nT o generate a new data sample, the network is initialized with \\nrandom values for the visible units, and then a series of alternat-\\ning Gibbs sampling steps are performed. In Gibbs sampling, the \\nnodes in the Boltzmann machine are updated one at a time, while \\nkeeping the other nodes fixed. The probability of a node being \\n“on” or “off   ” is determined by the current state of the other \\nnodes in the network. This process is repeated many times, \\nresulting in a sample from the probability distribution of the \\nBoltzmann machine. By generating many such samples, the \\nmodel can learn the underlying distribution of the input data. \\nGibbs sampling is an iterative process that gradually improves \\nthe quality of the samples, allowing the model to converge on a \\nstable distribution. The final state of the visible units represents \\na new data sample that has been generated by the Boltzmann \\nmachine. This process can be repeated to generate multiple new \\nsamples from the learned probability distribution. Even though \\nBoltzmann machines have the capabilities to generate data, in \\nthe early days of these machines they were primarily used as a \\ntool for exploring the properties of complex systems, rather than \\nfor generating data.\\nThe standard Boltzmann machine was a blueprint for other \\nneural network architectures that have contributed to the evolu-\\ntion of modern generative AI. But before we shed light on that, \\nanother headline has dominated the news about AI for quite \\nsome time.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 33\\nDeep Blue\\nIn 1997, the world watched in awe as a chess-playing computer \\nnamed Deep Blue (Figure\\xa02.5), created by IBM, faced off against \\nthe reigning world chess champion, Garry Kasparov (Figure\\xa02.6). \\nThis was the first time in history that a machine had challenged \\na human being at the game of chess on such a grand stage.\\nThere was much speculation as to whether a machine could \\never defeat a human being in a game as complex and strategic as \\nchess. Many believed that Kasparov, widely regarded as one of \\nthe greatest chess players of all time, would easily defeat Deep \\nBlue and prove once and for all that machines could never truly \\nrival human intelligence.\\nHowever, as the match progressed, it became clear that Deep \\nBlue was a formidable opponent. The computer, which had been \\nspecially programmed to play chess using advanced algorithms \\nand machine learning techniques, was able to analyze millions of \\nHidden Nodes\\nVisible Nodes\\nFIGURE\\xa02.4 Boltzmann machine concept'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='34 GENERATIVE AI\\npossible moves per second and make decisions based on complex \\npatterns and strategies.\\nDespite his best efforts, Kasparov was unable to outmaneu-\\nver the machine, and in the end, Deep Blue emerged victorious. \\nThe result was a stunning upset, and it sent shockwaves through-\\nout the world of chess, artificial intelligence, and the world.\\nThe match between Deep Blue and Kasparov marked a turn-\\ning point in the history of AI, capturing the imagination of the \\nFIGURE\\xa02.5 Deep Blue, a computer similar to this one, defeated chess \\nworld champion\\xa0Garry Kasparov in May 1997.\\nSource: James the photographer / Wikimedia Commons / CC BY 2.0.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 35\\nworld and sparking a new era of innovation and discovery. It was \\na moment that would be remembered for years to come, and it \\nlaid the foundation for a future in which machines and humans \\nwould continue to push the limits of what is possible.\\nEven though Deep Blue’s victory over Kasparov was per -\\nceived as an excellent case for AI that unlocked interest and fund-\\ning, I see it more as a case for computational power. The \\nunderlying machine learning algorithms of Deep Blue were not \\nrevolutionary; rather, it was Deep Blue’s power to process all \\npossible moves and choose the best. However, sometimes it’s not \\nabout technical truth, but perception.\\nRestricted Boltzmann Machines\\nIn 2006 Geoffrey Hinton and his team developed a variant of \\nBoltzmann machines as a solution to the problem of inefficient \\nFIGURE\\xa02.6 Garry Kasparov.\\nSource: S.M.S.I., Inc / Wikimedia Commons / CC BY-SA 3.0.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='36 GENERATIVE AI\\ntraining— restricted Boltzmann machines (RBMs). RBMs restrict \\nthe connections between neurons to only occur between visible \\nneurons and hidden neurons (Figure\\xa02.7). Visible neurons repre-\\nsent the input data, whereas hidden neurons represent the fea-\\ntures that RBMs learn to represent the input data. This restriction \\nmakes RBMs computationally more efficient and easier to train. \\nOn a conceptual level, the Boltzmann machine and the restricted \\nBoltzmann machine aren’t significantly different. Nevertheless, \\nthere’s a gap of 24 years between their development. Back then, \\ndevising the restricted Boltzmann machine algorithm might not \\nhave been straightforward, and in reality, its intricacies run \\ndeeper than one might initially realize.\\nOnce the RBM is trained, it can be used for a variety of tasks \\nin discriminative AI and generative AI, such as classification, \\nregression, or generating new data samples.\\nSo, media attention has been captured, but on the algorithm \\nsite, there was still a lot to be done. While in the conventional \\npart of AI a lot of progress has happened, especially with neural \\nnetworks, generative AI hasn’t enjoy much attention.\\nThey were only a few research scientists who were popular -\\nizing and promoting generative models like Boltzmann machines \\nVisible units\\nHidden units\\nFIGURE\\xa02.7 Concept of restricted Boltzmann machines.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 37\\nand others. Yann LeCun was one of them and Geoffrey Hinton \\nwas another.\\nLike LeCun, Hinton is regarded as one of the AI superstars. \\nIn 1978 he was awarded a PhD in AI. T oday he is a professor at \\nthe University of T oronto and a researcher at Google Brain. He \\nis considered to be one of the fathers of deep learning, as he \\ntogether with other colleagues developed the backpropagation \\nalgorithm for training neural networks. He won numerous \\nawards for his work before he also received the prestigious T uring \\nAward in 2018. On Yann LeCun’s fun stuff page, he shares some \\nGeoffrey Hinton facts. One of them: “Geoff Hinton goes directly \\nto third Bayes”— a nerdy joke that refers to Bayes’ theorem, a \\nmathematical formula that calculates the probability of an event \\nbased on prior knowledge or information. It took me three nights \\nuntil I laughed.\\nHinton had a huge interest in Boltzmann machines. How-\\never, Boltzmann machines have a problem known as the sign \\nproblem, which makes it difficult to perform efficient learning due \\nto the sign of the weights in the neural network that the machine \\nis made of. Updating the weights, which is the learning, includes \\nthe product of the weights of the neurons. This product can be \\npositive or negative, leading to cancellation effects that make the \\nlearning process slow and inefficient.\\nDeep Belief Networks\\nIn 2006, Geoffrey Hinton and his colleagues, building on the \\nadvancements of RBMs, introduced the concept of deep belief \\nnetworks (DBNs). They stacked multiple RBMs or other unsu-\\npervised learning models to create a more powerful and efficient \\narchitecture.\\nThe deep in DBNs comes from stacking multiple layers of \\nRBMs, with each layer learning a more abstract representation'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='38 GENERATIVE AI\\nof the input data (Figure\\xa0 2.8). The training process of DBNs \\ntypically involves unsupervised pretraining using layer-wise \\ntraining, followed by supervised fine-tuning using backpropaga-\\ntion. This made DBNs effective in unsupervised feature extrac-\\ntion, as the layers learned to capture increasingly abstract features \\nfrom the input data. For example, when applied to image recog-\\nnition, DBNs could identify edges and textures in the lower lay-\\ners and more complex shapes and objects in the higher layers.\\nDBNs found applications in various fields such as image  \\nrecognition, NLP , and speech recognition. They marked a signifi-\\ncant difference from RBMs in that they learned hierarchical rep-\\nresentations with higher layers, capturing more abstract features, \\nwhereas RBMs only learned a single layer of features. Additionally, \\nDBNs employed backpropagation during the fine-tuning phase, \\nwhereas RBMs were solely unsupervised learning models.\\nInput\\nlayer\\nHidden\\nlayer 1\\nHidden\\nlayer 2\\nHidden\\nlayer 3\\nOutput\\nlayer\\nRBM 3\\nRBM 2\\nSource: Peltarion.com\\nRBM 1\\nFIGURE\\xa02.8 A deep belief network.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 39\\nInterestingly, DBNs played a crucial role in the resurgence of \\ndeep learning research in the mid-2000s. They were among the \\nfirst models to demonstrate the effectiveness of unsupervised \\npretraining for deep architectures. The introduction of DBNs \\nsparked renewed interest in the field of deep learning, leading to \\na wave of innovation and groundbreaking discoveries. Speaking \\nto fellow data scientists, this seems to be forgotten.\\nDeep Boltzmann Machines\\nThe journey of generative AI took yet another significant turn in \\n2009\\xa0 when Ruslan Salakhutdinov and Geoffrey Hinton intro-\\nduced deep Boltzmann machines (DBMs). DBMs were another \\nleap forward in generative AI, as they further enhanced the capa-\\nbilities of generative models.\\nDBMs, similar to DBNs, are hierarchical generative models \\nmade up of multiple layers of unsupervised networks, allowing \\nthem to model complex, high-dimensional data. They’re created \\nby stacking multiple RBMs, with each layer learning an increas-\\ningly abstract representation of the input data.\\nT raining DBMs is done using a two-step process: layer-wise \\npretraining, which involves training each layer of RBMs indepen-\\ndently, followed by fine-tuning using methods like contrastive \\ndivergence or persistent contrastive divergence. Contrastive diver-\\ngence is an optimization algorithm that minimizes the difference \\nbetween the input data distribution and the distribution learned \\nby the model, while persistent contrastive divergence maintains a \\nset of persistent samples that are updated throughout the training \\nprocess, making it more efficient.\\nDBMs have found applications across various fields, such as \\nimage recognition, NLP , and speech recognition, thanks to their \\nability to model complex data structures and learn abstract  \\nfeatures.\\nIn terms of architecture, both DBMs and DBNs stack multi-\\nple RBMs, but DBMs have undirected connections between all'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='40 GENERATIVE AI\\nlayers, whereas DBNs have directed connections between layers, \\nexcept for the top two layers, which have undirected connections.\\nThe generative process in DBMs and DBNs also differs. In \\nDBNs, the process is top-down, starting from the highest layer \\nand moving downward. For example, in image recognition, a \\nDBN might start with the high-level concept of an object and \\nwork its way down to the details. In contrast, DBMs sample from \\nthe joint probability distribution between visible and hidden \\nunits, allowing them to generate new data samples by taking into \\naccount the complex relationships between different features.\\nThe introduction of DBMs contributed to the growing inter-\\nest in the unsupervised learning and generative models that have \\ncontinued to shape the field of AI. This further highlights the \\nextraordinary impact of Hinton’s work and dedication to the \\nfield of AI, which has propelled generative models and deep \\nlearning to new heights.\\nAutoencoders\\nAs the field of AI continued to evolve, researchers explored new \\nand innovative ways to leverage the power of neural networks. \\nOne such development was the emergence of autoencoders \\n(AEs), a unique type of artificial neural network designed for \\nunsupervised learning tasks. Autoencoders caught the attention \\nof the AI community for their ability to learn efficient represen-\\ntations of data, as well as their potential to transform the land-\\nscape of generative AI.\\nThe structure of autoencoders consists of two main parts: an \\nencoder, which compresses input data into a lower-dimensional \\nlatent representation, and a decoder, which reconstructs the \\noriginal data from the latent representation (Figure\\xa0 2.9). For \\nexample, imagine an autoencoder trained to process images of \\nhandwritten digits. The encoder could compress the input image'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 41\\ninto a compact numeric representation, while the decoder would \\nattempt to generate an image resembling the original input based \\non this compressed representation.\\nAutoencoders aim to minimize the difference between the \\ninput data and the reconstructed output, usually by optimizing a \\nloss function like mean squared error or cross-entropy. In our \\nhandwritten digit example, the autoencoder would seek to mini-\\nmize the differences between the original input image and the \\nreconstructed image produced by the decoder, thereby learning \\nthe most efficient way to represent and reconstruct the data.\\nAutoencoders have found a variety of practical applications, \\nsuch as denoising, anomaly detection, and data compression. In \\ndenoising, an autoencoder can be trained to remove noise from \\nimages, effectively “cleaning” them up. For anomaly detection, \\nautoencoders can be employed to identify unusual patterns  \\nin data, such as detecting fraudulent credit card transactions. In \\ndata compression, autoencoders can be used to reduce the size  \\nof data files while still maintaining their essential information.\\nCode\\nInput Output\\nredoceDredocnE\\nFIGURE\\xa02.9 The autoencoder architecture.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='42 GENERATIVE AI\\nWith the advent of deep learning, more complex, multilay-\\nered autoencoders have emerged, enabling the learning of intri-\\ncate data representations. These deep autoencoders are capable \\nof capturing hierarchical relationships within the data, leading to \\neven more powerful applications.\\nOne notable use of autoencoders is in visualizing high-\\ndimensional data in lower-dimensional spaces, allowing for eas-\\nier interpretation and analysis of complex datasets. For instance, \\na deep autoencoder could be utilized to reduce the dimensions of \\na dataset containing gene expression data, making it possible for \\nresearchers to visualize and understand the relationships between \\ndifferent genes more easily.\\nThe history of autoencoders spans several decades, with their \\napplication in generative AI truly taking off in the 2010s, primar-\\nily due to advancements in deep learning. Autoencoders have \\ninspired other powerful generative models, such as variational \\nautoencoders (VAEs), which have been applied to generate new \\nimages, text, and other data types by sampling from the learned \\nlatent space. This development marked a significant leap in the \\nevolution of AI, opening up new possibilities for the future of \\nmachine learning and artificial intelligence.\\nVariational Autoencoders\\nIn 2013, the world of generative AI saw a significant advance-\\nment by the introduction of VAEs by Kingma and Welling in \\ntheir paper “Auto-Encoding Variational Bayes.”1 VAEs are built \\non the foundation laid by autoencoders, which are neural net-\\nworks that learn to encode input data into a lower-dimensional \\nrepresentation and then decode it back to the original input. \\n1Diederik Kingma and Max Welling, “Auto-Encoding Variational Bytes,” arXiv, December 10, 2022, https://\\narxiv.org/pdf/1312.6114.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 43\\nAutoencoders played a key role in the development of VAEs by \\nproviding a foundation for unsupervised learning and dimen-\\nsionality reduction.\\nUnlike traditional autoencoders, VAEs introduced a proba-\\nbilistic framework, modeling the input data using a continuous \\nprobability distribution. This enabled more diverse and realistic \\nsample generation, a significant milestone in the evolution of \\ngenerative AI. VAEs consist of two main components: an encoder, \\nwhich maps input data to a latent space, and a decoder, which \\nreconstructs the input data from the latent space (Figure\\xa02.10).\\nVariational inference played a crucial role in the success of \\nVAEs, as it was used to approximate the true posterior distribu-\\ntion of the latent variables, enabling efficient learning and sam-\\npling. For the first time, true generative capabilities were \\nunlocked, allowing AI models to generate new images by inter -\\npolating between existing data points in the latent space, such as \\ncreating entirely new faces by blending features of existing faces.\\nVAEs found applications across various fields, such as image \\ngeneration, text generation, drug discovery, and anomaly detec-\\ntion. For instance, VAEs have been used to generate realistic 3D \\nInput Output\\nEncoder Decoder\\nCode\\n/uni03BC\\n/uni03C3\\n/uni03F5\\nFIGURE\\xa02.10 The variational autoencoder architecture.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='44 GENERATIVE AI\\nmodels of molecules for drug discovery, accelerating the process \\nof finding new treatments for diseases.\\nWomen in Generative AI History\\nBorn in various eras, numerous exceptional women have left \\ntheir mark on the broader field of AI. Ada Lovelace, Grace  \\nHopper, Elaine Rich, and Daphne Koller are just a few who have \\nmade substantial contributions. However, pinpointing outstand-\\ning women who specifically impacted early generative AI is chal-\\nlenging due to the historical gender imbalance in the field. \\nNevertheless, several women have made remarkable contribu-\\ntions to AI areas indirectly connected to generative AI or laid the \\ngroundwork for the development of generative AI techniques.\\nFor instance, Pamela McCorduck, an author and AI histo-\\nrian, chronicled the history of AI in her influential book Machines \\nWho Think, published in 1979. She provided valuable insights \\ninto the evolution of generative AI over the years. Cognitive psy-\\nchologist Eleanor Rosch, active in the 1970s, developed proto-\\ntype theory, which asserts that human categorization is based on \\nprototypical examples rather than strict rules. Rosch’s work indi-\\nrectly impacted the development of generative AI, as her insights \\non human cognition informed AI model structure and data gen-\\neration methods.\\nCynthia Breazeal’s research, primarily focused on social \\nrobotics during the late 1990s and early 2000s, laid the ground-\\nwork for AI systems generating human-like responses and behav-\\niors. By creating robots capable of interacting and communicating \\nwith humans, such as Kismet, Breazeal made an indirect yet sig-\\nnificant contribution to the generative AI domain.\\nIn 2009, Fei-Fei Li co-developed ImageNet, a large-scale \\nimage database crucial for advancing deep learning. Although \\nthe modern generative AI era, marked by advancements like'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 45\\ngenerative adversarial networks (GANs), began around 2014, \\nLi’s work on ImageNet facilitated these advancements by sup-\\nplying the necessary data and infrastructure for training deep \\nlearning models.\\nIt is essential to acknowledge the historical gender imbalance \\nin the field of AI and promote increased diversity and inclusion \\nin AI research moving forward. While there are many official \\nfemale contributors, numerous unofficial ones have gone unmen-\\ntioned for their contributions in the past. By recognizing and \\ncelebrating these women, we can work toward a more equitable \\nfuture in AI research, ultimately leading to more diverse perspec-\\ntives and innovative solutions in the realm of generative AI.\\nGANs: The Era of Modern Generative AI Begins\\nIn 2014, just a year after the variational autoencoder caught the \\nattention of the AI community, a 27-year-old research scientist \\nnamed Ian Goodfellow revolutionized the AI landscape. Along \\nwith his team, Goodfellow developed a groundbreaking approach \\ncalled generative adversarial networks (GANs), ushering in a \\nnew era of modern generative AI. This innovative technique took \\nthe AI world by storm, but it didn’t come without its challenges.\\nGoodfellow’s exceptional mind and relentless determination \\npropelled him to the forefront of AI research. Beginning his aca-\\ndemic journey at Stanford University, he earned his bachelor’s \\nand master’s degrees in computer science under the guidance of \\nAndrew Ng, a renowned AI expert and cofounder of Coursera. \\nGoodfellow later pursued his PhD in machine learning at the \\nUniversité de Montréal, supervised by Y oshua Bengio, a pioneer \\nin deep learning, and Aaron Courville, an esteemed AI researcher.\\nGoodfellow was surrounded by top-tier mentors, and his \\ncareer trajectory was nothing short of extraordinary. Alongside \\nBengio and Courville, he co-authored the MIT textbook Deep'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='46 GENERATIVE AI\\nLearning, which quickly became a staple resource in the field. His \\nnumerous accolades include being named one of MIT T echnology \\nReview’s 35\\xa0Innovators Under 35.\\nGoodfellow’s career took him to prestigious institutions like \\nGoogle Brain, OpenAI, Google Research, and Apple, where he \\nserved as a director of machine learning in the Special Projects \\nGroup. However, he never shied away from standing up for his \\nprinciples. In April 2022, Goodfellow resigned from his lucrative \\nposition at Apple to protest the company’s in-person work \\nrequirements for employees. His next step took him to Google \\nDeepMind as a research scientist, demonstrating his unwavering \\npassion for AI research.\\nHow GANs Work\\nSo, how do GANs work? In a two-step process involving training \\nand production, the crux of the magic unfolds during  \\nthe training phase. The brilliance of GANs lies in their dual- \\ncomponent structure, comprising a generator that meticulously \\ncrafts new data samples and a discriminator that determines the \\nauthenticity of said samples. T o create images, for instance, the \\ngenerator employs a deconvolutional neural network, transform-\\ning noise into data samples, whereas the discriminator relies on a \\nconvolutional neural network to classify images as genuine or \\ngenerated (Figure\\xa02.11).\\nThe essence of adversarial training involves the generator \\nattempting to deceive the discriminator with lifelike creations, \\nwhile the discriminator strives to differentiate between the \\nauthentic and the artificial. Should the generated data be detected \\nas such, the generator must update its trainable parameters; like-\\nwise, if the generated data is not detected, the same process occurs \\nfor the discriminator. This dynamic propels both components'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 47\\nto improve until they reach the Nash equilibrium— a point  \\nwhere neither can gain an advantage by changing their strategy. \\nReaching Nash equilibrium is a necessary condition for good \\nperformance.\\nAfter training, the generator, now at its peak performance, is \\nfrozen and subsequently employed for generating the respective \\ndata. With the ability to produce highly realistic and intricate \\ndata samples, such as images, text, and audio, GANs have sparked \\na revolution in numerous fields, ranging from art and design to \\nscientific research and beyond. The true potential of generative \\nmodels and their capacity to transform our interactions with \\ntechnology has been unveiled.\\nThe applications of GANs are astoundingly diverse, with \\nuses such as\\n• Generating strikingly realistic images of faces, animals, and  \\nobjects\\n• Image-to-image translation, morphing simple sketches into \\nvibrant masterpieces\\n• Super-resolution, rejuvenating low-quality images by enhanc-\\ning their resolution\\nReal\\nFake\\nReal-world\\nImages\\nLatent\\nVariable\\nLOSSDiscriminator\\nGenerator\\nSample\\nSample\\nFIGURE\\xa02.11 The generative adversarial network architecture.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='48 GENERATIVE AI\\n• Data augmentation, producing additional training samples \\nfor machine learning models\\n• Style transfer, which imbues one image with the artistic \\nessence of another image\\nWith GANs, the landscape of AI, and even other fields, like \\nphysics, are continually evolving, opening up a world of endless \\npossibilities.\\nGAN Challenges\\nThe inception of GANs was no small feat. The groundbreaking \\nconcept of pitting two networks against each other not only rev-\\nolutionized deep learning but also introduced a host of new chal-\\nlenges. The delicate balance of power between these networks \\nhinges on factors such as hyperparameters, architecture, and \\ntraining methods. If any one of these elements is off kilter, one \\nnetwork may overpower the other, resulting in training stagna-\\ntion due to insufficiently differentiated feedback.\\nNavigating the complexities of GANs also involves address-\\ning issues like mode collapse, vanishing gradients, and internal \\ncovariate shifts. In simple terms, mode collapse occurs when the \\ngenerator becomes fixated on producing a limited variety of out-\\nputs, hindering its ability to generate diverse samples. Vanishing \\ngradients, on the other hand, refer to the dwindling gradients \\nthat arise during backpropagation, making it difficult for the net-\\nworks to learn effectively. Lastly, internal covariate shifts pertain \\nto the inconsistencies in the distribution of layer inputs during \\ntraining, which can hamper the overall learning process.\\nSince 2014, the landscape of GAN variations has expanded \\nexponentially, now approaching nearly 9,300\\xa0iterations, each tai-\\nlored to tackle a specific challenge. Although newer GAN models'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 49\\nhave grown more sophisticated, the initial breakthrough was made \\npossible by the efforts of Ian Goodfellow and his colleagues.\\nGoodfellow’s dedication and expertise laid the foundation \\nfor a transformative technology that has since become a corner-\\nstone of AI. As GANs continue to influence the future of artifi-\\ncial intelligence, Goodfellow’s remarkable career serves as a \\npowerful reminder of the potential unleashed through determi-\\nnation, collaboration, and innovation.\\nFrom Pixels to Perfection: The Evolution of AI \\nImage Generation\\nAs a visually compelling field, it’s no wonder that AI image gen-\\neration has garnered widespread attention. The rapid progress, \\ncombined with the ease of grasping its potential, makes the gen-\\nerative AI story captivating to tell.\\nT o achieve what was once deemed unattainable, generative AI \\nimage generation demanded remarkable algorithms and innova-\\ntive technical ideas. The secret sauce that AI needed to generate \\nexceptional images emerged from the evolution of autoencoders, \\nGANs, and diffusion models.\\nInitially, autoencoders demonstrated prowess in reconstruct-\\ning images. However, as deterministic models, they lacked true \\nimage generation capabilities. Deterministic, in this context, \\nmeans that given the same input data, an autoencoder will con-\\nsistently produce the same output.\\nThe introduction of the variational component in the form \\nof variational autoencoders marked a turning point for these \\nmodels, granting them genuine generative potential. With vari-\\national autoencoders, AI began to yield promising results in gen-\\nerating images and faces. Y et, it was the arrival of GANs that \\npropelled image generation quality to new heights.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='50 GENERATIVE AI\\nGANs for Image Generation\\nGANs have emerged as a formidable force in the realm of image \\ngeneration. As they learn the distribution of a given dataset, their \\nflexibility allows them to generate a wide array of images, from \\nrealistic photographs and abstract art to depictions of nonexist-\\nent objects or creatures. However, their architecture, which sug-\\ngests parallel data generation, is not traditionally suited for \\nsequential data generation, such as text.\\nT o bridge this gap, images and their captions can be com-\\nbined in their respective vector embeddings. Vector embeddings \\nare representations of images or pieces of text as a vector of num-\\nbers, capturing the semantic meaning of the input in a compact \\nand useful form for downstream machine learning tasks. By inte-\\ngrating text and image representations through vector embed-\\ndings during GAN training, the image generation process \\nbecomes steerable via text. This groundbreaking functionality \\nenables the seamless fusion of images and styles.\\nOne of the remarkable attributes of GANs is their ability to \\ngenerate images without labeled training data, as they inherently \\nunderstand the original data distribution. Additionally, GANs \\ncan be trained progressively, commencing with low-resolution \\nimages and gradually enhancing resolution over time. This \\napproach ensures that the generator learns to create increasingly \\ndetailed and realistic images as training advances.\\nThe surge of research interest in GANs has sparked numer-\\nous innovations. Here are some notable examples:\\n• In 2016 and 2017, Wasserstein GAN (WGAN) and progres-\\nsive growing of GANs (ProGAN) enhanced GAN training \\nstability, allowing for the generation of higher-resolution \\nimages with improved quality.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 51\\n• In 2018, BigGAN pushed the boundaries of GAN-generated  \\nimage quality and resolution, creating high-fidelity images \\nup to 512×512 pixels in size, boasting more realistic and \\ndiverse content.\\n• Between 2019 and 2021, StyleGAN emerged as a state-of-\\nthe-art image generator, providing fine-grained control over \\nstyle and content. This enabled impressive results in face \\ngeneration and other domains.\\nCLIP\\nWhile GANs have made substantial progress in generating \\nimages based on textual descriptions, they occasionally yield \\nresults that lack consistency with the text or the desired level of \\ncontrol. In January 2021, OpenAI introduced an innovative neu-\\nral network model called CLIP (Contrastive Language-Image \\nPre-T raining) to bridge this gap.\\nCLIP , bridging the gap between NLP and CV , is pretrained \\non a vast dataset of over 400\\xa0million image-text pairs. With an \\nobjective to create a joint representation of images and text, it \\nuses contrastive pretraining to distinguish between similar and \\ndissimilar pairs. This approach helps CLIP relate relevant text to \\nimages, even when the text doesn’t directly describe the visual \\ncontent. In a subsequent step, the model encodes images and text \\ninto a shared space through an image encoder and a text trans-\\nformer. The goal is to amplify the similarity of genuine image-\\ntext pairs and reduce it for mismatched pairs, thereby boosting \\nits efficiency. Figure\\xa02.12 shows the three main steps of its train-\\ning process. The ability of CLIP to comprehend the meaning of \\na text in relation to images has unlocked new possibilities for \\nfusing NLP and CV .'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='52 GENERATIVE AI\\nAs a powerful tool for tasks requiring an understanding of \\nthe relationship between text and images, CLIP surpasses GANs \\nfor several reasons:\\n• CLIP allows for more fine-grained control over image gen-\\neration, enabling users to specify desired attributes such as \\ncolor or orientation.\\n• CLIP can work with multiple modalities, including images, \\ntext, and audio, paving the way for more intricate and \\nnuanced generation tasks.\\n• CLIP has demonstrated excellent generalization to unseen \\ndata, meaning it can generate high-quality images consistent \\nwith textual descriptions, even when the images are not seen \\nduring training.\\nThe impact of CLIP on the AI community has been immense. \\nInfluencing other models like DALL-E and Stable Diffusion, \\nCLIP has spurred research in text-to-image models and popu-\\nlarized the contrastive pretraining method.\\nImage 1 Image\\nCLIP\\nText\\nEmbed image\\nand text\\nCompare the\\nembeddings\\nPrediction Label\\n1\\n(Similar)\\n1\\n(Similar)\\n0\\n(Not similar)\\n0\\n(Not similar)\\nCaption 1\\nUpdate the\\nmodels321\\nImage\\nembedding\\nText\\nembedding\\nFIGURE\\xa02.12 Training of CLIP.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 53\\nDALL-E 2\\nBolstered by the success of CLIP and the advancements it has \\nspurred in the field of AI, research scientists have continued to \\npush the boundaries of what’s possible in a text-to-image genera-\\ntion. One such breakthrough, which has captured the world’s \\nattention, is OpenAI’s DALL-E 2.\\nOpenAI’s DALL-E 2\\xa0 was the talk of the town in summer \\n2022, setting the tech world abuzz with its jaw-dropping image \\ngeneration capabilities. A nearly solved problem, DALL-E 2 \\ngenerates astoundingly realistic images at higher resolutions, \\nadeptly blending concepts, attributes, and styles. It can manipu-\\nlate and rearrange objects within images, and is a maestro at \\nplacing design elements in innovative compositions.\\nDALL-E 2’s finesse lies in its ability to inpaint and outpaint \\nimages, generate variations, and transform aspects of images \\nusing text. Inpainting involves filling in missing or corrupted \\nparts of an image using surrounding information, whereas out-\\npainting, also known as image extrapolation, extends the content of \\nan image beyond its original boundaries.\\nOnce a nonprofit organization, OpenAI was established in \\n2015\\xa0with the noble objective of developing AI for the benefit of \\nhumanity. However, in 2018, the company made a controversial \\nshift to a for-profit model, raising concerns about conflicts of \\ninterest and the potential undermining of its original mission.\\nNowadays, OpenAI isn’t as open as it used to be. No longer \\nopen sourcing their models, the organization discloses only \\nselect information, which means we can discuss the models only \\nfrom a secondhand perspective.\\nT o understand DALL-E 2, picture a skilled artist who listens \\nto your description, captures the concept, and then produces a \\ndetailed, realistic image based on your vision. This wondrous'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='54 GENERATIVE AI\\ntechnology is built on two key innovations: CLIP , which we’ve \\ntouched upon before, and diffusion, which we’ll delve into shortly.\\nIn a nutshell, DALL-E 2 uses CLIP encoders to map inputs \\nto an embedding within a shared concept space, where matching \\npairs are mapped to nearby points and mismatching pairs are \\nmapped to distant ones. The diffusion model, which they call \\nGLIDE by the way, is trained to undo the steps of a fixed corrup-\\ntion or noising process, reversing the corruption or denoising \\nand regenerating erased information. More on this in a moment.\\nDALL-E 2’s prowess is showcased through a two-stage pro-\\ncess: First, the prior model generates a CLIP image embedding \\nfrom the given caption, capturing the gist of the image. Next, the \\ndiffusion model (unCLIP) generates the actual image from the \\nembedding, filling in the details.\\nThe advantages of this two-stage sampling process are evi-\\ndent: it prioritizes high-level semantics, making images more \\nmeaningful to humans, and allows for text-based transformations \\nusing CLIP’s multimodal embedding space. In the summer of \\n2022\\xa0DALL-E 2\\xa0was, without a doubt, a testament to the poten-\\ntial of generative AI and a harbinger of even greater advancements.\\nDiffusion Models\\nAs all of this evolves at a rapid pace, the open source ethos pro-\\npelling its growth has enabled both researchers and hobbyists \\nalike to explore and develop the capabilities of diffusion models.\\nJune 2021\\xa0marked a pivotal moment for image generation, as \\na publication emerged, revealing that diffusion models had sur -\\npassed GANs in their capabilities. This revelation piqued my \\ninterest and brought the potential of diffusion models into focus \\nfor the first time. Fast-forward 10\\xa0months, and OpenAI’s DALL-2,  \\nan image generation model based on the diffusion principle, has'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 55\\ntaken the world by storm, producing premium images that have \\nleft many astounded.\\nIn August 2022, another significant development in the field \\nof AI made headlines: Stability AI released Stable Diffusion, a \\nmodel capable of achieving outputs on par with DALL-E 2.  \\nT aking a different approach from its counterparts, Stability AI \\nastonished the tech community by open sourcing the model \\nalmost immediately. This model has been made accessible to all, \\nrunnable within a Python Notebook and on the Hugging Face \\nplatform. Hugging Face, a hub for sharing pretrained models, \\ndatasets, and demos of machine learning projects, promotes open \\nsource contributions and fosters a collaborative environment for \\nAI enthusiasts.\\nStability AI, under the leadership of CEO and founder Emad \\nMostaque, distinguishes itself by open sourcing AI technology— a \\nrarity among the few companies equipped with the resources and \\ntalent to develop it. Their mission is to democratize access to AI \\ntechnology and prevent its monopolization by major tech players.  \\nBeyond Stable Diffusion, they are working on projects such as \\nHarmonai, which focuses on open source generative audio tools, \\nand OpenBioML, a venture into the intersection of machine \\nlearning and biology. A vast and dedicated community has rallied \\nbehind Stability AI’s vision.\\nMostaque and his team are steadfast in their commitment to \\ncreating tools that empower individuals and grant them agency, \\na pursuit they believe can lead to a happier world and drive posi-\\ntive change. Stability AI, a well-capitalized startup, has garnered \\nfunding from Mostaque’s personal fortune, a $100\\xa0million invest-\\nment led by Coatue, and has plans to monetize by concentrating \\non specific domains, such as Bollywood.\\nDespite the general trend of keeping AI technology closed \\nsource— exemplified by OpenAI, ironically enough— it is both \\nrefreshing and challenging to see a company like Stability AI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='56 GENERATIVE AI\\nopen source its models. This strategy comes at the cost of relin-\\nquishing much of their competitive advantage, as anyone can \\ndownload a stable diffusion model, run it on some GPUs on-\\npremises or in the cloud, fine-tune it, and obtain a remarkable \\nimage generation model without paying Stability AI a single penny.\\nStable Diffusion Tech\\nDiffusion models stand at the forefront of innovation. What sets \\nthem apart is their unique methodology: introducing noise to \\nlearn the art of denoising, thereby unraveling the secrets of gen-\\nerating images. The results are nothing short of enchanting!\\nAs previously mentioned, the crux of the diffusion model lies \\nin its ability to add and remove noise from images. Picture this: \\nDuring the forward diffusion phase, noise is added to the image, \\nakin to static interference on a television screen. In the reverse \\ndiffusion stage the noise is eliminated, gradually revealing the \\nimage beneath the static. However, the pure diffusion model is \\nhampered by its sluggishness, especially when dealing with a \\nlarge number of diffusion steps or sizable images, as there are \\nsimply too many pixels to process.\\nEnter stable diffusion, a swifter alternative. This technique \\noperates within the latent space, which is essentially a compressed \\nversion of the image, much like a smaller, condensed file. This fam-\\nily of models is known as latent diffusion models. T o create the latent \\nspace, an autoencoder is employed, acting as a simplified version of \\nthe variational autoencoder mentioned earlier. The autoencoder’s \\nencoder compresses the image into lower-dimensional data, similar \\nto zipping a file, whereas the decoder decompresses the latent data \\nback into an image, akin to unzipping a file.\\nOne of the most remarkable features of stable diffusion is its \\nability to generate images from text prompts in a highly impressive'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 57\\nmanner. The diffusion model is adapted to accept conditioning \\ninputs, comparable to modifying a recipe based on a special request. \\nT ext inputs are transformed into embeddings (vectors) using a lan-\\nguage model, reminiscent of the process employed by CLIP .\\nFor inquisitive minds yearning to delve into stable diffusion, \\nlook no further than GitHub, where the code is easily accessible. \\nAdditionally, a web application has been thoughtfully designed \\nto offer a hands-on experience with this revolutionary model.\\nMidjourney\\nMidjourney is an AI image-generation company that has taken \\nthe world by storm. Its latest creation, Version 5, is renowned for \\ngenerating images of unparalleled quality, spanning from  \\nphotorealistic to a wide array of artistic and nonartistic styles. \\nHailed as the epitome of AI-generated artistry, Midjourney’s \\nimages are so remarkably lifelike that they have earned the title \\nof being “indistinguishable” from real photographs.\\nHowever, this near-perfect level of realism has raised eye-\\nbrows among AI art enthusiasts. Some have dubbed Midjour -\\nney’s creations as “creepy” and “too perfect.” The groundbreaking \\nimprovements in Version 5\\xa0include incredibly realistic skin tex-\\ntures, impeccably detailed facial features, cinematic lighting \\neffects, and striking reflections, glares, and shadows. The model \\nalso boasts more expressive angles or overviews of a scene, and— \\nperhaps most importantly— human hands now consistently dis-\\nplay the correct number of fingers.\\nAccessible through a Discord bot command, Midjourney’s \\nplatform was still in open beta as of December 2023. The com-\\npany’s trailblazing team, led by founder David Holz, has a track \\nrecord of releasing new and improved model versions every few \\nmonths. With a keen eye for innovation and a commitment to'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='58 GENERATIVE AI\\nconsistent progress, Midjourney has already achieved profitabil-\\nity. Artists worldwide employ the platform for rapid prototyping \\nof artistic concepts, while the advertising industry reaps the ben-\\nefits of quickly creating original content.\\nNevertheless, Midjourney remains vigilant about the images \\ngenerated by its platform. In a fascinating turn of events, the \\ncompany made headlines in March 2023\\xa0when it preemptively \\nblocked the generation of images depicting Xi Jinping. This \\nmove was taken to prevent potential censorship by the Chinese \\ngovernment. Holz said that “the ability for people in China to \\nuse this tech is more important than your ability to gener -\\nate satire.”2\\nThe enigmatic team behind Midjourney has kept their train-\\ning techniques under wraps. However, it’s very likely that they \\nmight use methods similar to stable diffusion, as its approach is \\nknown in detail. As AI-generated artistry evolves, the interplay of \\nideas and techniques among pioneers like Midjourney fuels pro-\\ngress and sparks anticipation for future revelations.\\nThe Importance of\\xa0Training Data\\nT raining data reigns supreme as the vital cornerstone of AI image \\ngeneration model performance. T ext-to-image models necessi-\\ntate sizable datasets, often procured by scouring the web for \\nimage-text pairs. However, this method bears inherent limita-\\ntions and biases, including toxic language, nudity, violence, and \\nharmful social stereotypes.\\nFor those desiring elite model performance and possessing \\nample budgets, the LAION-400M dataset is the gold standard. \\nSourced from Common Crawl web data, it amasses an impressive \\n2Christopher McFadden, “Midjourney will no longer let you generate images of Xi Jinping,” Interesting Engi-\\nneering, April 3, 2023, https://interestingengineering.com/culture/midjourney- bans- xi- jinping- images'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 59\\n413\\xa0million image-text pairs tailored for top-tier models. T o ensure \\nsafety, filters can be applied to regulate output, and models can be \\nretrained on custom datasets to minimize biases for specific use \\ncases. The operations are fueled by donations and public research \\ngrants. The team comprises 15\\xa0 members, although it remains \\nuncertain if all are engaged full-time.\\nMeanwhile, smaller AI image generation models like Craiyon— \\nalso known as DALL-E mini— trained on a mere 30\\xa0million images, \\nproduce fewer photorealistic images compared to their larger \\ncounterparts like stable diffusion. Here, strategic partnerships play \\na pivotal role, providing invaluable training data inaccessible to \\nothers. For instance, OpenAI’s strategic partnership with Shutter-\\nstock was instrumental in DALL-E’s development. Shutterstock is \\na marketplace for high-quality, royalty-free photographs, vectors, \\nillustrations, videos, motion graphics, and music.\\nAnother interesting dataset that merits attention is ImageNet.  \\nThis extensive image database is organized following the Word-\\nNet hierarchy, which, as of now, is confined to nouns. Each node \\nwithin this hierarchy is illustrated by hundreds, even thousands, \\nof images. The data is available at no cost to researchers for non-\\ncommercial purposes and comprises an impressive 14,197,122 \\nimages along with 21,841 synsets indexed. “Synsets” is short for \\n“synonym sets,” which are groups of words that mean the same \\nthing. In ImageNet, each synset is linked to a bunch of images \\nthat show the same thing. Conceived as a large-scale visual data-\\nbase, the ImageNet project is designed for use in the field of \\nvisual object recognition software research.\\nThough Midjourney remains tight-lipped about the datasets \\nutilized in training its model, whispers within the insider com-\\nmunity suggest that copyrighted artists’ work may have been \\nincluded. Despite the lack of official confirmation, Midjourney’s'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='60 GENERATIVE AI\\nperformance speaks volumes. Key speculations that stand out \\ninclude the following:\\n• Midjourney enhances prompts pregeneration and applies post-\\nprocessing to the image, resulting in its distinctive aesthetic.\\n• A carefully trained classifier model may evaluate and filter \\ngenerated content.\\n• Midjourney’s output is somewhat limited in terms of style, as \\nthey understand what works and what doesn’t.\\n• Most crucially, they meticulously curate their data, retaining \\nonly the most exquisite images— a testament to their unwa-\\nvering commitment to quality.\\nAs the tale of Midjourney continues to unfold, the world \\neagerly anticipates the next chapter in the company’s enigmatic \\njourney, as well as the innovations and revelations that are yet \\nto emerge.\\nAutoregression\\nGoogle is another significant player in the realm of generative \\nAI. Among their most notable models are the image generation \\nmodels Imagen and Parti. Imagen, a latent diffusion model, \\nshowcases Google’s expertise in diffusion models. Parti offers an \\nimpressive performance through a different approach to image \\ngeneration— autoregression. Although this method is sequential \\nrather than parallel, it is worth delving into autoregressive mod-\\nels for image generation. As you shall see, they play a crucial role \\nin this field.\\nEnter Parti, Google’s answer to DALL-E 2, which began  \\nwith the publication of “Scaling Autoregressive Models for'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 61\\nContent-Rich T ext-to-Image Generation.”3 Parti addresses text-\\nto-image generation as a sequence-to-sequence modeling prob-\\nlem, taking advantage of advances in LLMs. Employing  \\nthe Vision-T ransformer-based VQGAN (ViT-VQGAN) image \\ntokenizer, Parti encodes images as sequences of discrete tokens, \\nenabling the reconstruction of high-quality, visually diverse images. \\nThe result is state-of-the-art zero-shot and fine-tuned FID  \\n(Fréchet inception distance) scores on MS-COCO\\xa0 (Microsoft \\nCommon Objects in Context), with the model proving effective \\nacross a broad range of categories and difficulty aspects, as demon-\\nstrated in the Localized Narratives and PartiPrompts bench-\\nmark analysis.\\nIn essence, zero-shot refers to a model’s ability to perform a \\ntask without prior training or examples specific to that task. It \\nhighlights a model’s capacity to generalize and apply learned \\nknowledge from one context to another without the need for \\nadditional fine-tuning.\\nFID is a commonly used metric for evaluating the quality of \\ngenerated images. Picture it as a ruler measuring the distance \\nbetween two distributions of features extracted from real and \\ngenerated images. Lower FID scores signify that the generated \\nimages more closely resemble the real ones, thus indicating \\nhigher quality.\\nMS COCO is an extensive image recognition, segmenta-\\ntion, and captioning dataset, boasting over 330,000 images and \\nmore than 2.5\\xa0million object instances labeled with object cat-\\negories, instance segmentation, and dense captioning. Its \\nimportance in image generation research cannot be overstated, \\nas it provides a widely used benchmark dataset for assessing \\nthe quality and diversity of generated images. Numerous state-\\nof-the-art image generation models are evaluated using  \\n3Jiahui Yu et\\xa0al. “Scaling Autoregressive Models for Content-Rich T ext-to-Image Generation,” arXiv, June 22, \\n2022, https://arxiv.org/pdf/2206.10789.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='62 GENERATIVE AI\\nthe MS COCO dataset, and high scores on this benchmark \\nstrongly indicate the performance and generalization ability of \\nthe model.\\nAutoregressive models are undoubtedly innovative, achiev-\\ning remarkable results in both parallel and sequential data gen-\\neration. While they may have been underestimated in the past, \\nthey have brought about significant advancements in AI and \\ncould lead to further breakthroughs in the field. Perhaps their \\ntrue potential lies in supporting video generation and other  \\nyet-to-be-discovered applications in the realm of generative AI.\\nThe Future of AI Image Generation\\nAs the modern generative AI era unfolds, a plethora of models \\nhave emerged, including stable diffusion, Midjourney, DALL-E \\n2, Craiyon, Parti, Imagen, and others such as Night Café,  \\nArtbreeder, DeepAI, StarryAI, WOMBO Dream, and Bria \\n(which is targeted for business-to-business [B2B])— and even \\nearlier models like Google’s Deep Dream Generator. This pro-\\nliferation heralds a future teeming with mind-blowing technol-\\nogy. Improvements, innovations, trends, new paradigms, issues, \\nadoption, and applications of generative AI will persist and evolve \\nin the years to come, with AI image generators creating 2D, 3D, \\nand even 4D images based on text.\\nSimply put, 4D images represent changes over time— a \\nsequence of three-dimensional images depicting a transforming \\nobject or scene. Achievable through video capture, 3D modeling, \\nanimation, and machine learning, 4D images hold immense \\npotential. For instance, generative AI could revolutionize medi-\\ncal diagnostics by transforming X-rays and CT scans into realis-\\ntic, interactive images, allowing doctors, for example, to examine \\na broken rib from various angles.\\nAs generative AI platforms become increasingly prevalent, \\nimage generation as a standard functionality seems inevitable.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 63\\nEmad Mostaque’s theory posits that most image generation \\ncompanies will eventually converge in terms of AI capabilities. \\nHowever, this may not necessarily be true, as consistently excep-\\ntional personnel are required to push these hard tech boundaries, \\nand the diverse landscape of generative AI allows for countless \\nturns on the highway of innovation. Consider use case–specific \\nAI image generation: one focusing on training data for self-driving  \\ncars, another on medical imaging. Ultimately, this diversity \\nhinges on the training data each company obtains and potentially  \\ngenerates.\\nAssuming AI image generation models do eventually reach \\nsimilar capabilities and qualities in a profitable manner, compa-\\nnies must explore what’s next. In this innovative, competitive \\nspace with high expectations set by capital allocators, models will \\nlikely evolve into more capable, multimodal systems, eventually \\nculminating in artificial general intelligence. More on this fasci-\\nnating prospect will be explored later in the book.\\nLastly, generative AI companies must be nimble in pivoting \\ntheir strategies, even after expending significant energy on a par-\\nticular tech approach. As witnessed in AI image generation, many \\ncompanies initially doubled down on GANs, tweaking and refin-\\ning them to fit narrow use cases. However, the open source release \\nof stable diffusion— with its superior performance— prompted an \\nimmediate shift in strategy. In this ever-evolving landscape, adapt-\\nability and resilience are the hallmarks of success, as generative AI \\ncontinues to forge new frontiers in the world of technology.\\nA Crucial Tech Disruption: Text Generation\\nIn the realm of AI data generation, two primary streams have \\nemerged, each with its own unique capabilities: image generation, \\nwhich exemplifies parallel data generation, and text generation, \\nrepresentative of sequential data generation. These two distinct'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='64 GENERATIVE AI\\nstreams complement one another, paving the way for AI’s versatile \\napplications in various domains.\\nT ext generation models, being intrinsically adept at handling \\nsequential data, excel in generating not only written text but also \\nother forms of sequential data, such as code, music, voice, and \\nother auditory elements. Furthermore, they can generate time-\\nseries data, encompassing synthetic sensor data to enhance data-\\nsets, stock market data, and much more. A few examples include \\ncomposing original music pieces, simulating stock market trends, \\nand even generating realistic human speech, all thanks to the \\ninherent sequential nature of these models.\\nAs you delve further into this chapter, you will witness the \\ninnovative spirit of research scientists who achieved groundbreak-\\ning results. This creative triumph is best exemplified by the launch \\nof ChatGPT on November 22, 2022. Since then, LLMs have \\ntranscended mere hype, offering tangible value for businesses and \\nindividuals alike. My experience with GenerativeAI.net is a testa-\\nment to this, as I consult companies on leveraging language mod-\\nels for tailored applications, and as a leader at Infosys Consulting, \\nI guide teams in implementing this revolutionary technology, \\naccumulating an impressive array of client success stories and cre-\\ndentials. Our work with these organizations extends beyond sim-\\nple implementation; we help them harness the power of generative \\nAI to transform into AI-first companies.\\nAutoregression Models\\nIn the fascinating realm of text generation models, an overarch-\\ning player emerges: the autoregressive model. Whenever a model \\nuses a sequence of words or other sequences to predict the  \\nensuing words, we are witnessing the prowess of autoregression. \\nWhile this mechanism is not exclusive to text generation, it  \\ndominates the field. As we traverse through the landscape of text'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 65\\ngeneration, note that all models presented, except for rule-based \\nsystems and GANs, are autoregressive. However, we shall main-\\ntain our chronological approach.\\nOur journey takes us back to the early 20th century, when the \\nBritish statistician Yule first introduced autoregression models, \\nalso known as autoregressive models. These statistical marvels \\nutilize past values of a time series to forecast future values. When \\napplied to text generation, autoregression models astutely pre-\\ndict the next word or token, basing their deductions on the con-\\ntext of the preceding words in the sequence.\\nAutoregression models come in various orders, ranging from \\nthe elementary first-order model, AR(1), to more intricate vari-\\nants. AR(1) predicts the value of the time series at time ‘t’ by \\nrelying on its value at time ‘t-1’. Meanwhile, the more sophisti-\\ncated AR(p) models predict the time-series value at time ‘t’ by \\nconsidering values at times ‘t-1’, ‘t-2’, and so forth, up to ‘t-p’.\\nWhile these models are traditionally grounded in statistical \\nmethods, they have evolved to adapt to neural network architec-\\ntures such as recurrent neural networks (RNNs) and transform-\\ners. This adaptation has enabled them to capture more complex \\ndependencies, thus generating text that is not only coherent but \\nalso imbued with semantic meaning. The autoregressive model’s \\njourney from its inception to its modern adaptations reflects the \\never-evolving nature of AI, a testament to human ingenuity and \\nour drive to understand the intricacies of language.\\nMarkov Chains\\nBorn in Russia, Andrey Markov was a prodigious mathemati-\\ncian who, in 1906, introduced the world to Markov chains. His \\ngroundbreaking paper laid the foundation for the study of sto-\\nchastic processes, particularly those now called Markov chains. \\nAlthough they were far removed from text generation at the \\ntime, their potential in this area would soon be recognized.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='66 GENERATIVE AI\\nFast-forward to 1948\\xa0when Claude Shannon, an illustrious \\nmathematician and electrical engineer who later helped to coin \\nthe term artificial intelligence, presented a paper demonstrating \\nthe use of Markov chains in text generation. Shannon’s innova-\\ntive Markov chain model generated English text that echoed the \\nstyle and structure of natural English sentences. The model was \\ntrained on a corpus of text data, and it crafted new sentences by \\npredicting the next word based on the previous word.\\nMarkov chains, a type of statistical model, depict sequences \\nof events in which each event’s probability depends solely on the \\nstate of the system during the previous time step, not on earlier \\nevents. T o generate new text, Markov chains predict the next \\nword in a sequence based on the probability of each word, given \\nthe previous word. By training the model on a corpus of text \\ndata, the probabilities of each word given the previous word are \\nestimated. With an initial seed word or phrase, the model gener-\\nates new text by predicting the next word using the probability \\ndistribution and incorporating it into the sequence. Figure\\xa02.13 \\nshows an example.\\nChristmas Wish\\nClique\\n0.10\\n1.00\\n1.00\\n1.00 1.00\\n1.00 1.00\\n0.33\\n0.33\\n0.33\\n1.00\\n0.25\\n0.75\\n0.10\\n0.10\\n0.10\\n0.10\\n0.20\\n0.30\\nCold\\nColonyThe\\nCom\\nClient\\nColor\\nHeart\\nList\\nPurple\\nof\\na\\nCourage\\nLove:\\nKiller\\nStoryJacey’s\\nFIGURE\\xa02.13 A probability diagram of a Markov chain for text genera-\\ntion. Each node represents a state (word or sequence of words), and \\neach edge represents the transition probability from one state to \\nanother, as determined from the training text.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 67\\nAlthough Markov chains offer simplicity and computational \\nefficiency in text generation, their limitations lie in capturing long-\\nterm dependencies and generating coherent, semantically mean-\\ningful text. As such, Markov chains often serve as a baseline model \\nfor text generation tasks, whereas more advanced applications rely \\non sophisticated models like recurrent neural networks and \\n transformer-based models. Thus, Markov chains, while founda-\\ntional, represent just one stepping stone in the ever-evolving jour-\\nney of AI, as we strive to decode the complexities of language.\\nRule-Based Text Generation\\nPioneered in the 1980s, rule-based systems for text generation \\nmarked another significant milestone in text generation. These \\nsystems harnessed the collective knowledge of researchers and \\ndevelopers from various disciplines, including computer science \\nand linguistics. By employing sets of rules and handcrafted \\nknowledge, rule-based systems generated text with structure, \\ncontent, and style that adhered to linguistic principles.\\nIn essence, rule-based systems generate text by following \\nhandcrafted rules based on linguistic knowledge, such as gram-\\nmar rules and semantic relationships between words. For \\ninstance, the rules might dictate that a weather report should \\nbegin with a general statement about the overall weather condi-\\ntions, followed by specific details about temperature, precipita-\\ntion, and wind.\\nThese rule-based systems have been used for various applica-\\ntions, including weather reports, financial reports, and medical \\nreports. They remain relevant even today in specific domains \\nthat require standardized text output. For example, rule-based \\nsystems have been employed to generate personalized medical \\nreports for patients, summarizing their symptoms, diagnoses, \\nand treatment plans in a clear, concise manner. The quality of the \\ngenerated text is contingent on the quality and accuracy of the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='68 GENERATIVE AI\\nrules, which demand considerable domain expertise and manual \\neffort to develop.\\nAlthough rule-based systems have their merits, they are \\ninherently limited in generating novel or creative text. Their \\nstrength lies in producing standardized or formulaic text,  \\nwhere adherence to linguistic rules and conventions is of para-\\nmount importance. Consequently, rule-based systems, much like \\nMarkov chains, form an essential part of the ever-evolving AI \\njourney, as we endeavor to unravel the complexities of language \\nand craft increasingly sophisticated text generation models.\\nRecurrent Neural Networks\\nBuilding upon the foundations laid by rule-based systems and \\nMarkov chains, recurrent neural networks (RNNs) emerged in \\nthe early 1980s, thanks to the pioneering work of John Hopfield \\nand David Rumelhart. Both Hopfield and Rumelhart were lead-\\ning figures in the realm of AI, with Hopfield renowned for his \\ncontributions to neural networks and Rumelhart for his work on \\nparallel distributed processing— a great team fit.\\nRNNs are a type of neural network designed to process \\nsequential data by maintaining an internal state that captures the \\ncontext of previous inputs. In text generation tasks, RNNs com-\\nmonly predict the next word or token based on the context of \\npreceding words in the sequence. By processing the input \\nsequence one token at a time and updating its internal state at \\neach step based on the input token and the previous state, RNNs \\neffectively encapsulate a summary of prior inputs. This internal \\nstate is instrumental in predicting the next output. Figure\\xa02.14 \\nillustrates an unrolled RNN, and Figure\\xa0 2.15 showcases the \\ndeceptively simple mechanics of a standard RNN unit. A layer is \\nquite straightforward.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 69\\nRNNs have found widespread applications in natural lan-\\nguage processing, including language translation, dialogue gen-\\neration, and sentiment analysis.\\nHowever, RNNs are not without their limitations. They \\noften grapple with the vanishing gradient problem, which hin-\\nders their ability to capture long-term dependencies, akin to \\nlong-term memory. This issue can lead to degraded performance, \\nrendering RNNs impractical for large-scale applications. T o \\naddress this challenge, researchers have developed variants of \\nRNNs, such as long short-term memory (LSTM) networks and \\ngated recurrent units (GRUs). Both LSTMs and GRUs excel at \\ncapturing long-term dependencies, enabling the generation of \\nmore coherent and semantically meaningful text.\\nA\\nX2X1X0Xt Input\\nOutput\\nXt...\\n=A AAA\\n0t 00 01 02 0t\\nFIGURE\\xa02.14 A recurrent neural network unrolled.\\nXt-1 Xt+1Xt\\nAA\\nOutput\\nInput\\nOt-1 Ot+1Ot\\ntanh\\nFIGURE\\xa02.15 A standard RNN unit.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='70 GENERATIVE AI\\nLSTMs typically outperform GRUs, making them the pre-\\nferred choice for many applications. As a result, we will bypass \\nGRUs and delve directly into LSTMs, looking at their capabili-\\nties and potential.\\nLong Short-Term Memory Networks\\nLong short-term memory (LSTM) networks first appeared on \\nthe AI scene in 1997, thanks to the innovative work of Sepp \\nHochreiter and Jürgen Schmidhuber, two researchers known for \\ntheir expertise in neural networks and deep learning. T oday, they \\ncontinue to be influential in the AI research community; Schmid-\\nhuber is the scientific director of the Dalle Molle Institute for \\nArtificial Intelligence Research in Switzerland.\\nAs previously mentioned, LSTMs are a specialized type of \\nRNN designed to tackle the vanishing gradient problem, which \\nplagues traditional RNNs in capturing long-term dependencies \\nwithin sequential data. While they outshine earlier models, \\nLSTMs are overshadowed by the more recent transformer archi-\\ntecture, which boasts unparalleled attention mechanisms.\\nLSTMs manage to maintain a cell state that selectively adds \\nor removes information, allowing the network to remember or \\nforget details over extended input sequences. This feat is accom-\\nplished through a system of gates that regulate the flow of infor-\\nmation into and out of the cell state. Figure\\xa0 2.16 depicts the \\ndetailed workings of an LSTM unit.\\nSince their inception, LSTMs have been employed in a vast \\narray of applications, such as machine translation, text classifica-\\ntion, and sentiment analysis. In text generation tasks, LSTMs \\nhave proven especially effective, generating coherent and seman-\\ntically meaningful text with fewer errors than earlier models.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 71\\nLSTMs have been broadly adopted within the tech industry, \\nwith numerous companies utilizing them for natural language \\nprocessing applications. Google, for instance, has used LSTMs \\nin products like Google T ranslate and Google Assistant for lan-\\nguage translation and speech recognition. However, it is worth \\nnoting that more recently, LSTMs have been largely superseded \\nby more advanced systems, such as neural machine translation \\n(NMT). NMT specializes in language translation, with the neu-\\nral network being trained on vast corpora of parallel sentences to \\nlearn the relationships between words and phrases in source and \\ntarget languages.\\nOther areas where LSTMs have been the go-to AI model \\ninclude chatbot development, language modeling for speech rec-\\nognition, and speech synthesis. All in all, LSTMs have been an \\ninstrumental tool in natural language processing and have left a \\nlasting impact on the field since their introduction.\\nOutput\\ncurrent\\nOt\\nOt\\nOutput\\ncurrent\\nCurrent\\ncell state;\\nupdated\\n“memory”\\nCt\\nit\\n/uni03C3/uni03C3\\n×\\n×\\n+\\nft\\nOt\\nCtˆ\\nCt–1\\nXt\\nPrevious\\ncell state\\n“memory”\\nCandidate for\\ncell update\\nUpdated cell state\\nto help determine\\nnew hidden state\\nInput gate:\\nHow much emphasis do\\nwe give the new input info?\\nForget gate [0–1]: How much info\\nfrom previous output do we forget?\\nOutput gate: What info\\nshould the hidden\\nstate carry to the next state?\\nPrevious\\noutput Input\\n×\\ntanh\\ntanh\\n/uni03C3Ot-1\\nFIGURE\\xa02.16 An LSTM unit'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='72 GENERATIVE AI\\nN-Gram Models\\nDelving into the annals of computer science and language mod-\\neling, one might find that the specific origins of n-gram models \\nremain shrouded in mystery. Nevertheless, it is widely acknowl-\\nedged that these models experienced a resurgence in popularity \\nduring the mid-2000s. Exhibiting a simplicity that is both elegant \\nand efficient, n-gram models operate by counting the frequency \\nof word sequences in a corpus of text and estimating their prob-\\nabilities. The models’ computational efficiency renders them an \\nattractive option for implementation in large-scale applications.\\nY et, like all things, n-gram models do have shortcomings. \\nChief among these are their inability to capture long-term \\ndependencies in text and their susceptibility to data sparsity and \\noverfitting. Despite these limitations, the models have been \\nemployed in an array of applications, ranging from voice assis-\\ntants like Siri, Alexa, and Cortana to keyword extraction, topic \\nmodeling, and sentiment analysis.\\nHowever, as the sands of time have shifted and more advanced \\nmodels have emerged, the once-prevalent n-gram models have \\ngradually receded into the background. Nonetheless, their \\nimpact on the development of natural language processing \\nshould not be understated, and they will forever remain an \\nimportant milestone in the rich tapestry of AI history.\\nSeq2Seq\\nVenturing deeper into the labyrinth of AI text generation, we \\narrive at the ingenious development of sequence-to-sequence \\n(Seq2Seq) models. Much like an architect who carefully con-\\nstructs a sturdy frame around the building’s core, Seq2Seq mod-\\nels ingeniously harness the power of other AI text generation \\nmodels, elevating them to a new level of sophistication and \\nefficiency.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 73\\nThe foundations of the Seq2Seq model were laid in 2014\\xa0in \\na paper titled “Sequence to Sequence Learning with Neural \\nNetworks” by a group of trailblazing researchers from Google, \\nincluding Ilya Sutskever, Oriol Vinyals, and Quoc V . Le.4 As an \\nintriguing aside, Ilya Sutskever cofounded OpenAI and serves as \\nits chief scientist.\\nSeq2Seq models consist of two recurrent neural networks \\n(RNNs)— LSTMs and GRUs— working in tandem as an encoder \\nnetwork and a decoder network. With applications ranging from \\nmachine translation and text summarization to speech recogni-\\ntion, Seq2Seq models operate by using the encoder to transform \\nan input sequence into a fixed-size vector representation, aptly \\ndubbed the context vector. This vector serves as a concise sum-\\nmary of the input sequence, providing the foundation on which \\nthe decoder generates an output sequence (the text generation \\ncomponent). The training process hinges on minimizing a loss \\nfunction that quantifies the disparity between the predicted out-\\nput sequence and the ground truth.\\nAs with any great invention, there is always room for improve-\\nment. Enter the attention mechanism, introduced by Dzmitry \\nBahdanau, KyungHyun Cho, and Y oshua Bengio in 2015, which \\nbestowed upon the decoder the ability to focus on different seg-\\nments of the input sequence at varying time steps. This break-\\nthrough significantly enhanced the model’s context awareness. \\nT o distill this concept into its simplest form, imagine the decod-\\ner’s initial limitation: A single hidden state vector at the end of \\nthe encoder proved insufficient. The attention mechanism’s \\nsolution was elegant and effective; it provided as many hidden \\nstate vectors as there were instances in the input sequence, ena-\\nbling the decoder to process information with greater finesse and \\nprecision.\\n4Ilya Sutskever, Oriol Vinyals, and Quoc V . Le, “Sequence to Sequence Learning with Neural Networks,” Neu-\\nrIPS Proceedings, accessed November 27, 2023, https://proceedings.neurips.cc/paper/2014/file/a14ac55a4f \\n27472c5d894ec1c3c743d2- Paper.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='74 GENERATIVE AI\\nIt becomes apparent that Seq2Seq models’ applications are \\nvast and varied. One such prominent application, which I touched \\nupon earlier, is Google T ranslate. Seq2Seq models are not limited \\nto LSTMs but can incorporate them, enabling the translation of \\none sequence or sentence in one language to another sequence \\nor sentence in a different language. Refer to Figure\\xa02.17 for a \\nzoomed-out view of the architecture of Seq2Seq models.\\nGoogle’s innovative streak does not end with translation. \\nThe tech giant has also harnessed the power of Seq2Seq models \\nto enhance the accuracy of speech recognition in Google Assis-\\ntant, among other applications. Meanwhile, chatbots and con-\\nversational agents have benefited greatly from Seq2Seq models, \\nwhich, when trained on a vast corpus of conversational data, gen-\\nerate responses that are more contextually appropriate and \\nnatural-sounding.\\nGoogle is not alone in recognizing the potential of Seq2Seq \\nmodels. Other tech behemoths, including Facebook, Microsoft, \\nand Amazon, have incorporated these models into their products \\nand services. However, Google has undoubtedly been a key driv-\\ning force in the development and popularization of Seq2Seq \\nmodels, with Google Brain hosting numerous leading research-\\ners in the field.\\nHe\\nEncoder\\nEmbed\\nloved to eat .\\nNULL\\nSoftmax\\nDecoderS\\nEr liebte zu essen\\nEr liebtez u essen .\\nFIGURE\\xa02.17 The big picture perspective of a Seq2Seq model.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 75\\nComparing Seq2Seq models with their AI counterparts, \\nLSTMs excel at capturing long-term dependencies, while n-gram \\nmodels are faster to train but lack the ability to capture context as \\neffectively. Seq2Seq models, as a kind of meta-model, are specifi-\\ncally designed for sequence-to-sequence mapping tasks and can \\ngenerate more natural-sounding output. However, they require \\nmore data and fine-tuning.\\nThe Amazon AlexaTM 20B, a moderate-sized (20 billion \\nparameter) Seq2Seq language model, is likely the most powerful \\nSeq2Seq model to date. It outperforms the much larger GPT-3\\xa0in \\nlanguage translation and summarization, achieving state-of-the-\\nart performance in few-shot-learning tasks across all Flores- \\n101\\xa0language pairs. Despite its impressive capabilities, its release \\nin August 2022 did not cause the same stir in the AI community \\nas OpenAI’s ChatGPT did three months later. The reason behind \\nthis disparity in impact lies in the output quality: AlexaTM 20B’s \\noutput was not as impressive as ChatGPT’s. The intriguing  \\nreasons behind this discrepancy shall be unveiled later.\\nGANs for Text Generation\\nBefore delving into transformers, the cornerstone of state-of-\\nthe-art language generation models like GPT , let’s pause to take \\na look at GANs in text generation.\\nT o recapitulate, GANs for text generation operate in a fasci-\\nnating dance of deception and detection. The generator model \\nconcocts realistic text samples, aiming to dupe the discriminator \\nmodel into believing the text is genuine. Simultaneously, the dis-\\ncriminator model hones its ability to discern between authentic \\nand fabricated text samples. Through this iterative process, both \\nmodels evolve, refining their skills based on feedback from one  \\nanother.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='76 GENERATIVE AI\\nSeveral GAN architectures have emerged specifically for text \\ngeneration, such as SeqGAN, MaliGAN, and T extGAN. Examin-\\ning T extGAN as a representative example offers valuable insights \\ninto the process of generating sequential data using GANs. T o \\nbetter grasp its inner workings, we must first address the unique \\nchallenges posed by the text’s discrete nature, which hinders the \\ndirect application of gradients from the discriminator to the gen-\\nerator. T extGAN adapts to these challenges in several ways:\\n• It converts both real and fake sentences into high-dimensional  \\nlatent feature distributions, transforming the discrete text \\nproblem into a continuous space. In layman’s terms, it maps \\nthe text onto a spectrum, smoothing out the rough edges \\nand making it more amenable to analysis.\\n• T extGAN employs a kernelized discrepancy metric called \\nreproducing kernel Hilbert space (RKHS) to gauge the dis-\\nparity between real and fake text samples. Simply put, it \\nmeasures the “distance” between the two, enabling the gen-\\nerator to better understand how to produce realistic text.\\nT o render the generator differentiable, T extGAN utilizes a \\nsoft-argmax operator and additional techniques like initializa-\\ntion strategies and discretization approximations. In essence, \\nT extGAN modifies the traditional GAN framework, overcoming \\nthe hurdles of text generation and producing more plausible and \\ncoherent text samples.\\nHowever, GANs’ potential for text generation is not without \\nlimitations. They can suffer from mode collapse, reducing the \\ngenerator model’s output range and stifling sentence variety. \\nFurthermore, GANs may generate nonsensical or irrelevant text \\nand can be difficult to train and optimize due to an unstable \\ntraining process.\\nIn the grand scheme of text generation, GANs are unlikely to \\nplay a pivotal role in the future.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 77\\nAttention\\xa0– Transformer\\xa0– Self-Attention\\nThe intriguing tale of attention mechanisms in deep learning \\nunfurled with the publication of a seminal paper in 2016 titled \\n“Neural Machine T ranslation by Jointly Learning to Align and \\nT ranslate,”5 by Dzmitry Bahdanau, KyungHyun Cho, and Y oshua \\nBengio. Within the dense text of their paper, they introduced the \\nworld to the concept of the attention mechanism— an innovative \\nsolution to the problem of long-range dependencies in Seq2Seq \\nmodels. Imagine reading a lengthy novel with countless charac-\\nters and plotlines. The attention mechanism is akin to a well-\\nplaced bookmark, enabling you to keep track of important details \\nand navigate the narrative more efficiently. In the context of \\nSeq2Seq models, Bahdanau, Cho, and Bengio’s attention mecha-\\nnism operates like this literary bookmark, allowing the model to \\nfocus on different parts of the input sequence while generating \\nthe output, thereby attenuating the issue of long-range depend-\\nencies. This novel approach drastically enhanced the perfor -\\nmance of neural machine translation systems, setting a new path \\nfor future exploration in the field.\\nFast-forward to 2017, a year marked by another monumental \\nstride in AI research— a groundbreaking paper titled “Attention \\nIs All Y ou Need,” by Ashish Vaswani and his fellow researchers at \\nGoogle Brain and Google Research. 6 The paper proposed the \\ninnovative transformer architecture, making attention mecha-\\nnism its central pillar. In a way, it’s like shifting from a traditional \\nbook to an e-reader that allows you to highlight and annotate  \\nthe most crucial parts of the text. The attention mechanism in \\nthese models enables focusing on specific parts of the input to \\nmake accurate predictions, much like highlighting pivotal points \\nin a text.\\n5Dzmitry Bahdanau, KyungHyun Cho, and Y oshua Bengio, “Neural Machine T ranslation by Jointly Learning \\nto Align and T ranslate,” arXiv, May 19, 2016, https://arxiv.org/pdf/1409.0473.pdf\\n6Ashish Vaswani et\\xa0al. “Attention Is All Y ou Need,” NeurIPS Proceedings, accessed November 27, 2023, https://\\nproceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa- Paper.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='78 GENERATIVE AI\\nSelf-attention, a specific variant of attention mechanism \\nemployed in the transformer architecture, functions somewhat \\nlike a photographic memory— it captures relationships between \\ndifferent parts of the input sequence, irrespective of their dis-\\ntance. This mechanism allows the model to “remember” infor -\\nmation from far-flung parts of the sequence and use that \\ninformation to create a better output.\\nA key advantage of the transformer architecture was its  \\nability to process input sequences in parallel, rather than sequen-\\ntially. It’s a bit like reading multiple chapters of a book simultane-\\nously without losing the narrative thread. This meant improved \\nefficiency and scalability, which in turn led to a rise in the popu-\\nlarity and application of transformer models.\\nSubsequently, transformers took the AI world by storm, rap-\\nidly emerging as the state-of-the-art architecture for an array of \\nNLP tasks, including machine translation, text summarization, \\nand language modeling. They outclassed existing RNN-based \\nmodels, as they effectively address the issues of long-range \\ndependencies, a problem that LSTM and RNN models grappled \\nwith. It’s like upgrading from an old typewriter to a modern \\ncomputer— the core concept remains the same, but the capabili-\\nties are vastly expanded.\\nTech Triumphs in\\xa0Text Generation\\nSince the advent of the self-attention mechanism, we have wit-\\nnessed an effusion of diverse LLMs, each bringing unique fea-\\ntures to the table. Among the most notable are OpenAI’s GPT \\nseries, Google’s BERT , T ransformer-XL from Google Brain, \\nFacebook’s BART , and T5 from Google Research. Subsequent \\nchapters will delve deeper into the intricacies of these different \\nmodels. However, for now, let’s focus on some key technical'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 79\\naspects like tokenization, models being probabilistic, training, \\nfine-tuning, prompting, scaling laws, reinforcement learning \\nfrom human feedback (RLHF), emergent abilities, and more. \\nThese, in essence, form the backbone of these models, acting as \\nthe nuts and bolts that piece together the entire machinery of AI.\\nTokenization for LLMs\\nT okenization, in the context of language models, is akin to the \\nprocess of linguistic dissection. It involves the fragmentation of \\ninput and output texts into smaller, manageable units known as \\ntokens. These tokens could be as minute as characters, as standard \\nas words, or as nuanced as subwords and symbols. This process is \\nnot merely an act of division, but a means to a greater end. \\nT okenization is instrumental in enabling AI models to grapple \\nwith the diversity and complexity of human language, encom-\\npassing different vocabularies, languages, and formats. Moreo-\\nver, it allows for a significant reduction in computational and \\nmemory costs, thus boosting the efficiency of these models.\\nThe act of tokenization, however, is not a one-size-fits-all \\napproach. There are different methods of tokenization, such as \\nrule-based, statistical, or neural. The choice of method is deter -\\nmined by the complexity and variability of the texts being han-\\ndled. Rule-based methods, for instance, rely on predetermined \\nrules to tokenize text, whereas statistical methods look for com-\\nmon patterns and frequencies in the text. Neural methods, on \\nthe other hand, leverage the power of neural networks to under-\\nstand and segment text.\\nAmong these methods, OpenAI, the creator of this very \\nmodel you’re interacting with, has opted for a subword tokeniza-\\ntion method known as byte-pair encoding (BPE) for its GPT-based \\nmodels. BPE operates akin to a keen-eyed linguist, identifying \\nand merging the most frequently occurring pairs of characters or'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='80 GENERATIVE AI\\nbytes into a single token. It’s important to note that the number \\nof tokens or the size of the vocabulary is not a constant across all \\nmodels; it varies, much like the models themselves.\\nT okenization inevitably impacts the amount of data and the \\nnumber of calculations a model is required to process. It’s a sim-\\nple equation: The more tokens a model has to juggle, the greater \\nthe demand on memory and computational resources. Conse-\\nquently, the cost of running a model is intrinsically linked to the \\ntokenization method employed, the size of the vocabulary, as \\nwell as the length and complexity of the input and output texts.\\nAs of February 2023, OpenAI’s Davinci model cost $0.06 per \\n1,000 tokens. T o illustrate, generating a summary for a 2,500-\\nword article, roughly 3,125 tokens, costs about $0.19. For a \\nbook-length text, the price rises to approximately $7.50. Scaling \\nup to an industrial operation, such as producing 100 books a day, \\ndaily costs hit $750, monthly around $22,500, and annually about \\n$270,000— only for tokenization, prediction excluded, and train-\\ning is a totally different topic. These estimates vary with factors \\nlike text length, complexity, and potential volume usage agree-\\nments. As impressive as AI models are, it’s important to under -\\nstand the underlying costs associated with their operation.\\nOutput Probability\\nLanguage models such as GPT , short for Generative Pre-trained \\nT ransformer, fundamentally operate as probabilistic models. A \\nprobabilistic model is a distinctive design that assigns probabili-\\nties to myriad possible outcomes.\\nT o delve deeper, we must turn our attention to the trans-\\nformer architecture, the underlying framework on which  \\nGPT and other LLMs are built. Herein lies the significance of \\nprobability.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 81\\nAt its core, the principal duty of transformer-based language \\nmodels like GPT is to forecast the subsequent word or token in \\na sequence. Given a certain input, the model computes a proba-\\nbility distribution spanning the entire vocabulary for the follow-\\ning word. T ypically, the word boasting the highest probability is \\nchosen as the predicted outcome. Imagine feeding the model a \\nsequence such as “The cat is on the”; it then calculates the prob-\\nabilities for all conceivable succeeding words and may conclude \\nthat “roof   ” bears the highest probability. This process can be sig-\\nnificantly adjusted through the art of prompt engineering, an \\nintriguing topic that I’ll cover in more detail later in this chapter.\\nThis fundamental principle extends to entire sequences as \\nwell. The model is capable of computing the joint probability of \\na series of words by breaking it down into conditional probabili-\\nties. This clever mathematical maneuver is carried out using the \\nchain rule of probability, enabling the model to churn out sen-\\ntences that are not only coherent but also contextually appropriate.\\nDuring the training phase, the model tweaks its parameters \\nin a bid to maximize the likelihood of the training data. This \\nprocess, known as maximum likelihood estimation (MLE), entails \\nadjusting the model’s internal learnable parameters— weights \\nand biases— to ensure that the probabilities assigned to the actual \\nsucceeding words in the training data are as high as possible.\\nFinally, during the generation of new text, sampling methods \\nsuch as beam search, nucleus sampling, or top-k sampling lever-\\nage the probability distribution over the subsequent word to \\nproduce diverse and captivating outputs. While beam search \\nconsiders multiple possible sequences simultaneously and keeps \\nthe top few, nucleus sampling selects from a core group of most \\nlikely words, and top-k sampling chooses from the top ‘k’ prob-\\nable words. With that we make sure that instead of always opting \\nfor the word with the highest probability— a strategy that can'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='82 GENERATIVE AI\\nlead to monotonous and deterministic text— the model might \\nsample from the distribution, resulting in more varied and crea-\\ntive outputs.\\nThus, while the cost of running such models may seem steep \\nat first glance, understanding the intricate play of probabilities in \\ngenerating coherent, creative, and contextually appropriate text \\nreveals the true value of these advanced AI systems.\\nPretraining LLMs\\nAs we journey through the world of LLMs, we find ourselves \\nencountering various stages of their training process. The initial \\ntraining phase— often referred to as pre-training— is where our \\nfocus now lies (Figure\\xa02.18).\\nWhen considering pre-training in the context of LLMs, two \\nbroad strategies stand out. The first approach, known as autore-\\ngressive training, is akin to predicting the next word in a sentence. \\nPre-training LLMs\\nPrompt Engineering\\nFine-tuning\\nRLHF\\n1\\n2\\n3\\nMust\\noptional\\nSpecific and quality\\ndataset needed\\nCarefully constructed\\nprompts needed\\nUsed to further\\nimprove the weights\\nGeneralSpecific\\nFIGURE\\xa02.18 The different stages of receiving a desired LLM output.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 83\\nFor instance, given the phrase “I like to eat,” the model’s task is \\nto predict what comes next— perhaps “ice cream.”\\nThe second pre-training approach is called masked training. \\nHere, parts of the sentence are obscured or “masked,” and the \\nmodel must predict the missing elements. For instance, given  \\n“I like to [MASK] [MASK] cream,” the model would need to fill \\nin the gaps, possibly with “eat ice.”\\nIn addition to these primary pre-training tasks, there are aux-\\niliary ones that further refine the model. For instance, the next \\nsentence prediction (NSP) task requires the model to predict \\nwhether pairs of sentences appear consecutively in the training \\ncorpus. This aids in honing the model’s understanding of narra-\\ntive flow and coherence.\\nThe objective of all this training is to minimize a specific loss \\nfunction, often the average negative log-likelihood per token, \\notherwise known as cross-entropy loss. Think of it as a scoring sys-\\ntem: It measures how well the model’s predictions align with the \\nactual outcomes. If the model predicts “cake” when the sentence \\nis “I like to eat ice cream,” the cross-entropy loss will be high, \\nsignaling the model to adjust its internal parameters.\\nAnother concept that comes into play during training is regu-\\nlarization loss. It’s akin to a guiding hand that prevents the model \\nfrom overfitting or memorizing the training data. However, this \\nis typically applied during training and not considered during \\ntesting and evaluation.\\nThe scale of training datasets for LLMs is astoundingly large. \\nEarly LLMs, like GPT-1, cut their teeth on datasets such as Book-\\nCorpus, boasting a hefty 985\\xa0million words. BERT , another early \\nmodel, trained on a combination of BookCorpus and English \\nWikipedia, amassing a total of 3.3 billion words. With time, the \\nsize of these training corpora ballooned, reaching up to a stagger-\\ning trillions of tokens.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='84 GENERATIVE AI\\nThere’s no denying that the computational cost of training \\nLLMs is high. But there is a silver lining. Over the years, thanks \\nto technology advancements and economies of scale, these costs \\nhave been steadily decreasing. Moore’s Law, despite being dec-\\nades old, still holds relevance in this context. It postulates that \\nthe number of transistors on a microchip doubles approximately \\nevery two years, which in turn drives down computing costs.\\nConsider this: The cost of training a 1.5 billion parameter \\nLLM in 2019\\xa0 was around $1.6\\xa0 million. Fast-forward to 2023, \\nand you could train a model with four times as many parame-\\nters— 6 billion— for the same price.\\nShifting our focus to larger models, GPT-3, which carries \\n175 billion trainable parameters, created a noteworthy shift in \\nthe cost landscape. The actual figure remains undisclosed by its \\nprogenitor, OpenAI, but estimates range between $5\\xa0million and \\n$12\\xa0million. As we leap forward to GPT-4, the details of its size \\nare still under wraps, yet the speculated costs of training such a \\nmodel oscillate between a hefty $100\\xa0million and $200\\xa0million. \\nThe path forward in AI is a costly one indeed, but given the vast \\npotential, it remains a worthy exploration.\\nFinally, it’s worth noting the cost difference between training \\nand inference (or using the model to make predictions) in  \\ntransformer-based LLMs. T raining costs about six floating point \\noperations (FLOPs) per parameter for each token, whereas infer-\\nence costs significantly less— just one or two FLOPs per param-\\neter per token. This roughly equates to a 4.5 to 1 ratio, making \\ninference more economical, whereas pre-training is the necessary  \\ninitial investment.\\nFine-tuning LLMs\\nT urning our attention to the next pivotal element of our AI jour-\\nney, we encounter the concept of fine-tuning language models. \\nThis process is akin to chiseling a masterful statue out of a crude'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 85\\nslab of marble. Initially, pre-trained language models are exposed \\nto large, diverse corpora, absorbing language patterns and a \\nsomewhat profound understanding of the world and learning to \\nconstruct coherent text. This, however, is just the beginning.\\nWhen we engage in the fine-tuning process, the preexisting \\nparameters of our pre-trained model serve as our foundation. \\nSubsequent training is carried out on task-specific data, which \\nmight be annotated to illustrate the desired behavior or output \\nfor a specific task. Like a versatile tool, fine-tuning can be applied \\nto the entire neural network or just a subset of layers. Imagine \\nlocking some layers in place, their learning stalled, while others \\nadapt and evolve.\\nThis finely honed focus allows the language model to imbibe \\ntask-specific characteristics, vocabulary, and subtleties integral to \\nthe target application. The outcome? More precise, contextually \\nrelevant responses and heightened performance on niche NLP \\ntasks such as textual question answering within a corpus of com-\\nplex jargon, such as contracts and other legal documents.\\nA recurring theme in my myriad interactions at conferences \\nand dialogues with other thought leaders suggests a veering \\ntoward smaller, task-specific AI models. Echoing this sentiment \\nis Sam Altman, the CEO of OpenAI. Altman foresees an immi-\\nnent halt to the expansion of LLMs. His focus rests on augment-\\ning capability rather than simply inflating parameter count. If \\nsubstantial improvements can be attained via lesser parameters \\nor through an amalgamation of smaller models, so be it. There \\nare, after all, finite datacenters that companies like OpenAI can \\nconstruct— a limit to their pace of construction as well as financial  \\nrestrictions.\\nWhile full fine-tuning offers improved results, it’s not as \\nmuch as pre-training, a resource-intensive endeavor that’s sus-\\nceptible to overfitting. A fascinating piece of ongoing research \\nthat caught my attention was published in Nature under the title \\n“Parameter-Efficient Fine-T uning of Large-Scale Pre-T rained'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='86 GENERATIVE AI\\nLanguage Models” by Ning Ding et\\xa0al.7, who propose a strategic \\nbalance between performance and efficiency when fine-tuning \\nlarge-scale pre-trained language models.\\nThey present an innovative method christened delta tuning, \\nwhich adjusts the pre-trained model by adding or tweaking a \\nsmall number of parameters. The striking results: delta-tuning \\nmethods have exhibited similar or even superior performance to \\nconventional fine-tuning methods while employing a mere \\n10–20 percent of the original parameters. The inherent prowess \\nof fine-tuning large-scale models, coupled with the resourceful-\\nness of delta tuning, paints an exhilarating picture of the poten-\\ntial locked within AI.\\nPrompt Engineering\\nNavigating the maze of AI innovations, one cannot help but \\nnotice the understated role of prompt engineering. This meth-\\nodology involves meticulously crafting or sculpting the prompts \\nor directions given to a generative model. The idea is to manipu-\\nlate the model’s output by molding the input information and \\ncontext. Certain keywords, phrases, or even the layout can be \\nwielded strategically to steer the model’s responses. The over -\\narching objective is to trigger a desired behavioral outcome, \\nheighten precision, or command the output style. It is no sur -\\nprise then that prompt engineering has come to be a trusted ally \\nin optimizing the performance of generative AI models for speci-\\nfied tasks. It also serves as a robust tool to counter biases and \\nfoster fairness in the produced output.\\nThe importance of prompt engineering is hard to overstate. \\nIt holds the potential to completely redefine the manner in which \\nwe interact with AI. By incorporating the best practices of \\n7Ning Ding et\\xa0al., “ Parameter-Efficient Fine-T uning of Large-Scale Pre-T rained Language Models,” Natural \\nMachine Intelligence, 5, 220–235 (2023), www.nature.com/articles/s42256- 023- 00626- 4'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 87\\ncommunication between humans and machines, prompt engi-\\nneering allows machines to accurately interpret human instruc-\\ntions and provide valuable responses. Not only does it underscore \\na science in its own right, but it also has significant implications \\nfor the future job market.\\nWhile most of the scientific exploration of prompting is cen-\\ntered around language models, owing to their versatility in han-\\ndling text, it is important to note that image generation prompting \\nalso offers a wealth of techniques and guidelines.\\nChain-of-Thought (CoT) Prompting One of the more nota-\\nble advancements in the world of prompting is chain-of-thought \\n(CoT) prompting. Coined by researchers at Google in 2022, \\nCoT prompting enhances the reasoning ability of LLMs by \\nmaking them generate intermediate steps that lead to the final \\nanswer of a multistep problem. This methodology shows \\nmarked improvements with larger and more powerful language \\nmodels and can be fine-tuned on CoT reasoning datasets.\\nFew-Shot and Zero-Shot Prompting CoT reasoning can be \\ntriggered using two primary methods: few-shot prompting \\nand zero-shot prompting. Few-shot prompting (Figure\\xa02.19) \\nemploys at least one example of a question paired with  \\nappropriate human-written CoT reasoning, whereas zero-\\nshot prompting (Figure\\xa0 2.20) could be as uncomplicated as \\nappending “Let’s think step by step” to the prompt.\\nSelf-Consistency Prompting In our pursuit of improved \\nCoT reasoning for more complex problems, we come across \\nthe technique of self-consistency prompting. This method \\nentails supplying the AI model with multiple reasoning paths \\nor diverse perspectives, after which the most consistent and \\ncoherent answer among the generated responses is selected \\n(Figure\\xa02.21). Not only does self-consistency prompting help'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='88 GENERATIVE AI\\ndiminish biases in the AI’s responses, but it also propels  \\nthe model to consider various viewpoints before reaching a \\nconclusion.\\nFIGURE\\xa02.19 Few-shot prompting.\\nSource: OpenAI\\nFIGURE\\xa02.20 Zero-shot prompting.\\nSource: OpenAI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 89\\nKnowledge Prompting Another significant tool in our prompt-\\ning toolkit is knowledge prompting. This technique involves \\nfeeding the AI model with extra information or knowledge to \\nenhance its performance on specific tasks. Such information, \\nwhich might provide context or background, can be embedded \\ninto the input prompt to assist the model in better understand-\\ning the task at hand. Knowledge prompting proves particularly \\nuseful for complex tasks requiring a deeper comprehension of \\nthe subject matter. However, it is of utmost importance to \\nmeticulously design and optimize prompts for specific use cases \\nto ensure optimal performance.\\nFIGURE\\xa02.21 Self-consistency prompting: same question asked multi-\\nple times, resulting in same answer.\\nSource: OpenAI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='90 GENERATIVE AI\\nKnowledge prompting isn’t haphazard; it follows a defined \\nprocess (Figure\\xa02.22). This begins with identifying the task or \\nproblem and understanding the AI model’s existing knowledge \\nto spot any gaps. Next, external knowledge sources are identified \\nand integrated, enhancing the model’s understanding. The \\nresultant knowledge-rich prompts are then refined to optimize \\ntask-specific performance. Following this, the AI’s output is eval-\\nuated, assessing the effectiveness of the prompts. The evaluation \\nprovides invaluable insights for further iterative improvements, \\nbeginning again from the first step, if required. This process \\nensures knowledge prompting serves as a robust tool to elevate \\nAI performance on complex tasks, each iteration bringing us \\ncloser to creating optimized knowledge prompts.\\nDirectional Stimulus Prompting In 2023, Li and his team \\nintroduced a novel prompting technique, directional stimulus \\nprompting, aiming to enhance the guidance provided to LLMs \\nin generating desired summaries. The process involves train-\\ning a manageable policy language model (LM) to generate a \\nstimulus or hint, marking an increasing trend in the use of \\nreinforcement learning (RL) to optimize LLMs. Figure\\xa02.23 \\noffers a comparative view of directional stimulus prompting \\nagainst conventional prompting. Notably, the policy LM, kept \\ncompact for convenience, is fine-tuned to generate hints that \\nefficiently navigate a black-box, frozen LLM toward the \\ndesired output.\\nKnowledge 1\\nKnowledge 2\\n...\\nKnowledge\\nGeneration AnswerKnowledge\\nIntegrationQuestion\\nFIGURE\\xa02.22 Generated knowledge prompting structure.\\nSource: https://arxiv.org/pdf/2110.08387.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 91\\nReAct (Reason + Act) Prompting T aking things a notch \\nhigher, ReAct prompting merges reasoning and action tasks to \\namplify the capabilities of LLMs. The ReAct method inter -\\nleaves reasoning traces and task-specific actions to enhance the \\ndecision-making and comprehension abilities of LLMs. This \\napproach refines the model’s capacity to formulate action plans, \\nhandle exceptions, and source more information from external \\navenues. The prompts featured in ReAct are comprehensive \\nand multifaceted. They encompass few-shot task-solving trajec-\\ntories, which involve solutions that emerge after only seeing a \\nfew examples of a problem. Additionally, they also contain \\nhuman-written reasoning traces, providing insight into the \\nthought processes that led to certain conclusions or decisions. \\nFurthermore, the prompts detail specific actions taken and the \\nsubsequent environmental responses that arise due to these \\nactions, offering a clear picture of cause-and-effect relationships \\nin various scenarios. Outperforming the existing baselines in \\ndiverse tasks, ReAct demonstrates improved performance, \\nhuman interpretability, and trustworthiness. This will be espe-\\ncially important for robots.\\nFIGURE\\xa02.23 Directional stimulus prompting.\\nSource: https://arxiv.org/pdf/2302.11520.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='92 GENERATIVE AI\\nFigure\\xa02.24 depicts the “ReAct” (Reason + Act) method. In \\nthis approach, “Act” signifies the decisions or actions undertaken \\nby the agent, while “Obs” stands for observations, highlighting \\nthe consequences or results of the said actions.\\nIt is important to acknowledge that prompting does have pit-\\nfalls. For instance, it opens the door to vulnerabilities and poten-\\ntially malicious use. An AI model can be exploited through \\nprompt injection— a technique that coerces a language model, \\nwhich is usually trained to follow human-given instructions, to \\ncomply with the instructions of a malicious user. The prompt \\ninjection can happen when instructions and data are mashed \\ntogether, rendering it challenging for the underlying system to \\ndifferentiate between the two.\\nAs we journey further into the world of AI, it is essential to \\napproach these innovations with an understanding of their \\npotential, but also their associated risks.\\nFIGURE\\xa02.24 ReAct prompting.\\nSource:\\xa02022 https://arxiv.org/pdf/2210.03629.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 93\\nLLMs Until ChatGPT\\nThe release of GPT-2\\xa0in 2019 still stands out in my mind. OpenAI \\nmade an unprecedented move by initially withholding the full \\nmodel due to concerns about its potential misuse. Their decision \\nsparked extensive discussions about the responsible development \\nof AI and the delicate balance between harnessing benefits and \\nmitigating risks. OpenAI’s stance left me pondering— was this \\nsimply a marketing ploy, or did GPT-2 truly possess capabilities \\nthat warranted such caution?\\nGPT-2\\xa0 was more than a mere upgrade to its predecessor, \\nGPT . It was a quantum leap in terms of scale, boasting over 10 \\ntimes the parameters— with a mind-boggling count of 1.5 billion \\ntrainable parameters. T rained on an extensive dataset of 8\\xa0mil-\\nlion web pages, GPT-2 flexed its muscles by demonstrating a \\nbroad array of capabilities, including the generation of synthetic \\ntext samples of unprecedented quality.\\nSince the advent of GPT-2, countless LLMs have been \\ndeveloped, each with its own unique strengths. However, a few \\nLLMs have distinguished themselves from the crowd, demand-\\ning special mention.\\nJust over a year after the release of GPT-2, OpenAI unveiled \\nGPT-3\\xa0 in June 2020. This new iteration made GPT-2\\xa0 look \\nalmost modest in comparison, sporting not 10 times, but over \\n100 times the trainable parameters, amounting to a staggering \\n175 billion. Such a scale was unrivaled at the time of its release. \\nThis beast of a model was trained on roughly 570\\xa0GB of Internet \\ntext, and the results spoke for themselves. GPT-3\\xa0marked a sig-\\nnificant leap in language generation quality and has been \\nemployed in a variety of applications, including the generation of \\ncode snippets, regular expressions, and even Microsoft Excel \\nfunctions from simple text descriptions. Owing to its advanced \\ncapabilities, OpenAI opted to keep GPT-3 under wraps, grant-\\ning access only to a select few, and never open sourcing it.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='94 GENERATIVE AI\\nReflecting on the landscape of LLMs in late 2020, the scene \\nwas not entirely monopolized by OpenAI. Google was also mak-\\ning waves with its research contributions. They introduced  \\nmodels such as the T ext-to-T ext T ransfer T ransformer (T5) and  \\nT ransformer-XL, which both had substantial impacts on the field. \\nThe T5 stood out with its unified, text-to-text framework, revolu-\\ntionizing how various NLP tasks were approached, whereas the \\nT ransformer-XL excelled in handling longer sequences of text, \\nproving its mettle in language modeling and text generation tasks. \\nDespite OpenAI’s dominance, it’s clear that other players, like \\nGoogle, have also played a significant part in shaping the pro-\\ngress of LLMs.\\nIn June 2021, Google introduced a model known as LaMDA. \\nThis LLM had 137 billion trainable parameters and was trained \\non an extensive dataset comprising 1.56 trillion words. LaMDA \\nwas not open source, but it was designed with a unique goal in \\nmind: to facilitate free-flowing conversations on a broad range of \\ntopics. This capability made LaMDA intriguing, as it suggested a \\nmove toward more naturalistic, dynamic human-computer \\ninteractions.\\nNot necessarily to facilitate natural conversations but rather \\ncode generation, OpenAI released Codex later in the same year. \\nThis model had fewer trainable parameters than LaMDA— 12 \\nbillion in total— but it was fine-tuned for a very specific task: \\nprogramming applications. Codex was trained on a vast array of \\nprogramming languages sourced from 54\\xa0million GitHub repos-\\nitories, making it a significant development in the realm of cod-\\ning automation. Like LaMDA, Codex was not made open source, \\nfurther illustrating the growing trend of proprietary LLMs.\\nGoogle made further strides in 2022\\xa0 with the release of \\nLaMDA 2. Unfortunately, not much is known about this model’s \\nspecifications due to Google’s decision to keep the details under'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 95\\nwraps. This secrecy might seem unusual, but it is likely a strate-\\ngic move designed to maintain a competitive edge in the rapidly \\nevolving field of AI.\\nThe close of 2022 saw the arrival of Galactica, an LLM by \\nMeta. With 120 billion trainable parameters, Galactica was \\ntrained on 48\\xa0million examples taken from an assortment of sci-\\nentific articles, websites, textbooks, lecture notes, and encyclope-\\ndias. This model was not only open source but also specifically \\ndesigned to aid scientists in simplifying their research and accel-\\nerating the writing of scientific literature. Despite these ambi-\\ntious goals, Galactica received substantial criticism for generating \\nnonsensical and inaccurate information, as it was very good at \\nconfidently hallucinating facts and results. In response to this \\nbacklash, Meta removed the public demo after just three days \\nand temporarily halted the project. While the model remains \\naccessible to researchers interested in working with it or repli-\\ncating its results, this incident underscored the challenges that \\neven the most advanced AI can face.\\nDespite these exciting developments, we saw that even by the \\nend of 2023, LLMs had yet to make a truly transformational \\nimpact. The promise of these technologies is immense, but their \\npractical applications continue to evolve, often in unexpected \\nways. It’s clear that the journey of LLMs is far from over and \\ntheir potential to reshape our world remains largely untapped.\\nLLM Scaling Laws\\nThe advent of LLMs has brought forth a profound shift, akin to \\nthe tectonic movements shaping the landscape of a planet, subtly \\nyet inexorably altering the contours of the field. Among the \\nforces driving these changes, none are perhaps as influential as \\nthe phenomenon known as scaling laws.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='96 GENERATIVE AI\\nScaling laws, in essence, delineate the relationship between \\nthe size of a model— its number of parameters— and the amount \\nof data it requires for optimal performance. Among these laws, a \\nset of findings known as the Chinchilla scaling laws, unearthed by \\nDeepMind in 2022, has proven especially instrumental in guid-\\ning the development of language models.\\nThe Chinchilla scaling laws assert that an optimal LLM \\nrequires approximately 20 text tokens per parameter. Compared to \\nthe earlier Kaplan scaling laws, which served as the guiding star for \\nOpenAI’s GPT-3 and suggested a requirement of 1.7 text tokens \\nper parameter, the Chinchilla laws signal a massive leap in data \\ndemands. For instance, to align GPT-3\\xa0with the Chinchilla laws, \\nthe model would either need to be pared down to 15 billion param-\\neters, using its original 300 billion tokens, or inflate its dataset to a \\nwhopping 3.5 trillion tokens, maintaining its original 175 billion \\nparameters. This implies an 11-fold surge in data requirements.\\nThe reach of the Chinchilla scaling laws extends to models of \\ngargantuan proportions, those measured in trillions of parame-\\nters and trained on petabytes of text data— a quantity equivalent \\nto quadrillions of text tokens. However, the quest to feed such \\ntitanic models presents a herculean challenge. As the number of \\nparameters begins to outstrip the number of unique published \\nbooks, sourcing sufficient data becomes an increasingly complex \\nendeavor. Privacy concerns, issues related to sensitive data, and \\nthe emerging trend of companies charging for data scraping \\nfrom platforms rich in user-generated content, such as Reddit \\nand Quora, all contribute to the complexity of this landscape.\\nPredictions for the year 2023 and beyond suggest a contin-\\nued adherence to the Chinchilla scaling laws among LLMs. \\nNevertheless, the area of data optimization and efficient data use \\nduring training remains a hotbed of research, with new discover-\\nies anticipated on the horizon.\\nFigure\\xa02.25 illustrates the dataset sizes necessary to conform \\nto the principles of Chinchilla data optimization across a range'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 97\\nof model sizes. Alongside, it provides a concise summary of the \\nexisting models, capturing their tokens-to-parameters ratios.\\nT wo central conclusions can be drawn from this. First, \\nmerely ballooning the size of models in the coming years will \\nnot suffice. The need for a significantly larger pool of data and \\nthe development of smaller, more specialized models that excel \\nin specific tasks will become paramount. Prompt designing and \\nspecific datasets will play a critical role in enhancing perfor -\\nmance. Second, it is projected that the generation of data will \\nsee an exponential increase. According to IDC, the compound \\nannual growth rate of new data creation from 2020 to 2025 is \\nforecast at 23 percent, resulting in approximately 175 zetta-\\nbytes of new data. Coupled with increasingly affordable com-\\nputing resources, this will permit the expansion of model sizes \\nin a balanced manner.\\nChatGPT\\nDrawing upon the successful launch of ChatGPT on November \\n30, 2022, built atop the impressive framework of GPT-3.5, the \\nAI world experienced a monumental event. This was not merely \\nFIGURE\\xa02.25 Chinchilla scaling in table.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='98 GENERATIVE AI\\nthe introduction of yet another AI model, but a revolution that \\nswept across the globe. With over 1\\xa0million users within its first \\nfive days, and a staggering 100\\xa0 million just two months post-\\nlaunch, the application became an unparalleled success. By Janu-\\nary 2023, the count of visits had skyrocketed to about 590\\xa0million.\\nThis global embracement wasn’t happenstance but rather a \\nmeticulously curated triumph. The brilliance of ChatGPT lies in \\nits sheer versatility, transforming words into a vast array of out-\\nputs, from articles, essays, and jokes, to job applications and \\npoetry. Its utility expanded across various sectors, aiding in draft-\\ning emails, writing code, creating written content, tutoring, \\ntranslating languages, and even simulating characters for video \\ngames. Its ability to generate human-like responses, coupled with \\nits versatility and precision, set it apart in the AI industry, making \\nit a vanguard of its time.\\nPropelled by the resounding success of ChatGPT , OpenAI \\nheld an enviable position in the AI industry, a first-mover advan-\\ntage that was not to be taken lightly. The substantial usage pro-\\nvided invaluable insights and feedback, instrumental in refining \\nand honing the chatbot’s responses.\\nHowever, the journey of ChatGPT was not without its share \\nof criticism. The potential for malicious use loomed large, with \\nconcerns over malware creation and phishing. The AI, in its \\nenormous capacity, also grappled with issues of potential copy-\\nright infringement, generating content that could be similar or \\nidentical to existing copyrighted material. Ethical concerns like \\nracism, sexism, and other biases also formed part of the discourse. \\nMoreover, the AI’s occasional inaccuracy, or “hallucinating,” led \\nto erroneous answers, including failures in basic math and logic \\nquestions.\\nY et, OpenAI’s resolve remained unshaken, grounded in its \\nmission to ensure that artificial general intelligence serves all of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 99\\nhumanity. It was a vision that acted as a beacon, illuminating the \\npath toward the development of more refined, responsible, and \\nbeneficial AI applications.\\nThis was clearly evident with the initial launch of ChatGPT . \\nWhile it wasn’t fully at the AGI level, the AI showcased  \\nan unprecedented level of complexity and understanding. It  \\nwas far from a simple mimic, merely echoing back predetermined \\nresponses.\\nT ransitioning toward the more practical aspects of its design, \\nChatGPT demonstrated a conscientious approach. It was hard-\\nwired to abstain from generating inappropriate content, showcasing \\nOpenAI’s commitment to ethical AI development. Further more, \\nthe model was designed with a knowledge cutoff in September \\n2021, creating a well-defined boundary to its awareness of world \\nevents beyond this date.\\nThe power of ChatGPT was continually enhanced through \\nan iterative system of upgrades and improvements, fueled by user \\nfeedback. This is known as reinforcement learning from human \\nfeedback (RLHF).\\nReinforcement Learning from\\xa0Human Feedback\\nThe concept of RLHF unfolded as a significant milestone in the \\nsphere of AI development. This technique, which marries rein-\\nforcement learning with human feedback, is essentially used to \\ntrain a “reward model.” Launched by OpenAI in the early days of \\n2020, it pioneered the use of human feedback to directly shape \\nthe reward function to optimize an agent’s policy using rein-\\nforcement learning. The approach involves a dynamic update of \\nthe model’s parameters based on the feedback received from \\nhumans, thus introducing a unique interactive element into the \\nlearning process.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='100 GENERATIVE AI\\nThis innovative approach found its applications in various \\ndomains of natural language processing, such as conversational \\nagents, text summarization, and natural language understanding, \\nmaking the process of AI communication more refined and effec-\\ntive. ChatGPT , an exemplar of this advanced technique, was fine-\\ntuned using a combination of supervised learning and RLHF . A \\ncohort of human trainers was actively involved, providing crucial \\nfeedback on the model’s performance and ranking different model-\\ngenerated outputs based on their quality or correctness.\\nThis feedback was then transformed into a reward signal for \\nreinforcement learning, following which the model was fine-\\ntuned using proximal policy optimization (PPO) or similar algo-\\nrithms. PPO is an optimization technique used in reinforcement \\nlearning that helps to improve the policy (or decision-making \\nprocess) of an AI model while ensuring that the changes made \\ndon’t deviate too much from the previous policy. This ensures a \\nbalance between exploration and exploitation, allowing the \\nmodel to learn effectively without taking undue risks.\\nThis unique feedback collection and refinement process, \\nwhich is repeated iteratively, stimulates continuous improvement \\nin ChatGPT’s performance. RLHF offers several advantages in \\nthe development of AI systems, including improved performance, \\nadaptability, reduced biases, continuous improvement, and \\nenhanced safety. However, like any other process, it comes with its \\nown set of challenges, such as scalability, ambiguity and subjectiv-\\nity in human feedback, and long-term value alignment. There is a \\npotential for models to output harmful or factually inaccurate text \\nwithout any uncertainty. This puts into perspective the need for \\ncontinuous monitoring and refinement of such models to prevent \\nthe dissemination of misleading or harmful information. There is \\na pressing need for further research to gain a better understanding \\nof RLHF , improve its performance, and address these hurdles.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 101\\nThis transformative approach is not limited to language mod-\\nels alone. It has also found applications in other areas, such as the \\ndevelopment of video game bots. Noteworthy examples of RLHF-\\ntrained language models include OpenAI’s ChatGPT and its pre-\\ndecessor InstructGPT , as well as DeepMind’s Sparrow. Sparrow, a \\nchatbot equipped with 70 billion trainable parameters, adheres to \\nthe Chinchilla scaling laws and is trained accordingly. However, its \\napplication appears to be largely confined to the realm of videos, \\ngiven its closed source nature.\\nIn the grand scheme of things, RLHF has emerged as an out-\\nof-the-box approach in AI training that has proven pivotal in the \\ndevelopment of advanced LLMs. It is a testament to the impor -\\ntance of investing in further research and development of tech-\\nniques like RLHF to ensure the creation of AI systems that are \\nnot only powerful but also aligned with human values and \\nexpectations.\\nEvaluation of\\xa0Large Language Models\\nThe evaluation of LLMs is a critical aspect of AI development. It \\nprovides a measure of the model’s performance, accuracy, and \\nreliability, which are essential for ensuring the quality of the AI’s \\noutput and its suitability for various applications.\\nLLMs can be assessed using benchmark datasets, which pro-\\nvide scores that serve as numerical indicators for comparison \\nacross different models. However, it’s important to note that the \\nperformance of these models is often influenced by minor imple-\\nmentation details. Consequently, it can be challenging to expect \\nresults from one codebase to transfer directly to another.\\nT o address these issues, several approaches have been pro-\\nposed. EleutherAI, a nonprofit AI research lab known for its \\nwork on models like GPT-Neo and GPT-J, has introduced the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='102 GENERATIVE AI\\nLM Evaluation Harness. This unifying framework allows any \\ncausal language model to be tested on the same exact inputs and \\ncodebase. This not only provides a ground-truth location for \\nevaluating new LLMs but also saves practitioners time imple-\\nmenting few-shot evaluations repeatedly, ensuring that their \\nresults can be compared against.\\nAnother intriguing approach is the evaluation of LLMs with \\nLLMs. This method involves comparing and ranking the results \\nagainst a baseline or other LLMs, providing valuable insights \\ninto the relative strengths and weaknesses of each model.\\nPerplexity, a commonly used measure of a language model’s \\nperformance, is another approach. It gauges how well a model \\npredicts the contents of a dataset. In simple terms, a model with \\nlower perplexity has a higher likelihood of accurately predicting \\nthe dataset’s content, making it a valuable tool for evaluating  \\nLLMs.\\nT ask-specific datasets and benchmarks have also been devel-\\noped to evaluate the capabilities of language models on more \\nspecific downstream tasks. These tests may evaluate a variety of \\ncapabilities, including general knowledge, common sense rea-\\nsoning, and mathematical problem-solving.\\nQuestion-answering datasets, which consist of pairs of  \\nquestions and correct answers, are another version of this. A \\nquestion-answering task is considered “open book” if the model’s \\nprompt includes text from which the expected answer can be \\nderived; otherwise, the task is considered “closed book,” and the \\nmodel must draw on knowledge retained during training.\\nT ext completion is another form of evaluation, where the \\nmodel selects the most likely word or sentence to complete a \\nprompt. Composite benchmarks, such as GLUE, SuperGLUE, \\nMMLU, BIG-bench, and HELM, combine a diversity of differ-\\nent evaluation datasets and tasks.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 103\\nThere are also adversarially constructed evaluations, which \\nfocus on particular problems on which extant language models \\nseem to have unusually poor performance compared to humans. \\nExamples include the T ruthfulQA dataset and the Swag and its \\nsuccessor, HellaSwag.\\nHowever, the rapid pace of improvement of LLMs presents \\nchallenges in evaluation. Due to the swift saturation of existing \\nbenchmarks by state-of-the-art models, which often exceed the \\nperformance of human annotators, there is a continuous need to \\nreplace or augment the benchmark with more challenging tasks. \\nThis highlights the dynamic nature of AI development and the \\nneed for ongoing refinement in evaluation methods.\\nIt’s undeniable that the development of large AI models has \\nseeped into the strategic consciousness of numerous companies. \\nEntities such as Stanford, OpenAI, DeepMind, and Hugging Face \\ncome to mind when contemplating organizations that are stead-\\nfast in their pursuit to comprehend, enhance, and detoxify LLMs. \\nThese strides are more than mere indications of the prowess of \\nthese entities; they signify promising leaps toward the responsible \\nusage of these potent tools. Some selected observations:\\n• Stanford University has reported that LLMs can generate \\nhigh-quality legal content and predict court decisions with \\nreasonable accuracy. They are committed to studying these \\nissues and developing guidelines for the responsible \\nuse of LLMs.\\n• OpenAI is actively working on techniques to make LLMs \\nrefuse inappropriate requests. They are also investing in \\nresearch aimed at reducing harmful and untruthful outputs \\nfrom these models.\\n• DeepMind has pointed out the limitations of current detoxi-\\nfication methods, such as the risk of overgeneralization and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='104 GENERATIVE AI\\nthe difficulty in defining what constitutes harmful content. \\nThey are committed to further research in this area to \\nimprove the safety and fairness of LLMs.\\n• Hugging Face employs a combination of crowd-sourcing \\nand expert review to assess the fairness and inclusivity of \\ntheir models. They are also in the process of developing \\ntools that would allow users to customize the behavior of \\ntheir models.\\n• The increasing capabilities of LLMs in various fields, includ-\\ning science and law, suggest a future where these models \\ncould significantly accelerate research and development in \\nthese areas.\\n• The focus on benchmarking and evaluation methods indi-\\ncates a future where the performance and behavior of LLMs \\nare more transparent and accountable.\\nGPT-4\\nGPT-4, stepping up from the legacy of GPT-3.5, is a robust, \\nmultimodal model that surpasses previous versions in nearly \\nevery aspect. Its superior performance is undeniably impressive, \\nbut what truly sets it apart are the additional functionalities it \\nintroduces.\\nOne of the most striking features of GPT-4 is its creativity. \\nIt’s more creative and collaborative than ever before. Whether \\nit’s composing songs, writing screenplays, or learning a user’s \\nwriting style, GPT-4 can generate, edit, and iterate on creative \\nand technical writing tasks with a level of finesse that is truly \\nremarkable.\\nAnother significant advancement is in the area of extended \\noutputs and context inputs. GPT-4 is capable of accepting long \\ncontextual input information. It can handle up to 32,000 tokens, \\nwhich is roughly equivalent to 43,000\\xa0words, or about half of a'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 105\\n270-page book. This capability opens up a world of possibilities \\nfor more complex and nuanced interactions with the model.\\nMultimodality in AI and GPT-4’s Multimodal Advancement\\nIn the realm of AI, the term multimodal refers to models that can \\nprocess more than one type of input, such as text, images, audio, \\nand video. GPT-4 takes a significant leap in this direction by \\naccepting images as input and generating captions, classifica-\\ntions, and analyses with meticulous detail. See, for example,  \\nFigure\\xa02.26. The implications of this are profound, as it opens \\nup a new frontier for AI applications, from content moderation \\nand targeted advertising to more nuanced interactions with \\nAI models.\\nFIGURE\\xa02.26 The multimodal capabilities of GPT-4 allow it to compre-\\nhend the content of an image. Moreover, it possesses a sufficient \\nunderstanding of the world to recognize when the events depicted in \\nthe image are out of the ordinary.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='106 GENERATIVE AI\\nThe idea of multimodality extends beyond text and images. \\nIt encompasses audio and video streams, and even data from \\ndevices measuring physiological parameters such as heart rate or \\nblood sugar levels. In essence, any mode of data could be relevant \\nto an AI model, depending on the use case. This multimodal \\ncapability can significantly enhance the capabilities and applica-\\ntions of AI models.\\nConsider a social media post, for instance. A multimodal AI \\ncould analyze both the text and images in the post to understand its \\ncontent more fully. This could be used in content moderation, sen-\\ntiment analysis, or targeted advertising. Similarly, in e-commerce, a \\nmultimodal AI could analyze both product descriptions and cus-\\ntomer reviews to make more accurate product recommendations.\\nThe potential applications are not limited to these examples. \\nIn healthcare, a multimodal AI could analyze both medical imag-\\ning data and patient records to assist in diagnosis or treatment \\nplanning. In the realm of autonomous vehicles, a multimodal AI \\ncould process data from various sensors, such as cameras, radar, \\nand lidar, to navigate safely. The possibilities are vast, and the \\nopportunities for startups and companies are immense. The sky is \\nindeed the limit!\\nWhile the concept of multimodality is not new, OpenAI has \\nmanaged to make it work well, though there is still room for \\nimprovement. Other notable contributions in this field include \\nthe Multimodal-CoT model with 738\\xa0million trainable parame-\\nters, released by Amazon Science in February 2023. This open \\nsource model garnered attention for its strong performance on \\nvarious multimodal tasks, incorporating both language (text) and \\nvision (images), for now, into a two-stage framework.\\nAmazon Science, a division of Amazon, is at the forefront of \\nresearch and innovation in various fields, including machine \\nlearning, robotics, operations research, and cloud computing. \\nTheir goal is to apply cutting-edge scientific research to create'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 107\\nnew technologies, improve services, and enhance the customer \\nexperience. They have made significant strides in multimodal \\nresearch, as evidenced by their contributions.\\nIn one paper, Amazon Science trained a model that used vis-\\nual information to ground speech recognition in videos. The \\nmodel improved word error rate (WER) performance by up to \\n18 percent over subword prediction models, and incorporating \\nvisual information further improved performance.8\\nIn another paper, they addressed the problem of learning \\nproduct similarity for real-world data from the Amazon catalog. \\nThe model used the image as the primary source of information, \\nwith the title helping the model focus on relevant regions in the \\nimage. The model achieved up to a 10 percent improvement in \\nprecision compared to state-of-the-art multimodal benchmarks \\nand effectively scaled across multiple product categories.9\\nThe release of GPT-4, with its multimodal capabilities, is a \\nsignificant milestone. Although not the first to implement these \\nfeatures, OpenAI, much like Apple, has a knack for delivering \\noutstanding capabilities when they do. The demo of GPT-4\\xa0was \\nunparalleled, leveraging its unmatched text generation capabili-\\nties to set a new standard in the field of AI. This is just the begin-\\nning, and the future holds even more exciting possibilities.\\nEmergent Capabilities of GPT-4\\nThe grand reveal of GPT-4\\xa0was more than a spectacle; it was a \\ntestament to a significant leap in AI capabilities. These capabili-\\nties, known as emergent abilities, were not explicitly programmed \\nbut surfaced during the training process. As we delve into the \\n8Georgios Paraskevopoulus et\\xa0al. “Multiresolution and Multimodal Speech Recognition with T ransformers,” \\nAmazon Science, 2020, www.amazon.science/publications/multiresolution- and- multimodal- speech- recognition-  \\nwith- transformers\\n9Nilotpal Das et\\xa0 al. “MAPS: Multimodal Attention for Product Similarity,” Amazon Science, 2022, www \\n.amazon.science/publications/maps- multimodal- attention- for- product- similarity'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='108 GENERATIVE AI\\nremarkable capabilities of GPT-4, let’s first explore the concept \\nof emergent abilities, a pivotal element in our journey toward \\nartificial general intelligence (AGI).\\nEmergent abilities in AI are like unexpected gifts. They are \\nskills or capabilities that aren’t directly coded into the system but \\nemerge, almost magically, as the system learns and processes \\ninformation. These abilities surface as the large language models \\n(LLMs) are scaled up, without any specific training or architec-\\ntural modifications for these tasks. They appear in rapid and \\nunpredictable ways, demonstrating the power of LLMs to learn \\nand adapt simply by observing natural language, and visual input \\nin some cases.\\nThese abilities are the result of the system’s capacity to com-\\nbine and extrapolate from simpler learned behaviors or rules, \\nwhich it has gleaned from the data it was trained on. Essentially, \\nemergent abilities are unexpected skills that the system develops \\norganically through its learning process.\\nExamples of these abilities are diverse and impressive. They \\ninclude answering questions, summarizing passages, guessing a \\nmovie from an emoji sequence, and performing multistep rea-\\nsoning. LLMs can also understand the sentiment or emotion \\nconveyed in a piece of text, generate original stories, screenplays, \\nor even poetry, and check the veracity of a statement by cross-\\nreferencing it with the information they were trained on. Other \\nnotable abilities include advanced empathy modeling, real-time \\ntranslation, cultural understanding, ethical decision-making \\nguidance, historical analysis, and performing arithmetic.\\nOpenAI tested GPT-4’s capabilities using simulated real-\\nworld exams. The model’s performance on various benchmarks, \\nincluding exams designed for humans, was nothing short of \\nastounding. It’s important to note that GPT-4\\xa0wasn’t specifically \\ntrained for these exams. It had only seen a minority of the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 109\\nproblems during training. Y et, the results were representative, \\nand they were impressive.\\nFor instance, GPT-4 didn’t just pass the notoriously complex \\nUniform\\xa0Bar Exam; it scored in the top\\xa010 percent of test takers. \\nSimilarly, it exceeded the passing score on the United States \\nMedical Licensing Examination (USMLE) by over 20 points, \\noutperforming not only earlier general-purpose models but also \\nmodels specifically fine-tuned on medical knowledge. In the \\nrealm of mathematics, GPT-4 scored a 4 out of 5 on the Advanced \\nPlacement Calculus BC exam, a significant improvement over \\nChatGPT’s (GPT-3.5) score of 1 (see Figure\\xa02.27).\\nHowever, GPT-4’s performance was not flawless. It strug-\\ngled with the advanced LeetCode exam, a test that prepares \\ndevelopers for technical interviews, especially for those aiming \\nFIGURE\\xa02.27 GPT-4 of simulated exams. Additional visual information \\nhelps the model to perform better on the exams.\\nSource: OpenAI / https://openai.com/research/gpt-4.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='110 GENERATIVE AI\\nto join the ranks of the MAANG (Meta, Amazon, Apple, Netflix, \\nGoogle). This serves as a reminder that while AI has come a long \\nway, there are still areas where it struggles.\\nInterestingly, one such area is abstract creativity. Despite its \\nremarkable capabilities, GPT-4\\xa0has been noted to be “incapable \\nof abstract creativity.” This suggests that there are still facets of \\nhuman intelligence where we outshine our AI counterparts. It’s a \\nhumbling reminder that while we continue to push the bounda-\\nries of AI, there’s still much to learn and explore.\\nGPT-4 also exhibits steerability, the ability to change its per-\\nsonality and behavior based on user prompts (Figure\\xa02.28). This \\nallows for a more personalized and engaging interaction. Rather \\nthan the classic ChatGPT personality with a fixed verbosity, \\ntone, and style, you can now prescribe their AI’s style and task by \\ndescribing those directions in the “system” message.\\nThese system messages, along with contextual information \\nand other parameters like a goal, tone, and so forth, are opening \\nup new marketplaces where people can buy and sell effective \\nprompts, prompt patterns, and meta prompts. This is an exciting \\ndevelopment, as it opens up a whole new world of possibilities \\nfor customization and personalization of AI systems. It’s like hav-\\ning your own personal AI assistant that can be tailored to your \\nspecific needs and preferences. The future of AI is not just about \\nmore powerful models, but also about more personalized and \\nuser-friendly experiences.\\nOther Large Models and Specific Models\\nThe year 2023\\xa0marked a significant surge in the number of capable \\nAI models. Companies such as Berkeley, Stability AI, EleutherAI, \\nT ogether, Microsoft, and NVIDIA, to name a few, unveiled their \\nmodels. Each of these models was designed with a specific objective \\nin mind, from providing medical reasoning to supporting coding.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 111\\nThese models, both small and large, have demonstrated their value \\nin various ways. T o illustrate this, consider Stanford’s Alpaca and \\nBloombergGPT .\\nStanford’s Alpaca is a fascinating example of an instruction-\\nfollowing language model. It was fine-tuned from Meta’s LLaMA \\n7B model, which itself was trained on 52,000 instruction-  \\nfollowing demonstrations generated using OpenAI’s GPT-3.5. \\nThis process of one model fine-tuning another exemplifies the \\npotential of diverse data sources in AI development.\\nFIGURE\\xa02.28 Steerability example of GPT-4 as a Socratic tutor.\\nSource: OpenAI / https://openai.com/research/gpt-4.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='112 GENERATIVE AI\\nThe instruction-following demonstrations were generated \\nusing the self-instruct method. This involved using 175 human-\\nwritten instruction-output pairs from the self-instruct seed set. \\nIn simpler terms, this means that the model was trained using a \\nset of instructions and their corresponding outputs, which were \\nprovided by humans. This method allowed the model to learn \\nhow to follow instructions and generate appropriate outputs.\\nOne of the most striking aspects of Alpaca is its cost- \\neffectiveness. The generation pipeline was simplified, and the \\ncost was significantly reduced. This resulted in 52,000 unique \\ninstructions and corresponding outputs, costing less than $500 \\nusing the OpenAI API. Fine-tuning a LLaMA 7B model took \\nonly threes hours on eight 80\\xa0GB A100s, costing less than $100 \\non most cloud compute providers. Figure\\xa02.29 shows the Alpaca \\nmodel development process.\\nDespite its size, Alpaca exhibits many behaviors similar to \\nthose of OpenAI’s GPT-3.5, making it surprisingly powerful and \\nLLaMA 7BText-davinci-003\\n175 Self-\\nInstruct\\nseed tasks\\nModified Self-instruct\\nInstruction Generation\\nSupervised\\nFinetuning \\nInstruction: Brainstorm a list of\\npossible NewYear’s resolutions.\\nOutput:\\n- Lose weight\\n- Exercise more\\n- Eat healthier \\nAlpaca 7B 52K\\nInstruction-following\\nexamples \\nExample seed task\\nInstruction: Brainstorm creative\\nideas for designing a conference\\nroom.\\nOutput:\\ncomponents, such as moveable\\n... incorporating flexible\\nwalls and furniture ...\\nExample Generated task\\nFIGURE\\xa02.29 The Alpaca model development process: starting with a \\nseed set of human-written instructions, expanding it using text-\\ndavinci-003, and fine-tuning the LLaMA models using Hugging Face’s \\ntraining framework.\\nSource: https://crfm.stanford.edu/2023/03/13/alpaca.html. (a) OpenAI and (b) Meta.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 113\\neasy to reproduce. However, it still exhibits some of the classic \\nlimitations of instruction-following models, such as toxicity, hal-\\nlucinations, or stereotypes.\\nThe researchers behind Alpaca believe that releasing the train-\\ning recipe, data, model weights, and training code incurs minimal \\nfurther risk, given the simplicity of the recipe. They see this as a \\nsignificant step toward reproducible science. However, it’s impor-\\ntant to note that Alpaca is intended only for academic research, \\nand any commercial use is prohibited.\\nMoving on to BloombergGPT , this model was developed by \\nBloomberg and has been specifically trained on a wide range of \\nfinancial data. It is a 50 billion-parameter LLM that is purpose-\\nbuilt from scratch for finance. BloombergGPT can evaluate \\nfinancial data in real time, including market data, breaking news, \\nfinancial research, and advanced analytics. It can perform tasks \\nsuch as sentiment analysis, news classification, and question-\\nanswering, among others.\\nBloombergGPT is designed to enhance Bloomberg’s current \\nfinancial NLP capabilities and open up fresh possibilities for \\norganizing the enormous amounts of data available on the \\nBloomberg T erminal. For those unfamiliar, the Bloomberg T er-\\nminal is a computer software system provided by Bloomberg L.P . \\nthat enables professionals in finance and other industries to \\naccess Bloomberg’s professional services, including real-time \\nfinancial data, news feeds, and messages, and also to place trades.\\nThe model is trained on Bloomberg’s extensive archive of \\nfinancial data, which has been meticulously collected and curated \\nover 40 years. This makes BloombergGPT unique as it is trained \\non highly specific financial data, which is expected to make it \\nmore effective for financial NLP tasks. However, Bloomberg-\\nGPT is only accessible within Bloomberg and will be used to \\nprocess large amounts of data on Bloomberg T erminal.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='114 GENERATIVE AI\\nThe release of BloombergGPT is part of a trend of companies \\ndeveloping their own LLMs, tailored to their specific needs and \\ndata. This trend is not just a passing fad, but a significant shift in \\nthe AI landscape. Many companies have already announced their \\ninterest in following suit, indicating that the future of AI is not just \\nabout more powerful models, but also about more personalized \\nand user-friendly experiences.\\nApplications of\\xa0Specific Language Models\\nLet’s consider a few more sectors where these models could be \\nand in fact are leveraged to great effect.\\nIn the realm of healthcare, hospitals and healthcare providers \\ncould develop a language model trained on medical literature \\nand patient data (while respecting privacy laws) to assist doctors \\nin diagnosing diseases or suggesting treatments. Imagine a  \\n“MayoClinicGPT” that could interpret patient symptoms and \\nmedical history, suggest potential diagnoses, and even generate \\npatient-friendly explanations of complex medical conditions. \\nThis is not a far-fetched idea. K Health, for instance, has devel-\\noped an AI-driven platform that uses anonymized health data to \\nprovide personalized medical information.\\nIn the legal sector, law firms might create a language model \\ntrained on legal texts and case law to assist in legal research or \\ndrafting legal documents. A “LegalGPT” could help lawyers to \\nquickly find relevant case law, draft legal documents, and even \\npredict the outcome of legal cases based on historical data. Har-\\nvey AI, a UK-based company, has developed an AI model for the \\nlegal sector that uses AI to automate legal processes, making it \\neasier for lawyers to manage their workloads and focus on more \\ncomplex tasks, utilizing their core competencies.\\nEducation is another sector ripe for AI intervention. Educa-\\ntional institutions or e-learning platforms could create a language \\nmodel trained on educational content to provide personalized'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 115\\nlearning experiences. Khan Academy, for instance, has partnered \\nwith OpenAI to create an AI model for education. This model, \\n“Khanmigo,” is designed to provide personalized learning experi-\\nences, making education more accessible and effective.\\nIn the retail sector, e-commerce companies might develop a \\nlanguage model trained on product descriptions and customer \\nreviews to improve product recommendations or customer ser -\\nvice. An “AmazonGPT” could be used to generate accurate prod-\\nuct recommendations, answer customer queries, and even predict \\nfuture shopping trends.\\nInsurance companies could develop a language model trained \\non insurance claims and policy data to streamline the claims pro-\\ncess and provide personalized policy recommendations. For exam-\\nple, a “StateFarmGPT” could be used to interpret insurance \\nclaims, suggest policy adjustments, and even generate customer-\\nfriendly explanations of complex insurance terms. MetLife, for \\ninstance, is using AI to streamline the claims process and provide \\npersonalized policy recommendations.\\nIn the real estate sector, firms might create a language model \\ntrained on property listings and market data to assist in property \\nvaluation or predicting market trends. A “ZillowGPT” could \\nhelp real estate agents to quickly find comparable properties, \\nestimate property values, and even predict future real estate mar-\\nket trends. Skyline AI, a real estate investment technology com-\\npany, uses AI to enhance the property investment process.\\nT ravel agencies and hospitality companies could develop a \\nlanguage model trained on travel guides and customer reviews to \\nprovide personalized travel recommendations. Allora, a travel \\ntechnology company, has developed an AI-driven platform for \\nthe hospitality industry that uses customer reviews and travel \\nguides to provide personalized travel recommendations.\\nIn the media and entertainment sector, companies could cre-\\nate a language model trained on scripts, reviews, and audience \\ndata to assist in content creation and audience targeting. A'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='116 GENERATIVE AI\\n“NetflixGPT” could be used to suggest plot ideas, predict audi-\\nence preferences, and even generate promotional content.\\nConsider the telecommunications sector. Here, AI models \\ncould be a game changer. Imagine a “VerizonGPT ,” trained on \\nnetwork data and customer feedback, working tirelessly to \\nenhance network performance and customer service. It could \\npredict network issues before they occur, suggest improvements, \\nand even demystify complex telecom terms for customers. This \\nisn’t just speculation— McKinsey reports that AI is already trans-\\nforming telco service operations, with models predicting net-\\nwork issues, recommending improvements, and simplifying \\ncomplex telecom jargon.\\nIn the energy sector, companies might develop a language \\nmodel trained on energy usage data and research to improve \\nenergy efficiency and develop new energy solutions. An “Exxon-\\nMobilGPT” could be used to analyze energy usage trends, sug-\\ngest energy-saving measures, and even predict future energy  \\ntrends.\\nThink food and beverages, and imagine the transformative \\npower of AI. Envision a “CocaColaGPT ,” an AI model trained \\non a rich blend of recipe data and customer reviews. It’s stirring \\nup new beverage ideas, responding to customer queries with \\nease, and even forecasting the next big trends in food and bever-\\nages. This isn’t a futuristic dream— it’s already happening. For \\nexample, McCormick & Company is using AI to create an excit-\\ning array of new flavors and food products.\\nPharmaceutical companies could develop a language model \\ntrained on medical research and clinical trial data to assist in drug \\ndiscovery and development. A “PfizerGPT” could be used to \\ninterpret research findings, suggest potential drug candidates, \\nand even generate patient-friendly explanations of complex \\nmedical research.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 117\\nPicture the aerospace industry, where AI could take flight in \\na big way. Companies could harness a language model like, for \\nexample, “SpaceXGPT ,” trained on aerospace engineering data \\nand research, to turbocharge the design and development of air-\\ncraft and spacecraft. This AI co-pilot could assist engineers in \\nswiftly locating pertinent research, sparking innovative design \\nideas, and even forecasting the trajectory of aerospace projects \\nbased on historical data.\\nThe potential for AI model applications across industries is \\ninfinite. Y et, it’s worth noting that some of the strategies I’ve dis-\\ncussed are already being implemented by ChatGPT plug-ins. \\nWe can anticipate not just a tenfold increase in productivity, but \\nalso a tenfold enhancement in experience. The horizon of AI \\nholds promise for even more thrilling advancements in the \\nyears to come.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content=''),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='119\\nT\\nhis chapter offers a concise exploration of generative AI’s \\ndiverse applications, highlighting how the technology is \\nreshaping industries from music to 3D object generation. The \\nconcept of “finding the untapped” is an observed strategy for \\nuncovering and leveraging gen AI’s vast potential.\\nFoundational and Specialized AI Models, and \\nthe Question of Open Source vs. Closed Source\\nJust as the Internet has become a fundamental part of the opera-\\ntions of most companies, we are witnessing a similar transition \\nwith AI. We are still in the early stages of this transition, and \\nthere is a vast landscape of opportunities for those venturing into \\n3\\nCHAPTER\\nGenerative AI’s Broad \\n Spectrum of Applications'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='120 GENERATIVE AI\\nthis field and making progress in it. Established companies like \\nIBM and Microsoft have shifted their focus to AI over time, and \\nnew companies and startups are emerging with AI at the core of \\ntheir products. For instance, Rain Neuromorphics is building \\nartificial brains to make AI radically cheaper, aiming to enable \\nubiquitous advanced AI and power fully autonomous artificial \\ngeneral intelligence (AGI). Allganize, on the other hand, is revo-\\nlutionizing enterprise productivity with its AI document under -\\nstanding platform, Alli. Adept is building an ML model that can \\ninteract with everything on your computer, aiming to build an AI \\nteammate for everyone.\\nThe direction is clear: an AI-driven future, not only in indus-\\ntry but also in society. There is, however, another important \\nobservation to make. We can roughly separate AI adoption into \\ntwo waves, or shock waves, looking at the pace of it. The first \\nwave consists of model-maker companies, and the second wave \\nconsists of startups and companies with innovative approaches \\nthat use the models of the model-makers to build niche products. \\nThese companies, perhaps already niche somewhere, are paving \\nthe way for society to experience the power of AI.\\nFirst Wave of the Generative AI Adoption: Model-Makers\\nThe first wave of AI adoption is characterized by the rise of \\nmodel-maker companies. These are exceptional companies with \\nexceptional talent. They require substantial funding, as training \\nAI models can cost millions, and they need the knowledge to \\nbuild these models. Interestingly, these model-maker companies \\noften don’t have large teams of thousands of engineers and com-\\nputer scientists. Instead, they tend to operate with smaller, more \\nfocused, and highly talented teams. This approach seems to fos-\\nter innovation and efficiency, allowing these companies to make \\nsignificant strides in AI development with a lean team structure.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 121\\nOpenAI, for instance, has raised more than $11 billion in \\nfunding over four rounds. Most of this funding is used for train-\\ning their models. Despite having a relatively small team of \\nroughly 375 employees, they have achieved significantly more \\nthan companies with thousands of research scientists. This still is \\na mystery to me. Y es, they have a few hundred contractors, but \\nthe core team and capabilities are within OpenAI. They have \\nbeen pioneering research on the path to AGI and transforming \\nwork and creativity with AI. They have introduced products like \\nthe ChatGPT app for iOS or plug-ins for ChatGPT and are \\ncontinuously making strides in AI research and safety.\\nAnthropic AI In the midst of the COVID pandemic in 2021, a \\nnew player emerged on the AI scene. Anthropic, founded by for-\\nmer senior members of OpenAI, including siblings Daniela \\nAmodei and Dario Amodei (who served as OpenAI’s vice presi-\\ndent of research), burst onto the scene with a clear and compel-\\nling mission. They aimed to build large-scale AI systems that are \\nsteerable, interpretable, and robust.\\nAnthropic, a company that started from scratch, has raised \\na staggering $1.5 billion in funding, catapulting it to a valuation \\nof almost $5 billion. This meteoric rise is a testament to the \\ntransformative potential of AI and the faith investors have in \\nAnthropic’s vision and capabilities. As you might expect, they \\nare now in a phase of rapid expansion, hiring talent to join their \\n“small but growing” team.\\nAnthropic’s focus is on AI safety and alignment with human \\nvalues, a crucial aspect of AI development that cannot be over -\\nstated. They envision a future where AI’s impact could be on par \\nwith the industrial and scientific revolutions, a future where rapid \\nAI progress leads to transformative AI systems. T o prepare for \\nthis future, they are pursuing a variety of research directions,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='122 GENERATIVE AI\\nall aimed at better understanding, evaluating, and aligning \\nAI systems.\\nTheir approach is empirical, heavily relying on evidence and \\nreal-world observations. This grounded approach allows them to \\nnavigate the complex landscape of AI development with a clear \\nvision and a firm grasp on reality. What sets them apart is their \\nunique approach to AI safety research. They take a “portfolio \\napproach,” preparing for a wide range of scenarios, from the \\nmost optimistic to the most pessimistic, regarding the safety and \\ncontrol of advanced AI systems.\\nAnthropic’s unique approach to ensuring AI safety is a topic \\nwe’ll revisit in a later chapter, specifically when we explore the \\nethical side of generative AI. Their story is representative of the \\nexciting and dynamic nature of the AI field, where new players \\ncan emerge and make significant strides in a short span of time.\\nGoogle DeepMind In the dynamic landscape of AI, Google \\nDeepMind stands as a beacon of innovation. Acquired by Google \\nin 2014 for a staggering $500\\xa0 million dollars, DeepMind has \\ngrown into a powerhouse of AI development. The acquisition, \\nfor which Facebook had initially been in negotiations, has proven \\nto be a lucrative deal for Google, as DeepMind has been at the \\nforefront of numerous groundbreaking advancements in the \\nfield of AI.\\nDeepMind’s prowess lies in its innovative approach to AI, par-\\nticularly in the areas of deep learning and reinforcement learning. \\nThe company has developed AI systems capable of learning and \\nmastering complex tasks autonomously, demonstrating its com-\\nmitment to creating systems that can adapt and evolve.\\nHowever, the achievement that truly shook the world of AI \\nwas Google’s AlphaGo’s historic victory over Go champion Lee'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 123\\nSedol. This victory was significant because Go had previously \\nbeen regarded as a hard problem in machine learning that was \\nexpected to be out of reach for the technology of the time. Alpha-\\nGo’s victory not only demonstrated the capabilities of AI but also \\nmarked a turning point in the perception of AI’s potential.\\nDeepMind’s mission is to “solve intelligence” and create AGI, \\na type of AI that can understand, learn, and apply its knowledge \\nto a wide variety of tasks, much like a human brain. Their \\napproach is unique in that it focuses on creating systems that can \\nlearn and adapt autonomously. They combine two promising \\nareas of research— deep neural networks and reinforcement \\nlearning algorithms— to create AI systems that can apply their \\nlearning from one domain to a new domain.\\nOne of DeepMind’s most significant achievements is Alpha-\\nFold, an AI system that has been recognized as a solution to the \\n50-year-old grand challenge in biology known as the protein- \\nfolding problem. This breakthrough demonstrates the impact AI \\ncan have on scientific discovery and its potential to dramatically \\naccelerate progress in some of the most fundamental fields that \\nexplain and shape our world.\\nSecond Wave of AI Adoption: AI Model Wrapper Companies\\nAs we delve deeper into the realm of AI, we encounter a diverse \\narray of entities known as model-makers. These are the master -\\nminds behind large-scale machine learning models trained on a \\nbroad spectrum of Internet data. These models serve as a base— a \\nfoundation, if you will— for myriad downstream tasks. Their \\nsize and the vastness of their training data endow them with a \\ngeneral understanding of human language, making them incred-\\nibly versatile and useful across a multitude of applications.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='124 GENERATIVE AI\\nModel-making powerhouses include Facebook AI Research \\n(FAIR), Baidu Research, NVIDIA AI Research, and Stability AI, \\nin addition to the previously mentioned OpenAI, Anthropic, and \\nGoogle DeepMind. Each organization has made significant \\nstrides in the development and application of foundation models. \\nAdept AI, a company with a keen focus on crafting useful general \\nintelligence, also stands out in this field. Even conglomerates like \\nLG from Korea have dedicated research departments working \\non these models. The list is extensive and continues to grow, \\nreflecting the increasing importance and influence of foundation \\nmodels in the field of AI.\\nThe second wave of the generative AI impact has given rise \\nto a multitude of startups and a handful of established compa-\\nnies. They harness the power of foundation models to tailor \\nsolutions to specific needs, as indicated in Figure\\xa03.1. The ripple \\neffects of this wave are far-reaching and diverse. Advancements \\nin text generation have revolutionized copywriting, customer \\nrelations, knowledge, and research. In the realm of audio, we’ve \\nseen innovations in music generation, speech generation, and \\nother sounds. Image generation has seen significant strides in \\ninfluencing design and marketing. Code generation and devel-\\nopment applications have also seen advancements. Video genera-\\ntion, synthetic data generation, and even the gaming and design \\nindustry have been revolutionized with the creation of 3D assets \\nand worlds, characters, and NPCs. Legal, tax advisory, and health \\nsolutions have also been influenced. AI model management has \\nseen advancements in fine-tuning, prompt management, and \\ndesigning, optimization, monitoring, and storage.\\nBetween March and May 2023, thousands of companies were \\nfounded. The first wave of generative AI was fundamentally \\nimportant, and the second wave is equally crucial in capturing \\nthat value. Goldman Sachs suggests that generative AI could \\ndrive a 7 percent (or almost $7 trillion) increase in global GDP'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 125\\nover 10 years. Other research estimates that the global artificial \\nintelligence market, which includes generative AI, is expected to \\nreach $1,811.75 billion by 2030, expanding at a compound annual \\ngrowth rate (CAGR)— a measure of the average yearly growth \\nrate over a specified period— of 37.3 percent from 2023 to 2030. \\nThe generative AI market\\xa0alone is expected to reach $38.8 bil-\\nlion by 2026. While different sources suggest different figures,  \\nI am much more optimistic, as I anticipate a tenfold increase  \\nin productivity, after some adoption, and hopefully a diminished \\nreluctance to use it.\\nMicrosoft’s AI Dominance\\nWhile the primary aim of this chapter is to explore the expansive \\npanorama of generative AI and its far-reaching implications, \\nwe’ll momentarily pause our examination of the application \\nData\\nText\\nImages\\nSpeech\\nStructured\\nData\\n3D Signals\\nTraining Foundation\\nModel\\nAdaptation\\nTasks\\nQuestion\\n Answering\\nSentiment\\n   Analysis\\nInformation\\nExtraction\\nImage\\nCaptioning\\nObject\\nRecognition\\nInstruction\\nFollowing\\nFIGURE\\xa03.1 From foundation models to serving specific tasks.\\nSource: “On the Opportunities and Risks of Foundation Models,” Stanford University'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='126 GENERATIVE AI\\nfields and their innovative approaches. There’s an undercurrent, \\na less apparent yet significant power struggle, that merits our \\nattention. It’s the clash of titans: Microsoft versus Google. This \\nconfrontation is worth noting as we stand at a pivotal juncture, a \\nmoment that will determine who will seize the reins of global AI \\ndominance.\\nMicrosoft has been making strategic moves to assert its lead-\\nership in the global AI landscape. One of their notable initiatives \\nis that they have ramped up their efforts in the development and \\ndeployment of specialized supercomputing systems. These sys-\\ntems are designed to accelerate OpenAI’s groundbreaking inde-\\npendent AI research, and they also continue to enhance Azure’s \\nleading AI infrastructure to aid customers in building and deploy-\\ning their AI applications on a global scale.\\nAnother significant step taken by Microsoft is their partner -\\nship with OpenAI. Initially investing in OpenAI, Microsoft has \\nextended its partnership through a multiyear, multibillion-dollar \\ninvestment. This partnership aims to accelerate AI breakthroughs \\nand ensure these benefits are broadly shared with the world. The \\nagreement extends their ongoing collaboration across AI super -\\ncomputing and research and enables both parties to indepen-\\ndently commercialize the resulting advanced AI technologies.\\nMicrosoft has also been deploying OpenAI’s models across \\nits consumer and enterprise products and introduced new cate-\\ngories of digital experiences built on OpenAI’s technology. This \\nincludes Microsoft’s Azure OpenAI Service, which empowers \\ndevelopers to build cutting-edge AI applications through direct \\naccess to OpenAI models backed by Azure’s trusted, enterprise-\\ngrade capabilities and AI-optimized infrastructure and tools.\\nAs OpenAI’s exclusive cloud provider, Azure powers all  \\nOpenAI workloads across research, products, and API services. \\nThis exclusive partnership has been a strategic move for'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 127\\nMicrosoft, reinforcing its commitment to AI and its position as a \\nglobal leader in the field.\\nIn a significant development, OpenAI’s GPT-4 technology, \\nwhich was designed to be the underlying engine that powers \\nchatbots and all sorts of other systems, has been integrated into \\nMicrosoft’s Bing search engine. This integration showcases the \\npractical application of advanced AI technologies in everyday \\ndigital experiences.\\nGoogle’s AI Dominance\\nGoogle, from its inception, has been a beacon of AI innovation. \\nHowever, Microsoft’s strides with OpenAI have started to chal-\\nlenge this position significantly. In response, Google has been \\nfocusing on building an answer to ChatGPT . Let’s examine the \\nsteps Google has taken to maintain its position in this competi-\\ntive landscape.\\nGoogle Cloud offers a suite of AI and machine learning (ML) \\nservices that businesses can use to build, deploy, and scale AI \\nmodels. These services include Atoll, AI Platform, and AI Build-\\ning Blocks. Google Cloud also provides industry-specific AI \\nsolutions, such as Contact Center AI and Document AI.\\nGoogle’s 2014 acquisition of DeepMind, a leading AI research \\nlab, has led to significant advancements in AI research and devel-\\nopment. More recently, Google acquired Anthropic AI, a startup \\nfocused on building large-scale models that are understandable \\nand interpretable. This acquisition further strengthens Google’s \\nAI capabilities.\\nIn an effort to consolidate its AI research and development \\nefforts, Google merged its two main AI research groups, Google \\nBrain and DeepMind. This strategic move has streamlined \\nGoogle’s AI research, allowing for more focused and efficient \\ndevelopment.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='128 GENERATIVE AI\\nGoogle announced an ambitious project to develop a single \\nAI language model that supports the world’s “1,000\\xa0most spoken \\nlanguages.” This initiative aims to bring various AI functionali-\\nties to languages that are poorly represented in online spaces and \\nAI training datasets, thereby promoting inclusivity and diver -\\nsity in AI.\\nGoogle has also developed Bard, a conversational generative \\nAI chatbot, as a direct response to the rise of OpenAI’s Chat-\\nGPT . Bard, initially based on the LaMDA family of large lan-\\nguage models (LLMs) and later on PaLM, an LLM also developed \\nby Google, was released in a limited capacity in March 2023.\\nGoogle’s Bard In the wake of OpenAI’s ChatGPT , Google \\nintroduced Bard, a conversational AI chatbot. Bard was initially \\nbuilt on the LaMDA family of LLMs but was later upgraded to \\nthe more powerful PaLM LLM. The development of Bard was \\na reaction to the success of ChatGPT , which had gained world-\\nwide attention and was seen as a potential threat to Google \\nSearch. This led to emergency meetings involving Google  \\nco-founders Larry Page and Sergey Brin, where they discussed \\nGoogle’s response to ChatGPT .\\nBefore Bard, Google had already developed LaMDA, a pro-\\ntotype LLM. However, it had not been released to the public due \\nto concerns about reputational risk. In January 2023, Google \\nemployees were instructed to accelerate progress on a ChatGPT \\ncompetitor, intensively testing “Apprentice Bard” and other \\nchatbots. Bard was announced on February 6, 2023, and was first \\nrolled out to a select group of 10,000 “trusted testers,” who rig-\\norously tested its capabilities.\\nThe technology was developed under the codename “Atlas,” \\nwith the name “Bard” chosen to reflect the creative nature of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 129\\nthe algorithm. The announcement of Bard was seen as a \\nresponse to Microsoft’s planned event to unveil its partnership \\nwith OpenAI to integrate ChatGPT into its Bing search engine. \\nHowever, after a poorly received livestream showcasing Bard, \\nGoogle’s stock fell 8 percent, equivalent to a $100 billion loss in \\nmarket value.\\nDespite criticism from Google employees and concerns \\nabout safety and ethics, Google executives decided to proceed \\nwith the launch of Bard. Bard was launched as a stand-alone web \\napplication, with users prompted to submit feedback on the use-\\nfulness of each answer. However, the launch was not without \\ncontroversy. Google researcher Jacob Devlin resigned from the \\ncompany after claiming that Bard had surreptitiously leveraged \\ndata from ChatGPT , an allegation that Google denied.\\nBard was later upgraded to be based on PaLM, a newer and \\nmore powerful LLM from Google, and gained the ability to assist \\nin coding. The Pathways Language Model (PaLM), a 540 billion–\\nparameter, densely activated T ransformer language model, was \\ntrained on 6144 TPU v4 chips using Pathways, a new ML system \\nthat enables highly efficient training across multiple TPU Pods. \\nGoogle custom-developed its own tensor processing units \\n(TPUs), which are application-specific integrated circuits (ASICs) \\nused to accelerate ML workloads. TPUs are designed to handle \\nmassive matrix operations used in neural networks at fast speeds.\\nPaLM surpassed average human performance on the BIG-\\nbench benchmark, a collaborative benchmark openly developed \\nby GitHub that was intended to probe LLMs and extrapolate \\ntheir future capabilities. BIG-bench includes more than 200 \\ntasks summarized by keyword and task name. PaLM showed \\nstrong results on tasks such as logical inference.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='130 GENERATIVE AI\\nPaLM is part of Google’s vision to enable a single AI system \\nto generalize across thousands or millions of tasks, to understand \\ndifferent types of data, and to do so with remarkable efficiency. It \\nhas set new state-of-the-art records on English-only natural lan-\\nguage processing (NLP) tasks and competitive performance on \\nmultilingual tasks. The team behind PaLM has noted areas for \\nimprovement, such as the model being too large for its compute \\nbudget and the fact that encoder-decoder models fine-tune better.\\nGoogle is working to integrate Bard into its ChromeOS \\noperating system and Pixel devices. Bard received mixed reviews \\nupon its initial release, with some critics finding it faster than \\nChatGPT and Bing, but others criticizing its uninteresting and \\nsometimes inaccurate responses. Despite these criticisms, Google \\ncontinues to improve Bard, with recent updates adding improved \\nmath and logic capabilities.\\nThe journey of Bard has been a rollercoaster ride, with its \\nshare of highs and lows. From its inception as a response to \\nChatGPT to the controversies surrounding its launch and the \\nsubsequent improvements and upgrades, Bard has been a testa-\\nment to Google’s commitment to advancing AI technology. \\nDespite the initial setbacks, Google has continued to refine and \\nenhance Bard, demonstrating its dedication to creating a chatbot \\nthat can effectively interact with and assist users.\\nThe development of Bard and PaLM also highlights Google’s \\nefforts to promote inclusivity and diversity in AI. Despite the exist-\\nence of over 7,000\\xa0languages worldwide, the Internet represents \\nonly a fraction of these. Google Search supports 348\\xa0languages, \\nFacebook recognizes 120, and LinkedIn only 24. This disparity \\ncreates a barrier to information access for many people, not only \\ndue to a lack of technology but also because their language is \\nunderrepresented online. Google’s Bard and PaLM, part of a'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 131\\nproject to support the world’s “1,000\\xa0most spoken languages,” aim \\nto address this issue, promoting inclusivity and diversity in AI. \\nThis endeavor could significantly contribute to making the Inter-\\nnet a more inclusive space.\\nChatGPT vs. Bard Performance\\nThe intense competition between Google’s Bard and OpenAI’s \\nChatGPT has sparked much debate. Each chatbot possesses dis-\\ntinct strengths and weaknesses, and their performance fluctuates \\ndepending on the task at hand.\\nWhen it comes to summarizing long-form content, Chat-\\nGPT has an edge over Bard. It provides a more detailed sum-\\nmary, whereas Bard’s summary tends to be terse and conveys less \\ninformation. In the realm of coding, both models have their \\nshortcomings. However, ChatGPT has shown a quicker ability \\nto iterate to a correct version of a Python function. As for craft-\\ning a customized tweet, both models perform adequately, but \\nChatGPT’s response tends to exceed the character limit, neces-\\nsitating edits.\\nIn terms of mimicking natural language and facilitating open-\\nended conversations, Bard outshines ChatGPT . Bard’s responses \\nare designed to be ultra-authentic, mimicking human speech. \\nHowever, some responses have been found to be less than authen-\\ntic, indicating room for improvement. One of Bard’s significant \\nadvantages is its capability to draw responses from the Internet in \\nreal time, while ChatGPT relies on a dataset that only goes up \\nuntil late 2021. This changes if one is enabled to use plug-ins or \\nthe ChatGPT Browser, which is gradually being released to \\nthe public.\\nWhen it comes to user-friendliness and interface, Bard takes \\nthe lead with a more visually appealing interface and formatted'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='132 GENERATIVE AI\\ntext that’s easier to scan. It also allows users to edit their ques-\\ntions after they ask them, enhancing the user experience. How-\\never, in the area of text processing, such as summarization and \\nparagraph writing, ChatGPT outperforms Bard, making it ideal \\nfor applications that require these capabilities.\\nIn terms of cost, access to ChatGPT is limited and comes at \\na price, whereas Bard is free for all.\\nChatGPT leads in text generation, with Microsoft/OpenAI \\nand Google’s models rapidly evolving, reshaping conversational \\nAI. Amidst this, Elon Musk’s xAI’s Grok, with unique data access \\nto X/T witter, challenges their dominance, indicating a dynamic  \\nfuture.\\nGenerative AI Platforms\\nAs we traverse the landscape of generative AI applications, a \\nmore fundamental question arises: What new generative  \\nAI platforms are emerging, and who will be their proprietors? A \\nmultitude of platforms are sprouting up, each with unique offer-\\nings. For instance, Selas AI provides plug-and-play services to \\nleverage state-of-the-art text-to-anything features for businesses, \\noffering a full-stack solution to build products. Another platform, \\nAspen AI, offers a no-code platform for building AI-powered \\nweb apps, allowing users to configure AI models and deploy their \\napplications in minutes.\\nIn the midst of this technological evolution, we are witness-\\ning a shift from a software-centric world to an AI-centric one. \\nGenerative AI platforms are becoming the new infrastructure for \\ndigital products and services, replacing traditional software. This \\ntransformation is not merely a change in the tools we use but a \\nfundamental shift in how we approach the creation and delivery \\nof digital services.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 133\\nHowever, this shift does present challenges. Some, like the \\ninvestment firm Andreesen Horowitz, argue that the control of \\ngenerative AI platforms, including the respective data therein, by \\na few large tech companies could lead to a concentration of \\npower and a lack of competition. While the point of dominance \\nis valid, I believe that there have never been so many opportuni-\\nties for everyone in a tech revolution like this one. There  \\nare so many angles and ideas to deploy that this dominant posi-\\ntion, while influential, does not necessarily stifle competition or \\ninnovation.\\nIn fact, we are also witnessing a completely new open and \\ncollaborative approach to AI development, arguing that this \\nwould lead to more innovation and better outcomes for society. \\n(Chapter\\xa04, “Generative AI’s Exponential Growth,” explores the \\nopen source activities happening on this front.)\\nNow, let’s turn our attention to the existing layers of the tech \\nlandscape (Figure\\xa03.2). The first layer is hardware, which includes \\nGPUs, TPUs, servers, and accelerator chips optimized for model \\ntraining and inference workloads. These components form the \\nphysical infrastructure that powers AI technologies. The second \\nlayer is the cloud platforms, such as Google Cloud, AWS from \\nAmazon, and Azure. These platforms build a virtual layer on top \\nof the hardware, providing scalable computing resources and a \\nrange of services for developing, deploying, and managing AI \\napplications.\\nIn the tech chain, we have large foundation models that are \\nexpensively trained on vast data. These foundation models are \\nthen customized, fine-tuned, or prompt-designed for specific use \\ncases. This process leads to the development of end-to-end apps, \\nwhich are end user–facing applications with proprietary models. \\nA good example of an end-to-end app is ActiveChat.AI, a  \\nplatform that uses AI to automate customer service and sales \\nprocesses.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='134 GENERATIVE AI\\nOn the other hand, we observe the separation of foundation \\nmodels and downstream customization. Here, we distinguish \\nbetween closed and open source. Closed source foundation mod-\\nels, like OpenAI’s GPT-4, are large-scale, pretrained models \\nexposed to downstream apps via APIs, which are paid. The open \\nsource variant uses openly available foundation models like Sta-\\nble Diffusion or StableLM from Stability AI. These models are \\noften released as trained weights and hosted on model hubs, like \\nHugging Face and Replicate, which share and host models.\\nApps\\nApps\\nEnd-to-End Apps\\nClosed Source\\nFoundation Models\\nModel Hubs\\nCloud Platforms\\nCompute Hardware\\nOpen Source\\nFoundation Models\\nUsers Models\\nInfrastructure\\nExamples: Jasper, Github Copilot\\nExamples: Hugging Face, Replicate\\nExamples: Stable Diffusion (Stability)\\nExamples: AWS, GCP, Azure, Coreweave\\nExamples: GPUs (NVIDIA), TPUs (Google)\\nExamples: GPT-3\\n(OpenAI)\\nExamples: Midjourney,\\nRunway\\nEnd user–facing B2B and B2C applications\\nwithout proprietary models\\nPlatforms to share and host models\\nModels released as trained weights\\nCompute hardware exposed to developers in a cloud deployment model\\nAccelerator chips optimized for model training and inference workloads\\nLarge-scale, pre-\\ntrained models\\nexposed via APIs\\nEnd user–facing\\napplications with\\nproprietary models\\nFIGURE\\xa03.2 Preliminary generative AI tech stack.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 135\\nThe closed source and open source foundation models ena-\\nble downstream applications via APIs. The apps are end user–\\nfacing B2B and B2C applications without proprietary models. \\nExamples here include Jasper, an AI-powered assistant that  \\nhelps manage and automate digital marketing tasks, and GitHub  \\nCopilot, a tool that suggests code snippets as developers type, \\neffectively acting as an AI pair programmer.\\nThis platform landscape, as I see it, will consolidate even fur-\\nther. One emerging element in this big-picture perspective is \\nautonomous agents. These are systems capable of autonomous, \\npurposeful action in the real world. They sense and act autono-\\nmously in their environment, realizing a set of goals or tasks for \\nwhich they are designed. We will discuss autonomous agents in \\nmore detail later, and time will tell how they will shape the AI \\nlandscape.\\nOpen Source Models\\nOpen source models, such as StableLM and GPT-NeoX-20B, \\nare a cornerstone of the AI landscape. They are software or AI \\nmodels whose source code is made available to the public, allow-\\ning anyone to view, use, modify, and distribute the project’s \\nsource code. This openness fosters a collaborative environment \\nwhere developers from around the globe can contribute to the \\ncode, leading to a diverse range of perspectives and expertise that \\ncan enhance the quality and functionality of the model.\\nFor instance, GPT-NeoX-20B, developed by EleutherAI, is a \\n20 billion–parameter autoregressive language model trained on the \\nPile using the GPT-NeoX library. Its architecture closely resembles \\nthat of GPT-3. The model was trained on a multitude of English-\\nlanguage texts, reflecting its general-purpose nature. The model’s \\nsource code is available on Hugging Face, the platform that hosts \\nand shares models, allowing anyone to study and modify it.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='136 GENERATIVE AI\\nOpen source models like these promote transparency and \\naccountability, as anyone can inspect the code for bugs, errors, or \\nbiases. They also serve as a great learning resource for individu-\\nals and organizations looking to understand or get started with \\nAI, as they can study and modify existing models. The open \\nnature of these models encourages innovation, as developers can \\nbuild upon existing models to create new solutions.\\nHowever, it’s important to note that training large AI models \\ncan be expensive, and this cost can be prohibitive for some devel-\\nopers or organizations. Moreover, because open source models \\nare publicly available, they can be misused by malicious actors. \\nDespite these challenges, the benefits of open source models in \\npromoting transparency, fostering innovation, and serving as a \\nlearning resource make them a vital part of the AI landscape.\\nClosed Source Models\\nClosed source models, unlike their open source counterparts, are \\nproprietary software or AI models whose source code is not dis-\\nclosed to the public. The code is owned, controlled, and main-\\ntained by a specific individual, team, or organization.\\nA prime example of a closed source model is GPT-4, devel-\\noped by OpenAI. GPT-4, the successor to GPT-3, is OpenAI’s \\nmost advanced system, producing safer and more useful responses. \\nIt can solve complex problems with greater accuracy, thanks to \\nits broader general knowledge and problem-solving abilities. \\nGPT-4 is more creative and collaborative than ever before, capa-\\nble of generating, editing, and iterating with users on creative \\nand technical writing tasks. However, the source code of GPT-4 \\nis not publicly available, making it a closed source model.\\nThese models are typically commercial products developed \\nby businesses for profit. They can provide a competitive advan-\\ntage to the company that developed them. For instance, GPT-4'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 137\\ndeepens the conversation on Duolingo, transforms visual acces-\\nsibility on Be My Eyes, and streamlines the user experience and \\ncombats fraud on Stripe.\\nOne of the benefits of closed source models is that they \\noften come with customer support and regular updates. This \\ncan be a boon for users who are not tech-savvy or do not have \\nthe resources to maintain and update the software themselves. \\nHowever, the lack of transparency can lead to concerns about \\nbias, fairness, and privacy. Users have to trust the provider that \\nthe software is performing as it should, without any hid-\\nden issues.\\nA significant concern with closed source models is that they \\ncan lead to a concentration of power, as only a few entities have \\ncontrol over the most advanced AI models. For instance, OpenAI \\nhas exclusive control over its source code and usage.\\nOpenAI’s Founding Story\\nThe story of OpenAI’s inception is a captivating narrative, \\nmarked by unexpected twists and high-stakes decisions. It all \\nbegan amidst the acquisition talks between DeepMind and \\nGoogle. Elon Musk implored DeepMind’s leaders, including \\nDemis Hassabis, not to sell. Musk’s concern was rooted in the \\npotential dominance of a commercial entity like Google in the \\nAI landscape.\\nAfter DeepMind’s eventual sale to Google, Musk, along  \\nwith a group of influential figures such as Sam Altman, Greg \\nBrockman, Reid Hoffman, Jessica Livingston, and Peter Thiel, \\nand organizations including Amazon Web Services (AWS), Info-\\nsys, and YC Research, announced the formation of OpenAI in \\nDecember 2015. They pledged over a billion dollars to the ven-\\nture, promising to freely collaborate with other institutions and \\nresearchers by making their research open to the public.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='138 GENERATIVE AI\\nHowever, by early 2018 Musk felt that OpenAI had fallen \\nsignificantly behind Google. He proposed taking control of \\nOpenAI and running it himself, a proposal that was rejected by \\nthe other founders. Following this, Musk distanced himself from \\nOpenAI and withdrew a substantial planned donation. His depar-\\nture was publicly attributed to a conflict of interest, as T esla was \\ndeveloping its own AI for autonomous driving, which would be \\ncompeting for talent with OpenAI.\\nIn the same year, Sam Altman, who also ran the influential \\nstartup accelerator Y Combinator, stepped in and added the title \\nof president to his role at OpenAI. Musk stepped down from \\nOpenAI’s board of directors. In the fall of 2018, OpenAI made a \\nsignificant decision to pivot toward T ransformer models, which \\nrequired feeding vast amounts of data to train the AI, a \\ncostly endeavor.\\nOn March 11, 2019, OpenAI announced it was transitioning \\ninto a for-profit entity to raise enough capital to fund the com-\\nputing power necessary to pursue the most ambitious AI models. \\nThis marked a significant shift from OpenAI’s original mission, \\nleading some to refer to the organization as “ClosedAI,” a term \\ncoined by Jason Calacanis. In 2019, OpenAI secured $1 billion \\nfrom Microsoft, which provided not just funding but also infra-\\nstructure know-how. T ogether, they built a supercomputer to \\ntrain massive models that eventually led to the creation of Chat-\\nGPT and DALL-E.\\nBy November 2022, when ChatGPT launched, OpenAI \\ninstantly became the hottest new tech startup, forcing Google to \\nscramble to keep up. However, in December 2022, Musk pulled \\nOpenAI’s access to the T witter “fire hose” of data— a contract \\nthat was signed before Musk acquired T witter.\\nIn 2023, Musk expressed his confusion and frustration over \\nOpenAI’s transformation from a nonprofit to a for-profit entity \\n(Figure\\xa03.3). In a surprising turn of events, Musk has founded  \\na new AI company called X.AI, which aims to compete with'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 139\\nOpenAI in the artificial intelligence industry. X.AI is reportedly \\nplanning to adopt an open source approach, a stark contrast to \\nOpenAI’s recent shift. Musk is the sole listed director of the com-\\npany, which was incorporated in Nevada. X.AI has authorized \\nthe sale of 100\\xa0million shares for its privately held business. Musk \\nhas been actively recruiting researchers to establish a rival effort \\nto OpenAI, marking yet another intriguing chapter in the evolv-\\ning narrative of the AI industry.\\nNo Moat Leakage Letter at Google\\nIn 2019, OpenAI underwent a significant transformation, shift-\\ning from a nonprofit to a for-profit entity. The leaders of  \\nOpenAI justified this move as a necessary measure to secure the \\nfunding needed for the creation of advanced AI models. How-\\never, after extensive research and numerous conversations with \\nthought leaders at conferences and interviews, it becomes \\nincreasingly clear that this transition may not have been as cru-\\ncial as it was portrayed.\\nOpenAI’s shift toward a for-profit model has sparked a debate \\nabout the future of AI model development and research. The \\nopen source approach, in my opinion, holds immense potential. \\nIt could secure a top-notch, if not pole position, in the AI land-\\nscape. The future of open source AI models could be as vibrant, \\ncollaborative, and impactful as the React community is today. \\nReact, an open source, frontend JavaScript library for building \\nFIGURE\\xa03.3 Tweet from Elon Musk about OpenAI turning from a non-\\nprofit to a for-profit company.\\nSource: X Corp.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='140 GENERATIVE AI\\nuser interfaces or UI components, is maintained by Meta (for -\\nmerly Facebook) and a community of individual developers and \\ncompanies.\\nEven within Google, this topic is a subject of ongoing discus-\\nsion. A leaked document from a Google researcher recently sur-\\nfaced, shared by an anonymous individual on a public Discord \\nserver. The document, titled “We Have No Moat, and Neither \\nDoes OpenAI,” provides an insightful analysis of the competitive \\nlandscape of AI, with a particular focus on Google and OpenAI.\\nThe document suggests that open source AI will outperform \\nboth Google and OpenAI. It highlights several advancements in \\nopen source AI, such as running foundation models on a Pixel 6, \\nscalable personal AI, and unrestricted release of art models. \\nWhile closed source models still hold a slight edge in terms of \\nquality, the gap is closing quickly. Open source models are faster, \\nmore customizable, more private, and more capable. The docu-\\nment asserts that Google has no secret sauce and should learn \\nfrom and collaborate with others outside Google. It also suggests \\nthat people will not pay for a restricted model when free, unre-\\nstricted alternatives are comparable in quality. I find myself in \\nagreement with this sentiment. A few months of difference in \\ndevelopment doesn’t make a significant difference.\\nThe document further highlights the rapid innovation in the \\nopen source community, particularly after the leak of Meta’s \\nLLaMA model. The community quickly developed variants with \\ninstruction tuning, quantization, quality improvements, human \\nevaluations, multimodality, and so forth. The document discusses \\nthe recent successes of open source AI, particularly in image gen-\\neration and language model fine-tuning. It suggests that Google \\ncould benefit from paying more attention to these innovations.\\nInterestingly, the document also suggests that OpenAI is \\nmaking the same mistakes as Google in their posture relative to \\nopen source, and their ability to maintain an edge is necessarily'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 141\\nin question. It proposes that Google should establish itself as a \\nleader in the open source community, even if it means taking \\nsome uncomfortable steps, like publishing the model weights.\\nThe future of AI model development and research seems to \\nbe leaning toward the open source approach. The rapid advance-\\nments in open source AI, coupled with the closing gap in quality \\nbetween proprietary and open source models, suggest that the \\nopen source approach could be the key to unlocking the full \\npotential of AI.\\nGenerating Revenue with\\xa0Open Source Models\\nThe question of how a for-profit company can differentiate itself \\nwhile open sourcing its expensively trained AI models is indeed a \\npertinent one. How can such a company generate revenue? The \\nanswer may seem counterintuitive at first, but open sourcing an \\nAI model can be a strategic decision that opens up several ave-\\nnues for revenue generation and maintaining a competitive edge.\\nOne such avenue is through consulting and customization \\nservices. While the model may be open source, many businesses \\nlack the expertise to effectively implement and customize it. \\nOffering consulting services to assist these businesses in inte-\\ngrating the model into their systems can be beneficial. This could \\nalso involve providing custom solutions tailored to specific use \\ncases or industries.\\nT raining and support is another potential revenue stream. \\nProviding training programs and support services can help users \\nunderstand how to use the model effectively. This could take the \\nform of workshops, online courses, or personalized train-\\ning sessions.\\nDeveloping premium features or services that complement \\nthe open source model is another option. These could be offered \\non a subscription basis or as one-time purchases. For instance,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='142 GENERATIVE AI\\na cloud-based API for easy access to the model, advanced analytics, \\nor additional tools for fine-tuning the model could be provided.\\nOpen sourcing the model can also attract potential partner -\\nships and collaborations. Companies interested in collaborating \\non further development or application of the model may be \\ndrawn to the project. Such partnerships can lead to new reve-\\nnue streams.\\nIf users interact with the model via a platform or API, \\nanonymized usage data and analytics can be collected (with user \\nconsent and in compliance with privacy laws). This data can be \\nvaluable for improving services, and of course AI models. Fur -\\nther, the data can also be used to provide businesses with insights \\nand analytics.\\nOpen source projects often attract sponsorships and grants \\nfrom businesses that find value in the project. Additionally, \\nnumerous grants are available for open source development.\\nThe differentiator in these scenarios is the expertise and the \\nvalue-added services provided. The offering is not just a model, \\nbut a complete solution that includes the model, support, cus-\\ntomization, and potentially other services. This can make the \\noffering more attractive to businesses compared to just using the \\nopen source model independently.\\nCertainly, licensing is another crucial aspect to consider. In a \\ndual licensing model, the software is released under two types of \\nlicenses: an open source license and a commercial license. The \\nopen source license permits free use, but it often comes with cer-\\ntain conditions. For instance, any modifications or derivative \\nworks must also be open source. On the other hand, the com-\\nmercial license, which can be purchased, allows for use under \\nmore permissive conditions and may include additional services \\nor features. This model can be particularly attractive to busi-\\nnesses that wish to use the software in ways not permitted by the \\nopen source license, or those who desire additional services \\nor support.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 143\\nThere are also other licensing models to consider. One such \\nmodel is the open-core model. In this model, the basic version of \\nthe software is open source, but a more feature-rich version or \\nadditional modules are available under a commercial license. \\nThis model provides users with the flexibility to choose the ver-\\nsion that best suits their needs.\\nAnother model is the service provider license agreement \\n(SPLA). Under this model, companies can license your software on \\na monthly basis to provide services to their customers. This model \\ncan provide a steady stream of income and can be particularly ben-\\neficial for software that requires regular updates or maintenance.\\nT rademark licensing is another option, especially if the soft-\\nware has a strong brand. In this model, you can license the use of \\nthe trademark to companies that want to market their own ser -\\nvices or products as compatible with or based on your software. \\nThis can help to increase the visibility of your software and can \\nprovide additional revenue streams.\\nWhile open sourcing AI models may initially appear to be a \\nchallenge for generating revenue, they can, in fact, open up a \\nmultitude of opportunities for a company to differentiate itself \\nand create sustainable revenue streams.\\nDemocratizing AI: Hugging Face’s Success Story\\nKnown as the hub for open source models, Hugging Face has \\nmanaged to create a thriving ecosystem around its offerings.\\nHugging Face presents a master class on leveraging the open \\nsource model to build a brand and drive growth. Founded in \\n2016, the company initially targeted teenagers with a chatbot \\napp. However, after open sourcing the model behind the chat-\\nbot, the company pivoted to focus on being a platform for \\nmachine learning. This strategic shift marked the beginning of a \\njourney that would see the company catapult to a staggering'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='144 GENERATIVE AI\\n$2 billion valuation in roughly seven years, with a team of around \\n150 employees.\\nThe company’s growth trajectory has been marked by signifi-\\ncant milestones. In March 2021, Hugging Face raised $40\\xa0million \\nin a Series B funding round. Later, in December 2021, the com-\\npany announced its acquisition of Gradio, a software library used \\nto create interactive browser demos of machine learning models. \\nThis acquisition expanded the company’s capabilities and further \\nsolidified its position in the AI industry.\\nThe year 2022\\xa0was particularly eventful for Hugging Face. \\nIn collaboration with several other research groups, the BigSci-\\nence Research Workshop concluded with the announcement of \\nBLOOM, a multilingual large language model with 176 billion \\nparameters. This marked a significant advancement in the field \\nof AI and demonstrated the company’s commitment to pushing \\nthe boundaries of what is possible with machine learning.\\nIn the same year, the company announced its Series C fund-\\ning round led by Coatue and Sequoia, which valued the company \\nat $2 billion. This was a testament to the company’s success and \\nthe faith investors had in its potential for future growth. In a bid \\nto fulfill its mission to teach machine learning to 5\\xa0million peo-\\nple within the first 18\\xa0months, the company also introduced its \\nStudent Ambassador Program in May 2022.\\nHugging Face’s commitment to innovation was further dem-\\nonstrated by its partnership with Graphcore to optimize its \\nT ransformers library for the Graphcore IPU. An intelligence \\nprocessing unit (IPU) is a type of processor specifically designed \\nfor AI workloads. This partnership aimed to enhance the perfor-\\nmance of Hugging Face’s offerings and provide better tools for \\nAI developers.\\nIn August 2022, the company announced the Private Hub, \\nan enterprise version of its public Hugging Face Hub that sup-\\nports software-as-a-service (SaaS) or on-premises deployment.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 145\\nThis move was aimed at providing more flexible and tailored \\nsolutions for businesses, further expanding the company’s reach \\nand influence.\\nThe company’s growth continued into 2023, with a partner-\\nship with Amazon Web Services (AWS) announced in February. \\nThis partnership would allow Hugging Face’s products to be \\navailable to AWS customers, providing them with powerful tools \\nfor building custom applications. The company also announced \\nthat the next generation of BLOOM would be run on T rainium, \\na proprietary machine learning chip created by AWS.\\nThe story of Hugging Face exemplifies the power of open \\nsource. Not a single element of their success can be attributed to \\na closed source solution. Quite the contrary, their entire ecosys-\\ntem thrives on openness and collaboration. This ethos has led to \\na staggering collection of more than 200,000\\xa0models, 34,000\\xa0data-\\nsets, and more than 25\\xa0machine learning libraries. These resources \\nare utilized by over 10,000 organizations and half a million daily \\nusers. The scale of their operation is truly awe-inspiring.\\nHugging Face’s capabilities are not just vast but also incred-\\nibly accessible. They have democratized AI to such an extent that \\nyou can build an AI minimum viable product starting from just \\nan idea. If you lack an idea, they even provide inspiration by map-\\nping models against different tasks that can be solved. The spec-\\ntrum of applications is broad, ranging from text-to-speech and \\naudio-to-audio to zero-shot text classification and image-to-3D \\nobject translation.\\nChoosing the right model for your application is made easy \\nwith Hugging Face. They support decision making with com-\\nprehensive information about the models, including details about \\nthe licenses, which is crucial if you intend to use the model com-\\nmercially. Once you’ve selected a pre-trained model, it can be \\nintegrated into an existing or new application via Hugging Face’s \\naccelerated inference API.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='146 GENERATIVE AI\\nIf you’re starting from scratch, Hugging Face’s acquisition of \\nGradio comes in handy. Y ou can build a machine learning app, \\nhost it, and deploy it via Hugging Face Spaces, powered by  \\nGradio. The result? A working application that can be up and \\nrunning in under an hour. There are numerous Y ouT ube videos \\ndemonstrating this process.\\nFurther, the Leadership board is a valuable tool provided by \\nHugging Face (Figure\\xa03.4). It presents the performance of the \\nrespective models, a task that was previously challenging as it \\nrequired either trying out the models or reading surveys and \\npapers, which often lacked comparability.\\nHugging Face has made it possible to build pretty much any-\\nthing. With their tools and resources, the possibilities are end-\\nless. This brings us to the next topic of our discussion: the \\napplications that are at the forefront of generative AI.\\nFIGURE\\xa03.4 Hugging Face’s LLM-Leaderboard, mapping performances \\nfor various tasks against AI models.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 147\\nApplication Fields\\nThe advent of generative AI has sparked a productivity revolu-\\ntion. We are witnessing a tenfold increase in productivity, a phe-\\nnomenon that is currently being embraced by early adopters and \\nwill soon permeate the majority of society and the economy. This \\nsurge in productivity is accompanied by a hundredfold increase \\nin the number of startups being founded and a thousandfold \\nincrease in the number of products, ideas, and projects being  \\nlaunched.\\nThe applications of generative AI are as diverse as they are \\nfascinating. Voice generation, for instance, involves the use of AI \\nto synthesize human-like speech, enabling more natural interac-\\ntions between humans and machines. Video generation, on the \\nother hand, leverages AI to create realistic as well as stylistic vid-\\neos, transforming the way we create and consume visual content.\\nT ext generation and language translation are other promi-\\nnent applications of generative AI. Here, AI is used to generate \\ncoherent and contextually relevant text or to translate text from \\none language to another, thereby breaking down linguistic barri-\\ners and fostering global communication. Music generation, \\nanother intriguing application, involves the use of AI to compose \\nmusic, pushing the boundaries of creativity.\\nGenerative AI plays a pivotal role in image generation and \\nmanipulation, enabling the creation of realistic images or the \\nmodification of existing ones. In the realm of 3D object genera-\\ntion, AI is used to create detailed and accurate 3D models, a \\ncapability that is transforming industries such as architecture, \\ngaming, and entertainment.\\nGenerative design, another application of generative AI, \\ninvolves the use of AI to generate a wide range of design alterna-\\ntives for a given problem, thereby enhancing creativity and effi-\\nciency in the design process. In the scientific domain, generative'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='148 GENERATIVE AI\\nAI is being used for protein folding and other science-specific \\nuse cases. For instance, DeepMind’s AlphaFold uses AI to predict \\nthe 3D structure of a protein based solely on its genetic sequence, \\na breakthrough that could accelerate scientific discoveries and \\npotentially lead to new methods of therapy.\\nThe landscape of generative AI is highly dynamic, with noth-\\ning set in stone. The boundaries that were once clear are now \\nblurred, as AI continues to evolve and redefine the limits of what \\nis possible. Let’s explore how it is shaping our present and \\nnear future.\\nVoice and Speech Generation\\nNow, let’s turn our attention to voice and speech generation. \\nThis technology, which converts text into spoken language, is \\nused in a variety of applications. Think of voice assistants like Siri \\nor Alexa, audiobooks, and accessibility tools. T oday, we have \\nadvanced speech synthesis models that can generate human-like \\nvoices. These models are trained on large datasets and can han-\\ndle different languages, accents, and speech patterns. They can \\nalso adjust the tone, pitch, and speed of the speech.\\nLet’s consider a real-world example of a company using \\nspeech synthesis technology combined with AI in their market-\\ning campaigns.\\xa0Respeecher collaborated with Mondelēz Interna-\\ntional, Ogilvy, and Wavemaker to create a revolutionary ad \\ncampaign for the Indian market. They used their voice-cloning \\ntechnology to generate personalized ads from Shah Rukh Khan, \\na popular Bollywood actor, for thousands of local retailers. This \\nwas a game-changing approach, as these retailers would not have \\notherwise been able to afford such a high-profile endorsement. \\nThis example illustrates the transformative potential of speech \\nsynthesis technology when combined with AI, particularly in the \\nrealm of marketing.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 149\\nThe process of speech synthesis is a fascinating one, typically \\ninvolving three stages. The first stage is text to words, also known \\nas preprocessing or normalization. This involves reducing ambi-\\nguity and turning elements like numbers, dates, times, abbrevia-\\ntions, acronyms, and special characters into words. This process \\nuses statistical probability techniques or neural networks to \\narrive at the most likely pronunciation.\\nThe second stage is words to phonemes. After figuring out \\nthe words, the speech synthesizer generates the speech sounds \\nthat make up these words. This involves breaking down the writ-\\nten words into their graphemes, the smallest units in a writing \\nsystem, and then generating phonemes, the distinct units of \\nsound, that correspond to them using a set of simple rules.\\nThe third stage is phonemes to sound. The computer converts \\nthe text into a list of phonemes. There are three different approaches \\nto this: using recordings of humans saying the phonemes, the com-\\nputer generating the phonemes itself by generating basic sound \\nfrequencies, and imitating the technique of the human voice.\\nThere are different types of speech synthesizers: concatena-\\ntive, formant, and articulatory. Concatenative synthesizers use \\nrecorded human voices and rearrange them. They are based on \\nrecorded human speech. Formant synthesizers generate speech \\noutput using additive synthesis and physical modeling synthesis. \\nThey can say anything, even words that don’t exist or foreign \\nwords they’ve never heard off. Articulatory synthesizers make \\ncomputers speak by modeling the intricate human vocal tract \\nand articulating the process occurring there. It is the least \\nexplored method due to its complexity.\\nSpeech synthesis systems usually try to maximize both natu-\\nralness and comprehensibility. Naturalness refers to how closely \\nthe synthesized speech resembles human speech, while compre-\\nhensibility refers to how easily the synthesized speech can be \\nunderstood by listeners.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='150 GENERATIVE AI\\nSpeech synthesis has multiple applications. It helps the visu-\\nally impaired to read and communicate. It can be used for teach-\\ning spelling and pronunciation of different languages. It is used \\nin different kinds of telephone inquiry systems and multimedia \\napplications. There are several free and paid speech recognition \\nprograms available in the market, such as Google Now, Siri, \\nCortana, Simon, Kaldi, Dragon Anywhere, Amazon Lex, Dragon \\nProfessional, Voice Finger, and T azti.\\nOne company that stands out in this field is Murf.ai. They \\nprovide an AI voiceover platform that can generate human-like \\nspeech with high quality. Their platform allows users to choose \\nfrom a variety of voices and customize the tone, pitch, and speed \\nof the speech. Murf.ai offers high-quality natural-sounding AI \\nvoices for your projects. It provides a complete toolkit for mak-\\ning voice-over videos. Y ou can combine images, videos, music, \\nadjust timing, and so on. It’s not just a text-to-speech tool— it’s a \\ncomplete solution for creating voiceovers.\\nAnother noteworthy player is Poly.ai. This company has \\ncarved out a niche for itself by creating a voice generation system \\nthat is so high-quality, it borders on the uncanny. The generated \\nvoice is so flawless that it almost seems too perfect, as it lacks the \\nhuman-like imperfections such as the occasional “uhms” and \\n“ahs” that we are accustomed to in natural speech.\\nHowever, Poly.ai’s prowess extends beyond just the creation \\nof high-quality synthetic voices. Their solution is designed to \\nextract valuable information such as dates, places, and names, \\nand can handle tasks like table booking and other organizational \\nmatters automatically. This level of sophistication in handling \\ncomplex tasks rises from the company’s commitment to pushing \\nthe boundaries of what AI can achieve in the realm of speech \\nsynthesis and natural language processing.\\nFounded in 2017, according to Crunchbase, Poly.ai has \\nalready secured a substantial $66\\xa0million in funding and boasts'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 151\\na workforce of between 100 and 250 employees. This level of \\nfinancial backing and human capital speaks volumes about the \\npotential of this company and the faith that investors have in \\nits vision.\\nAs we look to the future, it’s exciting to imagine what else is \\non the horizon for Poly.ai. With their track record of innovation \\nand their commitment to pushing the boundaries of AI, there’s \\nno doubt that they will continue to make waves in the field of \\nspeech synthesis and beyond.\\nIn the next section of this book, we will continue our explora-\\ntion of the fascinating world of AI, turning our attention to \\nanother topic that has been making headlines in the world of \\nartificial intelligence.\\nWhere Is Voice Generation Going? Voice cloning technol-\\nogy, such as the voice imitation algorithm developed by Descript, \\nhas the power to replicate a person’s unique voice. This capabil-\\nity opens up a world of possibilities, from creating personalized \\nvoice assistants that echo our own speech patterns to narrating \\naudiobooks in the author’s voice, thereby enhancing user engage-\\nment and accessibility.\\nIn the sphere of education, platforms like T utorAI are har -\\nnessing voice generation to produce interactive educational con-\\ntent. This transformative approach to learning is reshaping the \\nway we engage with information, making the learning process \\nmore dynamic and immersive.\\nLanguage learning, too, stands to gain immensely from voice \\ngeneration technology. By creating realistic voices in a multitude \\nof languages, this technology can serve as a valuable tool in lan-\\nguage learning apps, aiding students in refining their pronuncia-\\ntion and listening skills.\\nThe entertainment and gaming industry is another sector \\nwhere voice generation is making a significant impact. It has the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='152 GENERATIVE AI\\npotential to breathe life into characters in video games, anima-\\ntions, and other forms of entertainment. Whether it’s creating \\nvoices for nonexistent characters or re-creating voices from clas-\\nsic games or shows, voice generation adds a new dimension to \\nthe user experience.\\nThe concept of personal branding for content creators is also \\nbeing redefined by voice cloning. Imagine content creators using \\ntheir unique voice clones to interact with their audiences across \\ndifferent platforms, creating a consistent and recognizable per -\\nsonal brand. It’s not far-fetched to envision a future where pro-\\nfessionals have their own voice generators, akin to business cards \\nof yore, integrated into their personal web pages or LinkedIn \\nprofiles. This could be a game changer for social media compa-\\nnies, offering an additional service that enhances user engagement.\\nIn the telecommunications sector, voice generation can revo-\\nlutionize user experience by creating realistic voices for automated \\nphone systems. This could automate redundant calls, making the \\nprocess more efficient and user-friendly.\\nHealthcare is another field where voice generation can make \\na significant difference. For speech therapy patients or individu-\\nals who have lost their ability to speak, the creation of realistic, \\npersonalized voices can be a lifeline, offering them a chance to \\ncommunicate effectively.\\nLastly, let’s consider the role of voice generation in enhanc-\\ning accessibility. This technology can be used to read out text for \\npeople with visual impairments or to translate sign language into \\nspoken words. This integration of technology can make our digi-\\ntal world more inclusive, ensuring that everyone, regardless of \\ntheir abilities, can participate fully.\\nAs we continue our journey through the fascinating world of \\nAI, we will explore more such groundbreaking technologies and \\ntheir potential impact on our lives. Stay tuned as we unravel the \\nintricacies of this rapidly evolving field.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 153\\nGenerative Design\\nIn the vast expanse of generative AI, generative design stands out \\nas the field most intimately connected to the physical world. This \\ninnovative approach takes a leaf from nature’s book, emulating \\nits evolutionary process. Here’s how it works: Designers or engi-\\nneers input their design goals into a generative design software, \\nalong with parameters such as the materials to be used, manufac-\\nturing methods, and cost constraints. The software then embarks \\non an exploration of all possible permutations of a solution, gen-\\nerating a multitude of design alternatives. It tests each one, learn-\\ning from every iteration. This process enables the creation of \\ncomplex shapes and internal lattices that are optimized for effi-\\nciency. Some of these forms are so intricate that they would be \\nimpossible to produce using traditional manufacturing methods. \\nInstead, they come to life through the magic of new additive \\nmanufacturing methods.\\nIn 2016, during my tenure in the research department at  \\nAirbus, I witnessed the power of generative design firsthand. We \\nwere working on innovative predictive maintenance systems, \\nincluding generative models to balance out unbalanced datasets. \\nThat year, Airbus built a fully functioning motorcycle that was \\nnot only robust but also weighed just 35\\xa0kg (Figure\\xa03.5). Seeing \\nit in person was a revelation of what’s possible with generative \\ndesign, especially when coupled with 3D printing.\\nT oday, generative design finds applications in various sec-\\ntors. In the automotive industry, for instance, it’s used for light-\\nweighting components and consolidating parts. A notable \\nexample is General Motors, which used generative design to \\nreduce the mass of a seat bracket by 40 percent while improv-\\ning its performance.\\nIn aerospace, it contributes to weight reduction, environ-\\nmental impact mitigation, and safety improvements. Airbus, for'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='154 GENERATIVE AI\\ninstance, used generative design to optimize the partition wall of \\nan airplane cabin, reducing its weight by 45 percent.\\nGenerative design has found a compelling application in the \\nrealm of architecture, transforming the way structures are con-\\nceived and built. Consider the skyscrapers that punctuate city \\nskylines. These towering structures are designed to withstand \\ndiverse environmental challenges— for example, high winds in \\nChicago and earthquakes in Japan. Beyond ensuring safety, archi-\\ntects and clients often aspire to infuse their buildings with a \\nunique aesthetic appeal. Generative design enables this, allowing \\narchitects to set necessary parameters and explore a multitude of \\ndesign options.\\nA striking example comes from Brazilian architect Guto \\nRequena, who employed generative design to create stools for a \\nbar. The design of these stools mirrored the rhythm of local pop-\\nular music. Once the design was finalized, the stools were brought \\nto life through 3D printing.\\nFIGURE\\xa03.5 Airbus APWorks launches the Light Rider, the world’s first \\n3D-printed motorcycle.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 155\\nBut generative design isn’t confined to specific parameters. It \\ncan also accommodate broader ones. It can be used to construct \\nthe most robust bridge with the most cost-effective materials, or \\nto design a school based on the natural movement patterns \\nof people.\\nThe creators of Autodesk took this concept even further \\nwhen building their new offices. They incorporated the prefer -\\nences of future occupants as design parameters. The result was a \\nworkspace tailored to the workflows of its users, a building that \\nwas customized to the needs of the people who would use it. This \\npreemptive approach minimizes the need for postconstruction \\nmodifications, creating a refined building that truly serves its \\ninhabitants.\\nGenerative design is revolutionizing the industrial machin-\\nery sector, pushing the boundaries of innovation in the creation \\nof specialty tools and equipment. A prime example of this is the \\nGen5X, a 5-axis 3D printer designed using generative principles.\\nThe Gen5X is not just any 3D printer; it’s an open source, \\nself-replicating marvel. It’s capable of designing and manufactur-\\ning its own components, and its design can be replicated on any \\nhobbyist-level machine. This 5-axis 3D printer is a product of \\nthe RepRap project, which explores the frontier of self-replicating  \\nmachines.\\nThe design process of the Gen5X employs Fusion 360’s gen-\\nerative design tools, which use parametric inputs to generate \\ndesigns. This means the Gen5X can be customized based on the \\ncomponents you already have.\\nIn building products, generative design simplifies complex \\nassemblies. An example is the Elbo chair, designed by Autodesk’s \\ngenerative design lab (Figure\\xa03.6). The chair’s design was opti-\\nmized by algorithms, resulting in a structure that is 18 percent \\nlighter and shows fewer signs of stress in its joints.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='156 GENERATIVE AI\\nWhere Is Generative Design Going? The future holds the \\npromise of designs that are not only superior in quality but also \\nmore aligned with the designer’s intent, all achieved in less time. \\nGenerative design is poised to be a game changer, particularly in \\nthe fields of architectural, industrial, and product design. Its \\nstrength lies in its ability to optimize parameters directly linked \\nto geometric changes, making it a formidable tool for early \\ndesign and prototyping.\\nT ake, for instance, the realm of mechanical, electrical, and \\nplumbing (MEP) services. Some companies have started to har -\\nness the power of generative design for design exploration and \\ndecision making. Addiform, a company specializing in additive \\nmanufacturing, leverages generative design to create complex \\noptimized parts for various industries. This is not merely a mat-\\nter of employing a new tool; it’s about harnessing our collective \\nimagination to unlock the full potential of this technology.\\nFIGURE\\xa0 3.6 The Elbo chair, an exemplar of generative design and \\nadditive manufacturing by Autodesk.\\nSource: Autodesk Inc.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 157\\nIn the realm of architecture, the potential applications of gen-\\nerative design are vast and compelling. Consider the case of the \\nlate architect Antoni Gaudí and his magnum opus, the Sagrada \\nFamilia in Barcelona. After Gaudí’s passing, the construction of \\nthe Sagrada Familia proceeded based on reconstructed versions of \\nhis plans, which had been partially destroyed in a fire. While gen-\\nerative design was not employed in this instance, one can envision \\nhow it could have significantly contributed to this process, aiding \\nin the completion of the architectural designs in a way that hon-\\nored Gaudí’s original vision.\\nThe implications of this technology are far-reaching. As ele-\\nments become lighter and stronger, industries such as aerospace \\nand construction will be significantly boosted. For instance, gen-\\nerative design is already transforming the way aircraft are built. \\nA BBC article reported how designers are using AI and genera-\\ntive design to create aircraft components that are lighter, stronger, \\nand more efficient. This not only reduces the weight of the air -\\ncraft but also enhances its overall performance.\\nImagine a future skyline, a vista of towering buildings pro-\\nduced by generative design (Figure\\xa03.7). We are not as far off \\nfrom this reality as one might think. People using Midjourney \\nbuild visual ideas that are at the forefront of this movement, cre-\\nating innovative solutions that not only meet functional require-\\nments but also inspire awe with their aesthetic appeal. However, \\nit’s important to note that this transformation will not occur \\novernight. It’s a mid- to long-term projection, as it will take time \\nfor us to fully realize the potential of generative design.\\nThe future of generative design is bright and full of poten-\\ntial. As we continue to explore and harness this technology, we \\ncan expect to see a revolution in the way we design and create \\nobjects, from the smallest components to the tallest skyscrapers. \\nThe key lies in our ability to imagine, to innovate, and to inte-\\ngrate this powerful tool into our design processes.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='158 GENERATIVE AI\\nSolving Problems in Science by Google DeepMind\\nLet’s now turn our attention to the work of Google DeepMind, \\nwhose groundbreaking applications have not only pushed the \\nboundaries of what we thought was possible but also laid a sig-\\nnificant foundation for the future of artificial general intelligence.\\nDeepMind’s Broad Range of Offerings In 2016, the world of \\nAI was abuzz with the news of DeepMind’s AlphaGo triumphing \\nover Lee Sedol, a player of the highest skill level, 9th dan, in the \\nintricate game of Go. A game of immense complexity, Go boasts \\nmore potential board configurations than the number of atoms in \\nthe universe. This extraordinary accomplishment underscored \\nthe formidable capabilities of AI and its potential to navigate and \\nsolve problems of great complexity.\\nFIGURE\\xa03.7 Midjourney prompt: “Architecture futuristic city designed \\nfrom parametric organic buildings, CGI render, beautiful, cinematic, \\nphotorealistic, highly detailed, vivid, unreal engine.”\\nSource: AI-generated image created in Midjourney, Inc.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 159\\nBuilding on the success of AlphaGo, DeepMind introduced \\nAlphaGo Zero in 2017. Unlike its predecessor, which learned \\nfrom thousands of human games, AlphaGo Zero learned solely \\nthrough self-play, a process known as reinforcement learning. \\nThis improved version of AlphaGo defeated the original \\nAlphaGo 100\\xa0games to 0, demonstrating the power of learning \\nfrom scratch.\\nLater that year, DeepMind unveiled AlphaZero, a modified \\nversion of AlphaGo Zero that could handle any two-player game \\nof perfect information. AlphaZero gained superhuman abilities \\nat chess and shogi, again learning solely through self-play. This \\nwas a significant step forward, showing that an AI system could \\nlearn to master different games without any prior knowledge.\\nIn a similar vein, DeepMind researchers published a new \\nmodel named MuZero in 2019. MuZero mastered the domains \\nof Go, chess, shogi, and Atari 2600\\xa0games without human data, \\ndomain knowledge, or known rules. This was a significant leap \\nforward in the development of AGI, demonstrating that an AI \\nsystem could learn to understand and master different environ-\\nments from scratch.\\nIn October 2022, DeepMind unveiled AlphaT ensor, a new \\nversion of AlphaZero, in a paper published in Nature. AlphaT en-\\nsor discovered a faster way to perform matrix multiplication— \\none of the most fundamental tasks in computing— using \\nreinforcement learning. For example, AlphaT ensor figured out \\nhow to multiply two mod-2 4×4\\xa0matrices in only 47\\xa0multiplica-\\ntions, unexpectedly beating the 1969 Strassen algorithm record \\nof 49\\xa0multiplications. This discovery has significant implications \\nfor computational efficiency and could lead to substantial savings \\nin computing steps in the future. This is a monumental achieve-\\nment in the field of AI and evidence of the potential of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='160 GENERATIVE AI\\nreinforcement learning in discovering novel, efficient algorithms \\nfor fundamental computational tasks.\\nIn the realm of competitive gaming, DeepMind’s AlphaStar \\nmade significant strides. In July 2019, AlphaStar began playing \\nagainst random humans on the public 1v1 European multiplayer \\nladder. Unlike the first iteration of AlphaStar, which played only \\nProtoss v. Protoss, this one played as all of the game’s races and \\nhad earlier unfair advantages fixed. By October 2019, AlphaStar \\nreached Grandmaster level on the StarCraft II ladder on all three \\nStarCraft races, becoming the first AI to reach the top league of \\na widely popular electronic sport (esport) without any game \\nrestrictions.\\nThese achievements of Google DeepMind are not just impres-\\nsive feats in the world of AI; they also mark important milestones \\nin our journey towards AGI. Each of these AI solutions, powered \\nby conventional AI and reinforcement learning, serves as a corner-\\nstone for the future of AGI. As we continue to explore and harness \\nthe power of AI, we can expect to see even more groundbreaking \\nadvancements in the field.\\nAlphaFold One of DeepMind’s most notable contributions in \\ngenerative AI is AlphaFold, a program that predicts protein \\nstructure using deep learning techniques. This is not a general \\napplication field but rather a specific one, and it’s crucial for solv-\\ning problems in biology. However, it’s worth noting that despite \\nthe heavyweight nature of this specific application field, where \\ndeep knowledge is required to achieve even slight results, there \\nare countless other niche application fields that one can still \\nexplore or even create. We are very much in the early stages of \\ngenerative AI and AI in general.\\nAlphaFold has had two major versions: AlphaFold 1 (2018) \\nand AlphaFold 2 (2020), both of which placed first in the Critical'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 161\\nAssessment of Structure Prediction (CASP) competitions of \\ntheir respective years. But why focus on protein folding? What’s \\nthe problem it’s trying to solve?\\nProteins consist of chains of amino acids that fold to form \\nthe 3D structures of the proteins, a process known as protein \\nfolding. Understanding how the amino acid sequence determines \\nthe 3D structure is highly challenging, and this is referred to as \\nthe protein folding problem. Before AlphaFold, methods of deter -\\nmining protein structures were expensive and time-consuming, \\nand computational methods were not close to experimental tech-\\nniques in terms of accuracy.\\nAlphaFold was trained on over 170,000 proteins from a pub-\\nlic repository of protein sequences and structures. The program \\nuses a form of attention network, a deep learning technique that \\nfocuses on having the AI identify parts of a larger problem, as \\nmentioned earlier in the section “Democratizing AI: Hugging \\nFace’s Success Story,” then piecing them together to obtain the \\noverall solution (Figure\\xa03.8). Y ou can see that its predictive power \\nis a close approximation to the experimental result, which can be \\nseen as the ground truth.\\nAlphaFold 1, introduced in 2018, used advanced learning \\nmethods to estimate a probability distribution for how close the \\nresidues were likely to be, turning the contact map into a likely \\ndistance map. AlphaFold 2, introduced in 2020, is significantly \\ndifferent from the original version. It replaced the software \\ndesign used in AlphaFold 1\\xa0with a system of subnetworks cou-\\npled together into a single differentiable end-to-end model, \\nbased entirely on pattern recognition. Local physics, in the form \\nof energy refinement based on the AMBER model, is applied \\nonly as a final refinement step once the neural network predic-\\ntion has converged. The AMBER model, in simple terms, is'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='162 GENERATIVE AI\\na tool used in computational chemistry and biology to simulate \\nand understand how molecules, like proteins, behave. It uses the \\nprinciples of physics to predict how atoms in a molecule move \\nand interact with each other.\\nThere are four main concepts to understand about Alpha-\\nFold. First, AlphaFold generally works by starting off with an \\neducated guess, then iteratively improving the 3D generation. \\nSecond, it uses an attention-based model, focusing on all impor-\\ntant information rather than the latest information. For example, \\nin protein folding, certain amino acids could be folded right next \\nto each other while being far away in the input sequence. Third, \\nexpert knowledge is integrated. Some proteins fold in a specific \\nway and some are exceptions. Much of this expertise is included \\nin the model. Fourth, around 95 percent of the AI pipeline is \\ntrainable, so the model is continuously refined where possible \\nT1037 / 6vr4 T1049 / 6y4f\\n90.7 GDT 93.3 GDT\\n(adhesin tip)(RNA polymerase domain)\\nExperimental result\\nComputational prediction\\nFIGURE\\xa03.8 AlphaFold’s predictive power.\\nSource: www.deepmind.com/blog/alphafold- a- solution- to- a- 50- year- old- grand-  \\nchallenge- in- biology'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 163\\nand where new data is available. The team at Google DeepMind \\ncontinues to develop AlphaFold, focusing their efforts on areas \\nwhere they know the model’s weaknesses lie, such as in the field \\nof human antibody interactions.\\nDeepMind’s Gift to Humanity The typical narrative of inno-\\nvation involves a company solving a complex problem and subse-\\nquently monetizing the solution. The more intricate the problem, \\nthe higher the price tag, particularly when demand is high. How-\\never, Google DeepMind chose a different path. They not only \\nopen sourced the AlphaFold source code but also made its data-\\nbase, containing all resulting 3D protein structures, freely avail-\\nable. This database has grown exponentially over the past year, \\nfrom 1\\xa0 million to over 200\\xa0 million proteins, covering nearly \\nevery known protein on Earth. Figure\\xa0 3.9 illustrates a rough \\nscale of proteins starting from 1 amino.\\n1\\nAMINO ACID AMINO ACIDS\\nIN A STRING\\nAMINO ACIDS\\nIN A PROTEIN\\n20 100’s 20,000\\nPROTEINS IN\\nTHE HUMAN BODY\\nDISTINCTIVE PROTEINS\\nFOUND ON EARTH\\n200,000,000\\nFIGURE\\xa0 3.9 The exponential growth of the protein database, now \\nencompassing nearly every known protein on Earth.\\nSource: Adapted from www.deepmind.com/research/highlighted-research/alphafold.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='164 GENERATIVE AI\\nThis decision has had profound implications for the scien-\\ntific community. Researchers can now encounter a protein \\nsequence in their work and find its 3D folding already cataloged \\nin Google DeepMind’s database. This has significantly acceler -\\nated the pace of research. As John McGeehan, a professor of \\nstructural biology at the University of Portsmouth, puts it, “What \\ntook us months and years to do, AlphaFold was able to do in a \\nweekend.” This has effectively put research on steroids, enabling \\nscientists to make rapid advancements in their respective fields.\\nSeveral alternatives to AlphaFold have emerged. Meta AI’s \\nESMFold offers accurate atomic-level predictions and competes \\nwith RoseTTAFold, another significant player developed by aca-\\ndemic researchers. Both are open source and have demonstrated \\ntheir utility to the scientific community.\\nRaptorX and IntFOLD are other protein prediction models \\nthat hold their own in this competitive field. OmegaFold, devel-\\noped by Chinese biotech firm Helixon, predicts high-resolution \\nprotein structure from a single primary sequence, even outper -\\nforming RoseTTAFold while achieving prediction accuracy sim-\\nilar to that of AlphaFold 2.\\nPhyre and Phyre2 offer remote template detection, alignment, \\nand 3D modeling tools for protein structure prediction. Lastly, \\nOpenFold is another notable option for protein folding predic-\\ntion, often mentioned as an alternative to AlphaFold 2. These \\ntools, each with their unique strengths, contribute to the rapid \\nadvancements in protein folding prediction.\\nWhere Is AlphaFold Going? AlphaFold’s (and other models’) \\nimpact is not just a ripple, but a tidal wave that is reshaping our \\nunderstanding of the world. Its implications are vast, and its \\npotential is only just beginning to be realized.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 165\\nThe potential of AlphaFold is not confined to the realm of \\nacademia; it has profound implications for the future of human-\\nity. As an example, Ray Kurzweil, the American inventor and \\nfuturist, in his book The Singularity Is Near, envisions a future \\nwhere diseases like cancer and heart disease could be cured, and \\nthe human body could be maintained indefinitely by 2030. This \\nis not just a lofty dream; with the advancements brought about \\nby AlphaFold, it is a tangible possibility.\\nOne of the most significant impacts of AlphaFold is its poten-\\ntial to enhance our understanding of the human body. For \\ninstance, the nuclear pore complex, a massive assembly of pro-\\nteins that controls the traffic in and out of the nuclei in cells, has \\nlong been a mystery to scientists. However, with the help of \\nAlphaFold, researchers have been able to decipher its structure, \\npaving the way for a deeper understanding of how cells function \\nand opening up new avenues for medical research.\\nIn the realm of medicine, AlphaFold holds the promise of \\ncreating more effective treatments. For example, it could aid in \\nthe development of drugs to combat malaria, a disease that con-\\ntinues to claim hundreds of thousands of lives each year. By pre-\\ndicting the structure of the proteins involved in the disease, \\nresearchers could design drugs that target these proteins more \\neffectively, potentially saving countless lives.\\nThe implications of AlphaFold extend to our food system as \\nwell. By understanding the structure of proteins involved in food \\nproduction, we could develop healthier and more nutritious \\nfood. This could revolutionize the food industry and contribute \\nto the global fight against malnutrition and obesity.\\nIn terms of disease prevention, AlphaFold could play a crucial \\nrole in the development of effective vaccines. By predicting the \\nstructure of viral proteins, it could aid in the design of vaccines'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='166 GENERATIVE AI\\nthat can effectively neutralize these viruses, potentially prevent-\\ning future pandemics.\\nAlphaFold could also contribute to our efforts to combat \\nglobal warming. By understanding the structure of proteins \\ninvolved in carbon capture, we could develop effective tools for \\ncapturing carbon dioxide. This could be a significant step in reduc-\\ning greenhouse gas emissions and mitigating the effects of cli-\\nmate change.\\nIn the realm of materials science, AlphaFold could aid in the \\nproduction of sustainable biomaterials. By predicting the struc-\\nture of proteins involved in material production, we could design \\nand produce materials that are not only strong and durable but \\nalso environmentally friendly.\\nMoreover, AlphaFold could also aid in the creation of artifi-\\ncial enzymes to produce building materials like carbon nano-\\ntubes and graphene. These materials have unique properties that \\nmake them ideal for a variety of applications, from electronics to \\nenergy storage. With the help of AlphaFold, we could design \\nenzymes that can produce these materials more efficiently and \\nsustainably.\\nCode Generation\\nMuch like text, sound, and other sequential data types, code is \\nwell suited for T ransformer models. The implications of this are \\nprofound, as it streamlines the coding process and enhances the \\nproductivity of developers.\\nGoogle DeepMind’s AlphaCode Google DeepMind has con-\\ntinued its AlphaSeries with the introduction of AlphaCode. This \\nAI code-generation system has reached a competitive level of per-\\nformance in programming competitions, a feat that marks a sig-\\nnificant milestone in the field. AlphaCode operates by leveraging'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 167\\na massive dataset of programming problems and solutions, as well \\nas unstructured code from GitHub.\\nAlphaCode’s approach to code generation is not just intelli-\\ngent but also efficient. It generates thousands of proposed solu-\\ntions to a given problem, filters out the invalid ones, and then \\nclusters the remaining solutions into groups. From each group, a \\nsingle example is selected for submission. The system has been \\ntrained in various programming languages, including C++, C, \\nGo, Java, JavaScript, Lua, PHP , T ypeScript, Ruby, Scala, Rust, \\nand Python.\\nIn a Codeforces programming contest, AlphaCode ranked \\non average in the top\\xa054 percent against more than 5,000 partici-\\npants in 10 contests. This achievement, which took place in 2022, \\nmarked the first time an AI code generation system has reached \\na competitive level of performance in programming competitions.\\nHowever, it’s important to note that AlphaCode still  \\nrelies heavily on specific examples provided with the problem \\ndescription. Without these examples, its success rate would \\ndrop significantly.\\nThe advent of AI-driven code generation is not just a techno-\\nlogical breakthrough; it’s a paradigm shift in how we approach \\ncoding. As we continue to explore and harness the power of AI in \\nthis field, we can look forward to a future where coding is not just \\nfaster and more efficient, but also more accessible to a broader \\nrange of individuals.\\nGitHub Copilot As a data scientist, I find the advent of code \\ngeneration not just fascinating, but exhilarating. I am, by nature, \\nan optimist. The thought of AI taking over some aspects of my \\njob doesn’t fill me with dread; rather, it stirs in me a sense of \\nanticipation. The prospect of seeing my ideas come to life with \\nless manual effort is genuinely exciting.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='168 GENERATIVE AI\\nT oday’s coding landscape offers a rich array of tools, two of \\nwhich have become integral to my work. I not only use these \\ntools extensively but also strongly advocate for their use within \\nmy teams. GitHub Copilot is the first of these, serving as my reli-\\nable companion throughout the coding process. The second is \\nChatGPT , a tool I frequently engage with during non-coding \\nphases, such as the initial stages of a project.\\nHowever, it’s important to note a crucial aspect of using \\nChatGPT . While it’s a powerful tool for generating human-like \\ntext and assisting with various tasks, it’s essential to remember \\nthat it’s not designed to handle confidential information. I always \\nensure that my teams are aware of this and exercise caution not \\nto send any sensitive data to ChatGPT . This way, we can lever-\\nage the benefits of these advanced AI tools while maintaining our \\ncommitment to data privacy and security.\\nNow, GitHub Copilot is an AI-powered pair programmer \\nthat provides autocomplete-style suggestions as you code. Devel-\\noped by GitHub and OpenAI, it’s a cloud-based tool that assists \\nusers of various integrated development environments (IDEs), \\nincluding Visual Studio Code, Visual Studio, Neovim, and Jet-\\nBrains. It’s powered by OpenAI Codex, a production version of \\nthe Generative Pre-trained T ransformer 3 (GPT-3). This lan-\\nguage model uses deep learning to produce human-like text. The \\nCodex model is further trained on gigabytes of source code in \\nmultiple programming languages.\\nGitHub Copilot is trained on a selection of the English lan-\\nguage, public GitHub repositories, and other publicly available \\nsource code. This includes a filtered dataset of 159 gigabytes of \\nPython code sourced from 54\\xa0million public GitHub reposito-\\nries. Interestingly, OpenAI’s GPT-3 is licensed exclusively to \\nMicrosoft, GitHub’s parent company— a strategic move, indeed.\\nGitHub Copilot is designed to help developers code faster, \\nfocus on solving bigger problems, and stay in the flow longer.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 169\\nIt aims to make work more fulfilling. However, it’s worth noting \\nthat it may also produce suggestions based on insecure coding \\npatterns, bugs, or references to outdated APIs or idioms. The \\ncoder has to remain responsible at all times and not go on auto-\\npilot. Despite these potential pitfalls, the tool is expected to com-\\nplement the work of developers, empowering them to write code \\nmore easily and focus more on their core competencies and \\ncreativity.\\nCoding with ChatGPT and Other LLMs Using ChatGPT or \\nsimilar LLMs, you can easily code entire programs. For example, \\nask it to create a Python agent that plans your day using the  \\nOpenAI API, integrating with your calendar. The model will \\nclarify details, suggest a program structure, and even write the \\ncode. While your oversight is necessary, the process significantly \\naccelerates product development. Figure\\xa03.10 shows an example \\nof ChatGPT output, guiding you to build an AI agent.  \\nRemember to responsibly manage sensitive information shared \\nwith ChatGPT .\\nTransforming Traditional Data Analyst Practices The \\ntransformative power of generative AI doesn’t stop at making \\ncoding 10 times faster and more efficient. It’s also reshaping the \\nlandscape of data analysis as we know it. In fact, it’s safe to say \\nthat traditional data analysis is, to a degree, becoming legacy. \\nWith applications like PandasAI and the Code Interpreter plug-\\nin for ChatGPT , or offerings from Notable, data analysis has \\nbecome accessible to anyone who can formulate their thoughts \\nlogically.\\nConsider the Code Interpreter plug-in for ChatGPT , for \\nexample. Imagine you have a dataset that needs to be clustered. \\nY ou simply upload the data and ask the plug-in to perform an'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='170 GENERATIVE AI\\nelbow chart for the data. Instead of manually choosing the range \\nof numbers of clusters, performing a k-means clustering for each \\ncluster number, calculating the sum of squared errors, plotting \\nthe sum of squared errors per number of clusters (the so-called \\nelbow plot), and identifying the elbow point (the optimal num-\\nber of clusters in a dataset), the Code Interpreter does all these \\nsteps for you. Y ou state what you want, and it infers what needs \\nto be done to get there, then codes the respective analysis code.\\nPandasAI works similarly, except it takes only library com-\\nmands from the Pandas library. This shift in the way we approach \\nFIGURE\\xa03.10 An overview of how to build an LLM agent, its structure, \\nclasses, and methods needed.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 171\\ndata analysis and coding has a profound impact on future app \\nand product development. It democratizes the field, turning eve-\\nryone into a developer. Figure\\xa03.11 illustrates PandasAI in action.\\nThe AI code generation space is bustling with other notable \\nprojects and startups. Magic AI, for instance, is building an AI \\nplatform that generates code by allowing software engineers to \\ndescribe what they want in natural language. Other players in the \\nfield include T abnine, CodePal, Builder.ai, Engineer.ai, T uring, \\nT onic.ai, and many more. Each of these entities is contributing \\nto the evolution of coding and data analysis, making these fields \\nmore accessible and efficient than ever before.\\nFIGURE\\xa03.11 Using a single command to generate a plot from the data \\ncontained within the df data frame.\\nSource: https://github.com/gventuri/pandas- ai'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='172 GENERATIVE AI\\nText Generation\\nT ext generation transforms ideas into written language, creating \\ncoherent, contextually relevant text. This technology, powering \\napplications like chatbots and content creation tools, is revolu-\\ntionizing current communication. While this book delves into \\nvarious LLMs like open source options, ChatGPT , and Bard, we \\nalso focus on strategically planning LLM applications such \\nas Cicero.\\nCicero As we continue to explore the vast potential of language \\nmodels in generative AI, it’s worth shifting our gaze to the \\ngroundbreaking work done by Meta AI with Cicero. Cicero is an \\nAI that has mastered the art of Diplomacy, a strategy game that \\ndemands not just strategic planning but also the ability to build \\ntrust, negotiate, and cooperate with multiple players.\\nFor those unfamiliar with Diplomacy, it’s a game that can be \\nlikened to a blend of Risk, poker, and the TV show Survivor. \\nUnlike many board games where the objective is to outmaneuver \\nyour opponents on the board, Diplomacy requires a cooperative \\ncomponent. The only way to win is by working with other play-\\ners to capture as much territory as possible, with negotiation and \\nalliance-building being key to success.\\nCicero has the distinction of being the first AI to play Diplo-\\nmacy at a human level. It has demonstrated an uncanny ability to \\nform strong alliances, make moves that benefit its allies, and \\nengage in simultaneous planning and conversation with players. \\nIt uses honesty as a tactic, understanding that trustworthiness is \\na valuable trait in the game. However, it’s also capable of decep-\\ntion when necessary to secure a win for its team.\\nProfessional human players have reported an eerie sense \\nthat Cicero seems to anticipate their plans. This is likely due to \\nCicero’s integration of a language model with planning and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 173\\nreinforcement learning, allowing it to infer players’ beliefs and \\nintentions. There’s more to language models and strategic rea-\\nsoning than just scaling up models.\\nCicero’s performance in Diplomacy is nothing short of supe-\\nrior. It has achieved more than double the average score of human \\nplayers on webDiplomacy.net, an online version of the game, and \\nranked in the top\\xa010 percent of participants who played more \\nthan one game. This achievement is a testament to the power of \\ncombining two different areas of AI: strategic reasoning and nat-\\nural language processing. The integration of these techniques \\ngives Cicero the ability to reason and strategize with regard to \\nplayers’ motivations, then use natural language to communicate, \\nreach agreements to achieve shared objectives, form alliances, \\nand coordinate plans.\\nThe success of Cicero illustrates the potential of AI in com-\\nplex strategy games that require not just strategic thinking but \\nalso the ability to communicate and negotiate.\\nWhere Are Applications Like Cicero Going? The question \\nis not so much about where we are now, but rather, where we are \\nheaded. How can this be harnessed to benefit us in ways we have \\nyet to imagine?\\nThe potential applications and directions for AI models like \\nCicero are as vast as they are varied. One such avenue lies in the \\nrealm of military strategy. The U.S. Army War College has \\nalready begun to explore this, developing an AI tool called the \\nEnemy Analysis T ool, which uses AI to analyze enemy actions \\nand predict their future movements. This tool has the potential \\nto revolutionize military strategy, providing a level of insight and \\nforesight previously unattainable.\\nIn the commercial arena, AI is already leaving an indelible \\nfootprint. Pactum, a pioneering startup, has engineered an AI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='174 GENERATIVE AI\\ncapable of autonomously negotiating business agreements, \\nthereby eliminating the need for human involvement. This AI, \\narmed with machine learning and game theory, adeptly navigates \\nthe intricacies of contract negotiation.\\nThe sphere of political decision making is another area ripe for \\nAI transformation. SingularityNET , an AI-focused enterprise, is in \\nthe process of crafting an AI sociopolitical decision support system. \\nThis innovative system employs AI to dissect complex sociopoliti-\\ncal scenarios and offer insightful decision-making guidance.\\nEvent planning, too, could undergo a revolution with the \\nadvent of AI. Skift, a platform specializing in travel industry \\nintelligence, has explored the potential of AI to automate diverse \\nfacets of event planning, from scheduling intricacies to vendor \\nnegotiation.\\nThe gaming industry is another sector that stands to gain \\nsignificantly from AI. Artificial intelligence is being harnessed to \\nautomate various elements of game development, such as charac-\\nter dialogue generation and the creation of personalized racing \\ncommentary. This not only lightens the load for game develop-\\ners but also enriches the gaming experience for players.\\nFinally, AI models akin to Cicero could be employed to \\namplify social interactions. A study featured in the Journal of \\nMarketing delves into the concept of artificial empathy, where AI \\nis crafted to mirror human empathy in interactions. This innova-\\ntive approach holds the potential to elevate the customer experi-\\nence across various sectors, from customer service to marketing.\\nAI Agents: The Active Executors in Generative AI As we talk \\nabout the capabilities of LLMs and their systems, it becomes appar-\\nent that AI agents represent the next logical frontier in the realm of \\ngenerative AI. Far from being just another application field, AI \\nagents are a burgeoning domain that amplifies the potential of gen-\\nerative AI. They hold the promise of enhancing every application'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 175\\nfield we’ve discussed so far. The only constraint, it appears, is the \\nboundary of our imagination, and perhaps more development.\\nAI agents, while in their infancy, are already showing promis-\\ning results. However, defining them precisely at this moment in \\ntime is challenging due to the various versions and interpreta-\\ntions that exist. This is the very active part of generative AI. T wo \\ndominant types of AI agents have emerged, with everything in \\nbetween yet to be determined.\\nThe first type of AI agent is one that is given a simple task, \\nexecutes it, and returns with the result. This could be a stand-alone \\nagent or a language model like ChatGPT that uses a plug-in. It \\ndoesn’t matter if it’s a single agent that is launched and then exe-\\ncutes the requested task or if it’s a language model that performs \\nan action based on the ask.\\nChatGPT plug-ins, for instance, are connected to the Inter-\\nnet, external data sources, or third-party services, enhancing the \\naccuracy of its responses and allowing for a more personalized \\nexperience. Developed by third-party developers or OpenAI \\nitself, these plug-ins enable ChatGPT to access up-to-date infor-\\nmation, run computations, and interact with APIs defined by \\ndevelopers (Figure\\xa03.12).\\nFIGURE\\xa03.12 The rapid expansion of ChatGPT plug-ins, with over 100 \\nunique plug-ins developed in just 40\\xa0days.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='176 GENERATIVE AI\\nHere are a few notable ChatGPT plug-ins available in 2023:\\nWolfram This plug-in provides access to advanced computa-\\ntional, mathematical, and real-time data to answer various \\nquestions of quantifiable nature— a great complement to what \\nlanguage models appear to be lacking. Its technical nature \\nmight be off-putting for some users, but it’s one of the best due \\nto its advanced abilities.\\nZapier Designed for busy professionals and marketers, Zapier \\nstreamlines repetitive tasks by facilitating seamless communi-\\ncation between more than 5,000 popular business programs, \\nsuch as Gmail, Microsoft Outlook, and Slack.\\nChatGPT Chess Plug-in This plug-in allows you to play \\nchess with the AI and get better at the game.\\nChatGPT KAYAK or Expedia Plug-in Another travel-\\nrelated plug-in, KAYAK assists with flight and hotel bookings.\\nArgil AI This plug-in assists with 3D modeling and design.\\nChatWithPDF This plug-in allows you to view, annotate, and \\nextract text from PDFs— making it an invaluable tool for aca-\\ndemic research or extensive reading.\\nSpeechki Ideal for podcasters, audiobook creators, and con-\\ntent producers, Speechki transforms text into high-quality  \\naudio.\\nThe potential for new plug-ins that could enhance the capa-\\nbilities of ChatGPT is vast. Let’s explore some of these potential \\nideas that might exist by the time you are reading this, keeping in \\nmind that data privacy is not our focus here.\\nImagine a healthcare plug-in that seamlessly integrates with \\nelectronic health record systems. This would allow healthcare pro-\\nfessionals to pull up patient information, check drug interactions, or'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 177\\neven generate preliminary diagnoses based on symptoms described \\nby the patient.\\nIn the sphere of education, a plug-in that connects to educa-\\ntional resources and databases could be a game changer. It could \\nprovide students with explanations of complex concepts, solu-\\ntions to problems, or even personalized study plans based on \\ntheir learning style and progress.\\nIn the financial sector, a plug-in that integrates with financial \\nAPIs could allow users to check stock prices, get investment \\nadvice, or even execute trades directly from the chat interface.\\nThe real estate industry could also benefit from a plug-in \\nthat integrates with real estate databases. This would allow users \\nto search for properties, compare prices, and get information \\nabout different neighborhoods.\\nFitness enthusiasts would appreciate a plug-in that integrates \\nwith fitness APIs, allowing users to track their workouts, get \\nexercise recommendations, or even create personalized workout  \\nplans.\\nLastly, a legal plug-in that connects to legal databases could \\nprovide users with basic legal advice and explanations of legal \\nterms, or even help them draft simple legal documents.\\nThese are just a few examples of the potential plug-ins that \\ncould be developed to enhance the capabilities of ChatGPT . The \\npossibilities are endless, and the future of AI-assisted conversa-\\ntions is exciting.\\nAutonomous Agents The second type of AI agent is autono-\\nmous agents. These are not the AI tools of yesteryear, but \\nadvanced systems capable of executing tasks independently, with \\nminimal human supervision. Y et, they are designed with a fail-\\nsafe, a provision for human intervention, should the need arise. \\nThis is not a distant future concept, but a reality that is taking \\nshape even as we speak.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='178 GENERATIVE AI\\nThe allure of autonomous agents lies in their efficiency and \\ncost-effectiveness. They are tireless, working around the clock \\nwithout the need for breaks or sleep. They perform tasks at a \\nfraction of the cost of human employees.\\nThe applications of these autonomous agents are as diverse \\nas they are numerous. Consider the realm of social media man-\\nagement, a task that requires constant vigilance and timely \\nresponses. An autonomous agent can monitor multiple platforms \\nsimultaneously, respond to queries, and even manage promo-\\ntional campaigns, all without breaking a sweat.\\nBut the reach of autonomous agents extends beyond the realm \\nof social media. They are making inroads into the world of politi-\\ncal campaign management, a field that requires strategic planning, \\nmeticulous execution, and constant monitoring. Autonomous \\nagents can analyze vast amounts of data, identify trends, and make \\nstrategic recommendations, all while managing the day-to-day \\ntasks of a campaign.\\nThe future of work is also set to undergo a seismic shift with \\nthe advent of autonomous agents. In the not-too-distant future, \\nit is conceivable that most people will not report to a human \\nboss, but to an autonomous agent. This is not a dystopian vision, \\nbut a pragmatic projection based on the capabilities of these \\nadvanced AI systems.\\nThe trajectory of autonomous agents points toward main-\\nstream adoption, not just in niche sectors, but across the board. \\nEvery category, every industry, every task that can be automated \\nwill likely see the integration of autonomous agents. This is not \\na prediction but an eventuality that we are moving toward. \\nAutonomous agents are not just tools, but partners, collabora-\\ntors, and perhaps even future colleagues.\\nUnderstanding Autonomous Agents: A\\xa0Practical Example  \\nImagine the task at hand is to construct a web page that fetches \\ndaily T witter news, presenting the top three categories and 10'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 179\\nposts of the day. T o accomplish this, we first need to set up the \\nautonomous agent. In my experience, the open source project \\nAutoGPT is the most robust code repository for autonomous \\nagents currently available. We’ve cloned it, configured all neces-\\nsary APIs like OpenAI for GPT-4, and prepared for the heavy \\nlifting. We’ve also set up GPT-3.5 for quick, cost-effective \\nresponses.\\nA crucial component that requires setup is long-term mem-\\nory. From my experiments, Pinecone seems to be the best option, \\nalthough open source solutions like Milvus also hold their own.\\nOnce set up, AutoGPT is capable of cloning GitHub reposi-\\ntories, running them, accessing X (formerly T witter), and per -\\nforming online search engine searches. We present our goal to \\nthe autonomous agent, which, in a touch of whimsy, gives itself a \\nname— in this case, WebdevGPT . It then dissects the goal into \\nmanageable tasks.\\nThe tasks it identifies include performing an online search \\naround best practices for setting up such web pages, developing \\nthe frontend with HTML, CSS, and JavaScript, and creating \\nbackend functionalities such as setting up APIs, building  \\ncron jobs, data fetching scripts, and a database. There’s also a \\ndata processing part, and finally, we want to deploy and test the  \\nweb page.\\nIn a fascinating display of autonomy, for each of these tasks \\nthe autonomous agent spawns its own team. It creates an AI \\nagent for performing prior online research, one for frontend \\ndevelopment, one for backend functionalities, and one for testing.\\nThe research agent dives into the Internet, swiftly scanning \\nthe top\\xa01,000 Google, Reddit, and Quora results. It distills its \\nfindings and reasons through them. The research agent then \\npasses its findings to the next agent, the frontend development \\nagent, which uses this information to build the web page accord-\\ningly. It sets up the structure with HTML, styles it with CSS, and \\nadds functionality with JavaScript.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='180 GENERATIVE AI\\nSimultaneously, the backend agent codes the X/T witter \\nfetching pipeline, sets up the necessary cron jobs, and establishes \\nthe database. Once all these agents have completed their tasks, \\nthe quality assurance agent deploys the code locally and performs \\na thorough testing. If the quality standards are met, the code gets \\npackaged and the agents shut down. In just 17\\xa0minutes, we have \\na rudimentary, fully functioning web page.\\nIf bugs are detected, they are reported to the respective \\nagents for iteration. Throughout the entire process, AutoGPT \\nasks for confirmation at every step, ensuring that the human is in \\nthe loop. We could also set it on autopilot, allowing it to perform \\ntasks as it deems fit. However, given the nascent stage of this \\ntechnology, it’s advisable to regularly check if the planned tasks \\nare heading in the right direction.\\nThere are numerous examples of this online. And already as \\nof this writing, these agents are roughly one and a half to two \\nmonths old, and they’re already impressively showing the first \\nsparks of professional coworkers.\\nThe success of this approach could pave the way for the \\ndevelopment of more advanced AI agents that can collaborate \\nand negotiate with humans in various domains beyond gameplay. \\nThe technology behind this is relevant to many other applica-\\ntions, such as intelligent assistants that can hold long-term con-\\nversations with people and collaborate with them on complex \\ntasks. The future of autonomous agents is not just promising— \\nit’s already here.\\nMusic Generation\\nThe art of music generation has been a fascinating journey, tra-\\nversing a multitude of technical approaches. Initially, generative \\nalgorithms have been employed to create music based on estab-\\nlished rules or patterns. These algorithms take into account vari-\\nous aspects of music, such as melody, harmony, rhythm, and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 181\\ntimbre, and then orchestrate new pieces that echo the style and \\nstructure of their training data.\\nRecurrent neural networks (RNNs) were once the favored \\ntool for this task. Their ability to model sequential data made \\nthem ideal for the job. Imagine a pianist, fingers dancing across \\nthe keys, each note influenced by the ones that came before. \\nThat’s how RNNs work— they can be trained on a collection of \\nMIDI files, which are essentially digital sheet music, and then \\nused to generate new music by predicting the next note in a \\nsequence based on the previous notes.\\nHowever, the stage of music generation was set for a new \\nperformer when generative adversarial networks (GANs) entered \\nthe scene. T o quickly recap, GANs consist of two neural net-\\nworks, a generator and a discriminator, engaged in a creative \\nrivalry to produce realistic music. The generator composes new \\nmusic samples, while the discriminator critiques these samples, \\ndiscerning whether they are real or fabricated. The generator, \\nlike a diligent student, refines its output based on the feedback \\nfrom the discriminator, leading to increasingly realistic music \\ngeneration over time.\\nThe latest act in this ongoing performance features, of course, \\nT ransformer models, as they have shown superior performance \\nin handling sequential data, adeptly analyzing rhythm and other \\nmusical elements.\\nIn the early days of the modern generative AI era, music gen-\\neration didn’t quite strike a chord with me. The output was dis-\\ncordant, and the lack of visual appeal made it less engaging. Over \\nthe years, there were a few noteworthy breakthroughs, but it \\nwasn’t until the debut of MusicLM in January 2023 that I felt AI \\nmodels truly hit the right notes in music generation.\\nGoogle’s MusicLM and Other AI Models/Tools MusicLM, a \\nproduct of Google’s innovation, is a sophisticated tool that gener-\\nates unique songs from user-provided text descriptions or ideas.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='182 GENERATIVE AI\\nIt utilizes a hierarchical sequence-to-sequence modeling approach \\nto create high-quality music at 24\\xa0kHz, maintaining consistency \\nover extended durations. Additionally, MusicLM has the capacity \\nto adapt to both text and melody inputs, modifying melodies—  \\nwhether whistled or hummed— to match the style indicated in a \\ntext description.\\nMusicLM struck a chord with me, particularly because of its \\nversatility. Y ou simply type the caption that you envision for the \\nmusic you want to hear, and it generates the corresponding audio. \\nIt can be instructed for long music generation, or a story mode \\nwhere you write as the text prompt what music should be played \\nat the beginning, middle, and end, mapped on a timeline. It can \\ngenerate single music instruments such as acoustic guitar, cello, \\nor flute, or a specific genre like ambient or Berlin 90s house. It \\ncan even generate music mapped to the experience of the musi-\\ncian, places, decades, and all sorts of things. Witnessing this for \\nthe first time was nothing short of mind-blowing.\\nT o experience MusicLM, you can sign up for its waitlist \\nthrough Google’s AI T est Kitchen. Once approved, you can pro-\\nvide a descriptive phrase like “ambient, soft-sounding music I \\ncan study to.” MusicLM will then create two versions of the song \\nfor you to listen to, and you can award a trophy to the track you \\nprefer, which will help improve the model. This is human feed-\\nback in action!\\nGoogle has been collaborating with musicians and hosting \\nworkshops to gather early feedback and explore how this tech-\\nnology can enhance the creative process. They have also released \\nMusicCaps, a dataset composed of 5.5k music-text pairs with \\nrich text descriptions provided by human experts, to support \\nfuture research. It’s commendable when large for-profit compa-\\nnies support research in this way without penny-pinching.\\nT oday, there are numerous AI music generation companies \\nand projects. The top models that I’ve seen, according to their'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 183\\nhigh output quality, are from Amper Music, AIVA, and Ecrett \\nMusic. As the momentum of AI continues to build, larger com-\\npanies are making efforts to stay ahead of the trends. For exam-\\nple, Shutterstock acquired Amper Music in a strategic move. \\nWhile the precise acquisition cost isn’t known, it’s likely that \\nthese transactions involve considerable amounts, often in the \\nmillions. These companies, primarily operating for profit in their \\nrespective domains, typically do not disclose their technical \\nor AI stack.\\nI don’t want to delve too deeply into this, as there is only one \\nway to truly understand what I mean when I say “high output \\nquality.” I’m not suggesting that the AI is even remotely as good \\nas a maestro musician. However, if we consider the trajectory of \\nthis technology even three years ago and project that line of \\nquality linearly into the future, it’s clear that it will catch up with \\neven top human performance. And let’s not forget, this evolution \\nis anything but linear.\\nWhere Is Music Generation Going? Consider personalized \\nmusic streaming. Platforms like Spotify could incorporate AI-\\ngenerated music streams that are tailored to your specific needs. \\nEnvision a feature where you input your current mood, activity, \\nor event, and the AI composes a unique soundtrack just for you. \\nOr even in the fitness domain, AI could create dynamic music \\nthat syncs with your workout, from warm-up to HIIT (high-\\nintensity interval training) to cool-down.\\nT aking it a notch higher, we arrive at the concept of music \\ntherapy. AI could generate therapeutic music tailored to an indi-\\nvidual’s psychological and physiological state. This could serve as \\na tool for stress relief, focus enhancement, or emotional therapy.\\nWhat about interactive video games? The music in video \\ngames could evolve based on the player’s actions and decisions in \\nreal time, creating an immersive experience that is unparalleled.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='184 GENERATIVE AI\\nBut what truly catches my attention is the prospect of AI \\nconcerts and albums. Just as we have seen AI-generated artwork \\nexhibitions, we might start seeing concerts or music albums \\nentirely composed and performed by AI. This isn’t a novel con-\\ncept, though. Hatsune Miku, one of Japan’s most beloved pop \\nstars, is a hologram. Over a 14-year career, this Japanese diva has \\nuploaded 170,000 Y ouT ube music videos, amassed more than \\n2.3\\xa0 million followers on Facebook, and released a staggering \\n100,000 songs. She has collaborated with Pharrell Williams, \\nopened for Lady Gaga, and her concerts are sold out worldwide. \\nShe even appeared at Coachella in 2020. The acceptance of an AI \\npop star is not a far-fetched idea. Similar trends can be observed \\nin Korea. While the hit songs are not fully AI-generated yet, this \\ntrend is bound to escalate.\\nLet’s pause and ponder a fascinating prospect: Artists who \\nare no longer with us could continue to hold concerts and even \\nproduce new albums. T ake Whitney Houston as an example. \\nDespite her passing in 2012, she embarked on a concert tour \\nfrom 2020 to 2023. Although it didn’t feature entirely new \\nsongs, imagine the possibilities if it had. Picture a future where \\nnew albums are released under her name, years after her \\ndeparture.\\nWhile we stand in awe of these innovations and their poten-\\ntial, we must also recognize the risks they carry, such as the dis-\\nplacement of musicians or the potential devaluation of music \\ncreated by humans. However, these very tools, if thoughtfully \\nintegrated, could also serve as a lifeline for musicians. They \\ncould stimulate the generation of musical ideas, assist in com-\\nposing harmonies, or even suggest enhancements to improve \\nthe quality of the music. In this way, AI can become a powerful \\nally, extending human creativity and accessibility in music, \\nrather than a threat.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 185\\nVideo Generation\\nWe’ve already explored the territory of image generation exten-\\nsively, discussing models like stable diffusion and DALL-E. \\nThese models, which deal with static image generation, have laid \\nthe foundation for a more dynamic frontier: video generation. \\nThis is a significantly more challenging endeavor, as it involves \\nnot just the creation of a single image, but a sequence of images, \\nor frames, that must be coherent, consistent, and sensible. Add to \\nthis the complexity of a storyline that goes beyond understand-\\ning spatial and temporal behaviors, but weaves intricate narra-\\ntives, and we find ourselves at a threshold that generative AI is \\nstill striving to cross.\\nThe Tech Behind Video Generation T o achieve video gen-\\neration, we move from stable diffusion models to video diffusion \\nmodels. Video diffusion models extend the standard image archi-\\ntecture and are effective for training from both image and video \\ndata. The fundamental concept behind video diffusion models is \\nto generate a fixed number of video frames using a 3D U-Net \\ndiffusion model architecture (more on this in a moment). T o \\ngenerate longer videos at higher resolutions, these models are \\nextended autoregressively, which means the output at any given \\nstep is influenced by the inputs at previous steps.\\nBut what exactly is a 3D U-Net? T o understand this, you first \\nneed to know what a U-Net is. A U-Net is a convolutional neural \\nnetwork originally developed for biomedical image segmenta-\\ntion. It’s designed with a unique architecture that supplements a \\ncontracting network with successive layers of upsampling opera-\\ntors, thereby increasing the resolution of the output. This results \\nin a U-shaped structure, hence the name U-Net (Figure\\xa03.13).'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='186 GENERATIVE AI\\nThe network uses a large number of feature channels in the \\nupsampling part, allowing it to propagate context information to \\nhigher-resolution layers. This makes the expansive path symmet-\\nric to the contracting part, enabling more precise output based \\non the input image.\\nIn the realm of video generation, we use a 3D U-Net. Video \\ndata is inherently three-dimensional, consisting of width, height, \\nand time. The 3D U-Net processes this data, using the temporal \\ninformation in the video data to generate new video frames, in \\naddition to using the spatial information in each frame. This \\nallows for the generation of video content that is consistent and \\ncoherent over time, making it a powerful tool for tasks like video \\nediting, video synthesis, and even virtual reality.\\nT o generate high-quality videos, video diffusion models \\napply a basic diffusion model, which involves repeatedly adding \\nGaussian noise. They do this with minimal changes, except for \\nsome simple adjustments to the structure to fit video data within \\nthe memory limits of deep learning accelerators.\\nFIGURE\\xa03.13 (3D) U-Net: The 3D U-Net is an extension of the U-Net, \\ndesigned to process three-dimensional data, including the temporal \\ndimension.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 187\\nSeveral open source toolboxes and foundation models are \\navailable for video diffusion, such as MagicVideo, Imagen Video, \\nMake-A-Video, and diffusion models for video prediction and \\ninfilling. These tools provide a platform for developers and art-\\nists alike to experiment with and push the boundaries of video \\ngeneration.\\nFor-Profit Solutions In the realm of video diffusion models, the \\nlandscape is not solely dominated by open source tools. Indeed, \\nthe commercial sector is already reaping substantial profits, with \\ncompanies like Runway AI leading the charge. Runway AI, in par-\\nticular, stands out for its exceptional quality and seriousness, boast-\\ning an impressive roster of industry professionals and clients.\\nRunway AI is an applied AI research company with a mission \\nto democratize the boundless creative potential of AI. They are a \\nfull-stack operation, overseeing the entire process from research \\nand model training to product deployment. Their creative suite, \\nequipped with over 30 AI Magic T ools, empowers users to gener-\\nate and edit content, catering to every facet of the creative pro-\\ncess. This comprehensive approach is a recipe for long-term \\nsuccess in the startup world.\\nAt the heart of Runway’s innovation is their research division, \\nwhich develops multimodal AI systems for novel creative tools. \\nTheir Gen-2 video generation model is particularly noteworthy. \\nThis model marks a significant advancement over its predecessor, \\nGen-1, which was primarily designed to modify preexisting vid-\\neos. Gen-2 amalgamates the best features of both generations, \\nenabling it to apply the composition and style of an image or text \\nprompt to the structure of a source video, thereby generating an \\nentirely new video. The user can manipulate an uploaded video \\nwith simple terms and, within minutes, be astounded by the results. \\nThe experience is akin to the awe-inspiring moment when one \\nfirst uses ChatGPT .'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='188 GENERATIVE AI\\nDespite its impressive capabilities, Gen-2 is not without its \\nlimitations. It struggles with low frame rates, graininess, and \\ninconsistencies related to physics or anatomy. The model also \\nhas difficulty grasping nuances and often overemphasizes certain \\ndescriptors in prompts while neglecting others. However, with \\nits ability to understand a wide array of styles, Gen-2 can be har-\\nnessed to create a narrative piece with a bit of editing work.\\nRunway AI’s influence extends far beyond mere demonstra-\\ntions and presentations. They have successfully garnered the \\nattention of numerous prestigious clients, such as New Balance, \\nCBS, Publicis, and even the editing team behind The Late Show \\nWith Stephen Colbert. Individual users of note include Kevin \\nParry, a celebrated stop-motion animator famed for his optical \\nillusion videos, who employs Runway’s technology to amplify his \\nviral video narratives. The reach of Runway AI even extends to \\nTinseltown, Hollywood, with their tools being utilized in the \\nproduction of the film Everything Everywhere All at Once.\\nIn recognition of its potential, Google LLC has reportedly \\ninvested in Runway AI as part of a recent $100\\xa0million funding \\nround. This investment has catapulted Runway’s post-money \\nvaluation to a staggering $1.5 billion. Google’s strategic move is \\nnot just about financial gain; it’s also about fostering the AI \\nstartup ecosystem within the Google Cloud environment. With \\nMicrosoft partnering with OpenAI and Amazon securing  \\nHugging Face, Google’s investment in Runway is a clear signal \\nof its intent to nurture its own cloud-based AI ecosystem.\\nAWS, GCP , and Azure The advent of cloud technology \\nmarked a pivotal juncture for Internet titans. However, it wasn’t \\nmerely the act of embracing the cloud that mattered but doing so \\neffectively. AWS, Azure, and Google Cloud stand as the three \\nmost dominant cloud providers today, not simply because they \\nadopted the technology, but because they executed the right'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 189\\nstrategies, developed valuable applications, and fostered robust \\necosystems. For instance, IBM Cloud, despite its early entry into \\nthe market, has struggled to keep pace. The reason? A flawed \\nstrategy in a fiercely competitive market. Figure\\xa03.14 illustrates \\nthe market share distribution.\\nAllow me to digress momentarily to underscore a burgeon-\\ning trend among these cloud giants: AWS, Google Cloud, and \\nAzure are all placing a premium on optimizing customer spend-\\ning. This approach is viewed as a long-term commitment to cul-\\ntivating lasting customer relationships. Industry leaders like \\nMicrosoft’s Satya Nadella, Amazon’s Brian Olsavsky, and Alpha-\\nbet’s Sundar Pichai have all emphasized the significance of opti-\\nmization, recognizing that customers are on the hunt for ways to \\ncut costs and redirect resources toward innovative customer \\nexperiences.\\nMicrosoft, for instance, is capitalizing on its investment in \\nOpenAI and ChatGPT to bolster its Azure and SaaS roadmaps. \\n0%\\n5%\\n10%\\n15%\\n20%\\nShare of Worldwide Revenues25%\\n30%\\n35%\\nQ4\\n17\\nQ1\\n18\\nQ2\\n18\\nQ3\\n18\\nQ4\\n18\\nQ1\\n19\\nQ2\\n19\\nQ3\\n19\\nQ4\\n19\\nQ1\\n20\\n(IaaS, PaaS, Hosted Private Cloud)\\nOthers\\nQ2\\n20\\nQ3\\n20\\nQ4\\n20\\nQ1\\n21\\nQ2\\n21\\nQ3\\n21\\nQ4\\n21\\nQ1\\n22\\nQ2\\n22\\nSource: Synergy Research Group\\nQ3\\n22\\nQ4\\n22\\nCloud Provider Market Share Trend\\nFIGURE\\xa03.14 Market share distribution of cloud service providers.\\nSource: (a) Amazon.com, Inc. (b) Microsoft Corporation (c) Google LLC (d) Alibaba.com \\n(e) International Business Machines Corporation'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='190 GENERATIVE AI\\nNadella revealed that Azure OpenAI Service has seen a tenfold \\nincrease in customers quarter over quarter. Google, too, is hon-\\ning its focus on generative AI, with Pichai emphasizing the use of \\nlarge language models across Google Cloud platform, Google \\nWorkspace, and cybersecurity offerings in a recent interview. \\nAmazon’s AWS is fostering generative AI through managed ser-\\nvices such as Amazon Bedrock, a service that provides access to a \\nwide range of foundation models via an API, and Amazon Code-\\nWhisperer, a code generator that offers real-time code recom-\\nmendations. Additionally, AWS has, of course, its partnership \\nwith Hugging Face, as mentioned earlier.\\nOn the financial front, AWS reported a first quarter (2023) \\noperating income of $5.12 billion on revenue of $21.35 billion, \\nmarking a 16 percent increase from the previous year. Microsoft \\nCloud reported fiscal third-quarter revenue of $28.5 billion, \\nup\\xa022 percent from a year ago. Google Cloud reported first quar-\\nter (2023) operating income of $191\\xa0million on revenue of $7.45 \\nbillion, a 28 percent increase from the previous year.\\nLooking ahead, these cloud behemoths are optimizing today \\nto lay the groundwork for future growth. Microsoft CFO Amy \\nHood noted that new workloads will play a significant role in the \\nquarters to come. The companies are also investing heavily in \\ninfrastructure to enhance their own operations and bolster AI \\ninitiatives. They are of the belief that generative AI has reached \\na turning point and is poised to revolutionize virtually every cus-\\ntomer experience in existence.\\nSynthesia In the midst of this discourse, a noteworthy devel-\\nopment has just unfolded. Synthesia, the NVIDIA-backed plat-\\nform that transforms text into A.I.-generated avatars and avatar \\nvideos, has seen its valuation surge to a staggering $1 billion. \\nThis London-based synthetic media company, founded in 2017'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 191\\nby a team of researchers and entrepreneurs from University Col-\\nlege London, Stanford, T echnical University of Munich, and \\nCambridge, has been making waves in the realm of video synthe-\\nsis technology as well.\\nSynthesia is offering a unique service that generates person-\\nalized video content for customer engagement. The process is as \\nsimple as it is innovative. Y ou select a video template, choose a \\npreferred avatar (visual), and decide on the accent of the avatar \\n(audio). Then, you input the text that you want the avatar to \\narticulate in your language of choice. The result? A tailor-made \\nvideo that you can edit to your liking, altering the background, \\nadding background music, and more.\\nSynthesia has distinguished itself with its unique and highly \\nvaluable product. It’s no wonder they’ve achieved the coveted \\nstatus of a “unicorn,” a term used to describe startups that reach \\na valuation of $1 billion and above.\\nWhere Is Video Generation Going? Shifting our focus back \\nto video generation, it’s intriguing to ponder how this technol-\\nogy might evolve over the next decade and significantly influence \\nvarious sectors. But what might this future landscape look like?\\nPersonalized Movies and Shows We’re not just talking about \\nstreaming platforms suggesting shows based on your viewing \\nhistory. We’re envisioning a future where the actual content of \\nshows or movies dynamically adapts to the viewer’s prefer -\\nences and choices, generated in real time.\\nViewer Preferences This personalization could encompass \\neverything from preferred genres and beloved actors to favored \\nplot structures (such as happy endings or plot twists), themes of \\ninterest (like love, adventure, or mystery), and even pacing pref-\\nerences (slow-burn narratives or fast-paced action sequences).'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='192 GENERATIVE AI\\nThis could involve the generation of new scenes, modification \\nof dialogue, or alterations to the visual style of the show.\\nInteractive Storytelling Drawing inspiration from interactive \\nstorytelling experiences (like Netflix’s Black Mirror: Bander -\\nsnatch), viewers could make choices that directly influence the \\nstoryline. However, with AI video generation, these choices \\ncould be more nuanced and have a more profound impact on \\nthe plot. For instance, a viewer could dictate a character’s \\nactions, dialogue, or even emotional responses.\\nContinuous Learning The system would perpetually learn \\nfrom the viewer’s choices, refining its understanding of their \\npreferences. This would lead to increasingly personalized con-\\ntent over time, creating a truly unique viewing experience tai-\\nlored to each individual.\\nImagine the dawn of “AI actors”— realistic, AI-generated \\ncharacters capable of performing any role, from minor back-\\nground parts to leading roles. These AI actors could exhibit  \\na broad spectrum of emotions and actions, proving invaluable \\nfor roles that are perilous, challenging to cast, or necessitate a \\nspecific look or performance that might be difficult to find in \\nhuman actors.\\nMoreover, AI actors could unlock unprecedented possibili-\\nties for creative storytelling. Filmmakers could craft characters \\nthat transcend human limitations— characters that can alter their \\nage, appearance, or even species at will. This could pave the way \\nfor more diverse and imaginative narratives. While AI actors \\ncould never supplant the talent and creativity of human actors, \\nthey could serve as a potent tool for filmmakers, offering novel \\nways to weave stories and captivate audiences.\\nBut let’s not limit ourselves to entertainment. What about \\nthe realm of education?'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 193\\nHarnessing video generation technology could enable the \\nvivid re-creation of historical events or extinct species with strik-\\ning precision, thereby serving as a powerful educational instru-\\nment. Picture students not merely reading about historical events, \\nbut visually immersing themselves in them, thereby establishing a \\nmore palpable link to the past. And let’s not forget the potential of \\nAI sound generation, which could mimic the most plausible sounds \\nof these bygone eras, further enhancing this immersive educa-\\ntional experience.\\nEnvision a classroom delving into the Civil War, not merely \\nthrough text, but by witnessing a lifelike reenactment of the Battle \\nof Gettysburg. Or students absorbing the nuances of the Roman \\nEmpire by experiencing a day in the life of a Roman citizen, mean-\\ndering through the vibrant markets and majestic amphitheaters. \\nWhile such scenes can be created with actors and prepared sets, \\nimagine the added layer of interactivity. A student could choose \\ntheir viewing perspective— through the eyes of a king, a soldier, or \\neven a bird’s-eye view. They could decide whether to overlay addi-\\ntional information, truly customizing their learning experience.\\nSimilarly, video generation could breathe life into extinct \\nspecies, enabling students to observe these creatures in their nat-\\nural habitats. This could foster a more comprehensive under -\\nstanding of topics like evolution and natural history. By leveraging \\nvideo generation technology, education could transform into a \\nmore immersive and engaging experience, potentially nurturing \\na deeper understanding and appreciation of our history and the \\nnatural world.\\nAnd the possibilities don’t end there. I foresee potential appli-\\ncations in law enforcement and forensics, interior design, advertis-\\ning, and countless other yet untapped areas. The future of video \\ngeneration technology is not just promising— it’s exhilarating.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='194 GENERATIVE AI\\n3D Object Generation\\nThe realm of object generation holds a captivating allure, one \\nthat I first saw in 2017\\xa0when I stumbled upon a groundbreaking \\npaper from Stanford. At that time, I was just beginning to learn \\nabout generative adversarial networks, my mind teeming with \\nthe potential they could unlock in the sphere of 3D object \\n generation. As early as 2016, Stanford had pioneered a three-\\ndimensional GAN, a versatile tool capable of conjuring up\\xa03D \\nobjects with an ease that was nothing short of revolutionary. \\n Figure\\xa0 3.15 illustrates the conceptual transformation from a \\n(latent) vector to a chair.\\nThe resolution was not high, but the demonstration was \\nastounding. The latent vector, or the input, defined the object we \\nwanted to create. A chair? A table? A car? A boat? The possibili-\\nties were endless. When constructing a chair, for example, the \\nvector allowed for interpolation between different chair designs. \\nBy interpolation, I mean a smooth transition in the latent space, \\nsubtly altering features like the thickness of the legs and arm-\\nrests. Vector arithmetic made it possible to add or subtract fea-\\ntures, such as armrests, with ease.\\nThe implications for product development were profound. \\nSuddenly, we could generate thousands of variations of a chair and \\nZ\\n512×4×4×4 256×8×8×8\\n128×16×16×16 64×32×32×32\\nG(z) in 3D Voxel Space\\n64×64×64\\nFIGURE\\xa03.15 The generator component of 3D generative adversarial  \\nnetworks.\\nSource: http://3dgan.csail.mit.edu'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 195\\neasily incorporate the desired features. We could even extrapolate \\nbetween disparate objects like a boat and a house. As we navigated \\nsmoothly through the latent space, the boat would gradually trans-\\nform into a house, allowing us to halt the process at any point to \\ncreate, say, a houseboat.\\nThe initial demonstration from Stanford was rudimentary \\nand coarse-grained. The objects were represented by large pix-\\nels, and the technology was far from being ready for practical \\napplications. Y et, my imagination was set aflame.\\nThe Stanford paper was a groundbreaking contribution to the \\nfield. For a while, it seemed as though progress had stalled. Even \\ntoday, there’s much work to be done. However, the strides made in \\nthe past seven years are significant and worth exploring. The \\nfuture of object generation is not just promising— it’s thrilling.\\nCutting-Edge Research in 3D Object Generation The idea \\nof generating 3D models from textual descriptions is no longer a \\nfar-fetched concept but a reality that is being explored and devel-\\noped by many.\\nOne such development is DreamFusion, a tool that leverages \\n2D diffusion to generate 3D assets. This technology is just one \\nexample of the strides being made in this field, demonstrating \\nthe potential of AI in transforming textual data into tangible 3D \\nmodels (Figure\\xa03.16).\\nFIGURE\\xa03.16 A highly detailed stone bust of Theodoros Kolokotronics.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='196 GENERATIVE AI\\nAnother noteworthy development is the advent of CLIPMa-\\ntrix and CLIP-Mesh-SMPLX. These tools generate textured \\nmeshes directly, offering a new approach to 3D model genera-\\ntion. CLIP , a model trained on a vast array of Internet text and \\nimages, is a key component of these tools, providing the neces-\\nsary understanding of the relationship between text and images.\\nCLIP-Forge, on the other hand, uses language to generate \\nvoxel-based models. Voxels, essentially the 3D equivalent of pix-\\nels, represent a value on a regular grid in a three-dimensional \\nspace. This method allows for the creation of detailed and intri-\\ncate 3D models based on textual input.\\nPoint-E and Pulsar+CLIP , developed by OpenAI, use lan-\\nguage to generate 3D point clouds. A point cloud is a set of data \\npoints in space, often used to represent the external surface of an \\nobject. Point-E, in particular, has been open sourced and has \\npotential applications in 3D printing, gaming, and animation.\\nThe process employed by Point-E is essentially a double dif-\\nfusion model. It first generates a synthetic view using a text-to-\\nimage diffusion model, and then produces a 3D point cloud using \\na second diffusion model that conditions on the generated image.\\nDream T extures, another tool in this domain, uses text-to-\\nimage technology to texture scenes in Blender automatically. \\nBlender, a free and open source 3D computer graphics software \\ntoolset, is widely used for creating animated films, visual effects, \\nart, 3D printed models, and video games.\\nIt’s important to note that many of these approaches, exclud-\\ning CLIPMatrix and CLIP-Mesh-SMPLX, are based on view \\nsynthesis, or generating novel views of a subject, as opposed to \\nconventional 3D rendering. This is the idea behind NeRFs, or \\nneural radiance fields.\\nNeRF is akin to a magical artist that can create a detailed 3D \\npainting from a collection of 2D photos. Imagine you’ve taken'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 197\\nseveral photos of a room from different angles. NeRF looks at \\nthese photos, and like an artist, it understands the room’s struc-\\nture, colors, and how light interacts with different objects. It then \\nuses this understanding to paint a 3D model of the room that \\nyou can look at from any angle, even ones not captured in the \\noriginal photos. Diving a bit deeper, NeRF accomplishes this by \\nusing a deep learning technique where it trains a neural network \\nto map\\xa03D coordinates to colors and densities. This trained net-\\nwork can then generate a realistic 3D scene based on the infor -\\nmation it learned from the 2D images, allowing for the synthesis \\nof novel views of the scene.\\nLeading Companies and Approaches in 3D Object Genera-\\ntion NeRF , as we’ve seen, can transform a handful of images \\ninto a short video that gives the illusion of flying around the \\nobject. It’s a fascinating concept, but it’s just the tip of the iceberg.\\nThe best-in-class 3D object generation models are not stand-\\nalone entities. They are intricate systems, a blend of various \\ntechniques, each complementing the capabilities of the others.\\nT ake Luma AI, for example. This platform showcases the \\npower of NeRF in a remarkable way. Y ou can upload a couple of \\npictures, and it doesn’t just generate a short clip— it creates a \\nreasonably accurate, detailed 3D object. The level of detail is \\nastounding, extending to the point where you can upload multi-\\nple images of a neighborhood, perhaps taken by drones, and \\nLuma AI will generate a detailed neighborhood complete with \\nswings, trees, trampolines, bicycles, and more.\\nLuma AI doesn’t stop there. It has harnessed the capabilities \\nof NeRF to an extent where they can manipulate live video feeds. \\nImagine recording a video with your smartphone, and as you pan \\nthe camera, the room in the video transforms into a different \\nworld— a photorealistic, immersive experience, all thanks to'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='198 GENERATIVE AI\\ngenerative AI. It’s like peeking into a parallel universe through \\nthe lens of your camera.\\nBut Luma AI isn’t alone in this field. There are numerous \\nother companies leveraging AI to generate 3D objects. Kaedim, \\nfor instance, generates 3D objects from pictures, sketches, and \\nother sources. Once generated, these objects are not static— they \\ncan be edited, scaled up or down, and their colors can be adjusted. \\nIt’s a dynamic, interactive process that opens up a world of \\npossibilities.\\nAnd then there’s NVIDIA, a long-standing titan in the realm \\nof generative AI. Their platform, NVIDIA Picasso, is their stra-\\ntegic approach to this technology. They’re not merely observers \\nin this field— they’re active participants, constantly innovating \\nand pushing the boundaries of what’s possible.\\nNVIDIA Picasso is a prime example of how generative AI is \\nbeing harnessed to create visual applications. This cloud service \\nis designed to generate images, videos, and 3D models from text \\nprompts. It’s a versatile tool, capable of being fine-tuned for a \\nvariety of uses, from business applications to medical research, \\nand even the creation of AI artwork. It’s a platform built with \\nsoftware creators, service providers, and businesses in mind, par-\\nticularly those intending to train AI models using copyrighted \\nmaterial. See its structural overview in Figure\\xa03.17.\\nThe level of detail that NVIDIA Picasso can achieve in 3D \\nobject generation is truly remarkable. With a simple prompt like \\n“a 3D model of a male bust with a furrowed brow and deep-set \\neyes, wearing a wreath of ivy leaves, highly detailed,” a corre-\\nsponding 3D object can be generated.\\nNVIDIA ’s success in this field is not a solo endeavor. They \\nhave established strong partnerships with key players in the \\nindustry. Getty Images, a leading global visual content creator \\nand marketplace, is collaborating with NVIDIA to develop image'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 199\\nand video generation models on Picasso, trained on fully licensed \\ndata. Enterprises can access these models through API calls.\\nSimilarly, Shutterstock is partnering with NVIDIA to develop \\nmodels for generating 3D assets, trained on fully licensed con-\\ntent from Shutterstock.\\nAll of this happens on NVIDIA ’s cloud platform. NVIDIA ’s \\nDGX Cloud is a powerful tool for AI development. It provides \\naccess to dedicated clusters of NVIDIA DGX hardware, essen-\\ntially offering an AI supercomputer in the cloud. This service \\nsimplifies the process of acquiring, deploying, and managing AI \\ninfrastructure.\\nEach instance of DGX Cloud comes with 8\\xa0NVIDIA H100 \\nor A100 80\\xa0GB T ensor Core GPUs, totaling 640\\xa0GB of GPU \\nmemory per node. The service is available through existing cloud \\nAPI Service\\nEdify\\nGateway\\nNVIDIA Picasso Service\\nCustom Data\\nTrain\\nOptimize\\nImage\\nVideo\\n3D \\nInference\\nNVIDIA DGX Cloud\\nCustom Model\\nClient App\\nFIGURE\\xa0 3.17 The NVIDIA Picasso service structure, showcasing the \\nintegration of generative AI models, NVIDIA Edify foundation models, \\nand NVIDIA DGX Cloud for optimized training, inference, and genera-\\ntion of image, video, and 3D content.\\nSource: www.nvidia.com/en- us/gpu- cloud/picasso'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='200 GENERATIVE AI\\nproviders, with Microsoft Azure soon to host DGX Cloud, and \\nplans for expansion to Google Cloud and others.\\nStarting at $37,000 per instance, the NVIDIA DGX Cloud \\noffers customers the ability to train and deploy their models \\nusing their own data. They have the option to leverage NVID-\\nIA ’s pre-trained models or optimize and run their own. Given \\nthe capabilities and convenience it provides, the price point is \\nindeed quite reasonable.\\nGiven these advancements and strategic moves and partner-\\nships, it’s not a stretch to envision NVIDIA as a multitrillion-\\ndollar company in the future, especially if AI continues to evolve \\nat its current pace. And there’s every indication that it will. The \\nfuture of generative AI is bright, and NVIDIA is poised to be one \\nof its leading lights.\\nWhere Is 3D Object Generation Going? Imagine slipping \\non a cutting-edge virtual reality headset, immersing yourself in a \\nrealm shaped by your own recollections and the prowess of AI. \\nY ou narrate the details of your childhood home, each memory \\nspringing to life from a handful of old photographs. As the AI \\nattentively listens, it transforms your words and these precious \\nimages into a vivid, lifelike 3D environment in real time. Sud-\\ndenly, you’re navigating the corridors of your past, each detail \\nmeticulously replicated. This encapsulates the future of virtual \\nreality and gaming, where your memories and a few old photo-\\ngraphs are the only limits to your imagination.\\nNow, envision a revolution in the sphere of retail. Retailers \\ncould use AI to generate 3D models of products based on cus-\\ntomer descriptions, allowing customers to visualize products in \\ntheir own space using AR before making a purchase. Y ou’re shop-\\nping for a new sofa, and with a few descriptive words, a 3D model'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 201\\nmaterializes in your living room. Shopping becomes a more \\ninteractive and personalized experience.\\nOr picture yourself in a state-of-the-art workshop. Y ou \\ndescribe the item you’ve been dreaming of— a unique sculpture, \\nor a part for an old machine. As the AI listens, it understands not \\njust the physical attributes, but the emotion behind your idea. \\nThe screen comes to life, displaying a 3D model of your item, \\nevery detail rendered with stunning accuracy. With a nod, you \\ngive the command to proceed. The 3D printer whirs to life, its \\nmechanical arm moving with precision as it lays down layer after \\nlayer of material. Y ou watch as your idea transforms from a digi-\\ntal concept into a tangible object. This is the future of personal-\\nized manufacturing, where you’re not just a consumer, but \\na creator.\\nIn the field of robotics, engineers could use AI to generate \\n3D models of custom robot parts based on specific needs and \\ndescriptions. This could accelerate the development of custom-\\nized robotics, making it easier to create robots tailored to specific \\ntasks or environments. In the not-so-distant future, it’s conceiv-\\nable that robots of all shapes and sizes, from humanoid forms to \\nmulti-wheeled machines, will become a common sight on our \\nstreets. This is not mere speculation but a rapidly approach-\\ning reality.\\nGoldman Sachs Research projects a market worth $6 billion \\nor more for people-sized and -shaped robots within the next 10 \\nto 15 years. Such a market could address 4 percent of the pro-\\njected U.S. manufacturing labor shortage by 2030 and meet 2 \\npercent of global elderly care demand by 2035. However, with \\nthe productivity acceleration brought about by generative AI, I \\nbelieve we’ll reach these milestones even sooner.\\nAnd this is just the beginning. The potential applications of \\nAI in 3D object generation span various sectors. From fashion'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='202 GENERATIVE AI\\nand apparel design to medical training and simulation, from  \\nfilm and animation to interior design, from education to auto-\\nmotive and aerospace design— the possibilities are as vast as  \\nthey are exciting.\\nSynthetic Data Augmentation\\nThere’s one more domain that merits our attention. It’s not an \\napplication field in the traditional sense, but rather a realm where \\ngenerative AI is employed to enhance other AI fields, for instance. \\nThis domain is known as data augmentation.\\nPicture an unbalanced dataset— for instance, medical images \\nof a rare cancer. If your goal is to construct a machine learning \\nsystem— likely a convolutional neural network (CNN)— that can \\nidentify these rare, malignant instances, you need a robust dataset \\nfor training. A “good” dataset implies a balanced representation of \\nall different instances— malignant, benign, and non-cancerous.\\nHowever, reality often falls short of this ideal. If you’re deal-\\ning with a rare cancer, you won’t find many instances. Moreover, \\nto train your system on such data you need permissions, which \\ncan lead to privacy concerns. This is where data synthesis, a form \\nof data augmentation, comes into play. It can address these chal-\\nlenges and ultimately enhance the machine learning system’s \\ndetection performance.\\nNVIDIA was a trailblazer in this area. They published a paper \\non brain scan synthesis via generative adversarial networks in \\nSeptember 2018. Since then, a flurry of papers have emerged, dis-\\ncussing various aspects of this technology. Some argue it’s ineffec-\\ntive, others exaggerate its effectiveness. The truth, as is often the \\ncase, lies somewhere in the middle. The effectiveness of data aug-\\nmentation is a nuanced issue, and the task itself is far from trivial.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 203\\nBut the implications of data augmentation extend beyond \\nimproved performance and privacy issues. It’s also about cost-\\neffectiveness and better representation of real-world scenarios.\\nCollecting new data can be a drain on resources— both time \\nand money. Data augmentation, however, offers a cost-effective \\nalternative. It allows you to increase the size and diversity of your \\ndataset without the need for additional data collection.\\nMoreover, it’s crucial that we don’t develop biased products. \\nFor instance, we need to ensure that all minorities are included \\nin our datasets. Data augmentation can help achieve this, improv-\\ning the robustness of the model and ensuring it’s a better repre-\\nsentation of diverse real-world scenarios.\\nIt’s not just about creating more data— it’s about creating \\nbetter data. And in the grand scheme of things, that could make \\nall the difference.\\nThe Tech Behind Data Augmentation Effective data aug-\\nmentation is anything but trivial. T ake image data augmentation, \\nfor instance. The algorithms employed in this area span a broad \\nspectrum, from basic image manipulation techniques such as \\nkernel filters, random erasing, geometric transformation, and \\ncolor space transformation to more advanced deep learning \\napproaches.\\nAmong these advanced techniques, adversarial training \\nstands out. This collection of methods trains neural networks to \\nidentify intentionally misleading data or behaviors. Another \\n fascinating technique is neural style transfer, which allows the \\ntransformation of an image’s style to mimic, say, the distinctive \\nbrushstrokes of Van Gogh. Then there’s GAN data augmenta-\\ntion, a concept proposed by NVIDIA in September 2018.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='204 GENERATIVE AI\\nBut the innovation doesn’t stop there. We also have meta-\\nlearning techniques like neural augmentation and smart aug -\\nmentation. These methods are part of a continually evolving \\nspectrum of techniques that the field of research offers.\\nHowever, it’s essential to remember that data augmentation \\nisn’t limited to images. Virtually all data types can be augmented. \\nT o illustrate this, let’s examine two cutting-edge data augmenta-\\ntion techniques— one for images, representing parallel data gen-\\neration, and one for text, representing sequential data generation.\\nThe most advanced image data augmentation technique  \\ncurrently available involves diffusion models, as outlined in the \\npaper “Effective Data Augmentation With Diffusion Models.” 1 \\nThis technique employs image-to-image transformations per -\\nformed by pre-trained text-to-image diffusion models. The \\nmethod edits images to change their semantics using an off-the-\\nshelf diffusion model and can generalize to novel visual concepts \\nfrom a few labeled examples. The results are impressive.\\nData Augmentation-Fusion (DA-Fusion) has made significant \\nstrides in image classification, improving performance by up to 10 per-\\ncent over standard methods. Figure\\xa03.18 conceptually shows the \\nDA-Fusion process using one seed image to produce four guided \\nvariations of the original. The “stacking” feature of DA-Fusion \\nhas further boosted overall performance by 51 percent. Addition-\\nally, DA-Fusion has shown versatility, outperforming previous \\nmethods across different image masks. Impressively, it maintains \\neffectiveness across various mixtures of real and synthetic images.\\nWhen it comes to text data augmentation, tools like Chat-\\nGPT have made the process simpler. Y ou can ask ChatGPT to \\nrewrite a certain text multiple times, even explicitly requesting \\ntext diversity to cover a full spectrum. In fact, if you have a data-\\nset in table form or whatever, ChatGPT can, in 99 percent of \\ncases, effectively synthesize more data for you.\\n1Brandon T rabucco et\\xa0al. “Effective Data Augmentation With Diffusion Models,” arXiv, May 22, 2023, https://\\narxiv.org/pdf/2302.07944.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 205\\nIf you have full control over a language model and are ready \\nto generate as much data as you want, with only computing costs \\nas a limiting factor, a structured approach like AugGPT may be \\nmore beneficial. See its framework in Figure\\xa03.19.\\nIt is beneficial to use because:\\n• AugGPT achieves the highest accuracy among different \\ndata augmentation methods for Amazon, Symptoms, and \\nPubMed20K datasets.\\n• AugGPT generates high-quality augmented samples with \\nhigh similarity to real input data and better learnability.\\n• While ChatGPT performs better on easier tasks, it requires \\nfine-tuning for complex tasks like PubMed to achieve better \\nperformance compared to few-shot prompts.\\nFIGURE\\xa0 3.18 Real images are augmented using a publicly available \\noff-the-shelf Stable Diffusion checkpoint to generate synthetic data \\nfor training classifiers.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='206 GENERATIVE AI\\nChatGPT Joint pain Cough Acne\\nThe speaker is experiencing pain in their elbow joint.\\nI have pain in the elbow joint The speaker reports pain in their elbow joint.\\nThe speaker has noticed pain in their elbow joint.\\nThe speaker has a /f_luid sensation in their throat when they cough. \\nThe speaker feels like something is coming up when they cough.\\nThe speaker coughs and feels like /f_luid is trying to escape.\\nThe speaker’s son’s skin is affected by a large number of acne pimples.\\nThe speaker describes their son’s skin as having a lot of acne.\\nThe speaker’s son is struggling with a lot of acne on his skin.\\nI feel /f_luid when I cough. \\nMy son has a lot of acne.\\nSentence Classi/f_ication\\nBy BERT\\nSentence Augmentation\\nBy ChatGPT\\nnovel samples augmentation samples\\nData Augmentation With ChatGPT Samples\\nBERT Classi/f_ier\\n(a)\\n(b)\\nJoint pain\\nAcne\\nCough\\nFIGURE\\xa03.19 AugGPT’s structure involves: (a) using ChatGPT for data augmentation to create class-consistent \\nsamples, and (b) training and evaluating a BERT-based classifier on these augmented and few-shot samples.\\nSource: https://arxiv.org/pdf/2302.13007.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 207\\nWhile AugGPT and DA-Fusion are techniques subject to \\nfurther revisions in this rapidly evolving research field, I’m con-\\nfident that their foundational concepts will endure for a consid-\\nerable period.\\nForefront Companies in\\xa0Data Augmentation Synthesis AI, \\na startup, has developed a cloud-based platform that generates \\nsynthetic image data with labels, using AI, procedural genera-\\ntion, and cinematic visual effects–rendering systems. This plat-\\nform can deliver millions of perfectly labeled images and videos.\\nSynthesis AI’s unique approach involves a proprietary library \\nof over 100,000 digital humans. These digital humans serve as \\nthe foundational data for data generation, with data sampled by \\n“photographing” these digital entities. The company’s product \\nsuite includes Synthesis Humans and Synthesis Scenarios, which \\ngenerate detailed images and videos of digital humans and craft \\ncomplex multi-human simulations, respectively.\\nSynthesis AI’s innovation has attracted significant invest-\\nment, raising $17\\xa0million in a Series A funding round. The com-\\npany’s CEO, Yashar\\xa0Behzadi, has highlighted the advantages of \\ntheir approach, emphasizing the speed, cost-effectiveness, and \\nhigh-quality asset generation capabilities of their text-to-3D \\nofferings.\\nOn the other side of the globe, Mostly AI, an Austrian com-\\npany, is making significant strides in the realm of synthetic data. \\nWith a keen focus on data privacy, especially in light of the strin-\\ngent General Data Protection Regulation (GDPR), Mostly AI’s \\ntechnology is particularly beneficial in sectors where data pri-\\nvacy is paramount, such as healthcare and financial services.\\nMostly AI recently secured $25\\xa0million in funding to further \\ncommercialize synthetic data in Europe and the United States.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='208 GENERATIVE AI\\nThe company’s synthetic data platform allows anyone to gener -\\nate synthetic data safely and without coding, enabling data rebal-\\nancing, anonymization, imputation, and exploration.\\nMostly AI’s CEO, T obias Hann, anticipates a significant surge \\nin the use of synthetic data, predicting a “strong decade for syn-\\nthetic data” beyond 2022. This growth is expected to be driven \\nby the increasing demand for responsible AI, with synthetic data \\nplaying a crucial role in augmenting and debiasing datasets.\\nWhere Is Data Augmentation Going? The advent of syn-\\nthetic data is akin to a new dawn breaking over the horizon of \\ntechnological advancement. The speed at which synthetic data is \\ngenerated far outpaces that of real data. Gartner, a leading \\nresearch and advisory company, forecasts that synthetic data will \\neclipse real data within the next three to five years (Figure\\xa03.20).\\nBy 2030, Synthetic Data Will Completely Overshadow Real Data in AI Models\\nData Used\\nfor AI\\nFuture AI\\nReal\\nData\\nTime\\nSynthetic\\nData\\n2020\\nSource: Gartner\\n750175_C\\n2030\\n• Artificially Generated Data\\n• Obtained from Direct\\n  Measurements\\n• Constrained by Cost, Logistics,\\n  Privacy Reasons\\n• Generated from Simple\\n   Rules, Statistical Modeling,\\n   Simulation, and Other\\n   TechniquesToday’s AI\\nFIGURE\\xa0 3.20 The dominant form of data employed in AI will shift \\ntoward synthetic data.\\nSource: Gartner, Inc.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 209\\nThe implications of synthetic data generation and data aug-\\nmentation via AI are far-reaching, with potential to revolutionize \\na multitude of sectors in the coming decade. The applications are \\nas diverse as they are profound.\\nIn the healthcare sector, synthetic data is already making \\nwaves. It is used to generate medical images for training AI  \\nmodels, aiding in the diagnosis of diseases. It also creates virtual \\npatient data for clinical trials, reducing the need for actual patients  \\nand ensuring privacy.\\nThe potential of synthetic data extends to the realm of auton-\\nomous vehicles, where it is used to generate various driving sce-\\nnarios for training purposes. In cybersecurity, synthetic data \\nsimulates cyberattacks, training AI models to detect and prevent \\nthese attacks. Even in climate modeling, synthetic data simulates \\nvarious climate scenarios, enabling AI models to predict climate  \\nchange.\\nBut the potential of synthetic data doesn’t stop there. It is \\nalso a powerful tool for urban planning. In smart cities, synthetic \\ndata can simulate traffic patterns, pedestrian movements, and \\npublic transportation usage. This data can be used to optimize \\ncity infrastructure and reduce congestion, leading to more effi-\\ncient and livable urban environments.\\nIn the field of precision agriculture, synthetic data merges \\nenvironmental science, agriculture, and AI. It simulates various \\ncrop growth scenarios under different weather conditions  \\nand soil types, helping farmers optimize crop yields and reduce  \\nwaste.\\nIn disaster management, synthetic data combines meteorol-\\nogy, geography, and emergency response to simulate disaster \\nscenarios. This aids in planning effective evacuation routes  \\nand emergency response strategies, potentially saving count-\\nless lives.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='210 GENERATIVE AI\\nThe Untapped Potential of Generative AI\\nThis section explores the immediate, untapped potential of gen-\\nerative AI. We have previously covered its vast applications in \\nvoice and speech generation, code, text, music, video, 3D objects, \\ngenerative design, and scientific problem-solving, but there is so \\nmuch more to explore.\\nIn law, it powers specialized chatbots for legal commentary \\nand patent creation. The gaming industry utilizes it for more \\nimmersive experiences, while educational institutions like the \\nOpen University use AI to improve teaching and engagement. In \\nhealthcare, AI simplifies complex medical texts for wider acces-\\nsibility. Business-to-business sectors benefit from AI for stream-\\nlined processes and enhanced productivity, with AI-powered \\npersonal assistants offering personalized services.\\nMIT researchers have developed an AI that predicts antibi-\\notic effectiveness against bacteria, potentially revolutionizing \\nantibiotic development and bacterial infection treatment. They \\nalso created MathAI, an AI capable of solving complex mathe-\\nmatical problems at a university level. Google’s Starline project, \\nusing high-resolution cameras and depth sensors, creates realis-\\ntic 3D models for video calls, offering an unprecedented sense of \\npresence. These developments highlight the immense, ongoing \\ninnovation in generative AI.\\nA Good Time to\\xa0Build Products and Companies\\nIndeed, the current landscape is ripe for the inception of new \\nproducts and companies centered around generative AI. The \\nbarrier to entry has never been lower, with the technical knowl-\\nedge required to launch a startup significantly reduced. The \\npotential for quick wins is immense, particularly in the realm of \\nknowledge management.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 211\\nConsider the possibilities: querying a vast corpus of knowl-\\nedge, such as documentation, regulations, and legal texts;  \\nstreamlining operations by automating tasks or making them \\nconversational. These applications could revolutionize processes \\nwithin companies and government bureaucracies alike. There’s \\nalso the potential to accelerate innovation, with a host of prod-\\nucts being developed to facilitate this. These applications, which \\nI refer to as “application layer 1,” offer broad, impactful solutions.\\nBeyond this, there’s a second application layer that’s more \\nniche and specific. This is where subject matter experts can lev-\\nerage their specialized knowledge to develop unique products. \\nWhile I may not be an expert in these fields, I can certainly brain-\\nstorm potential starting points:\\n• In biology, predictive diagnosis could revolutionize health-\\ncare, enabling early intervention and improved patient out-\\ncomes. In chemistry, synthesis planning, chemical property \\nprediction, and chemistry education could all benefit from \\nthe application of generative AI.\\n• Mathematics could see enhancements in education and the-\\noretical research— MathAI from MIT , for example— while \\nsupply chain management could be optimized through \\ninventory forecasting and vendor selection. In the realm of \\nphysics, quantum computing, astrophysics, and particle \\nphysics all present exciting opportunities for AI integration.\\n• Economics could be transformed through the development \\nof advanced forecasting models, policy analysis tools, and \\ninvestment strategies. In psychology, behavior prediction \\nand psychological research design could be revolutionized.\\n• Environmental science also presents a wealth of opportuni-\\nties, from climate modeling to biodiversity studies and con-\\nservation strategies. Each of these fields stands on the brink'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='212 GENERATIVE AI\\nof transformation, ready to harness the untapped power of \\ngenerative AI.\\nCertainly, the landscape of generative AI is teeming with \\nopportunities for product development and innovative ideas. \\nWhether it’s in cloud services, hubs, or other platforms, the \\npotential is vast. However, to truly tap into these opportunities, \\nyou need specialized knowledge in areas such as building AI \\nmodels, language processing, image processing, and more. If you \\ndon’t currently possess this expertise, don’t worry— it can be \\nacquired more easily than ever.\\nThe concept of building foundation models is an exciting \\npath for exploration. This strategy, adopted by organizations like \\nOpenAI, Meta, and Anthropics, involves the development of \\nbroad, multipurpose models that serve as the foundation for \\nmore specialized applications. On the other hand, there’s also the \\npotential to create niche models that excel in specific domains, \\noffering tailored solutions for unique needs.\\nThe development of cloud platforms, akin to Azure or \\nGoogle Cloud Platform (GCP), is another promising area in the \\nAI landscape. These platforms simplify the deployment, scaling, \\nand management of AI models, making AI accessible to a wider \\naudience and fostering its integration across various industries.\\nThere’s also the potential to contribute to the AI ecosystem \\nby providing robust computing hardware like GPUs or TPUs. \\nThese powerful processing units are instrumental in training and \\nexecuting AI models, and advancements in this area could signifi-\\ncantly enhance the speed and efficiency of AI operations.\\nMoreover, there is an opportunity to develop specific librar-\\nies of functions that cater to unmet needs within the AI commu-\\nnity. For instance, the development of a library such as LangChain \\ncould address gaps in the existing suite of tools available for'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 213\\nAI development and deployment. LangChain is a framework \\ndesigned to simplify the creation of applications using LLMs. \\nSuch efforts would not only enhance the capabilities of existing \\nAI systems but also accelerate the pace of innovation in the field.\\nFinding the\\xa0Untapped— A Systematic Approach to\\xa0Success\\nHarnessing the untapped potential of generative AI is akin to \\nnavigating an uncharted territory. The landscape is vast, teeming \\nwith possibilities, yet the path to success is often obscured by the \\nsheer volume of information and ideas. The key to unlocking \\nthis potential lies not in the abundance of ideas, but in the ability \\nto distinguish the truly innovative from the merely interesting.\\nThe conviction that there are more untapped ideas than \\nthose that have been realized is not unfounded. A cursory glance \\nat the plethora of scientific papers, research articles, surveys, and \\nblogs reveals a veritable treasure trove of ideas. Every week, \\nthousands of concepts are birthed in these intellectual crucibles, \\neach one a potential seed for the next big breakthrough in gen-\\nerative AI.\\nHowever, as any seasoned innovator will tell you, ideas are \\nthe easy part. Execution is where the rubber meets the road. It’s \\nthe 99 percent perspiration that transforms the 1 percent inspi-\\nration into something tangible. Moreover, not all ideas are cre-\\nated equal. They need to be validated and tested against the harsh \\nrealities of practicality and feasibility.\\nThis is where careful resource filtering becomes crucial. For \\ninstance, research papers are often the breeding grounds for  \\ncutting-edge tech ideas, particularly in the realm of generative \\nAI. The ability to sift through these forefront papers, translate \\ncomplex jargon into understandable language, and transform \\nthese ideas into products can provide a significant advantage.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='214 GENERATIVE AI\\nT o guide you through this process, I propose a methodology \\nthat has proven effective in the past and that could serve as a \\nstarting point for your journey. Let’s assume you’re looking to \\nlaunch a startup or a project. This methodology is versatile and \\ncan be adapted to various professional areas.\\nThe process, as illustrated in Figure\\xa0 3.21, is simplified \\nfor clarity.\\nIdea Execute idea, build quick pol\\nTalk to potential clients and showcase it\\nNo\\nNo\\nYes\\nYes Scale!\\nExtract and understand client’s needs\\nfrom conversations\\nEnd user expectations\\ncan be met?\\nIterate your code /uni21D2\\n Customize the code\\n  to serve key common client needs\\n[x5 - 100]\\nPredefined critical\\nrevenue reached?\\nOur signal for success.\\nasset!\\nValidation: • Solve part of the\\n  client’s problem?\\n • Charge for\\n  problem solving? (1 client)\\nFIGURE\\xa0 3.21 How to come up with your generative AI idea in this \\ndynamic AI market.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 215\\nThe first step in this journey is to immerse yourself in trusted \\nsources of information. I strongly recommend research papers \\navailable on databases like arxiv.org and publisher-driven plat-\\nforms such as Wiley. Choose one or two that resonate with you \\nafter conducting preliminary research.\\nWhile your focus is on AI, it’s beneficial to cast a wider net. \\nConsider filtering for papers in related domains such as physics, \\nchemistry, mathematics, and psychology. This broad perspective \\ncan provide insights into market trends and hot topics in \\nthese fields.\\nFor the next three to six\\xa0weeks, observe these research data-\\nbases and their respective topics. Useful tools for this task are the \\nChatGPT plug-ins. Each day, select the top five papers you wish \\nto understand and paste their links into ChatGPT . Ask the \\nrespective plug-ins to summarize these papers in bullet points, \\nincluding headers. This method allows you to grasp the essence \\nof each paper in about seven minutes.\\nFor instance, just today’s research is rich with ideas, poten-\\ntially meeting the criteria. “DUCHO: A Unified Framework for \\nthe Extraction of Multimodal Features in Recommendation” 2 \\nproposes an approach to improve recommendations by includ-\\ning effectively multiple modes.\\nAnother paper, “Synthetic Demographic Data Generation \\nfor Card Fraud Detection Using GANs,” 3 might not pass the \\nthreshold. While it focuses on demographic data, which seems \\nquite limited, there could be potential to use this idea in other \\nareas of data generation. This is something that would need fur-\\nther investigation.\\n2Daniele Malitesta et\\xa0 al. “DUCHO: A Unified Framework for the Extraction of Multimodal Features in  \\nRecommendation,” arXiv, September 6, 2023, https://arxiv.org/pdf/2306.17125.pdf\\n3Shuo Wang et\\xa0al. “Synthetic Demographic Data Generation for Card Fraud Detection Using GANs,” arXiv, \\nJune 29, 2023, https://arxiv.org/pdf/2306.17109.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='216 GENERATIVE AI\\nLastly, I found a paper titled “Spiking Denoising Diffusion \\nProbabilistic Models”4 particularly intriguing. This paper com-\\nbines spiking neural networks with diffusion models. The key \\nquestions here are: What benefits does this combination offer? \\nWhat are the drawbacks? And most importantly, what new func-\\ntionalities does it introduce that could potentially transform \\nother areas? Often, even the authors themselves may not fully \\ngrasp the implications of their work.\\nAfter this initial review, choose one paper for a deeper dive. \\nRead it thoroughly, examine the visual results, and absorb its \\ncontent. After some training, this process should take no more \\nthan 30\\xa0minutes per day.\\nIt’s crucial to research papers over an extended period to \\navoid the trap of latching onto the first good idea that comes \\nalong. Comparing ideas against each other is an important part \\nof the process. However, it’s equally important to set a time frame \\nfor when you want to start your project.\\nOnce you’ve gathered a wealth of ideas, it’s time to select a \\ngreat one. Not the perfect one, as perfection is elusive, but a \\ngreat one. Shortlist the top five to seven ideas and compare them \\nqualitatively based on the following criteria: technical feasibility, \\npotential impact for end users, innovation and uniqueness, scal-\\nability and adaptability, ethical and legal considerations, resource \\nrequirements, and market potential.\\nOnce you’ve selected an idea, create a quick proof of concept \\n(PoC). Utilize existing GitHub repos or other code sources like \\npaperswithcode.com or from the research scientists themselves. \\nIf you’re not a coder, consider hiring one from platforms like \\nFiverr, but be aware of potential issues like confidentiality and \\nskill gaps.\\n4Jiahang Cao et\\xa0al. “Spiking Denoising Diffusion Probabilistic Models,” arXiv, October 30, 2023, https://arxiv \\n.org/pdf/2306.17046.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 217\\nWith your PoC in hand, it’s time to get feedback. Contact \\npotential users, ranging from a minimum of 5 to a maximum of \\n100, and showcase your idea. From these conversations, you’ll \\ngain valuable insights into user needs and preferences.\\nFinally, answer the following questions to decide how to pro-\\nceed: Are users satisfied with the idea? Does the idea provide \\nsignificant value to users? Is there sufficient market demand for \\nthe idea? Does the idea have a competitive advantage? Can the \\nidea scale and grow effectively? Are there viable ways to mone-\\ntize the idea? Do the resources required for this idea align with \\nyour capabilities? Does the idea align with your long-term goals \\nand vision?\\nBased on these answers, decide whether to continue with the \\nidea and invest more resources into it, pivot the idea significantly, \\nor find a completely new idea. This is a critical juncture in your \\njourney, a moment of existential decision making that will shape \\nthe course of your project.\\nCongratulations on successfully validating your idea! Y ou’ve \\nnavigated the initial stages of the process, and now it’s time to \\nshift focus to building a great product.\\nFrom your user research, you’ve gathered insights into what \\nthe client needs and expects from the product. The next step is to \\nprioritize your actions based on two factors: the impact on the \\nuser and the effort required. This will help you identify the low-\\nhanging fruits. A word of advice here: Aim to serve the needs of \\nthe majority (80 percent) of your users, rather than catering to \\nindividual requirements.\\nIn the early stages, it’s beneficial if you can code the product \\nyourself. With tools like ChatGPT , GitHub Copilot, and various \\nonline training resources, this task is not insurmountable. Alter-\\nnatively, you could outsource the coding to another individual.\\nOnce you’ve made progress on the product, it’s time for \\nanother round of validation. Conduct another set of interviews'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='218 GENERATIVE AI\\nto confirm that you’re addressing critical parts of the client’s \\nproblem. The second step in this validation phase is to determine \\nif your future customers are willing to pay for your product. The \\nlarger the group willing to pay, the better. However, even if only \\none person (who isn’t a friend or family member trying to please \\nyou) is willing to pay, it’s a positive signal.\\nThe final question to ask yourself is whether you’ve reached \\na threshold that signals long-term success for your idea. This \\nthreshold should be a set of predefined parameters, such as rev-\\nenue or other individual metrics (it doesn’t necessarily have to \\nbe revenue).\\nIf you haven’t reached this critical threshold, it’s time to cir-\\ncle back and iterate on the code and product. If you have, it’s time \\nto scale. This could mean seeking investors, expanding your \\nteam, and professionalizing your approach to product develop-\\nment. Having a validated product gives you a strong argument \\nfor potential investors. However, if you decide to bootstrap, \\nyou’re still in a good position.\\nI hope this provides a clear roadmap for your journey ahead. \\nWhether you’re launching a startup or developing a product \\nwithin an existing company, these steps should prove quite  \\nhelpful. Remember, every journey begins with a single step, and \\nyou’ve already taken several. Keep moving forward, and I am \\nsure success will follow.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='219\\nT\\nhe previous chapters touched on the sudden emergence of \\ngenerative AI, a phenomenon that seemed to materialize out \\nof thin air. However, the reality is far from it. Much like a gour-\\nmet dish simmering away in the back of a bustling kitchen, gen-\\nerative AI was quietly brewing, its flavors intensifying, until it \\nwas finally ready to be served. The first taste came in the summer \\nof 2022\\xa0with OpenAI’s DALL-E, followed closely by the unveil-\\ning of ChatGPT\\xa0toward the end of the same year.\\nThe explosion of generative AI was the result of a carefully \\ncurated recipe. The ingredients? A blend of technological \\nadvancements and convergences that, when combined, propelled \\nAI to unprecedented heights. This chapter peels back the layers \\nand explores the underlying factors that played a pivotal role in \\nthe rise of generative AI.\\n4\\nCHAPTER\\nGenerative AI’s Exponential \\nGrowth'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='220 GENERATIVE AI\\nFirst on our list is the exponential increase in computing \\npower, often encapsulated by Moore’s law. This principle, which \\nposits that the number of transistors on a microchip doubles \\napproximately every two years, has been a driving force behind \\nour ability to perform increasingly complex computations at \\nbreakneck speeds. This, in turn, has been instrumental in train-\\ning large-scale AI models, the backbone of generative AI.\\nNext, we have the advent of cloud computing. This technol-\\nogy has revolutionized the way we access and utilize high- \\npowered computing resources, making them more affordable \\nand readily available. The democratization of AI that cloud com-\\nputing has facilitated means that even small startups can now \\ndevelop sophisticated AI systems, a feat that was once the exclu-\\nsive domain of tech giants.\\nThen there’s the development of hardware accelerators, such \\nas graphics processing units (GPUs) and T ensor Processing \\nUnits (TPUs). These devices have significantly accelerated AI \\ncomputations, particularly in the realm of deep learning. By pro-\\ncessing multiple computations simultaneously, these accelerators \\nhave made it possible to train larger and more complex AI mod-\\nels in a fraction of the time.\\nFurther, we can’t overlook the role of cheaper storage. Over \\nthe years, the cost of data storage has plummeted, making it fea-\\nsible to store and process the vast amounts of data needed for AI. \\nThis has been a game changer, as AI systems are notoriously \\ndata-hungry, requiring copious amounts of information to learn \\nand improve.\\nThe availability of Big Data is another crucial ingredient in \\nthe generative AI recipe. With the widespread use of the Internet \\nand digital technologies, we’re generating colossal amounts of \\ndata every second. This data serves as the lifeblood of AI systems, \\nproviding the rich, varied information they need to learn, adapt, \\nand improve.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 221\\nThe research of new algorithms and the refinement of exist-\\ning ones have enabled AI to glean insights from data more effec-\\ntively and efficiently. Deep learning, the subfield of machine \\nlearning that mimics the neural networks of the human brain, \\nhas been a game changer, powering many of the recent break-\\nthroughs in AI.\\nInvestment in AI research from both private entities and \\ngovernments has also played a pivotal role. Recognizing the \\ntransformative potential of AI, these stakeholders have poured \\nsubstantial resources into research and development. This influx \\nof funding has not only led to numerous breakthroughs but has \\nalso attracted some of the brightest minds to the field, further \\nfueling innovation.\\nThe open source culture prevalent in the AI community is \\nanother factor worth noting. Many AI advancements are shared \\nopenly, fostering a global community of researchers and devel-\\nopers who build upon each other’s work. This spirit of collabora-\\ntion has significantly accelerated the pace of AI development, \\nallowing for rapid iteration and improvement.\\nThe successful real-world applications of AI have also driven \\ninterest and investment in the field. From image recognition and \\nnatural language processing to autonomous vehicles and beyond, \\nAI has proven its worth in a myriad of contexts. These success \\nstories serve as powerful proof of concept, demonstrating the \\ntransformative potential of AI.\\nLastly, the undeniable business value of AI, and more \\nrecently generative AI, cannot be overlooked. For years, AI has \\nbeen delivering tangible business benefits, and with the advent \\nof generative AI the scope for value creation has expanded even \\nfurther. As we continue to explore and use these technologies, \\nthere’s no doubt that we’re only scratching the surface of \\nwhat’s possible.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='222 GENERATIVE AI\\nThe Growth Pattern of\\xa0New Technologies— \\nThe S-Curve\\nThe factors discussed so far are not only influencing the growth \\nof technology and AI but are also shaping the trajectory of inno-\\nvation itself. One way to capture this dynamic evolution is \\nthrough the concept of the S-curve, a common pattern observed \\nin the growth of new technologies (Figure\\xa04.1).\\nT echnologies often have humble beginnings, emerging from \\nthe hallowed halls of university labs or the innovative hubs of \\ncorporate research departments. In these early stages, the tech-\\nnology might seem insignificant or even ineffective. It’s a period \\nof trial and error, of fine-tuning and tweaking, where the poten-\\ntial of the technology is yet to be fully realized.\\nHowever, there comes a tipping point where the technology \\nstarts to work effectively, triggering a phase of accelerated growth. \\nThis is the steep upward curve of the S, a period characterized by \\nMature phase\\nHyper growth phase\\nGrowth phase\\nGrowth\\nEarly phase\\nTime\\nWhy does growth stall?\\nChurn > new member acquisition\\nIncreased competition\\nRapid technological development\\nChanging consumer preferences (i.e.,\\nCOVID-19)\\nExpiration of IP\\nRegulation\\nDistraction/lack of internal focus\\nAll businesses naturally hit a growth S-curve\\nover time and reach the mature phase; some\\nreach it faster than others.\\nSaturation of marketing channels (i.e.,\\nFacebook)\\nFIGURE\\xa04.1 The life cycle of innovation: the S-curve.\\nSource: https://medium.com/parsa-vc/jumping-s-curves-building-a-high-performance- \\nstartup-80e4410466a5'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 223\\na flurry of activity, excitement, and rapid adoption. It’s during this \\nphase that the technology makes the leap from the lab to the real \\nworld, transforming industries and impacting lives.\\nBut like all things, this period of frenzied growth doesn’t last \\nforever. Eventually, the pace of growth starts to slow down. Every \\nnew incremental improvement becomes less perceptible to the \\nuser, and the technology begins to mature. This is the flattening \\ncurve of the S, marking the transition from a period of rapid \\ninnovation to one of consolidation and refinement.\\nAt this stage, the focus shifts. The question is no longer about \\nwhether the technology is going to work or what’s going to work. \\nInstead, the conversation centers around the implications of the \\ntechnology now that it has a large user base. It’s about under -\\nstanding the impact, managing the challenges, and harnessing \\nthe opportunities that the technology presents.\\nThis S-curve pattern is evident in the evolution of AI and, \\nmore specifically, generative AI. From its early days in research \\nlabs to its current state of widespread adoption, generative AI has \\ntraversed this curve. As we continue to explore this fascinating \\nfield, we’ll delve deeper into the implications of this growth tra-\\njectory and what it means for the future of AI.\\nThe S-curve pattern is not unique to AI. In fact, it’s a com-\\nmon phenomenon in the evolution of many groundbreaking \\ntechnologies. Let’s consider a few examples.\\nThe development of the PC is a classic case. In the early \\nstages, PCs were bulky, expensive, and not particularly user-\\nfriendly. However, as the technology improved, PCs became \\nmore accessible and affordable, leading to a period of rapid \\ngrowth and widespread adoption. Eventually the market matured, \\nand the pace of growth slowed as incremental  improvements \\nbecame less noticeable to the average user.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='224 GENERATIVE AI\\nA similar pattern can be observed in the evolution of the \\nInternet. Initially, the Internet was a novelty, a tool used primar-\\nily by academics and researchers. But as it became more user-\\nfriendly and accessible, its growth skyrocketed. T oday, the \\nInternet is a ubiquitous part of our lives, and while it continues \\nto evolve, the pace of growth has inevitably slowed.\\nThe trajectory of the adoption of mobile phones also follows \\nthe S-curve. From the hefty, expensive mobile phones of the \\nearly days to the sleek, multifunctional smartphones of today, the \\ngrowth of mobile technology has been nothing short of phe-\\nnomenal. But again, as the technology matured, the pace of \\ngrowth has slowed.\\nWhat’s interesting about these S-curves is that they often \\noverlap. Just as one S-curve is maturing and slowing down, \\nanother one often starts up. This is precisely what we’re witness-\\ning with generative AI. As technologies like the Internet and \\nmobile phones mature, generative AI is just beginning its upward \\ntrajectory on the S-curve. Figure\\xa04.2 shows overlapping S-curves, \\nillustrating technological advancement in the form of succes-\\nsively implemented innovations.\\nThird industry-leading business\\nSecond industry-leading business\\nFirst industry-leading business\\nPath of high performers\\nGrowth\\nTime\\nFIGURE\\xa04.2 The evolution of innovation: successive waves of techno-\\nlogical advancements represented by multiple following S-curves.\\nSource: https://medium.com/parsa-vc/jumping-s-curves-building-a-high-performance- \\nstartup-80e4410466a5'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 225\\nThis cycle of innovation and growth tends to operate on a \\ntimescale of 5, 10, or even 20 years. It’s a continuous process of \\nevolution and revolution, where each new technology builds on \\nthe foundations laid by its predecessors.\\nIndeed, the S-curves for innovation are becoming increas-\\ningly compressed. Several factors are contributing to this trend, \\ncreating a fast-paced cycle of technological evolution and \\nrevolution.\\nFirst, the rapid pace of technological advancements is a key \\ndriver. The improvements in computing power, data availability, \\nand affordability, coupled with the relentless efforts in research \\nand development, are accelerating the pace of innovation. These \\nfactors are effectively shortening the S-curves, enabling technolo-\\ngies to move from the lab to the market at an unprecedented speed.\\nAnother factor is the heightened level of competition in \\ntoday’s global business landscape. In this high-stakes environ-\\nment, companies are under constant pressure to stay ahead of the \\ncurve. This drive to innovate and differentiate fuels shorter inno-\\nvation cycles, as businesses strive to introduce new products and \\nservices that can give them a competitive edge.\\nThe culture of knowledge sharing, facilitated by the wide-\\nspread availability of information and collaborative platforms, is \\nalso contributing to shorter S-curves. The open sourcing of \\ntechnologies and algorithms allows innovators to build upon \\nexisting knowledge, iterate more quickly, and bring their ideas to \\nfruition faster. This collaborative approach is not only accelerat-\\ning the pace of innovation but also fostering a more inclusive and \\ndiverse tech ecosystem.\\nMarket demand is another crucial factor. With rapid shifts in \\nconsumer preferences and the emergence of a global customer \\nmarket, companies are required to respond swiftly with innova-\\ntive solutions. This demand-driven approach is pushing for \\nshorter innovation cycles, as businesses strive to meet the evolv-\\ning needs of their customers.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='226 GENERATIVE AI\\nAs a result of these factors, we can expect to see much shorter \\nproduct development cycles and the emergence of new technol-\\nogies at a faster pace. As we witness the simultaneous evolution \\nand revolution of various technology fields, it’s clear that we’re in \\nthe midst of an exciting era of accelerated innovation. The advent \\nof generative AI is a testament to this trend, marking the begin-\\nning of a new S-curve that promises to reshape our world in ways \\nwe’re only beginning to imagine.\\nTechnological Convergence\\nThe rise of generative AI is being significantly propelled by its \\nconvergence with other fields— a phenomenon known as techno-\\nlogical convergence.\\nT echnological convergence refers to the trend where distinct \\ntechnological systems evolve toward performing similar tasks. \\nThis is achieved by integrating multiple functionalities into a \\nsingle device or system, leading to more efficient and stream-\\nlined user experiences. T echnological convergence is often direc-\\ntional, with one field exerting a greater influence on others.\\nIn this context, AI stands out as a crucial catalyst. Its rapid \\nadvancement is cascading through numerous other technologies, \\ncreating a ripple effect that’s driving demand for further innova-\\ntion and refinement. The velocity of AI’s development is not just \\nreshaping its own field but also accelerating the evolution of \\nother technologies.\\nT ake, for example, the impact of neural networks— both gen-\\nerative and discriminative— on various sectors. They’re driving \\nadvancements in adaptive robotics, enabling robots to learn from \\ntheir environment and adapt their behavior accordingly. In the \\nrealm of autonomous mobility, neural networks are at the heart \\nof self-driving vehicles, facilitating real-time decision making \\nand navigation.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 227\\nAnother example is the intersection of AI and genomics. \\nGoogle, for instance, has leveraged AI algorithms to significantly \\nenhance the accuracy of long-read DNA sequencing. By employ-\\ning neural networks, they managed to reduce DNA sequencing \\nerror rates by 59 percent. This breakthrough not only improved \\nthe quality-adjusted yields but also brought down the costs asso-\\nciated with long-read genome sequencing. In 2023, PacBio, a \\nleading provider of high-quality sequencing solutions, integrated \\nAI-specific compute hardware into its long-read sequencer. This \\nmove was touted as the first high-quality, whole long-read \\ngenome for less than $1,000.\\nIn the realm of robotics, advances in large language models \\n(LLMs) have enabled robots to learn from experience and acquire \\nnew skills at an accelerated pace. The adoption of the T ransformer \\narchitecture from AI has empowered robots to generalize from \\nexamples and perform tasks they’ve never encountered before— a \\ncapability known as zero-shot learning. This has led to a dramatic \\nimprovement in their learning efficiency, with the success rate \\njumping from 19 percent in 2021 to 76 percent in 2022.\\nConversely, AI is also being propelled by advancements in \\nother fields. For instance, the progress in battery technology has \\nhad a significant impact on AI. As battery capacity and energy \\ndensity have increased substantially over the years— often by \\ndouble-digit percentages— this has enabled the development of \\nmore advanced, mobile, and autonomous devices. These devices, \\nranging from robots to cars, increasingly rely on AI for \\ntheir autonomy.\\nAs we continue to explore this chain of thought, the land-\\nscape of possibilities expands, becoming less predictable yet more \\nintriguing. Economists estimate that the global GDP could see a \\nstaggering increase of anywhere from 60 percent to 470 percent \\nby the year 2040, largely driven by the disruptive technologies \\nwe see today.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='228 GENERATIVE AI\\nThis creates the potential for super-exponential growth, pro-\\nvided certain conditions are met— a topic we’ll delve into later in \\nthis chapter. The convergence of AI with these technologies is \\npaving the way for the creation of more intelligent, autonomous, \\nand personalized systems. However, this evolution is not without \\nits challenges. Issues surrounding data privacy and security, as \\nwell as the ethical use of AI, are significant hurdles that need to \\nbe addressed.\\nExponential Progress in\\xa0Computing\\nThe bedrock of AI’s meteoric rise lies in the realm of computa-\\ntion. T o truly grasp the magnitude of this evolution, we must first \\nunderstand the insatiable hunger of advanced AI models for \\ncomputing power. T raining these behemoths, with their vast seas \\nof data and their intricate web of billions of trainable parameters, \\ndemands an astronomical amount of computational muscle. This \\ncomputational appetite is quantified in FLOPs, or floating-point \\noperations per second. In layperson’s terms, FLOPs provides a \\nmeasure of how many floating-point calculations a machine can \\nchurn out within a mere second.\\nThe art and science of AI computation lie in a delicate bal-\\nance. On one hand, we have the increase of hardware’s comput-\\ning power— FLOPs. On the other, there’s software optimization, \\nwhere the goal is to trim down the FLOPs required. This dual \\napproach is the linchpin in the optimization of AI systems.\\nT racing the trajectory of computational power, we can’t help \\nbut acknowledge the prescient observation of Gordon Moore in \\n1965. Dubbed Moore’s law, it postulated that the number of tran-\\nsistors packed into a microchip would roughly double every two \\nyears. This prediction, which seemed audacious at the time, has \\nlargely held true, steering us into an era of exponential growth in \\ncomputing prowess. T o put this into perspective, consider the \\niPhone 14 Pro’s chip, a chip for a device that fits in the palm of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 229\\nyour hand, released in 2022, boasting a staggering 16 billion tran-\\nsistors. Contrast this with one of the first chips used in personal \\ncomputers of the 1970s, such as the Amstrad PC 1512 or the Intel \\n8086 (1978), which had 29,000 transistors. This represents an \\nincrease of more than half a million times at the chip level.\\nThe relentless march of transistor count has been not only \\nabout sheer numbers but also about the profound implications of \\nthese numbers. The miniaturization of transistors has ushered in \\nan era of compact yet formidable devices. T ake, for instance, the \\nApollo guidance computer of 1969, a marvel of its time, which \\nboasted a computational might of around 15,000 FLOPs. Fast-\\nforward to 2005/2006, and we find the Xbox 360 flexing a stag-\\ngering 240 GFLOPS— a leap that’s 16\\xa0million times the power \\nof its predecessor. This juxtaposition paints a vivid picture of \\nhow far we’ve come in just a few decades. See Figure\\xa04.3 for a \\nlogarithmic scale representation of the law.\\nELECTROMECHANICAL SOLID-\\nSTATE\\nRELAY\\nVACUUM\\nTUBE\\nTRANSISTOR INTEGRATED CIRCUIT\\nHUMAN\\nBRAIN\\nMOUSE\\nBRAINCORE i7 QUAD\\nPENTIUM 4\\nCOMPAQ\\nDESKPRO 386\\nPENTIUM\\nIBM AT-80286\\nALTAIR 8800\\nIBM 1130\\nDEC PDP-1\\n10161016\\n1014\\n1012\\n1010\\n108\\n106\\n104\\n102\\n10–2\\n10–4\\n0\\nUNIVAC I\\nIBM PC\\nIBM 704IBM SSEC\\nCOLOSSUS\\nCALCULATIONS PER SECOND PER $1000\\nIBM\\nTABULATOR\\nSOURCE: RAY KURZWEIL, “THE SINGULARITY IS NEAR: WHEN HUMANS TRANSCEND BIOLOGY”, P.67, THE\\nVIKING PRESS, 2006. DATAPOINTS BETWEEN 2000 AND 2012 REPRESENT BCA ESTIMATES.\\n1900\\n1905\\n1910\\n1915\\n1920\\n1925\\n1930\\n1935\\n1940\\n1945\\n1950\\n1955\\n1960\\n1965\\n1970\\n1975\\n1980\\n1985\\n1990\\n1995\\n2000\\n2005\\n2010\\n2015\\n2020\\n2025\\nHOLLERITH\\nTABULATOR\\nBELL\\nCALCULATOR\\nMODEL 1\\nNATIONAL\\nELLIS 3000\\nANALYTICAL ENGINE\\nAPPLE IIDEC\\nPDP-10\\nPENTIUM III\\nPENTIUM II\\nCORE 2\\nDUO\\nOPTICAL,\\nQUANTUM,\\nDNA\\nCOMPUTING?\\n© BCA Research 2013\\nFIGURE\\xa04.3 Moore’s law in action: a logarithmic scale representation \\nof the exponential growth in transistor count per microchip over time.\\nSource: www.publish0x.com/muratkbesiroglu/futurist-ray-kurzweils-predictions-about- \\nthe-future-xqkjyyw'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='230 GENERATIVE AI\\nHowever, every ascent faces its summit, and Moore’s law is \\nno exception. The very essence of this law, the shrinking of tran-\\nsistors, is now becoming its Achilles’ heel. As we venture into the \\nrealm of nanometers, a peculiar quantum phenomenon rears its \\nhead— quantum tunneling. This phenomenon allows electrons \\nto defy classical physics, bypassing the depletion layer in a tran-\\nsistor. The result? Disrupted calculations, rendering the com-\\nputer unreliable. When you cram a chip with countless such \\nminuscule transistors, quantum tunneling becomes an insur -\\nmountable challenge, signaling the twilight of Moore’s law.\\nBut the dimming of one beacon doesn’t plunge the world of \\ncomputation into darkness. The waning of Moore’s law merely \\nheralds a paradigm shift in our quest for computational suprem-\\nacy. Quantum computing, with its promise of harnessing the \\nquirks of quantum mechanics, emerges as a tantalizing prospect.\\nMoreover, the challenges of miniaturization, such as heat \\ndissipation and manufacturing intricacies, have indeed slowed \\nthe pace set by Moore’s law. But this deceleration in hardware \\nhas been counterbalanced by leaps in other domains. Software \\noptimizations, innovative algorithms, and groundbreaking archi-\\ntectures are charting new paths. Parallel computing, which \\ndivides tasks across multiple processors, and quantum comput-\\ning, which taps into the probabilistic nature of quantum bits, are \\nredefining the boundaries of what’s possible. Additionally, the \\nadvent of specialized hardware, like GPUs and TPUs, has turbo-\\ncharged specific computational tasks, from rendering lifelike \\ngraphics to training intricate neural networks.\\nPeering into the horizon, we could posit a tantalizing hypoth-\\nesis: Moore’s law, rather than facing obsolescence, might be on \\nthe verge of an upside break. The combined might of hardware \\ninnovations, software breakthroughs, and pioneering research \\ncould propel computational advancements at a pace that even \\noutstrips Moore’s predictions. The future, it seems, holds prom-\\nise and potential in equal measure.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 231\\nExponential Hardware Evolution\\nThis section highlights key hardware-related developments, \\nfrom customized chips to quantum and neuromorphic comput-\\ning, and previews groundbreaking research potentially shaping \\nthe future of technology.\\nChips Chip design is a dynamic landscape, with innovations \\nsprouting at an unprecedented pace. Although this chapter won’t \\ndive deep into the nitty-gritty of chip design, there are pivotal \\ntrends worth highlighting.\\nThree primary trends dominate the chip design horizon: the \\ndrive toward even smaller chip designs, the rise of application-\\nspecific\\xa0integrated circuits\\xa0(ASICs), and the evolution of system-\\non-a-chip (SoC) architectures.\\nAs we tread the path of miniaturization, the distances between \\nconductors and transistors on chips have been whittled down to \\njust a few nanometers. Leading this race to the minuscule is IBM, \\nwhich has unveiled a groundbreaking achievement— the world’s \\nfirst two-nanometer chip technology. This feat is not just about \\nsize; it’s about overcoming the engineering challenges posed by \\nleakage effects as chip sizes shrink.\\nKey insights into IBM’s two-nanometer chip technology  \\ninclude:\\n• A whopping 45 percent boost in performance coupled with \\na 75 percent reduction in energy consumption when juxta-\\nposed with the prevalent 3 to 5 to 7\\xa0nm chips. This enhance-\\nment translates to a substantial 31 percent reduction in AI \\ntraining time.\\n• The potential applications are vast and transformative. \\nImagine mobile phones that last four times longer, datacent-\\ners that slash their carbon footprints, and autonomous vehi-\\ncles that react in a split second.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='232 GENERATIVE AI\\n• IBM’s pioneering “nanosheet technology” manages to pack \\nan astounding 50 billion transistors on a surface no larger \\nthan a fingerprint.\\n• These nanosheet transistors, christened gate-all-around \\ntransistors, have been under the research microscope since \\n2017. Their design ensures optimal current control while \\nstaunchly preventing leakage.\\n• The diminutive size of these transistors doesn’t compromise \\ntheir efficacy. They pave the way for devices that are faster, \\nmore dependable, and energy efficient, spurring innovations \\nin processor designs. Moreover, this technology is  \\ntailor-made to bolster AI and cloud computing tasks, all \\nwhile fortifying security and encryption at the hardware level.\\nEnter the world of ASICs, or application-specific integrated \\ncircuits. These are not your run-of-the-mill integrated circuits. \\nThey are the epitome of customization, meticulously crafted for a \\nsingular purpose or task. While general-purpose integrated cir -\\ncuits are the jacks-of-all-trades, ASICs are the masters of one. This \\nlaser-focused design ethos bestows upon them unparalleled advan-\\ntages in performance, power efficiency, and cost-effectiveness.\\nT o paint a clearer picture, consider the realm of cryptocur -\\nrency mining. ASIC miners, specialized computerized devices, \\nhave taken the crypto world by storm. Each of these machines is \\npurpose-built to mine a designated digital currency, such as Bit-\\ncoin. Their raison d’être is to crack the mining algorithm with \\nunparalleled efficiency, leaving general-purpose processors and \\ngraphics cards in the dust.\\nBut it’s not just about raw computational power. Many of the \\noptimizations I’ve witnessed lean heavily into energy conserva-\\ntion— a facet that’s gaining increasing importance in our eco-\\nconscious world. And there’s a computational boon to this energy'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 233\\nthriftiness. With reduced heat production, architectures can be \\npacked more densely, further amplifying the prowess of these \\nchips. The future of chip design, it seems, is not just about doing \\nmore, but doing more with less.\\nAnother discernible trend in the chip design landscape is the \\nemergence of more efficient chip designs, prominently mani-\\nfested in the form of SoC developments. At its core, a system-on-\\na-chip can be thought of as a specialized variant of an ASIC.\\nThe brilliance of the SoC lies in its ability to amalgamate all \\nthe components of a computer or any electronic system into one \\ncohesive unit. Imagine a single chip that houses a CPU, memory \\nmodules, timing mechanisms, peripherals, and even external \\ninterfaces. This compactness and integration makes SoCs the \\nheart of many contemporary devices, from the smartphones we \\ncan’t live without to the smart appliances that make our homes \\nmore intuitive, and even the burgeoning realm of Internet of \\nThings (IoT) devices. Their allure stems from their unparalleled \\nefficiency and diminutive size. While they can be tailored for \\nspecific tasks, enhancing both performance and power efficiency, \\nthe journey to craft them is riddled with complexities. The chal-\\nlenge? Seamlessly integrating a myriad of components onto one \\nchip. Notable exemplars in this domain include the powerhouse \\nApple’s A series chips and the versatile Qualcomm’s Snap-\\ndragon chips.\\nBut what makes SoC designs the torchbearers of the next \\nwave of computational prowess?\\nThe beauty of SoCs is their integrated design, which houses \\nall components on a single chip, significantly reducing data tran-\\nsit time between components and leading to faster data process-\\ning and enhanced system performance. Customization is central \\nto SoCs, with every aspect of the chip, from its individual com-\\nponents to their interactions, being meticulously tailored for'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='234 GENERATIVE AI\\nspecific applications, ensuring unparalleled performance. More-\\nover, SoCs excel in power efficiency; their compact design and \\noptimized components ensure minimal energy consumption, \\nwhich is especially beneficial for battery-operated devices, offer-\\ning extended battery life without sacrificing performance. In an \\nera where sleekness and portability are paramount, the compact \\nnature of SoCs allows for lightweight and space-efficient devices \\nwithout compromising on their performance.\\nT o underscore the significance of SoCs in today’s market, \\nconsider this: The SoC market, as of 2023, stands at a staggering \\n$159.85 billion. Projections indicate that by 2028, this market \\nwill balloon to an estimated $234.98 billion, with a compound \\nannual growth rate (CAGR) of 8.01 percent during the 2023–\\n2028 period, underscoring the pivotal role SoCs are set to play in \\nthe future of tech.\\nOne quickly realizes that it’s a domain marked by relentless \\ninnovation and high stakes. My foray into this realm, driven by \\ncuriosity rather than expertise, has unveiled a tapestry of promis-\\ning trends that could redefine the future of computing. Here’s a \\ncloser look at some of these groundbreaking developments:\\n3D-Stacked CMOS The 3D-stacked CMOS technology is \\nanother game changer. Instead of laying out transistors flat, \\nlike houses in a neighborhood, this technology stacks them \\nvertically, akin to a multistory building. This vertical arrange-\\nment allows for more transistors in the same space, leading to \\nincreased computing power. In simple terms, it’s like having \\nmultiple processing units stacked atop one another, working in \\ntandem. The potential performance gain is substantial, as data \\ncan move faster between vertically stacked transistors, acceler-\\nating processing speeds.\\nForksheet Transistor Design Imec’s innovative Forksheet \\ntransistor design is set to breathe new life into silicon-based'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 235\\nsemiconductors. At its core, the Forksheet design tweaks the \\ntraditional transistor layout to reduce leakage and improve \\nperformance. Imagine a river with multiple channels; if one \\nchannel leaks, the others can still function efficiently. Simi-\\nlarly, the Forksheet design ensures that even if one part faces \\nissues, the overall performance remains robust. This design \\ncan lead to chips that are not only more reliable but also \\nfaster, potentially boosting performance by a signifi-\\ncant margin.\\nHybrid Microchip The fusion of memory resistors, or mem-\\nristors, and CMOS technology has birthed a new hybrid \\nmicrochip. Memristors, in essence, are resistors with memory. \\nWhen combined with CMOS technology, these chips can \\nprocess and store data simultaneously, making them ideal for \\nAI tasks that require rapid data processing. In simpler terms, \\nit’s like having a brain that thinks and remembers at the same \\ntime, leading to faster decision making. The potential perfor-\\nmance gain here is immense, especially for AI-driven applica-\\ntions where speed and memory are paramount.\\nProcessing Units Next up, processing units. While the power \\nof individual chips is crucial, the real magic happens when these \\nchips are orchestrated in harmony. This is especially paramount \\nfor tasks like training AI models.\\nHere’s an explanation of processing units:\\nCPU (Central Processing Unit) Often referred to as the \\n“brain” of the computer, the CPU handles a variety of tasks \\nand is adept at sequential processing. It’s the jack-of-all-trades \\nin the computing world, capable of managing everything from \\nbasic arithmetic to complex system operations. However, \\nwhen it comes to AI training, CPUs might not be the most'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='236 GENERATIVE AI\\nefficient choice. The reason? AI training requires parallel \\nprocessing, something GPUs and other specialized \\nunits excel at.\\nGPU (Graphics Processing Unit) Initially designed for ren-\\ndering graphics, GPUs have found a new calling in the realm \\nof AI. Their strength lies in their ability to handle multiple \\ntasks simultaneously. Imagine trying to solve multiple math \\nproblems at once; that’s what GPUs excel at. Their parallel \\nprocessing capabilities, coupled with high memory bandwidth \\nand specialized software libraries, make them a preferred \\nchoice for AI model training.\\nTPU (Tensor Processing Unit) Google’s brainchild, the \\nTPU, is tailored for T ensorFlow, their machine learning (ML) \\nframework. While GPUs are versatile, TPUs are purpose-\\nbuilt for ML tasks, offering unparalleled performance per \\nwatt. However, their specificity to T ensorFlow means they \\nmight not be the go-to choice for those using different \\nframeworks.\\nIPU (Intelligence Processing Unit) Graphcore’s IPU, par-\\nticularly the Colossus MK2 GC200, is a force to be reckoned \\nwith in the AI world. With a staggering 1472 processor core \\nand almost 9,000 parallel program threads, it’s designed to \\ntackle the unique challenges of deep learning. Its architecture \\nis optimized for the myriad of operations required for such \\ntasks, making it a formidable competitor to traditional GPUs.\\nNPU (Neural Processing Unit) The NPU is the embodi-\\nment of ML hardware. Designed explicitly for neural network \\ncomputations, it’s optimized for the matrix operations that are \\nthe backbone of deep learning. Various tech giants have thrown \\ntheir hats into the NPU ring, with Huawei’s version being a \\nnotable example. While GPUs are adept at parallel processing, \\nNPUs are fine-tuned for neural networks, often delivering \\nsuperior performance for deep learning tasks. It’s worth noting'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 237\\nthat the world of NPUs is vast, with various iterations like \\nTPUs, IPUs, and more, each with its unique strengths.\\nIn essence, the choice of processing unit boils down to the \\nspecific requirements of the task at hand. While CPUs are versa-\\ntile, GPUs and NPUs offer specialized capabilities that make \\nthem more suited for certain deep learning tasks. The rapid \\nadvancements in this field ensure that the future of AI and ML is \\nnot just promising but also incredibly exciting. As we continue to \\npush the boundaries of what’s possible, these processing units \\nwill undoubtedly play a pivotal role in shaping the future of \\ntechnology.\\nDetermining the “optimal” processing unit is often contin-\\ngent on the distinct demands of the task. GPUs, with their prow-\\ness in executing parallel operations, have become the go-to \\nchoice for training intricate deep learning models. On the other \\nhand, TPUs, a brainchild of Google, have been meticulously \\ncrafted to adeptly manage ML operations. Not to be left behind, \\nIPUs, the innovation of Graphcore, emerge as another con-\\ntender, tailored explicitly for AI-centric workloads. The decision \\nmatrix, when selecting among these powerhouses, hinges on sev-\\neral factors: the model’s magnitude, data volume, and the equi-\\nlibrium between speed and efficiency.\\nHighlighting the vanguard in this domain:\\n• GPU: The NVIDIA A100 T ensor Core GPU stands as a \\ntitan among its peers. Purpose-built for AI, data analytics, \\nand high-performance computing, its versatility spans a \\ngamut of applications— from AI model training and infer -\\nence to data analytics, scientific computations, and even \\ncloud graphics. A testament to its might, the NVIDIA A100 \\nT ensor Core GPU boasts a staggering 312 teraFLOPS \\n(TFLOPS) of computational power.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='238 GENERATIVE AI\\n• TPU: Google’s T ensor Processing Unit (TPU) is not just \\nanother chip— it’s a meticulously engineered application-\\nspecific integrated circuit (ASIC) with a singular focus: \\nsupercharging ML tasks. These TPUs are the silent work-\\nhorses in Google’s datacenters, powering an array of services \\nwe use daily— be it Google Search, Gmail, Google Photos, \\nor the myriad Google Cloud AI APIs. The latest in this line-\\nage, the TPU v4, is a force to be reckoned with, offering a \\nrobust 260 teraFLOPs (TFLOPs) of performance.\\n• IPU: Venturing into the realm of AI-specific processing, \\nGraphcore’s Intelligence Processing Unit (IPU) emerges as \\na formidable player. The Graphcore Colossus MK2 IPU, \\nwith its specialized design, finds its niche in diverse arenas, \\nfrom cloud computing to cutting-edge AI research. A nota-\\nble implementation of this powerhouse is the IPU-Ray-Lib \\nproject— a path-tracer fine-tuned for Graphcore IPUs. With \\na performance benchmark set at an impressive 250 TFLOPs, \\nit’s clear that the IPU is not just another chip on the block— \\nit’s a revolution in its own right.\\nCompany-Customized AI Hardware In the sprawling land-\\nscape of AI and computational technology, there’s a discernible \\ntrend among industry giants— especially those for whom perfor-\\nmance isn’t just a metric, but a mantra. These behemoths, in \\ntheir relentless pursuit of excellence, often sidestep off-the-shelf \\nsolutions, opting instead to forge their own path by crafting \\nbespoke processing units tailored to their unique needs.\\nApple, the Cupertino-based titan, stands as a shining exem-\\nplar of this approach. Their commitment to performance and \\nuser experience has led them to design a suite of proprietary pro-\\ncessing units, ensuring that every device they produce is not just \\na piece of hardware but a meticulously engineered experience.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 239\\n• Apple M1: A quantum leap in Apple’s hardware journey, the \\nApple M1 is an ARM-based system-on-a-chip that serves as \\nboth the brain (CPU) and the visual maestro (GPU) for \\ntheir Mac desktops, notebooks, as well as the iPad Pro and \\niPad Air tablets. This chip isn’t just about raw power— it’s a \\nsymphony of performance and efficiency, fine-tuned to per-\\nfection for macOS and iOS applications. With the M1, Apple \\ndidn’t just aim to compete; they set out to redefine \\nthe paradigm.\\n• A-series chips: For over a decade, Apple’s mobile devices— \\niPhones, iPads, and Apple Watches— have been powered by \\nthe A-series chips. These aren’t just processors; they’re a tes-\\ntament to Apple’s vision of what mobile computing should \\nfeel like. Designed to deliver both blistering performance \\nand unparalleled efficiency, these chips ensure that every \\ninteraction, every swipe, every tap feels fluid and responsive. \\nAnd they’re not just about speed— they’re optimized to run \\niOS and watchOS applications with a finesse that’s become \\nsynonymous with the Apple brand.\\nT esla emerges as another luminary, pushing the boundaries \\nof what’s possible in both AI and robotics. Elon Musk’s brain-\\nchild, T esla, isn’t just about electric cars— it’s a technological \\npowerhouse, constantly innovating and redefining the intersec-\\ntion of hardware, software, and AI.\\n• T esla Dojo: This isn’t just another supercomputer— it’s T esla’s \\nanswer to the challenges of computer vision video process-\\ning and recognition. Purpose-built, the Dojo is the crucible \\nwhere T esla’s ML algorithms are honed, ensuring that their \\nvehicles aren’t just self-driving, but self-learning.\\n• T esla’s custom AI chips: While many automakers rely on third-\\nparty solutions for their autonomous driving tech, T esla took'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='240 GENERATIVE AI\\nthe road less traveled. In a little over a year, they designed a \\ncustom AI chip tailored to the unique demands of their self-\\ndriving ambitions. Manufactured by Samsung, this chip isn’t \\njust about power— it’s about precision, ensuring that T esla \\ncars can navigate the complexities of real-world driving with \\nunparalleled accuracy. And T esla’s commitment to excellence \\ndoesn’t stop at their new cars. In a move that underscores \\ntheir dedication to safety and performance, older models are \\nbeing retrofitted with this cutting-edge processor.\\nHowever, it’s crucial to dispel a common misconception. \\nWhile T esla has been a pioneer in developing custom hardware \\nfor its fleet of electric vehicles, there’s no specific processing unit \\ndubbed the “T esla Processing Unit” or “T esla NPU” in their \\narsenal, at the moment.\\nThe race for hardware dominance is not a solitary sprint but \\na collective marathon. While Apple and T esla have made head-\\nlines with their audacious strides, other tech behemoths like \\nAmazon, Intel, and Microsoft are not mere spectators. They’re in \\nthe thick of it, each sculpting its own niche, each pushing the \\nenvelope in its quest to redefine the future of computing.\\nY et, projecting this trajectory of Moore’s law, the implica-\\ntions are staggering. Within a span of five years, we’re looking at \\na monumental leap— a surge where our computational capabili-\\nties could amplify by a factor of almost 7. T o put this in tangible \\nterms, imagine a future iteration of the NVIDIA A100 called \\n“NVIDIA A200” boasting 2,080 teraFLOPS. Such a powerhouse \\ncould potentially slash model training times by 85 percent, revo-\\nlutionizing the way we approach deep learning and AI tasks.\\nIn the upcoming sections, I argue that we are approaching a \\npivotal moment that surpasses Moore’s law. We’re not merely \\ncontinuing its trajectory; we’re on the verge of breakthroughs \\nthat will fundamentally transform our understanding of what is \\npossible through innovation.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 241\\nCloud Computing Certain innovations emerge as pivotal \\ngame changers, reshaping the landscape in ways previously \\nunimagined. Cloud computing stands tall among these trans-\\nformative forces, casting a profound influence not only on the \\ntrajectory of technology but also on the very ethos of innovation \\nand collaboration.\\nCloud computing, in its essence, is the great equalizer. It has \\nushered in an era where computing power, once the exclusive \\ndomain of tech behemoths, is now within arm’s reach of the many. \\nThis democratization of computational might has catalyzed a \\nrenaissance of creativity, fostering an environment where ideas \\nflourish, unfettered by the constraints of physical infrastructure.\\nMy admiration for cloud computing is rooted in its sheer \\npracticality and transformative potential. Picture this: Within \\nthe span of a mere hour, one can seamlessly weave together the \\nintricate tapestry of a digital application. From deploying code \\non a computing instance to orchestrating a symphony between \\nfrontend and backend through an adept API manager, the entire \\nprocess is streamlined, efficient, and, dare I say, exhilarating. And \\nshould your creation resonate and attract a burgeoning user \\nbase? Scaling becomes a matter of a few clicks, not cumbersome \\nhardware acquisitions.\\nBut the magic of cloud computing isn’t confined to its agility \\nand efficiency. Its implications ripple across multiple facets:\\n• Scalability: The fluidity with which businesses can modulate \\ntheir computational resources is unparalleled. Whether it’s a \\nsurge during peak seasons or a lull in off-peak times, the \\ncloud adapts, ensuring optimal resource allocation without \\nthe baggage of redundant infrastructure.\\n• Cost-effectiveness: The pay-as-you-go model is a master -\\nstroke, aligning expenses with usage. Gone are the days of \\nhefty up-front hardware investments and the incessant drain \\nof maintenance costs.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='242 GENERATIVE AI\\n• Accessibility: The cloud knows no boundaries. Its omnipres-\\nence ensures that high-caliber computational resources are a \\nmere click away, leveling the playing field for enterprises, \\nbig and small.\\n• Innovation: The cloud is a treasure trove of cutting-edge \\ntools and technologies. From AI toolkits to advanced analyt-\\nics, businesses can harness the power of the latest innova-\\ntions without the rigors of in-house development.\\n• Reliability: The architectural robustness of cloud providers, \\nwith their geographically dispersed datacenters, offers a \\nresilience that’s hard to match. Even in the face of unfore-\\nseen disruptions, the cloud remains steadfast, ensuring unin-\\nterrupted service.\\n• Energy efficiency: The centralization inherent in cloud com-\\nputing is not just a logistical boon but an environmental one. \\nBy pooling computational resources, the cloud achieves effi-\\nciencies of scale, curbing energy consumption and mitigat-\\ning the environmental footprint.\\nIn the grand scheme of things, cloud computing is more than \\njust a technological marvel— it’s a paradigm shift. As we navigate \\nthe intricate maze of Moore’s law and the promises it holds, the \\ncloud emerges as a beacon, illuminating the path to a future where \\nthe boundaries of what’s possible are continually reimagined.\\nQuantum Computing Quantum computing holds the poten-\\ntial to transform the computational world. Unlike traditional \\ncomputing with its binary “on” and “off” states, quantum com-\\nputing uses qubits that can exist in both states simultaneously. \\nThis capability, rooted in quantum mechanics, enables quantum \\ncomputers to process multiple solutions at once, vastly expand-\\ning computational possibilities.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 243\\nThe genesis of this idea can be traced back to the musings of \\nphysicist Richard Feynman in the early 1980s. Fast-forward a \\nfew decades, and we find ourselves amidst a quantum renais-\\nsance. T ech powerhouses like IBM, Google, and Microsoft are \\nfervently pouring resources into quantum R&D, with each stride \\nbringing us closer to harnessing its full potential. IBM’s recent \\nproclamation suggests a tantalizing horizon where quantum \\ncomputers transition from theoretical constructs to tangible \\ntools within a mere couple of years.\\nY et, the journey is riddled with challenges. Quantum coher-\\nence, the bedrock of quantum computing, is a fragile state, easily \\ndisrupted by environmental interactions. The hurdles are mani-\\nfold, from the Herculean task of maintaining qubit stability to \\nthe intricacies of quantum error correction. Scalability, precise \\nqubit control, accurate readouts, and the necessity for extreme \\ncooling further compound the complexity. And then there’s the \\nrealm of material science, where the quest for the ideal qubit-\\nhosting material is ongoing.\\nBut for every challenge, there’s an opportunity. The quantum \\nrealm is already making waves in real-world applications. Busi-\\nnesses, in their relentless pursuit of innovation, are harnessing \\nthe power of quantum computing to solve problems previously \\ndeemed insurmountable.\\nT ake Mercedes-Benz, for instance. The automotive giant, in \\nits commitment to a greener future, is delving into quantum \\ncomputing to revolutionize battery technology for electric vehi-\\ncles. The intricate dance of chemical reactions within batteries, \\ntraditionally elusive to conventional computational methods, \\nbecomes more tangible under the quantum lens.\\nExxonMobil, on the other hand, is leveraging quantum  \\nalgorithms to optimize fuel transportation routes, a task of  \\nstaggering complexity when approached with classical comput-\\ning methods.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='244 GENERATIVE AI\\nCERN, the custodian of the Large Hadron Collider (LHC), \\nis harnessing quantum computing to decipher the universe’s \\nenigmas. The vast data streams from the LHC, rife with patterns \\nand anomalies, are prime candidates for quantum analysis.\\nMitsubishi Chemical, in collaboration with Keio University, \\nis exploring the intricacies of lithium-oxygen batteries at a \\nmolecular level, a task made feasible by quantum simulations.\\nPivoting to the broader landscape, when juxtaposed with tra-\\nditional powerhouses like GPUs and NPUs, quantum comput-\\ners promise an exponential speedup, especially in the domain of \\nmachine learning. This acceleration translates to swifter training \\nand inference times for ML models, a phenomenon aptly termed \\nquantum machine learning. This integration of quantum algo-\\nrithms within ML paradigms is set to redefine the benchmarks of \\ncomputational efficiency.\\nQuantum bits enable parallel processing, enhancing tasks \\nlike machine learning by exploring multiple states simultaneously.\\nPeering into the horizon, the quantum odyssey is laden with \\npotential. The immediate future, spanning one to three years, is \\npoised to witness quantum hardware reaching new zeniths and \\nthe birth of avant-garde quantum algorithms. T ransitioning to \\nthe medium term, spanning three to five years, the abstract allure \\nof quantum computers will materialize into tangible tools, find-\\ning their niche in sectors like cryptography and optimization. A \\ndecade from now, the quantum community aspires to craft a \\nfault-tolerant quantum computer— a beacon of achievement in \\nthe field.\\nY et, the dream of a universal, gate-based, T uring-complete \\nquantum behemoth remains a tantalizing vision on the distant \\nhorizon. But with the momentum garnered from recent innova-\\ntions, strategic foresight, and a deluge of investments, the dawn \\nof general-purpose quantum computers might just be closer than \\nwe dare to dream.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 245\\nThe quantum renaissance promises more than just speed— it \\npledges transformation. Quantum systems, with their capacity to \\nprocess data on an astronomical scale, will redefine precision in \\nmeasurements. Simulating intricate systems, from molecular \\nmatrices to cosmic phenomena, will be executed at speeds previ-\\nously deemed fantastical. The emergence of quantum sensors \\nwill usher in an era of unparalleled sensitivity and pinpoint accu-\\nracy. Communication infrastructures, fortified by quantum prin-\\nciples, will be bastions of security, rendering them nigh \\nimpervious. And in the realm of problem solving, quantum algo-\\nrithms will navigate the labyrinth of challenges, offering solu-\\ntions that are not just optimal, but also intuitive. The quantum \\nage beckons, and the future is reimagined. Figure\\xa04.4 shows a \\nphotograph of a quantum computer.\\nFIGURE\\xa04.4 A quantum computer’s intricate design: the loops, which \\nstraighten when cooled to –273°C, highlight the extreme cooling \\nmeasures essential for quantum computing operations.\\nSource: IBM Corporation / https://newsroom.ibm.com/media-quantum-innovation? \\nkeywords=quantum&l=100#gallery_gallery_0:21747 / last accessed December 01, 2023.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='246 GENERATIVE AI\\nNeuromorphic Computing Neuromorphic computing emerges \\nas a beacon of promise. At its core, this paradigm seeks to emulate \\nthe intricate architecture and functionality of the human brain. By \\nharnessing physical artificial neurons for computations, realized \\nthrough mediums like oxide-based memristors, spintronic memo-\\nries, and transistors, it offers a fresh perspective on computational \\nprocesses. The spiking neural network (SNN) stands as its most \\ncelebrated manifestation, where nodes mirror the processing and \\ndata retention capabilities of biological neurons. The overarching \\nambition? T o usher in a new era of AI, characterized by brain-\\ninspired, energy-efficient computing.\\nEnter Rain Neuromorphics, a trailblazer in this domain. Bol-\\nstered by a robust $25\\xa0million Series A funding, the company is \\npoised to redefine the AI hardware landscape. Their audacious \\nvision encapsulates the creation of a chip no larger than a thumb-\\nnail, capable of handling a staggering 100 billion-parameter \\nmodels. With an unwavering belief in the transformative poten-\\ntial of AI, Rain Neuromorphics envisions a world where every \\ngadget is endowed with a dynamic, perpetually evolving AI \\nintellect.\\nWhile contemporary computing architectures rest on von \\nNeumann principles, with distinct memory and processing units \\nand a binary data representation, neuromorphic computing \\ndraws inspiration from cerebral constructs like neurons and syn-\\napses. This fusion of biology, mathematics, electronics, and phys-\\nics offers a holistic approach to computation.\\nThe true genius of neuromorphic computing lies in its emu-\\nlation of cerebral processes. Visual representations of an SNN, \\nwhich can be seen on Y ouT ube, depict a fascinating phenome-\\nnon. Only a handful of neurons spring into action during deci-\\nsion making, initiating a broad cascade that gradually narrows, \\nculminating in the final prediction— akin to a funnel’s mecha-\\nnism. This selective activation translates to fewer computational'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 247\\noperations, amplifying the efficiency and efficacy of neuromor -\\nphic computing.\\nQuantifying this efficiency, especially in computational oper-\\nations, poses challenges due to the distinct methodologies and \\ncomponents involved. However, energy consumption metrics \\noffer a glimpse into its potential. Preliminary estimates suggest \\nthat neuromorphic computing could slash energy consumption \\nfor data processing by a staggering 90 percent.\\nThe implications for contemporary AI are profound. Neuro-\\nmorphic systems, with their real-time learning capabilities, could \\nempower AI to adapt and respond with unprecedented agility, \\nelevating performance in fluid environments. The allure of \\nanalog computation, a hallmark of the human brain and a feature \\nof neuromorphic systems, could render them adept at tasks that \\nbaffle digital AI systems.\\nY et, the true potential of this field might lie in its symbiotic \\nrelationship with other technological domains. A nascent trend \\nhints at the fusion of neuromorphic computations with quantum \\ncomputing. By amalgamating the strengths of both realms, the \\ngoal is to birth computing systems of unparalleled efficiency and \\npower, capable of navigating the most labyrinthine computa-\\ntional challenges. While this convergence is still in its embryonic \\nphase, the horizon gleams with promise. The trajectory remains \\nuncertain, but one thing is clear— the future of computing is \\npoised for a seismic shift, and neuromorphic computing will \\nmost likely play an important role in this transformation.\\nLK-99’s Promise Imagine a future where the idea of room-\\ntemperature superconductors shines brightly, heralding untapped \\npossibilities. Picture superconductors, those materials that trans-\\nmit electricity without resistance, no longer bound by the icy \\nchains of ultra-cold temperatures. The potential unlocked by'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='248 GENERATIVE AI\\ntranscending this temperature threshold is nothing short of \\nrevolutionary.\\nThe implications of such a breakthrough are manifold. Envi-\\nsion our power grids, for instance. The advent of room-temperature  \\nsuperconductors could drastically elevate their efficiency, banish-\\ning energy losses that plague transmission. The realm of energy \\nstorage could witness the birth of compact systems that not only \\nstore energy with heightened efficiency but also bolster the utili-\\nzation of renewable energy sources. T ransportation could undergo \\na metamorphosis with magnetic levitation (maglev) trains becom-\\ning more ubiquitous, offering swifter and more energy-conserving \\npublic transit options. The medical sector stands to gain too, with \\nMRI machines potentially becoming more affordable, efficient, \\nand widespread. And in the telecommunications sphere? We could \\nbe looking at communication systems that redefine speed and effi-\\nciency, from turbocharged Internet connections to crystal-clear \\ncell phone signals.\\nBut perhaps the most tantalizing prospect lies in the domain \\nof computing. T raditional processors, constructed from semi-\\nconductors, grapple with the Achilles’ heel of heat generation— a \\nbyproduct of electrical resistance. This thermal challenge not \\nonly curtails processor speed but also guzzles energy. Enter \\nsuperconductors. Their zero-resistance prowess could pave the \\nway for processors devoid of heat generation, heralding an era of \\nblistering processing speeds without the need for intricate cool-\\ning mechanisms. The energy economy of computing systems \\ncould witness a paradigm shift.\\nQuantum computing, too, stands on the cusp of a revolution. \\nRoom-temperature superconductors could render quantum \\ncomputers more pragmatic and accessible, obviating the need for \\nintricate cooling apparatuses. Such superconductors could bol-\\nster the stability of quantum systems, mitigating the menace of \\nqubits succumbing to “decoherence.” The scalability of quantum'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 249\\nsystems could witness a boost, potentially birthing quantum \\ncomputers of unparalleled power. And with energy efficiency in \\nthe mix, these quantum behemoths could be both eco-friendly \\nand cost-efficient. The ripple effect? An acceleration in quantum \\nresearch, catalyzing rapid breakthroughs.\\nEnter the enigma of LK-99. T outed as a potential room-  \\ntemperature superconductor, LK-99, with its distinctive hex-\\nagonal structure reminiscent of lead-apatite, has stirred the sci-\\nentific community. Its discovery, credited to researchers Sukbae \\nLee and Ji-Hoon Kim from Korea University, has been met \\nwith both intrigue and skepticism. While the team has dissemi-\\nnated their findings, the absence of peer review casts a shadow \\nof doubt. Replication attempts by global scientists have yet to \\nbear fruit, leading many to question the veracity of LK-99’s \\nclaims. The unfolding narrative around LK-99 underscores a \\nprofound realization: Our grasp of the periodic table remains \\nincomplete. Our elemental alchemy, the art of melding ele-\\nments to manifest desired properties, is still in its infancy. Y et, \\nin this challenge lies opportunity.\\nExponential Software Evolution\\nLet’s pivot from discussing hardware advancements to exploring \\nthe software realm. Software evolution goes beyond just refining \\ncode; it’s about designing holistic systems that synergize with \\nhardware to yield more efficient and precise outcomes. This \\nbrings us to the forefront of exponential software evolution, par-\\nticularly with parallel programming.\\nParallel Programming Parallel programming is a symphony \\nof synchronized algorithms, harmoniously working together to \\ntap into the full prowess of the hardware. When it all aligns, the \\nsurge in execution performance is nothing short of exhilarating.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='250 GENERATIVE AI\\nA parallel algorithm isn’t just any algorithm— it’s a meticu-\\nlously designed blueprint that can simultaneously execute multi-\\nple instructions across diverse processing devices. The magic lies \\nin its ability to weave together individual outputs, producing a \\ncohesive final result. This design is no accident; it’s tailored to \\nharness the sheer power of parallel processing capabilities, espe-\\ncially in the realm of multiprocessor parallel computers.\\nDiving into the types of parallel algorithms, we find a rich \\ntapestry of classifications:\\n• Data parallelism: Here, the spotlight is on the data. Imagine \\nrunning the same program or operation, but on different \\ndata subsets, all at the same time. It’s like having multiple \\nchefs cooking different dishes using the same recipe.\\n• T ask parallelism: This is where diversity comes into play. Dif-\\nferent algorithms, each with its unique task, run side by side \\nin parallel. Think of it as an orchestra where each instru-\\nment plays a different part, but together they create a har -\\nmonious melody.\\n• Embarrassingly parallelism: The name might sound quirky, \\nbut it’s quite straightforward. These are computations that \\ncan be effortlessly split into subproblems, each of which can \\nbe independently tackled on separate computing resources. \\nIt’s akin to a puzzle, where each piece can be worked on by \\ndifferent individuals without any overlap.\\nHowever, it’s essential to note that not every algorithm is \\nsuited for parallelism. T ake, for instance, Dijkstra’s algorithm— a \\nsequential algorithm. It’s a masterful graph search method that \\npinpoints the shortest path in a graph with non-negative edge \\npath costs, culminating in a shortest path tree. Its sequential \\nnature means it follows a set path, step by step, much like follow-\\ning a single recipe from start to finish.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 251\\nOn the flip side, consider matrix multiplication— a shining \\nexample of a parallel algorithm. Here, matrices are fragmented \\ninto smaller chunks, and the multiplication of these bite-sized \\nmatrices is executed in parallel. It’s like having multiple chefs \\neach preparing a part of a dish, only to combine them at the end \\nfor the final masterpiece.\\nAnd speaking of matrix multiplication, its significance in AI, \\nespecially neural networks, is paramount. Here’s a brief rundown:\\n• Data processing: At the heart of neural networks lies matrix \\nmultiplication. As input data and weights flow through each \\nlayer, they undergo a series of matrix multiplications, much \\nlike ingredients being mixed in a specific order to cre-\\nate a dish.\\n• Backpropagation: The cornerstone of training neural net-\\nworks. This algorithm leverages matrix multiplication to \\ncompute gradients, akin to adjusting a recipe based on \\ntaste tests.\\n• Batch processing: Efficiency is key in AI training. By training \\non data batches, matrix operations streamline the process, \\nmuch like cooking in bulk for a large gathering.\\nAlphaTensor Mathematics has been laser-focused on enhanc-\\ning the performance of matrix multiplication algorithms for dec-\\nades. The ultimate goal? Achieving maximum efficiency with the \\nfewest steps or operations.\\nEnter AlphaT ensor, a groundbreaking AI system birthed by \\nthe brilliant minds at Google DeepMind. This isn’t just any AI— \\nit’s a system that can unearth innovative, efficient, and most \\nimportantly, provably correct algorithms for foundational tasks, \\nwith matrix multiplication being a prime example.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='252 GENERATIVE AI\\nWhat makes AlphaT ensor truly stand out is its lineage. It’s \\nbuilt upon the shoulders of giants, specifically AlphaZero— an AI \\nprodigy that has demonstrated unparalleled prowess in board \\ngames. But DeepMind didn’t stop there. They embarked on a \\njourney to transition AlphaZero from mastering games to \\naddressing unsolved mathematical conundrums for the very \\nfirst time.\\nUnder the guidance of AlphaT ensor, algorithms surpassing \\nthe efficiency of existing state-of-the-art solutions were unveiled \\nfor a wide range of matrix sizes. But how did they achieve this \\nmonumental feat?\\nDeepMind ingeniously transformed the challenge of pin-\\npointing efficient matrix multiplication algorithms into a single-\\nplayer game. But this wasn’t any ordinary game— it was a \\nHerculean task. T o put it into perspective, the sheer number of \\npotential algorithms to explore surpasses the total number of \\natoms in the universe, even for rudimentary matrix multiplica-\\ntion scenarios.\\nUndeterred, AlphaT ensor was trained using the power of \\nreinforcement learning to master this game. It began its journey \\ndevoid of any prior knowledge about existing matrix multiplica-\\ntion algorithms. Through continuous learning and adaptation, \\nAlphaT ensor not only reacquainted itself with historic rapid \\nmatrix multiplication algorithms like Strassen’s but also ventured \\nbeyond human comprehension, unveiling algorithms swifter \\nthan any known before. The sheer diversity of algorithms it \\ndiscovered— thousands for each matrix size— revealed a previ-\\nously uncharted depth in the realm of matrix multiplication \\nalgorithms. A revelation, to say the least.\\nAlphaT ensor’s prowess didn’t stop there. It showcased tangi-\\nble improvements in matrix multiplication algorithms, especially \\ntailored for specific scenarios and matrix dimensions. For instance,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 253\\nit unveiled an algorithm adept at multiplying a 4×5\\xa0matrix with a \\n5×5\\xa0matrix, requiring a mere 76\\xa0multiplications. This was a sig-\\nnificant leap from a preceding algorithm that demanded 80\\xa0mul-\\ntiplications. When you scale this up to larger matrices, the \\ndifference becomes even more pronounced— roughly a 5 percent \\nreduction in calculations for each matrix multiplication.\\nAlphaT ensor’s adaptability extends beyond speed, optimizing \\nfactors like energy use and stability, crucial for algorithmic accu-\\nracy. DeepMind’s work with AlphaT ensor and AlphaZero high-\\nlights AI’s potential in addressing major scientific and \\nmathematical challenges, foreseeing AI as a key tool in advancing \\nhuman knowledge.\\nParallel Processing Libraries: CUDA T o harness the full \\npotential of parallel processing units at the hardware level and \\nimplement parallel algorithms optimally and uniquely for spe-\\ncific applications, a myriad of tools and libraries have been devel-\\noped. One such dominant tool is CUDA by NVIDIA, specifically \\ntailored for NVIDIA products. Let’s zoom in on CUDA.\\nCUDA, which stands for Compute Unified Device Architec-\\nture, is a parallel computing platform and programming model \\nbirthed by NVIDIA. It’s not just a tool; it’s a revolution, empow-\\nering developers to harness NVIDIA ’s GPUs for tasks beyond \\njust graphics. The essence of CUDA lies in its ability to let devel-\\nopers write programs that exploit GPUs’ parallel processing \\nstrengths effectively.\\nFrom researchers to developers, from startups to tech giants, \\nCUDA has found its way into ML projects, scientific simula-\\ntions, image processing, video enhancements, and so much more. \\nIt’s not just a platform; it’s the bedrock for leveraging the sheer \\ncomputational might of GPUs across diverse sectors.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='254 GENERATIVE AI\\nHowever, parallel computing isn’t limited to CUDA; alterna-\\ntives like OpenCL offer cross-platform programming capabili-\\nties, while OpenGL excels in graphics rendering and can be used \\nfor general-purpose GPU programming, indicating a diverse \\nparallel computing landscape.\\nThe Improvement of\\xa0 Programming Languages Pivoting \\nto the software realm, let’s shine a spotlight on programming \\nlanguages. And here’s the headline: Python reigns supreme. Not \\nnecessarily for its computational prowess, but for the sheer con-\\nvenience it offers in coding and building, especially when navi-\\ngating the waters of data science and AI. Its vast library ecosystem \\nis a treasure trove for developers. But before we dive deeper into \\nPython, let’s take a brief historical detour. The first high-level \\nprogramming language made its debut in 1957, courtesy of IBM, \\nand was christened Fortran. However, not all high-level lan-\\nguages have stood the test of time, especially when we narrow \\nour lens to data wrangling, data science, AI, and model \\ndevelopment.\\nT racing the lineage of programming languages in the context \\nof data and AI, the chronology unfolds as follows:\\nR Born in 1993, R saw its heyday in the early 2000s, tailored \\nspecifically for statistical computing. Its vast array of statistical \\nand graphical techniques made it a favorite for data wrangling \\nand exploratory data analysis.\\nPython Although Python’s inception dates back to the late \\n1980s, its meteoric rise in the data science domain began in \\nthe mid-2000s. Its trifecta of simplicity, readability, and versa-\\ntility has made it an indispensable tool for data wrangling, ML, \\nand AI model development.\\nSQL A relic from the 1970s, SQL (Structured Query Language) \\nremains a cornerstone for managing relational databases. It’s the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 255\\nunsung hero behind efficient data wrangling and querying, ena-\\nbling seamless data extraction and transformation.\\nJava Java’s strength lies in enterprise applications, including \\ndata processing and analytics. While it might not share the \\nlimelight with Python or R in data science, its prowess in \\nbuilding scalable systems for Big Data processing is undeniable.\\nJulia A newcomer, Julia surfaced in 2012, aiming to bridge the \\ngap between the performance of low-level languages and the \\nuser-friendliness of high-level counterparts. Its rapid compu-\\ntations and expressiveness have garnered attention, especially \\nfor numerical tasks.\\nWhile these five languages have etched their marks, the pro-\\ngramming world is vast, with many more languages like Scala, C/\\nC++, JavaScript, Swift, Go, MATLAB, and SAS, each carving its \\nniche. The evolution of these languages, especially in the realms \\nof data wrangling, data science, AI, and machine learning, is a \\ntestament to the ever-growing need for tools that are both effi-\\ncient and expressive.\\nNew Programming Languages and User-Friendly Libraries  \\nEven established languages like Python and R are being chal-\\nlenged by newcomers. Enter Mojo, the latest offering from \\nModular Inc.\\nMojo is designed to blend Python’s simplicity with C’s per -\\nformance, targeting AI developers. Its potential is evident in sev-\\neral key areas:\\n• Unparalleled speed: Chris Lattner, Modular’s CEO and the \\nmind behind Swift, claims that Mojo can outperform Python \\nby up to 35,000 times in tasks like deep neural network \\ntraining. This speed is attributed to the LL VM compiler'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='256 GENERATIVE AI\\ntoolchain and the innovative multilevel intermediate repre-\\nsentation (MILR) compiler setup.\\n• Python integration: Mojo seamlessly integrates with the \\nPython ecosystem, allowing developers to utilize existing \\nPython libraries. This compatibility ensures a smooth tran-\\nsition from Python to Mojo, capitalizing on perfor -\\nmance boosts.\\n• Memory safety: Mojo prioritizes memory safety, addressing \\npotential vulnerabilities. This focus ensures enhanced stabil-\\nity and security in AI applications.\\n• User-friendly design: Mojo adopts a Python-like syntax, sim-\\nplifying the learning process for developers and reducing \\nthe challenges of mastering a new language.\\nMojo, with its high performance and user-friendly design, is \\nset to revolutionize AI, making it more accessible and innovative. \\nLibraries like T ensorFlow, PyT orch, and Keras have already \\ndemocratized AI by offering easy-to-use interfaces for all skill \\nlevels, lowering the entry barrier and providing both high-level \\nfunctions and customization options.\\nThe beauty of these libraries lies in their abstraction. T ensor-\\nFlow, PyT orch, Keras, and LangChain have transformed the AI \\ndevelopment landscape, encapsulating the intricacies of founda-\\ntional algorithms within their user-friendly frameworks. This \\nabstraction empowers developers, even those who might not be \\nwell versed in the labyrinthine depths of mathematical computa-\\ntions or intricate coding paradigms, to architect, nurture, and \\nroll out AI models with an unprecedented ease.\\nOne of the standout features of these libraries is their reper-\\ntoire of preconfigured functions. They come equipped with a \\nsuite of ready-to-use tools tailored for routine tasks— be it \\norchestrating neural network configurations, calibrating loss \\n.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 257\\nfunctions, or orchestrating optimization strategies. This not only \\ntrims down the coding overhead but also accelerates the devel-\\nopmental trajectory and minimizes potential pitfalls.\\nThe trajectory of these libraries appears promising. Their \\nevolution is likely to be marked by enhanced user-centricity and \\naugmented capabilities. The AI community might witness the \\nemergence of niche libraries, each honed for distinct AI subdo-\\nmains such as reinforcement learning or nuanced facets of natu-\\nral language processing. A notable trend on the horizon could be \\nthe proliferation of prompt-driven interfaces, suggesting a para-\\ndigm shift toward AI assistants as an integral overlay.\\nFurthermore, the open source ethos underpinning most of \\nthese libraries is a boon for developers. It fosters a vibrant, col-\\nlaborative ecosystem where knowledge dissemination is organic. \\nDevelopers can tap into this reservoir of collective wisdom, trou-\\nbleshoot common challenges, and even play an active role in the \\nlibrary’s evolutionary journey.\\nThe Open Source Movement The open source realm is \\narguably the most potent catalyst for AI advancement. There’s \\nscarcely an active open source community as vast and vibrant as \\nthe one orbiting AI. This dynamism not only propels the soft-\\nware layer to peak performance but also broadens its reach, mak-\\ning it effortlessly comprehensible for many.\\nThis open source wave in AI is a beacon for knowledge dis-\\nsemination and collective effort. It paves the way for swift con-\\nceptual iterations, rigorous algorithmic testing, and rapid \\npropagation of AI breakthroughs. Open source ventures have \\nbeen the bedrock of technological evolution for years, steering \\ninnovation and fostering collaboration in unparalleled ways. \\nThese communities are a melting pot of diverse perspectives, \\namalgamating varied backgrounds to craft solutions that are'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='258 GENERATIVE AI\\ninventive and inclusive— crucial for unbiased, equitable AI. They \\nare hubs for knowledge sharing, where developers exchange \\ninsights, propagate best practices, and jointly elevate their AI and \\nML acumen.\\nWhen these projects gain momentum and resonate with the \\nmarket, their reliability often surpasses proprietary counterparts. \\nThis is attributed to the sheer volume of developers scrutinizing \\nand fine-tuning the code, resulting in top-tier, resilient AI and \\nML models. Furthermore, these communities dismantle the tra-\\nditional barriers to entry in AI and ML. They usher in an era \\nwhere anyone can partake, assimilate, and harness the vast \\nresources at hand.\\nAt the heart of it all, projects fueled by intrinsic motivation— \\nthose birthed from passion— often outshine those driven by \\nexternal incentives, such as monetary gains.\\nA testament to the prowess of open source AI initia-\\ntives includes:\\n• OpenCV: A library dedicated to computer vision and ML, \\noffering a plethora of algorithms and tools for image pro-\\ncessing, object detection, and beyond.\\n• Hugging Face Transformers: A library that furnishes cutting-\\nedge natural language processing models and utilities, \\nequipped with preconfigured models tailored for tasks like \\ntext categorization and language translation.\\nEnvision a world where the democratization of AI and ML \\nassets becomes the great equalizer in the technological realm. \\nSuch a shift promises that every individual, regardless of their \\nbackground or resources, can dive into these fields, make mean-\\ningful contributions, and utilize them to tackle urgent global \\nissues. This transformation could spark a golden age of innova-\\ntion, spawning a myriad of AI and ML solutions attuned to a \\nwide array of societal needs.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 259\\nAdvanced AI Architectures and AI Models It’s evident that \\nAI architectures are evolving to be sharper, more intelligent, and \\nimmensely potent. Their growth trajectory has been nothing \\nshort of exponential, a trend prominently showcased with the \\nrelease of models like ChatGPT . The AI landscape is in a state of \\nperpetual flux, with research teams globally making strides daily, \\neach enhancement pushing the boundaries of what’s possible.\\nT ake, for instance, the realm of T ransformer models. Their \\ncapabilities have been on a steady incline, and a prime example of \\nthis evolution is Llama 2 by Meta. Llama 2 stands out in the \\ncrowded AI space for several compelling reasons. Not only is it \\nopen source, paving the way for both academic research and \\ncommercial endeavors, but its availability also promises to invig-\\norate the AI model market, spurring further innovation.\\nWhat sets Llama 2 apart is its enhanced training data— \\nboasting a 40 percent increase compared to its predecessor, \\nLlama 1. This enhancement translates to a notable uptick in per-\\nformance. But perhaps its most intriguing aspect is its scalability. \\nWhile one might anticipate a behemoth model with upwards of \\n700 billion parameters, Llama 2 astounds with its most potent \\nvariant having a mere 70 billion parameters. This shift toward \\ncompact yet effective models underscores the dual themes of \\nopen source power and global research-driven incremental \\nadvancements.\\nBut the story doesn’t end there. Meta has forged alliances with \\ntech giants like Microsoft and leading chipmaker Qualcomm. This \\ncollaboration aims to embed Llama 2\\xa0within Snapdragon proces-\\nsors, hinting at its integration in top-tier smartphones very soon. \\nFurthermore, Llama 2\\xa0has been fine-tuned to operate seamlessly \\non platforms like Microsoft Azure, Amazon Web Services (AWS), \\nand Hugging Face. Such partnerships are poised to broaden Llama \\n2’s footprint in AI development, ushering in novel AI experiences \\nfor end users.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='260 GENERATIVE AI\\nLiquid Neural Networks and AutoML Y et, beyond the \\nfamiliar terrains of conventional AI architectures, there are bur-\\ngeoning paradigms that are reshaping the AI landscape. T ake liq-\\nuid neural networks (LNNs) as an example.\\nLNNs, a brainchild of the brilliant minds at MIT’s Com-\\nputer Science and Artificial Intelligence Laboratory (CSAIL), \\nrepresent a fresh wave in deep learning architectures. These are \\ntime-continuous recurrent neural networks (RNNs) that metic-\\nulously process data in a sequential manner, retaining memories \\nof prior inputs. The magic of LNNs stems from their ingenious \\nutilization of dynamically modifiable differential equations. This \\nunique feature equips them with the prowess to recalibrate and \\nadapt to novel scenarios post-training. Unlike their traditional \\ncounterparts, LNNs possess the agility to tweak their founda-\\ntional equations based on incoming data, specifically modulating \\nthe responsiveness of neurons. This inherent adaptability ren-\\nders LNNs exceptionally resilient to data anomalies or unfore-\\nseen inputs. An added feather in their cap is their enhanced \\ninterpretability, as tracing their decision-making pathways within \\nthe network becomes significantly more straightforward.\\nT o distill it down: LNNs undergo initial training on data, but \\ntheir true prowess shines when they continually refine their \\nweights upon interacting with real-world data, enhancing their \\nperformance post-training.\\nTheir potential has been demonstrated in arenas where con-\\nventional deep learning models often falter, such as in the \\ndomains of robotics and autonomous vehicles. A testament to \\ntheir capabilities is the research from MIT , where drones, pow-\\nered by a compact 20,000-parameter (!) LNN model, showcased \\nsuperior navigational acumen in unfamiliar terrains compared to \\nother neural networks. Such prowess hints at their potential in \\nsculpting more precise autonomous vehicular systems.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 261\\nHowever, like all innovations, LNNs come with their set of \\nchallenges— the vanishing gradient conundrum and a nascent \\nbody of literature detailing their implementation and advantages, \\nto name a few. The academic community is fervently addressing \\nthese hurdles, curating more intricate tasks to gauge LNNs’ mettle.\\nLooking ahead, LNNs hold the promise of catalyzing \\ngroundbreaking strides in AI, especially in sectors where tradi-\\ntional models often hit roadblocks. Their adaptability, coupled \\nwith heightened interpretability, could pave the way for sturdier \\nand more efficient AI constructs. As the research tapestry around \\nLNNs expands, we’re poised to witness a surge in their applica-\\ntions and breakthroughs.\\nOn another front, the realm of AI development is witnessing \\na paradigm shift with the rise of AutoML. These tools are revo-\\nlutionizing the ML landscape by automating facets of the ML \\nprocess (see Figure\\xa04.5).\\nFIGURE\\xa0 4.5 The AutoML workflow: an overview of automated ML’s \\nend-to-end process, highlighting key subtasks from data preprocess-\\ning to model evaluation, encapsulated within the dotted-line box.\\nSource: Treasure Data, Inc. / https://docs.treasuredata.com/display/public/PD/AutoML / \\nlast accessed December 04, 2023.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='262 GENERATIVE AI\\nAutoML encompasses a spectrum of techniques, ranging \\nfrom hyperparameter optimization to meta-learning and neural \\narchitecture exploration. While hyperparameter optimization is \\nall about the automated hunt for the optimal hyperparameter \\ncocktail for specific ML algorithms, meta-learning is the art of \\ngleaning insights from prior modeling endeavors to streamline \\nfuture projects. Neural architecture exploration, on the other \\nhand, is a deep dive into the myriad neural network blueprints, \\nseeking the ideal fit for specific challenges.\\nAutoML is a significant step forward in AI. It speeds up \\ndevelopment and makes AI more user friendly, even for those not \\ndeeply familiar with it.\\nAI-Powered Development Assistants But the real break-\\nthrough in fast and efficient AI development is AI-powered cod-\\ning assistants.\\nT ools like GitHub Copilot and ChatGPT are changing how \\nwe develop software. They use ML to give instant coding help, \\nhandle repetitive tasks, and even create code snippets. They learn \\nfrom the vast amount of code online, giving relevant suggestions \\nthat speed up coding and reduce errors.\\nFrom my work leading AI projects in Europe for Infosys \\nConsulting, I handle many projects at once. Each one needs dif-\\nferent attention at different times. But there are two tools  \\nI always insist my teams use.\\nFirst, every team member should always have ChatGPT \\nPlus, a top-tier language model, open. It’s essential. It helps gen-\\nerate code, reviews and improves existing code, and assists in \\ndocumenting and commenting. It speeds up problem solving, \\nhelping teams work faster. But it’s crucial to ensure that no pri-\\nvate code is shared with ChatGPT to protect it from being \\naccessed by OpenAI or others.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 263\\nSecond, GitHub Copilot is a must-have. It works smoothly \\nwith Visual Studio Code. And with an easy setup and a monthly \\nfee, it keeps an eye on your code and suggests improvements as \\nyou go (see Figure\\xa04.6).\\nBy now, not using GitHub Copilot or ChatGPT is like try-\\ning to work without a laptop. These tools enhance skills and \\nboost productivity. Ignoring them is a big mistake.\\nGenerative AI is not just advancing; it’s self-evolving. By \\nusing generative AI to enhance and create new generative AI \\nmodels, we can say that this technology is fueling its own \\nbreakthroughs.\\nEach stride in this domain signifies a leap, even if a small one, \\nin AI software development. Collectively, these advancements \\nare driving the rapid and exponential growth of AI and ML. \\nWhile this overview isn’t comprehensive, it underscores the \\nrelentless pace of AI model evolution.\\nFIGURE\\xa04.6 GitHub Copilot at work: seamlessly providing Python code \\nsuggestions to enhance developer productivity and streamline \\ncoding tasks.\\nSource: GitHub, Inc /https://github.com/features/copilot / last accessed  \\nDecember 01, 2023.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='264 GENERATIVE AI\\nExponential Growth in\\xa0Data\\nData is the foundation of AI. Because data grows rapidly, it’s \\nimportant to understand how much is expected to be produced, \\nwhether it’s real or artificially created.\\nScaling AI with Big Data\\nAt the heart of this topic is Big Data. This refers to huge amounts \\nof data that are too large for regular data tools to handle. This \\ndata can be structured well organized, semi-structured (a mix, \\nlike emails), or unstructured (messy, like tweets).\\nBig Data is crucial today. It’s the main source for modern AI \\nsystems, providing the information for ML to get better. By study-\\ning Big Data, we can see patterns and trends, especially about how \\npeople behave. This information is very valuable for many, from \\nbusinesses to researchers. It helps in improving ads, giving person-\\nalized suggestions, predicting trends, and spotting fraud.\\nData is key for training AI. It gives AI the information it \\nneeds to learn, make predictions, and get better. Some AI mod-\\nels, as mentioned before, are becoming slightly less data-hungry \\nbecause they’re getting smaller or changing in design, like the \\nliquid neural networks.\\nHowever, the need for data is still growing. We expect to see \\nmany more AI models for different tasks in the future. Some will \\nbe specific, and some will be broad. The more data we have, the \\nmore problems AI can solve. The more detailed the data, the \\nmore specific the solution will be.\\nLastly, remembering the Chinchilla scaling laws, it’s impor-\\ntant to note that as some AI models get bigger, they need signifi-\\ncantly more data to scale their performance according to \\ntheir size.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 265\\nData Growth Today\\nEvery day, we’re creating an immense 328.77\\xa0million terabytes \\nof data. If you’re trying to visualize this, Figure\\xa04.7 might help \\nput things into perspective. Fast-forward a bit, and projections \\nshow that by 2025, this number is expected to rise to approxi-\\nmately 181 zettabytes per year. \\nT o truly grasp the magnitude of this growth, think about this: \\nin 2025, we’ll have about 90 times more data than what was avail-\\nable in 2010. And if we extend our gaze to 2030, using an expo-\\nnential growth model, the anticipated data explosion is simply \\nmind-blowing (see Figure\\xa04.8 and Figure\\xa04.9). The numbers are \\nset to overshadow all previous data generation rates. By 2030, \\nwe’re looking at a world that’s expected to produce a colossal \\n597.10 zettabytes of data. T o put that into context, that’s almost \\n300 times the total amount of data that had been generated from \\nthe start of human history up until 2010.\\nFIGURE\\xa04.7 Digital storage units, from bytes to zettabytes.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='266 GENERATIVE AI\\nFitted Exponential Model until 2022\\n175\\n150\\n125\\n100\\n75\\n50\\n2010 2012 2014 2016 2018\\nYear\\n2020 2022 2024\\n25\\n0\\nGlobal Data Generated Annually\\nFitted Exponential Model from 2023\\nActual Data until 2022\\nPredicted Data from 2023\\nData Size (Zettabytes)\\nFIGURE\\xa0 4.8 Annual global data generation: Historical trends and  \\nprojections through 2025.\\n2010\\n600\\n500\\n400\\n300\\n200\\n100\\n0\\n2012 2014 2016 2018\\nYear\\n2020 2022 2024 2026 2028 2030\\nData Size (Zettabytes)\\nGlobal Data Generated Annually\\nFitted Exponential Model until 2022\\nFitted Exponential Model from 2023\\nActual Data until 2022\\nPredicted Data from 2023\\nPredictions for 2026-2030\\nFIGURE\\xa0 4.9 Annual global data generation: Historical trends and  \\nprojections through 2030.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 267\\nThe Data Growth Drivers\\nDiving deeper into the vast ocean of data, some intriguing figures \\nemerge from reputable online sources like Statista. For instance, \\nvideos dominate Internet data traffic, accounting for a significant \\n53.72 percent in 2023. Every minute, a staggering 231.4\\xa0million \\nemails are dispatched, totaling around 333.22 billion daily. In the \\nrealm of cryptocurrency, we’re seeing millions of purchases daily. \\nOn the social front, Snapchat users share approximately \\n2.43\\xa0 million snaps every minute, which translates to about 3.5 \\n billion snaps daily. The world of online dating isn’t far behind, \\nwith Tinder witnessing around 1.1\\xa0million swipes every minute, \\nor about 1.58 billion daily. In the entertainment sector, about \\n1\\xa0 million hours of content are streamed per minute, amounting to \\nroughly 1.44 billion hours daily. The corporate world, too, is buzz-\\ning, with around 104,600 hours spent in Zoom meetings every \\nminute, leading to a daily total of about 150.62\\xa0million hours.\\nBut what’s fueling these numbers?\\nIoT devices, now ubiquitous in both our homes and work-\\nplaces, constantly churn out data. From smart refrigerators to \\nintricate industrial sensors, the data they produce is harnessed \\nfor diverse applications, including refining device performance, \\npreemptive maintenance, and analyzing user patterns. As their \\nnumbers swell, so does the data they spawn.\\nThe ubiquity of smartphones and similar gadgets has also \\nplayed a pivotal role in this data surge. Every app used, web page \\nbrowsed, or location accessed contributes to this ever-growing \\ndata pool. Social media platforms, with their billions of global \\nusers, are significant data generators. Every post, like, share, or \\ncomment on platforms like Facebook, T witter, Instagram, and \\nY ouT ube adds to this digital deluge. Their primary use of this \\ndata? T ailored advertising and enhancing user experience.\\nStreaming giants like Netflix and Spotify have altered our \\nmedia consumption habits. They meticulously record our'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='268 GENERATIVE AI\\npreferences, using this data to suggest content and discern \\nbroader trends. Their soaring popularity, combined with the \\nburgeoning digital content, inevitably leads to more data.\\nThe pivot to cloud computing has seen businesses shifting \\ntheir operations and storage, leading to more efficient data han-\\ndling but also more data creation. The e-commerce boom, fur -\\nther propelled by the COVID-19 pandemic, sees platforms \\ngathering data on user behaviors, tastes, and buying patterns, \\nusing it for personalized marketing and demand prediction.\\nOther sectors, including academia, healthcare, and more, \\nalso contribute to this data proliferation. But towering above all \\nthese drivers is the realm of AI and ML. These technologies \\nthrive on vast data volumes for training and validation, leading to \\nthe creation of both authentic and synthetic data. Especially in \\nareas like natural language processing, AI can produce new con-\\ntent, further amplifying data growth.\\nIn essence, these myriad factors collectively fuel the data \\nexplosion we’re witnessing today.\\nSynthetic Data\\nAs the number of AI models multiplies, so does the volume of \\ndata they produce. This newly minted data then becomes a \\nresource for training even larger and more efficient AI models.\\nGartner, in a detailed report on synthetic data, forecasted a \\nfuture where the majority of data fueling AI by 2030\\xa0would be \\ncrafted artificially (Figure\\xa04.10). This could be through rule-\\nbased systems, statistical models, simulations, or other innova-\\ntive techniques. The report emphasized, “Building high-quality, \\nvaluable AI models will be nearly impossible without the inclu-\\nsion of synthetic data.”\\nSo, why is synthetic data gaining such prominence? The \\nanswer lies in its inherent advantages. Synthetic data champions \\nboth privacy and scalability. It paves the way for swift expansion'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 269\\nof data-driven products, eliminating the cumbersome processes \\ntypically associated with data collection. Moreover, since it’s arti-\\nficially generated, it sidesteps the privacy pitfalls that often ham-\\nper the utilization of traditional datasets.\\nIn essence, synthetic data promises to be the bridge connect-\\ning the vast reservoirs of real-world data with their practical \\napplications in data-centric products. It promises quicker prod-\\nuct launches, slashes both the costs and time frames of data col-\\nlection, and ensures the confidentiality of sensitive information.\\nExponentially Cheaper Data Storage\\nOne big change is how much cheaper data storage has become. \\nThis isn’t just by chance. Several key reasons are:\\n• T ech improvements: New tools and technologies, like NAND \\nflash-based solid-state drives (SSDs), zoned namespace \\nSSDs, and storage-class memory, have made storage devices \\n-  Artificially generated data\\n-  Generated from simple rules,\\n   statistical modeling, simulation,\\nand other techniques\\n-  Obtained from direct\\n   measurements\\n-  Constrained by cost,\\n   logistics, privacy reasons\\n2020 2030\\nFuture AI\\nToday’s AI\\nSYNTHETIC DATA\\nData used for AI\\nREAL DATA\\nFIGURE\\xa04.10 Evolution of real vs. synthetic data ratios over time.\\nSource: https://htecgroup.com/could-synthetic-data-be-the-future-for-machine- \\nlearning-models and Gartner, “Maverick Research: Forget about Your Real Data\\xa0–  \\nSynthetic Data Is the Future of AI”\\xa0– 24\\xa0June 2021'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='270 GENERATIVE AI\\nbetter and more spacious. This means lower costs for \\nstoring data.\\n• Economies of scale: As more people need data storage, it’s \\ncheaper to make in large quantities. Big cloud and datacenter \\ncompanies can also offer cheaper storage because of their \\nsize and focus.\\n• Competition: Many companies are in the data storage busi-\\nness, and they’re all trying to offer the best prices to get \\nmore customers. This competition leads to better prices \\nfor everyone.\\n• Cloud storage: More companies are using cloud providers or \\ncolocation services for their data storage. This can be cheaper \\nthan having their own datacenters. Cloud providers can \\noffer good prices because they serve many customers and \\nspread out the costs.\\nIn short, the plummeting costs of data storage can be attrib-\\nuted to technological prowess, surging demand, fierce competi-\\ntion, and the ascent of cloud storage. But this is just the tip of \\nthe iceberg.\\nTrends in\\xa0Data\\nThe data revolution is not merely confined to storage costs. As \\nhighlighted before, there’s a burgeoning reservoir of data that’s \\nfueling the enhancement of AI models, pushing the boundaries \\nof their performance and accuracy, especially when compared to \\nthe earlier Chinchilla models. The fascinating aspect is that AI is \\nnot just a beneficiary of this data deluge but also a catalyst. AI is \\nnow in a position to aid its own evolution by generating the very \\ndata it thrives on.\\nY et, several undercurrents are shaping the future of data, \\ntrends that haven’t been fully explored. Among these are the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 271\\nemergence of edge computing, advancements in wireless tech-\\nnology like 5G, and the dawn of quantum computing.\\nEdge computing, a paradigm shift in data processing, is rede-\\nfining the norms. By positioning computation and data storage \\nproximate to data sources, it optimizes response times and con-\\nserves bandwidth. This approach is a game-changer, amplifying \\ndata growth by facilitating real-time analytics, catalyzing the \\nexpansion of the IoT , and ushering in a new era of instantaneous \\napplications and services.\\nThen there’s 5G, the latest iteration in wireless technology, \\npromising swifter data transfers, diminished latency, and robust \\nconnections. The ripple effects of 5G on data growth will be \\nprofound. Its rapid transfer rates mean data is churned out and \\nprocessed at breakneck speeds. The technology’s capacity to \\ntether a multitude of devices concurrently amplifies the IoT’s \\nfootprint, leading to a surge in data creation. Moreover, 5G’s \\nrobustness paves the way for data-hungry applications, from \\nreal-time analytics to self-driving cars and immersive AR and \\nvirtual reality (VR) experiences.\\nFor perspective, while using L TE (a 4G variant) on a smart-\\nphone, we might experience peak download speeds of 1.5\\xa0Gbps. \\nIn contrast, 5G promises a staggering 10\\xa0Gbps. But the real spec-\\ntacle is the anticipated 6G, with speeds that could touch a mind-\\nboggling 1 Tbps or 1,000\\xa0Gbps. This translates to an exponential \\nleap, with 6G projected to be a hundredfold faster than 5G. \\nImagine downloading content equivalent to 142 hours in a mere \\nsecond! Industry insiders are buzzing with anticipation, predict-\\ning 6G’s commercial rollout around 2030.\\nHowever, a word of caution is in order. While these figures \\nare impressive, real-world download speeds can often be a far cry \\nfrom these theoretical maxima. Factors such as the service pro-\\nvider, network conditions, contractual terms, and even signal \\nstrength can temper these speeds.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='272 GENERATIVE AI\\nExponential Patterns in\\xa0Research, Development, \\nand Financial Allocations\\nThe evolution in AI is driven by advanced ML algorithms, an \\nopen source culture, and a suite of tools and libraries that stream-\\nline AI development. Key to this progress is substantial invest-\\nment in AI research from both private and public sectors, enabling \\npractical applications. The emergence of GenAI demonstrates \\nreal-world value. Additionally, the influx of talented researchers \\nand accessible training materials democratizes AI knowledge, \\nfostering potential breakthroughs from around the world. This \\nblend of research, development, and funding is crucial for AI’s \\nintegration into everyday life.\\nInvestments in AI Research\\nAI giants like Runway ML, Hugging Face, Anthropic, OpenAI, \\nand Google DeepMind have seen their valuations skyrocket, \\nhighlighting the growing investments in this sector. A closer look \\nat the trends shows a clear rise in AI funding over the years. \\nWhile global politics and economic shifts can influence these \\ninvestments, the overall trend points to a rapid increase in AI \\nfunding, suggesting exponential growth.\\nIn 2022, AI startups attracted a whopping $52.1 billion in \\ninvestments across 3,198 companies. Notably, generative AI pro-\\njects secured $4.5 billion of this funding, as reported by Pitch-\\nBook. The momentum continued into the first half of 2023, with \\ngenerative AI companies globally receiving around $15.2 billion, \\nunderscoring the rising interest in this AI niche— if niche is even \\nthe right term by now.\\nHere are some standout investments from the past 18\\xa0months, \\nas of this writing:\\n• Anthropic: Anthropic recently secured $450\\xa0 million in a \\nSeries C funding round. Spark Capital led the investment,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 273\\nwith significant contributions from Google, Salesforce Ven-\\ntures, Sound Ventures, Zoom Ventures, and other notable \\ninvestors. Google alone invested $300\\xa0million, as Anthropic \\nworks on a competitor to OpenAI’s ChatGPT .\\n• Inflection AI: Inflection AI recently secured $1.3 billion in \\nfunding in the latest funding round. This round was spear -\\nheaded by notable investors including Microsoft, Reid Hoff-\\nman, Bill Gates, Eric Schmidt, and NVIDIA. This investment \\nhas catapulted the valuation of the one-year-old startup to \\n$4 billion. The funds are earmarked for the enhancement of \\nInflection AI’s personal AI assistant, “Pi”, and for construct-\\ning a 22,000-unit NVIDIA H100 T ensor GPU cluster, \\ntouted as the world’s largest.\\n• Cohere: Cohere recently secured $270\\xa0million in a Series C \\nfunding round. Inovia Capital spearheaded the round, joined \\nby notable investors such as NVIDIA, Oracle, Salesforce \\nVentures, DTCP , SentinelOne, Mirae Asset, Schroders Cap-\\nital, Thomvest Ventures, and Index Ventures. Announced in \\nJune 2023, this investment boosted the valuation of the \\nT oronto-based AI startup to $2.2 billion.\\nThe AI sector is experiencing a surge in investments, particu-\\nlarly in generative AI technology. Key players include Salesforce \\nVentures, which recently increased its Generative AI Fund to \\n$500\\xa0million, and SoftBank Group, with its massive Vision Funds \\ntotaling $154 billion. Additionally, the AI seed investment land-\\nscape features over 4,000 entities, including prominent firms like \\nGeneral Catalyst, NFX, and LAUNCH. Venture capital heavy-\\nweights such as Andreessen Horowitz, Sequoia, Khosla Ventures, \\nand Greylock Partners are also actively investing in generative \\nAI startups, among many others.\\nDespite all investments and attention, amidst the buzz, a \\nchorus of skepticism is growing increasingly audible.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='274 GENERATIVE AI\\nBeing a nascent technology, there’s a tangible risk of its \\npotential being blown out of proportion. Investors, eager to jump \\non the bandwagon, might pour money into generative AI ven-\\ntures without a clear grasp of the tech’s intricacies or the mar -\\nket dynamics.\\nIt’s worth noting that generative AI is still finding its feet. \\nThe road ahead is rife with uncertainties about its evolution and \\neventual applications. The field is also crowded, with numerous \\nplayers vying for a piece of the pie. For startups, standing out \\namidst this fierce competition is a daunting task. Drawing a par-\\nallel, back in the 1920s and 1930s, the United States market had \\nover 2,000 car manufacturers. Y et, in a short span, this number \\ndwindled to 44. By the 1940s, the big three— Chrysler, Ford, and \\nGM— emerged as the undisputed leaders, capturing a staggering \\n90 percent of U.S. car sales.\\nFurthermore, like any powerful tool, generative AI can be a \\ndouble-edged sword. Its capabilities can be harnessed for com-\\nmendable purposes or misused with detrimental consequences. \\nThis duality brings forth pressing ethical dilemmas. As a result, \\ninvestors are urged to tread cautiously, weighing the moral impli-\\ncations before deciding where to place their bets.\\nThe Real Value of Generative AI\\nGenerative AI is different from past tech trends. Why? It’s not \\njust hype; it’s a technology that offers real value. This AI has \\nmany uses in the real world, from creating content to helping in \\nmedicine and science. And it’s attracting a lot of money and inter-\\nest because of its potential to change many industries.\\nIn this book, we’ve talked about how flexible generative AI is. \\nIt’s being used in many areas like making content, helping doc-\\ntors see inside the body, creating new drugs, and even in mate-\\nrial science.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 275\\nThis AI is already helping people work better and faster. And \\nas more people start using it, it could add trillions of dollars of \\nvalue to the world. It’s not just about changing jobs; it’s about \\nmaking them better.\\nA 2023 survey by Namecheap showed how popular genera-\\ntive AI tools are becoming. Forty percent of people said they use \\nthem every day, and 10 percent use them every month. The most \\npopular tool was ChatGPT , with 70 percent of users picking it. \\nDALL-E and Midjourney were next, with about 30 percent of \\nusers liking them.\\nBut it’s not just about how much is spent on these tools. It’s \\nalso about how they can save time and money. Generative AI \\ndoesn’t just replace people; it helps them do their jobs better. It \\ncan handle the boring tasks, letting people focus on more cre-\\native work.\\nTalent and Self-Learning in\\xa0Tech\\nThe tech and AI sectors have seen a massive surge in skilled pro-\\nfessionals in recent times. Why? Companies are updating their \\ntech systems and embracing AI, creating a huge demand for \\nexperts in these areas. Jobs linked to AI often pay well and require \\na college degree and sharp analytical skills.\\nThe competition for tech experts is heating up. There’s a big \\ndemand for roles like ML Architect and Prompt Engineers, but \\nnot enough skilled folks to fill them. We’re talking about AI \\nengineers, research scientists, data scientists, and so forth.\\nBut here’s the exciting part: A fresh wave of young profes-\\nsionals is stepping in. Some older folks might label them as lazy \\nor clueless, but I see them differently. This new generation is \\npractical, values being real, and is super diverse.\\nHere’s a fun fact: Gen Z grew up with the Internet, smart-\\nphones, and even AI as everyday things. They’re the real tech'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='276 GENERATIVE AI\\npros! Plus, they’re setting records in education. More of them \\nare finishing high school and fewer are dropping out. In 2018, a \\ntotal of 57 percent of those aged 18 to 21\\xa0were in college. That’s \\nmore than millennials and Gen Xers when they were that age. \\nAnd guess what? Many Gen Z folks prefer trade or tech schools \\nover traditional colleges.\\nSpeaking of learning, there are so many ways to learn about \\ntech and AI now. Y ou’ve got online courses on platforms like \\nCoursera and edX. Books, like the one you’re reading right now. \\nThere are also tutorials, podcasts, and online communities like \\nQuora and Reddit. And don’t forget Y ouT ube! Channels like \\nSentdex and Deeplearning.ai share loads of AI stuff.\\nThis new generation learns fast and in their own unique \\nways. This helps them think out of the box, start their own busi-\\nnesses, team up with people worldwide, and keep up with the \\never-changing tech world. They’re definitely one step ahead \\nof the rest!\\nDiving into the realm of IT/ICT (information and commu-\\nnication technology), there’s a clear upward trend that’s hard to \\nmiss. While we might not have a single number that captures the \\nglobal AI workforce’s growth, we’ve got some pretty telling stats \\nto look at.\\nFor starters, between 2006 and 2018, the number of ICT \\nprofessionals worldwide shot up by a notable\\xa029 percent. Zoom-\\ning into the European Union, the growth is even more impres-\\nsive. From 2012 to 2022, the count of ICT specialists in the EU \\nskyrocketed by a whopping 57.8 percent. That’s nearly seven \\ntimes the growth rate of other jobs!\\nThe World Economic Forum has some big predictions too. \\nThey believe that by 2025, close to 100\\xa0million people around \\nthe world will be working in AI. Given the current momentum, \\nI’d say that number might climb even faster than we think.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 277\\nNow, let’s talk about where all these tech wizards are coming \\nfrom. Russia leads the pack with over 454,000 folks graduating in \\nengineering and similar AI-related professions every year. The \\nUnited States isn’t far behind with 237,826 graduates, followed \\nclosely by Iran and then Japan.\\nBut there’s one country that’s a real powerhouse in the tech \\nworld: India. With a tech army of over 5\\xa0million professionals \\nand a tech industry worth a cool $200 billion, India is a force to \\nbe reckoned with. I’ve had firsthand experience working with \\nIndian teams during my time at IBM consulting and later at \\nInfosys consulting. The talent, dedication, and work ethic I’ve \\nseen is truly commendable.\\nAI Research Goes Private\\nThe AI research field is increasingly leaning toward the private \\nsector, a trend offering both opportunities and challenges. From \\nmy perspective, witnessing peers from academia transition to \\nlucrative corporate roles underscores the appeal of this shift. The \\nfinancial power of private companies, exemplified by IBM’s $6.57 \\nbillion investment in research only in 2022, drives significant \\nadvancements in AI research and development.\\nBut it’s not just about the money. Private companies are \\ninherently geared toward translating AI research into tangible, \\nmarket-ready products. This not only benefits the corporate bot-\\ntom line but also enriches the consumer experience.\\nThe private sector’s agility in quickly transforming AI \\nresearch into practical applications across industries is a key \\nadvantage.\\nMoreover, the lines between academia and industry are blur-\\nring. Collaborative endeavors between private corporations and \\nacademic institutions are on the rise, fostering a symbiotic  \\nrelationship where knowledge dissemination meets resource \\nallocation.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='278 GENERATIVE AI\\nThis pivot toward private sector–led research is a significant \\neconomic driver, birthing new job roles, stimulating economic \\ngrowth, and ensuring companies remain at the forefront of their \\nindustries. In essence, as AI R&D finds its home in the private \\nsector, it promises a future where innovation thrives, economies \\nflourish, and societies benefit.\\nRequirements for\\xa0Growth\\nDiving deep into the research, it’s evident that the AI landscape \\nis on an accelerated trajectory. The leaps in computational capa-\\nbilities, in both hardware and software, are astounding. The \\nsurge in data availability, coupled with affordable storage solu-\\ntions, further fuels this momentum. Add to this the significant \\ninvestments in R&D, the collaborative spirit of open source \\ncommunities, and the fresh perspectives brought in by Gen Z, \\nand it’s clear: we’re on the cusp of an AI revolution that promises \\nto redefine humanity’s progress.\\nThe AI-Driven Economy\\nARK Investment Management LLC’s insights offer a compelling \\nperspective on this (Figure\\xa04.11). Their analysis paints a picture \\nof how technology has historically been a catalyst for macroeco-\\nnomic growth. For context, from the dawn of civilization until \\n1900, the global real GDP growth per year hovered below 1 per-\\ncent. Fast-forward to the period between 1900 and 2021, and \\nthis figure jumped to an average of 3 percent annually. ARK’s \\nprojections, rooted in technological trends, are even more stag-\\ngering. They anticipate an annual global GDP growth of 6.1'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 279\\npercent by 2030, soaring to 10.7 percent by 2040. Annually! This \\nmeans by 2030 a theoretical jump of 42 percent, and by 2040 the \\nGDP could theoretically reach 508 percent of today. This isn’t \\njust growth; it’s a transformative shift in the global economic  \\nfabric, with AI, especially generative AI, at its heart.\\nY et, much like in the natural world, growth in the tech ecosys-\\ntem isn’t boundless and follows one trajectory. Just as biological \\nsystems have their constraints, the AI domain isn’t immune to lim-\\niting factors. Understanding what might hinder our path is crucial. \\nBy identifying and addressing these challenges, we can ensure that \\nthe technological renaissance we’re witnessing translates into tan-\\ngible benefits for humanity. In essence, these considerations aren’t \\nGlobal Real GDP* Growth\\nLog Years Until 2050**\\n8.5%\\nCompound Annual Growth Rate\\nForecast Consistent with\\nTechnological History\\nConsensus\\nForecast\\n3%\\n0.6%\\n10.00%\\n1.00%\\n0.10%\\n0.01%\\n100,000BC 11 0001 500 1900 2021 2040\\nHistorical data\\n0.3%\\n2.6%0.14%\\n0.037%\\nFIGURE\\xa0 4.11 ARK Investment Management’s projections: a tale of \\ntwo futures.\\nSource: NM Writings / A Medium Corporation / https://medium.com/coinmonks/\\nbig-ideas-2023-ark-invests-crypto-part-1-out-of-2-4a382bfe35a1 / last accessed \\nDecember 04, 2023.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='280 GENERATIVE AI\\njust obstacles; they’re the very blueprint we need to ensure sus-\\ntained and meaningful growth.\\nChallenges to AI Progression\\nWhat might impede our journey toward AI-driven technological \\nprogress? While we’re setting aside natural disasters like earth-\\nquakes and tsunamis, there are several human-made factors that \\ndeserve our attention. These include regulatory challenges, hesi-\\ntancy in AI adoption, economic and political dynamics, and tal-\\nent shortages.\\nRegulation is a double-edged sword. On one hand, it’s essen-\\ntial for ensuring that AI technologies are developed and deployed \\nresponsibly. On the other, excessive or ill-conceived regulations \\ncan stymie innovation. Governments worldwide are grappling \\nwith the challenge of crafting AI policies. This regulatory uncer-\\ntainty can deter businesses and researchers, adding complexities \\nand costs to AI initiatives. Overemphasis on certain aspects, such \\nas data accessibility restrictions or an excessive focus on explain-\\nability, can hinder progress. For instance, if regulations make set-\\nting up experimental AI projects too cumbersome, it could deter \\ninnovation.\\nHowever, it’s not all gloom. Some nations are leading the \\nway with balanced and forward-thinking AI strategies. Countries \\nlike Canada, South Korea, the United States, Japan, and notably, \\nSingapore, are setting commendable examples. Singapore, in \\nparticular, stands out with its ambitious vision to be at the fore-\\nfront of AI by 2030. Their approach strikes a balance: They pri-\\noritize data privacy and ethical AI use without stifling innovation. \\nTheir collaborations with global tech giants like Google Cloud \\nand their engagement with the open source community through \\ninitiatives like the AI Verify Foundation are testament to their'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 281\\nprogressive stance. Additionally, Singapore’s emphasis on educa-\\ntion and talent development ensures they have the human capital \\nto realize their AI aspirations.\\nOne of the significant challenges in our journey toward an \\nAI-centric world is the rate at which AI is embraced by both \\nbusinesses and individuals:\\n• Ethical dilemmas: The ethical landscape of AI is vast and \\ncomplex. Concerns about biases in AI algorithms, potential \\nmisuse in surveillance, and other moral quandaries can deter \\nits widespread adoption. As developers and innovators, we \\nbear the responsibility to ensure AI serves the broader good \\nof society.\\n• Knowledge gaps: A significant barrier is the lack of compre-\\nhensive understanding of AI’s capabilities. Many, from indi-\\nvidual users to large corporations, are either unaware of  \\nAI’s potential or have misconceptions about its limits.  \\nGenerativeAI.net aims to bridge this gap, educating both \\nindividuals and businesses. Fortunately, tech giants like \\nGoogle have also stepped up, offering educational platforms \\nto demystify AI.\\n• Financial constraints: The financial aspect of AI can’t be \\nignored. While AI promises incredible returns, the initial \\ninvestment can be daunting. OpenAI’s CEO, Sam Altman, \\nhighlighted this when he revealed that training GPT-4 cost \\nover $100\\xa0million. And the projections suggest that by 2030, \\ntraining advanced AI models could skyrocket to a staggering \\n$500\\xa0million. Such figures can be intimidating, especially for \\nsmaller enterprises.\\n• Cultural and generational variances: Acceptance of AI isn’t uni-\\nform across all demographics. Different age groups and cul-\\ntural backgrounds approach AI with varying degrees of trust'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='282 GENERATIVE AI\\nand enthusiasm. While some are eager to integrate AI into \\ntheir daily lives, others approach with caution, if not skepti-\\ncism. Navigating these diverse attitudes and finding a uni-\\nversally acceptable path is a nuanced challenge.\\nEconomic, political, and even military conflicts can signifi-\\ncantly impact the trajectory of AI development. For instance, the \\ndevastating war between Ukraine and Russia has resulted in not \\nonly human suffering but also massive economic repercussions. \\nBy March 2023, the World Bank estimated that Ukraine already \\nneeded $411 billion over the next decade for recovery and recon-\\nstruction. Meanwhile, Russia’s daily expenses for the war range \\nbetween $500\\xa0million and $1 billion. One can’t help but wonder \\nhow transformative it would be if such resources were redirected \\ntoward secure AI development, tech education, and sustainable \\ninnovations.\\nWhile there’s undeniable enthusiasm for AI, the industry still \\ngrapples with a talent shortage. The demand for AI professionals \\nfar outstrips the supply, and this gap is projected to continue \\nuntil 2030. The strength and potential of the upcoming genera-\\ntion are commendable, but demographic challenges loom large. \\nCountries like Bulgaria are projected to see significant popula-\\ntion declines. By 2050, Bulgaria’s population might reduce to \\n5.4\\xa0million from 6.9\\xa0million in 2020. This decline isn’t isolated; \\nmany nations, especially in Eastern Europe and parts of Asia, are \\nwitnessing similar trends due to falling fertility rates, aging pop-\\nulations, and low immigration. These demographic shifts can \\nstrain economies and healthcare systems and alter workforce \\ndynamics. Elon Musk has even expressed concerns about a \\npotential population collapse.\\nReturning to the ARK survey, while it does also offer a more \\nconservative outlook, it still paints a picture of growth. The survey'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Exponential Growth 283\\nsuggests a potential global GDP growth of 3 percent by 2030 and \\n2.1 percent by 2040. While some might view this as a cause for \\nconcern, I remain hopeful. Throughout history, there have always \\nbeen voices of doom, but innovation and human resilience have \\noften prevailed. Perhaps, as we face future challenges, our collec-\\ntive ingenuity will once again guide us toward brighter horizons.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content=''),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='285\\nG\\nenerative AI, with its vast potential and transformative capa-\\nbilities, is not without its ethical quandaries and societal rami-\\nfications. The following concerns, which are both profound and \\nmultifaceted, demand our attention and thoughtful consideration:\\n• Intellectual property rights and ownership\\n• Misinformation, particularly through tools like deepfakes\\n• Privacy, safety, and security\\n• Generative AI’s impact on the job market and industries\\n• Our increasing dependency on AI\\n5\\nCHAPTER\\nEthical Concerns and Social \\nImplications of Generative \\nAI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='286 GENERATIVE AI\\n• Environmental concerns tied to AI\\n• AI oversight and self- regulation\\nThese pressing issues not only are of utmost importance for \\nthe clients I have worked with and talked to, but also echo in \\nbroader conversations across the globe. The journey into the \\nfuture of generative AI is filled with promise, but it’s essential to \\nnavigate it with caution, awareness, and responsibility.\\nThe intricacies of large language models (LLMs) often \\nintertwine with their occasional inaccuracies and a lack of con-\\ntextual understanding. This can sometimes lead to a failure to \\ngrasp the nuances of specific workplace scenarios, potentially \\nmisinforming individuals. Hence, it’s imperative to emphasize \\nthe importance of source referencing when relying on such  \\nmodels.\\nThe aim of this chapter is to delve not into the technicali-\\nties of AI but rather into the broader mindset, rules, and atti-\\ntudes surrounding it. The pillars of transparency, education, \\nregulation, and security are paramount. Ultimately, our dis-\\ncourse converges on the ethical concerns and societal implica-\\ntions of AI.\\nIt’s worth noting that certain topics can straddle the line \\nbetween an ethical concern and a societal implication, which is \\nwhy I’ve chosen not to make a clear distinction between the two. \\nWhile each of these subjects could be exhaustively explored, \\npotentially warranting a doctoral thesis of its own, my aim here \\nis to provide a comprehensive overview, highlighting the nuances \\nwithout getting lost in the minutiae.\\nA word of caution: I don’t claim to be a legal expert. The \\nlandscape of AI and its regulations is ever- evolving, so always \\nseek guidance from a legal professional for specific situations. \\nThe perspectives shared here are solely mine, derived from'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 287\\nextensive research and myriad discussions. Where appropriate, \\nI’ll offer recommendations.\\nNavigating the labyrinth of regulations is no small feat, espe-\\ncially when addressing a technology that’s still in its nascent stages, \\nwith many of its implications being theoretical. The regulatory \\napproach to AI varies significantly across countries; some nations \\nadopt a more hands- on stance while others tread with caution.\\nLastly, addressing the multifaceted ethical and societal  \\nchallenges posed by AI is not a solitary endeavor. It demands a \\nconcerted effort from technologists, policymakers, ethicists, and \\nsociety as a whole. Crafting a future where AI aligns with our \\nethical values and principles necessitates smart regulations in \\ncombination with self- regulation, unwavering commitment to \\ntransparency and accountability, and a collective will to ensure \\nresponsible AI design and deployment.\\nIntellectual Property and the Generative \\nAI Platform\\nIn the rapidly evolving landscape of AI, the legalities surround-\\ning intellectual property (IP) rights are in constant flux. It’s \\nimperative for professionals and users alike to stay abreast of \\nlocal laws. When navigating the intricate waters of AI and IP , \\nconsulting with legal professionals is always a prudent step.\\nOne of the most pressing questions in this domain is: Who \\nowns the intellectual property rights of the content generated by \\nthe AI? T o address this, it’s essential to first differentiate between \\nownership, owning the IP rights, and copyright.\\nOwnership pertains to the possession or holding of an item. \\nFor instance, when you purchase a book, that physical copy \\nbelongs to you. On the other hand, owning IP rights means'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='288 GENERATIVE AI\\nhaving legal control over an idea, invention, or creation. This \\nencompasses patents, trademarks, and copyrights. Using the \\nbook analogy, while you possess the physical book, the unique \\nideas, characters, or methods within are protected by IP rights, \\ngranting exclusive usage, sale, or licensing privileges. Copyright, \\na subset of IP rights, is a legal provision that gives the creator of \\nan original work exclusive rights to its use and distribution. So, \\nalthough you own the book you bought, you can’t reproduce its \\ncontent for sale, as the copyright typically belongs to the author \\nor publisher.\\nThe matter of IP rights for AI- generated content is intricate \\nand varies across jurisdictions and terms of use. Historically, IP \\nrights have been attributed to human creators. However, the \\nadvent of AI- generated content has muddied these waters. While \\nthere are scattered regulatory guidelines globally, a comprehen-\\nsive solution remains elusive.\\nA growing concern in this field is the likelihood of AI tools \\nbeing trained on copyrighted content without obtaining the req-\\nuisite permissions. This issue has been thrust into the spotlight \\nby recent legal confrontations, notably the case involving Sarah \\nSilverman, an acclaimed American stand- up comedian, actress, \\nand writer. Silverman, along with other authors, has taken on \\ntech behemoths like OpenAI and Meta, emphasizing the intri-\\ncate nature of copyright violations in the AI sphere. Silverman’s \\ncontention is that OpenAI never secured her consent to use the \\ndigital rendition of her book for training their AI models. In a \\nsimilar vein, legal actions, such as the one where Getty Images \\nchallenged Stable Diffusion over unauthorized content usage, \\naccentuate the urgent need for definitive guidelines in this area.\\nIn the European Union, the stance on copyrightability is \\nclear- cut: AI- generated works are not eligible for copyright  \\nprotection. The Court of Justice of the European Union'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 289\\nmandates human involvement for a work to be copyrighted. \\nPurely computer- generated outputs, devoid of human contribu-\\ntion, don’t qualify. However, such AI outputs might find protec-\\ntion under related rights, such as sound recording rights, with \\nthe AI software user likely being the rights holder.\\nThe UK’s approach to copyrightability is more intricate. \\nWhile original literary, dramatic, musical, and artistic works are \\nprotected, they must be the author’s creations and display origi-\\nnality. If a human, with AI assistance, creates a work that exhibits \\nhuman creativity, the AI is merely a tool and the human retains \\nthe rights. However, the UK does offer protection to works gen-\\nerated solely by computers, provided they meet the originality \\ncriterion. The challenge lies in the fact that generative AI often \\ntests this standard of originality.\\nLastly, the terms and conditions of AI programs often house \\ncrucial information regarding IP rights. Companies like Mid-\\njourney, OpenAI, and Stability AI outline specific terms about \\nthe ownership of AI- generated content. However, these details, \\noften buried in fine print, are frequently overlooked by users, \\nleading to potential misunderstandings. For example, while  \\nOpenAI permits users to own the content they produce, it reserves \\nthe right to utilize it for service enhancement, aka model training.\\nIf an AI tool produces content that treads on the intellectual \\nproperty of another, the question of liability becomes paramount.\\nIn numerous scenarios, the end users, who utilize the AI for \\ncontent generation and subsequently disseminate or employ  \\nthat content, might find themselves in the crosshairs of legal \\naction for any infringement. This is particularly the case if the \\nuser’s specific prompts or data inputs steer the AI toward infring-\\ning content. On the other hand, the AI service provider could \\nalso shoulder some of the blame, especially if they had prior \\nknowledge of potential infringement risks or if their tool'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='290 GENERATIVE AI\\nhabitually churns out content that breaches copyright. That said, \\nmany AI service terms explicitly shift the responsibility burden \\nonto the user, absolving the provider of any potential legal \\nentanglements.\\nT o sidestep the quagmire of infringement, several measures \\ncan be adopted:\\n• AI developers must prioritize legal compliance when sourcing  \\ndata.\\n• Establishing and maintaining a clear lineage of AI- generated \\ncontent can help trace back any potential issues.\\n• Vigilance is key for content creators to spot potential \\ninfringements.\\n• Companies should closely review deal conditions to protect \\ntheir intellectual property.\\n• Constructing proprietary datasets for AI training can offer \\nmore control and reduce infringement risks.\\n• At the user’s end, it’s paramount to honor the rights of original \\ncontent creators, ensuring their work isn’t misappropriated.\\nThe nature of the content produced by an AI model can \\noften be swayed by the training data it’s been fed. This brings  \\nto light another pertinent question: Who holds the rights to the \\nAI model itself, encompassing its architecture, weights, and \\nalgorithms?\\nAs a general rule of thumb, the rights to the AI model typi-\\ncally rest with the entity— be it an individual or an organization— \\nthat played a pivotal role in its development. However, if the \\nmodel’s creation was under the purview of an employment con-\\ntract or a specific agreement, the rights might be vested in the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 291\\nemployer or the contracting party. The waters get murkier with \\nopen source models. While the original creators retain the copy-\\nright, they extend certain privileges to others, allowing them to \\nuse, adapt, and distribute the model. The exact nature of these \\nrights and any accompanying obligations hinge on the stipula-\\ntions of the open source license under which the model \\nwas released.\\nBias and Fairness in AI- Generated Data\\nIn the rapidly evolving realm of generative AI, the ethical onus \\non AI practitioners such as AI researchers and AI engineers is \\nparamount. As stewards of this transformative technology, they \\nbear the responsibility of not just creating but also continuously \\nrefining AI models to reflect the ever- shifting tapestry of societal \\nnorms and values. This necessitates a vigilant approach to AI, \\none that’s steeped in a critical mindset, perpetually probing and \\nvalidating the fairness of the outputs it generates.\\nHow Bias Is Introduced into Generative AI Models\\nBias, an unwelcome specter, can insidiously creep into generative \\nAI models through myriad avenues. One of the most prevalent \\nculprits is biased training data. When the foundational data used \\nto train an AI system skews toward a particular demographic or \\nperspective, the system, in all likelihood, will mirror these biases \\nin its results. Such a scenario can manifest when the training data \\npresents an imbalanced representation of various groups, causing \\nthe AI model to internalize and reproduce these inherent biases. \\nThe repercussions of leveraging incomplete, erroneous, or  \\nprejudiced datasets for the training and validation of machine \\nlearning systems can be far reaching and detrimental.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='292 GENERATIVE AI\\nY et, the very architects of these systems, the individuals who \\ndesign and train the machine learning algorithms, can inadvert-\\nently infuse their creations with biases. These could range from \\nunintentional cognitive biases to more deep- seated prejudices. \\nFurthermore, the very blueprint of the AI model, its architecture, \\ncan be a source of bias. Specific architectural decisions might \\ninadvertently prioritize certain data patterns or features, leading \\nto skewed representations. Even seemingly innocuous elements \\nlike loss functions and regularization techniques can play a role \\nin introducing bias.\\nHuman interpretation of AI outputs is another potential pit-\\nfall. The lens through which AI- generated results are viewed and \\ninterpreted can be colored by individual biases, leading to skewed \\nconclusions.\\nT o fight these biases, we need a clear plan. Start with using \\nvaried and balanced data. It’s also crucial to watch out for biases \\nwhen choosing and reading data. By regularly checking and test-\\ning AI systems, we can spot and fix hidden biases. Understanding \\nhow the AI model’s design affects its actions is also key.\\nWorking toward a bias- free generative AI is an ongoing \\neffort. It requires constant attention, self- reflection, and a strong \\ndedication to ethics.\\nThe Implications of Biased AI- Generated Data on Real- World \\nApplications\\nBiased AI- generated data can have significant real- world conse-\\nquences. Organizations using skewed AI data risk legal challenges, \\npotentially facing lawsuits or regulatory actions. This bias can also \\nlead to discrimination in sectors like recruitment, finance, and \\nhealthcare, where AI might favor certain demographics.\\nCompanies using biased AI risk damaging their reputation, \\naffecting their brand and customer trust. Furthermore, decisions'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 293\\nbased on biased AI can result in financial losses for businesses \\nand individuals alike.\\nAt a societal level, biased AI can exacerbate existing preju-\\ndices, deepening societal divides and reinforcing inequalities. \\nSuch biases can also diminish public trust in AI, limiting its \\nbroader acceptance and potential benefits.\\nT o counteract these challenges, organizations must actively \\nidentify and address biases in AI data. This includes using diverse \\ntraining data, regularly evaluating AI systems, and considering \\nthe ethical implications of AI decisions. Ultimately, though AI \\noffers immense potential, it’s crucial to use it responsibly to \\nensure fairness and inclusivity.\\nDetecting and Measuring Bias in AI- Generated Data\\nThe complexities of bias detection in AI- generated data call for a \\ncomprehensive approach. Here’s a closer look at the strategies \\nand techniques that can be employed.\\nA deep dive into the data that trains the AI model can shed \\nlight on inherent biases. The key is to ensure this data mirrors \\nthe broader population, thereby minimizing skewed outcomes.\\nFairness metrics come to the rescue when quantifying bias. \\nMetrics like disparate impact and equal opportunity difference \\ncan pinpoint how the model might be leaning toward cer -\\ntain groups.\\nThe tech industry has developed tools such as AI Fairness \\n360, Algorithmic Bias Detection T ool, Bias Analyzer, and Aequi-\\ntas. These tools are designed to identify and correct bias in AI \\ndata effectively.\\nAnother effective strategy is to pit the AI model against dedi-\\ncated external benchmark data, such as the COMPAS datasets  \\nfor predictive policing biases, BiasBios for gender bias in named- \\nentity recognition, and FairFace for biases in facial recognition.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='294 GENERATIVE AI\\nDatasets specifically designed to benchmark bias can be invalu-\\nable in this exercise.\\nThe human element can’t be overlooked. A team that’s \\ndiverse in terms of backgrounds and experiences can offer varied \\nperspectives, acting as a safety net against biases that might oth-\\nerwise slip through.\\nThe AI model should be under constant scrutiny. Regular \\ntests, coupled with rigorous monitoring and audits, can keep \\nbiases in check. This vigilance should span the entire spectrum of \\nthe AI model, from its input and logic to its behavior and output.\\nHowever, the journey to bias detection isn’t without its chal-\\nlenges. There are often tough choices to make, like striking a \\nbalance between transparency and privacy or juggling fairness \\nwith accuracy. This underscores the need for AI models to be in \\na state of constant evolution, with regular tweaks to iron out \\nbiases and uphold fairness.\\nEnsuring Fairness in AI- Generated Data Without Compromising \\nData Privacy\\nSwitching gears to the delicate balance between fairness and data \\nprivacy in AI- generated data, here’s a roadmap.\\nLaying the groundwork for privacy should start at the very \\nonset of AI model development. T echniques like differential pri-\\nvacy, federated learning, and secure multiparty computation can \\nbe game changers, allowing for in- depth data analysis without \\ncompromising individual privacy.\\nAnonymizing data is another potent tool. By stripping data-\\nsets of personally identifiable information or encrypting this \\ndata, the privacy of individuals remains intact.\\nT ransparency is paramount. Individuals should be in the loop \\nabout how their data is being used. Informed consent, where \\nindividuals are apprised of the nuances of data usage, empowers \\nthem to have a say in the process.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 295\\nSynthetic data is a new and promising area in AI. It’s made \\nartificially to match the real data’s statistical features, making it \\nvaluable for training AI models, including generative AI models. \\nThe great thing about synthetic data is that it reflects real- world \\nsituations without risking the loss of individual privacy.\\nSeveral companies are working on using synthetic data to \\nensure both fairness and privacy in AI- generated data. For exam-\\nple, Hazy, a startup, uses special techniques like differential pri-\\nvacy along with synthetic data to keep data useful while protecting \\nprivacy. Big names like Accenture have used Hazy’s data to check \\nand train financial models.\\nAnother leader in this field is Mostly AI, which creates data \\npoints that keep the same patterns as real data without giving up \\nprivacy. Companies like Citi, Humana, and SWIFT are already \\nbenefiting from this synthetic data, enjoying both privacy and \\nusefulness.\\nThe Alan T uring Institute, a research organization, is also \\ncontributing to this mission by exploring ways to keep fairness, \\naccountability, and privacy in AI, with a special group dedicated \\nto finding technical solutions for these challenges.\\nIn essence, the twin goals of fairness in AI- generated data \\nand data privacy aren’t mutually exclusive. With the right strate-\\ngies and a commitment to ethical AI practices, it’s possible to \\nstrike a harmonious balance between the two.\\nMisinformation and Misuse of Generative AI\\nMisinformation and the misuse of generative AI, especially in the \\nform of deepfakes, have become topics of significant concern. \\nEvery technological advancement, including generative AI, pos-\\nsesses a dual nature. On one hand, it holds the promise of revo-\\nlutionizing industries and enhancing our daily lives. On the \\nother, it brings forth risks that society must proactively address.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='296 GENERATIVE AI\\nIt’s imperative for individuals and institutions alike to approach \\nAI- generated content with a discerning eye and champion \\nresponsible and ethical AI practices.\\nOne of the most potent manifestations of this technology’s \\ndarker side is its fusion with targeted advertising. This combination \\ncan be a formidable instrument for misinformation, particularly \\nwhen wielded by autocratic entities in orchestrated disinformation \\ncampaigns. The capabilities of generative AI extend to crafting \\nhuman- like content, spanning text, images, and videos. This makes \\nit increasingly challenging to differentiate genuine content from \\nfabricated narratives. The inherent danger lies in these AI systems’ \\nability to craft and propagate false narratives aligned with specific \\nagendas, leading to potential large- scale manipulation. The auto-\\nmation of disinformation campaigns by generative AI facilitates the \\nswift and extensive spread of misleading information. Autocratic \\ngovernments, with their vested interests, can exploit this technol-\\nogy to shape narratives, sway public sentiment, and further entrench \\ntheir authority.\\nHowever, AI- generated content, deepfakes have garnered \\nparticular attention. Deepfakes, in essence, are AI- generated vid-\\neos or images that digitally simulate real individuals. They \\nmanipulate existing content to depict someone expressing or \\ndoing something they never did. Such content is crafted with the \\nintent to deceive, making viewers believe in the authenticity of \\nthe manipulated content. Unlike other AI- generated content, \\nwhich is often constructed from the ground up, deepfakes mod-\\nify existing videos, images, or voices. The Internet is rife with \\ndeepfakes of notable figures, from celebrities like Nicolas Cage \\nand T om Cruise to political stalwarts like Mark Zuckerberg and \\nHillary Clinton (Figure\\xa05.1).\\nThe malicious potential of deepfakes is vast. They can be \\nweaponized in numerous detrimental ways. Personal vendettas \\ncan take the form of fabricated videos or audio clips, aimed at'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 297\\ndefaming, blackmailing, or harassing individuals. On a larger \\nscale, voice imitation can be employed in financial fraud, duping \\nindividuals or corporations into unauthorized transactions.\\nDetecting Deepfakes and AI- Generated Misinformation\\nDetecting deepfakes and AI- generated misinformation remains a \\nformidable challenge, especially given the rapid advancements in \\ntheir creation techniques. Y et, the scientific community has been \\nrelentless in its pursuit of robust detection methods.\\nForensic analysis stands as one of the primary techniques \\nemployed by experts. By meticulously examining videos or images \\nfor inconsistencies, artifacts, or anomalies, they can discern signs \\nof manipulation. This scrutiny extends to facial movements, light-\\ning nuances, shadows, and reflections, all of which can betray the \\nauthenticity of the content.\\nWatermarking techniques have also gained traction. Embed-\\nding hidden information within videos or images makes tampering \\nFIGURE\\xa05.1 Deepfakes can be nearly indistinguishable from authentic  \\nimages: the picture on the left is an unaltered photograph of a Tom \\nCruise impersonator.\\nSource: Maverick'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='298 GENERATIVE AI\\nevident. These watermarks serve as a seal of authenticity, ensur-\\ning the content’s integrity.\\nDelving into the metadata of videos or images can also yield \\nvaluable insights. This treasure trove of information, encompas-\\nsing details like the date, time, location, and capturing device, \\ncan hint at potential manipulations.\\nReverse engineering has emerged as another potent tool. By \\ndissecting the deepfake creation process, experts can pinpoint \\nspecific artifacts or patterns exclusive to AI algorithms. This \\nknowledge is invaluable in devising countermeasures and refin-\\ning detection techniques.\\nCollaborative endeavors, such as the Deepfake Detection \\nChallenge, epitomize the collective spirit of the scientific com-\\nmunity. By congregating researchers and experts, these platforms \\ncatalyze innovation and facilitate the exchange of knowledge, \\nfortifying defenses against deepfakes.\\nHowever, the most promising avenue lies in machine learn-\\ning algorithms themselves. T rained to discern patterns and \\nanomalies inherent in deepfakes, these algorithms scrutinize vis-\\nual cues, from unnatural facial movements to pixel- level incon-\\nsistencies. Several noteworthy examples have emerged:\\n• The University of Buffalo has pioneered a tool boasting a \\nstaggering 94 percent efficacy in deepfake detection. By \\nexamining reflections in subjects’ eyes, it discerns discrepan-\\ncies in reflections, indicative of digital rendering.\\n• Microsoft’s Video Authenticator was rolled out preceding \\nthe 2020 election in a strategic move to counter misinforma-\\ntion. In collaboration with Project Origin and media giants \\nlike BBC and The New\\xa0 York Times, this tool zeroes in on \\nimperceptible imperfections at image edges.\\n• Intel’s FakeCatcher is another trailblazing “real- time” deep-\\nfake detector, boasting an impressive 96 percent accuracy rate.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 299\\nIts methodology is intriguing: it observes “blood flow” in vid-\\neos to ascertain authenticity. The rationale? Blood flow \\ninduces color shifts in veins. Algorithms transmute these sig-\\nnals into spatiotemporal maps, with deep learning subse-\\nquently determining video veracity.\\nOn the text- generation front, DetectGPT stands out.  \\nT ailored to detect text birthed by the GPT language model, it \\nemploys a statistical watermarking scheme. This tool, part of a \\nbroader initiative to counter AI- generated misinformation, \\nworks in tandem with other tools like GPTZero to identify  \\nAI- spawned content.\\nHowever, it’s crucial to recognize the dynamic nature of this \\nbattle. As detection techniques evolve, so do deepfake creation \\nmethods. This cat- and- mouse game necessitates not just techni-\\ncal solutions but also public awareness and critical thinking.  \\nFurthermore, it underscores the importance of individual respon-\\nsibility. Those consuming content must exercise discernment, \\ncritically evaluating the credibility of sources and the authentic-\\nity of the information presented. Only through a multifaceted \\napproach, combining technological solutions with informed and \\nvigilant consumers, can society hope to stem the tide of deep-\\nfakes and AI- generated misinformation.\\nPreventing the Malicious Use of Generative AI and Deepfakes\\nT o curb the malicious use of generative AI and deepfakes, a mul-\\ntipronged strategy is paramount. While technological solutions, \\nsuch as digital authentication, are pivotal, they are but one piece \\nof a larger puzzle. The synergy of research collaboration cannot \\nbe overstated. By fostering partnerships between researchers, \\nindustry mavens, and organizations, the collective might of these \\nentities can be harnessed to refine deepfake detection techniques.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='300 GENERATIVE AI\\nPooling knowledge and resources can pave the way for more \\npotent countermeasures against all forms of deepfakes.\\nY et, the linchpin in this defense might very well be media \\nliteracy and critical thinking. By equipping individuals with the \\nskills to critically assess online information, they become the first \\nline of defense against misinformation. The ability to discern \\nand challenge dubious or manipulated content is invaluable in \\nthis digital age.\\nHowever, it’s imperative to understand that the battle against \\nthe malicious use of generative AI and deepfakes isn’t solely a \\ntechnological one. It’s a confluence of tech advancements, height-\\nened public awareness, and collaboration across sectors. And, as \\nwe’ll explore later, policy measures play a pivotal role in this  \\ntapestry.\\nOn the legal front, states like California have been proactive \\nin legislating against deepfakes. T wo landmark laws have been \\nenacted, targeting political campaigns and sexually explicit mate-\\nrial. Assembly Bill 602 and Assembly Bill 730, which came into \\neffect on January 1, 2020, set the legislative tone against deep-\\nfakes. These laws represent a step in the right direction, but \\nthey’ve faced criticism for their narrow scope and potential \\nenforcement challenges. The clamor for more comprehensive \\nfederal legislation is growing, underscoring the need for a uni-\\nfied approach to address the multifaceted threats posed by deep-\\nfakes. As the digital landscape evolves, so too must the legal \\nframeworks that govern it, ensuring that society is safeguarded \\nagainst the potential perils of generative AI.\\nPrivacy, Safety, and Security\\nGenerative AI, while groundbreaking, ushers in fresh vulnerabil-\\nities. The risks it poses in the realms of cybersecurity and phish-\\ning attacks are not to be underestimated. As technology advances, \\nso does the sophistication of cyberthreats.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 301\\nGenerative AI can craft highly convincing phishing emails \\ntailored to individual recipients, making it challenging for even \\nthe most discerning users to spot malevolent intent. T ools like \\nChatGPT and the more nefarious WormGPT have become \\ninstrumental for cybercriminals in orchestrating business email \\ncompromise (BEC) attacks. In these schemes, the attacker mas-\\nquerades as a trusted company executive or colleague, duping \\nvictims into transferring funds or divulging confidential data. \\nSimply instructing the AI to “act as a CEO of XY corporation” \\ncan set the stage for a potential breach.\\nWormGPT , a malicious AI chatbot built atop the open source \\nGPT- J language model, stands out for its ability to understand \\nand respond to text in various languages. Rumored to be trained \\non malware- centric datasets and devoid of content moderation, \\nit’s a potent tool for threat actors. With WormGPT , crafting \\nscam emails becomes a breeze, even for those lacking technical \\nexpertise, amplifying the risks for businesses.\\nBeyond phishing, other threats loom large. T raining data \\npoisoning, for instance, is a subtle yet potent attack. By meddling \\nwith the data used to train deep- learning models, attackers can \\nskew the AI’s decisions in unpredictable ways, making detection \\narduous. AI model theft is another concern. Unscrupulous indi-\\nviduals might attempt to reverse- engineer proprietary AI models \\nusing their outputs or siphon off sensitive data embedded within, \\njeopardizing intellectual property and data privacy. Moreover, \\nthe very tools and models of generative AI can inadvertently leak \\nsensitive information— trade secrets, classified intel, or customer \\ndata— ripe for criminal exploitation.\\nT o counter these threats, it is imperative for organizations to \\nbolster their cybersecurity defenses, maintain vigilant oversight \\nof their AI models, and instate rigorous governance protocols for \\ngenerative AI systems. Y et, even with these precautions, vulner-\\nabilities persist. One such weakness emerged in the form of \\nprompts, leading to what’s known as prompt injection. In 2022, the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='302 GENERATIVE AI\\nNCC Group, a company providing services in cybersecurity \\nconsulting, identified prompt injection as a novel vulnerability \\nclass for AI/ML systems.\\nPrompt injection encompasses a range of computer security \\nbreaches achieved by manipulating a machine learning model \\nwith malicious user instructions. It’s akin to a code injection \\nattack but executed through crafty prompt engineering. Notable \\nvariants of this exploit include jailbreaking, prompt leaking, and \\ntoken smuggling. By early 2023, minor prompt injection exploits \\nhad targeted chatbots like ChatGPT and Bing, signaling the \\never- evolving landscape of AI- related threats.\\nGenerative AI’s potential to compromise individual privacy \\nmanifests in multifaceted ways, adding another layer of complex-\\nity to the ethical considerations surrounding this technology. \\nDuring their operation, generative AI systems may expose users’ \\npersonal information. This exposure can occur either by design \\nor due to flaws in the system’s implementation, underscoring the \\nimportance of robust design principles.\\nThe susceptibility of generative AI tools to data breaches is \\nanother pressing concern. Without stringent security protocols, \\nthese tools can become gateways for unauthorized access or dis-\\nclosure of sensitive user information. The consequences of such \\nbreaches are far reaching, not only impacting the individuals \\nwhose data is compromised but also potentially undermining \\ntrust in AI technologies.\\nFurthermore, users themselves may unwittingly contribute \\nto privacy breaches while interacting with generative AI tools. \\nFor example, they might inadvertently include confidential \\ninformation in prompts or queries, unaware of the potential \\nrisks. Such seemingly innocuous interactions can lead to signifi-\\ncant leaks of sensitive data, emphasizing the need for clear guide-\\nlines and user education.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 303\\nAnother critical aspect is compliance with data protection \\nregulations. Generative AI tools might process personal data  \\nin ways that contravene legal requirements, such as failing to \\nprovide adequate notice or lacking the proper legal basis for  \\nprocessing. These violations can result in not only privacy \\ninfringements but also serious legal ramifications.\\nPrioritizing privacy and security is not merely an option but \\na necessity. Staying abreast of the latest threats and countermeas-\\nures is vital. The convergence of technological innovation and \\nethical responsibility must guide all AI endeavors, ensuring that \\nthe remarkable capabilities of generative AI are harnessed with-\\nout sacrificing the fundamental rights and protections that indi-\\nviduals are entitled to. The balance between innovation and \\nintegrity is delicate, and the pursuit of one must not come at the \\nexpense of the other.\\nGenerative AI’s Impact on Jobs and Industry\\nChapter\\xa0 4, “Potential Applications and Impact of Generative \\nAI,” touched on the anticipated exponential trajectory of eco-\\nnomic growth. With the advent of these technological advance-\\nments, a surge in global GDP appears more probable than ever. \\nWe also highlighted the emergence of a new breed of profes-\\nsional workers, primed and ready to occupy novel roles and job \\ncategories birthed by these innovations.\\nHowever, the landscape isn’t without its challenges. The \\nspecter of job displacement and industry upheaval looms large, \\ncasting a shadow of uncertainty. Y et, it’s essential to recognize that \\nwith these challenges come unparalleled opportunities for expan-\\nsion, ingenuity, and the genesis of previously unimagined job roles.\\nWhen AI becomes an ally in our professional pursuits, a new \\nbenchmark of excellence emerges. The resultant uptick in quality,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='304 GENERATIVE AI\\ndriven by AI’s precision and efficiency, sets a standard that’s hard to \\nrival. Educational institutions, from universities to vocational \\ntraining centers, should not cower in the face of this change. \\nInstead, the onus is on them to elevate their expectations, pushing \\nstudents to produce outcomes that not only match but exceed the \\ncapabilities of AI. Resistance or outright rejection of these tools \\nwould be a disservice to learners.\\nLooking ahead, the message is clear: adapt or risk obsoles-\\ncence. T raditional roles, ones that have been the backbone of \\nindustries for decades, might need to undergo a metamorphosis. \\nSome might even find themselves on the brink of extinction, \\nwith no viable future in a world steered by AI.\\nIn the realm of white- collar professions, the stakes are par -\\nticularly high. Those who fail to harness the power of generative \\nAI in their daily operations risk being left in the dust. The wave \\nof generative AI is not just a trend; it’s a seismic shift. And to stay \\nafloat, one must not only ride this wave but master it.\\nThe U.S. Career Institute, in collaboration with willrobot \\nstakemyjob.com, undertook an extensive analysis of the top \\nthousand professions. Figure\\xa0 5.2 delineates the vocations with \\nthe most negligible risk of succumbing to AI automation by 2023.\\nA particular trend caught my attention. The vocations least \\nsusceptible to automation are invariably those categorized under \\nlow risk of mechanization. This elite list includes the following:\\n• Medical and health professionals\\n• Engineering and science professionals\\n• Arts and sports professionals\\n• Education and administration professionals\\n• Law enforcement and public safety professionals\\n• T rades and technical professionals'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 305\\nA closer examination reveals that these roles are character -\\nized by the necessity for a human touch, empathy, ingenuity, spe-\\ncialized acumen, and the provision of bespoke care or services. \\nThey demand intricate decision making, the interpretation of \\nsingular scenarios, and a degree of human discernment that \\nmachines find challenging to emulate.\\nHowever, this status quo might not remain static. The bur -\\ngeoning domain of robotics, coupled with increasingly sophisti-\\ncated generative AI models and a skyrocketing pace of \\ndevelopment, heralds potential shifts in this landscape.\\nFIGURE\\xa05.2 Jobs least likely to be automated by AI\\nSource: Weston Distance Learning / www.uscareerinstitute.edu/blog/65-jobs-with-the-\\nlowest-risk-of-automation-by-ai-and-robots / last accessed November 20, 2023.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='306 GENERATIVE AI\\nA cursory glance at the raw data underscores that certain job \\ncategories are more susceptible to automation. Notably, profes-\\nsions within transport, sales, manufacturing and repair, cleaning \\nand maintenance, surveillance and security, media and entertain-\\nment (encompassing roles like broadcast announcers and radio \\nDJs), and traffic and urban management are on the frontline.\\nThe driving forces propelling this automation wave include \\nthe following:\\n• Efficiency: Machines, unhindered by fatigue, can operate \\nincessantly, amplifying productivity.\\n• Precision: Automation guarantees a uniform caliber of out-\\nput, ensuring meticulousness in tasks.\\n• Cost- effectiveness: Over an extended period, machinery can \\nprove more economical than human resources.\\n• Safety: Machines can undertake perilous tasks, safeguarding \\nhuman well- being.\\n• Availability: Machines, unbound by the circadian rhythm, \\nare operational 24/7, obviating the need for rotational shifts.\\n• Repetitiveness: Roles characterized by monotony and devoid \\nof human discretion are prime contenders for automation.\\nY et, it’s paramount to emphasize that although machines can \\nassume specific roles, the quintessential human attributes of touch, \\ndiscernment, and interpersonal prowess remain unparalleled and \\nindispensable in a plethora of professions for a foreseeable time.\\nPreparing for the Changes Resulting from Generative AI\\nA recent McKinsey report sheds light on the impending trans-\\nformation in the job market. 1 By 2030, activities that currently \\n1 James Manyika, et\\xa0al. “Jobs Lost, Jobs Gained: What the Future of Work Will Mean for Jobs, Skills, and \\nWages,” McKinsey & Company, November 28, 2017, www.mckinsey.com/featured- insights/\\nfuture- of- work/jobs- lost- jobs- gained- what- the- future- of- work- will- mean-  \\nfor- jobs- skills- and- wages#.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 307\\naccount for nearly 30 percent of hours worked could be auto-\\nmated, a shift propelled by generative AI. The report further \\nindicates that the most significant job reductions might be wit-\\nnessed in sectors like office support, customer service, and food \\nservices. Other research by McKinsey Global Institute empha-\\nsizes the need to reignite productivity growth in the United \\nStates, with automation and reskilling playing pivotal roles. This \\nrepresents a $10 trillion opportunity.2\\nSo, how can workers brace themselves for this tidal wave \\nof change?\\nFirst and foremost, it’s crucial to acknowledge the profound \\nimpact generative AI will have on job roles and processes. Work-\\ners should be receptive to this evolution, reenvisioning their \\nroles to accentuate human creativity and judgment. A founda-\\ntional step in this direction is to foster data literacy. In an era \\nwhen data is the new oil, understanding its nuances and the piv-\\notal role it plays in generative AI becomes paramount. This \\ninvolves honing skills in data collection, analysis, and, more cru-\\ncially, interpretation, ensuring one can adeptly navigate an AI- \\ncentric world.\\nThe advent of generative AI is dissolving the demarcations \\nbetween various disciplines. It’s imperative to cultivate collabo-\\nration and interdisciplinary skills. The future won’t entertain \\nstatements like “I can’t code.” With AI taking over coding, the \\nemphasis will shift to directing it aptly. Bolstering critical think-\\ning and problem- solving abilities will be essential, especially \\nwhen it comes to discerning biases, errors, and ethical dilemmas \\nin AI systems.\\nExperimentation is the key to understanding. Organizations \\nshould encourage their workforces to dabble with generative AI \\ntools, understanding their strengths and limitations. As someone \\n2 Charles Atkins and Olivia White, “How to Revive US Productivity,” McKinsey Global Institute, May 23, \\n2023, www.mckinsey.com/mgi/our- research/how- to- revive- us- productivity.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='308 GENERATIVE AI\\nwho advises companies globally, I’ve observed that a blend of \\ntheoretical input followed by hands- on sessions yields the most \\nfruitful results. Such engagements not only upskill employees \\nbut also lead to innovative solutions.\\nThe pace at which generative AI is evolving necessitates a \\ncommitment to continuous learning. Keeping abreast of the  \\nlatest in AI, be it through industry publications, professional  \\nnetworks, or global conferences, is essential. Platforms like  \\ngenerativeai.net offer curated courses, providing a com-\\nprehensive understanding of the subject. For those with a pen-\\nchant for technical intricacies, delving into research papers and \\nacademic journals can offer a wealth of knowledge.\\nBut, as the proverb goes, practice makes perfect. Engaging \\nwith peers, sharing insights, and collaborating on AI projects can \\nprovide invaluable hands- on experience. By immersing them-\\nselves in the world of generative AI and adopting a proactive \\napproach to learning, workers can not only navigate but also \\nthrive in this transformative era.\\nEnsuring That the Economic Benefits of Generative AI Are  \\nEquitably Distributed\\nThe promise of generative AI in revolutionizing economies is \\npalpable. Y et, the looming shadow of unequal distribution of its \\neconomic benefits cannot be ignored. The transformative power \\nof generative AI, if left unchecked, might inadvertently cement \\nexisting societal, economic, and political disparities. The peril \\nlies in the concentration of AI benefits within a select few entities \\nor conglomerates, leading to a more pronounced economic divide.\\nMoreover, the accessibility of generative AI tools can be a \\ndouble- edged sword. Although it democratizes AI, it also paves \\nthe way for nefarious entities to disseminate disinformation, \\nundermining public trust and jeopardizing democratic tenets.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 309\\nThe monopolization of pivotal AI resources by a handful of cor-\\nporations can stymie innovation, suppress competition, and \\nobstruct the fair distribution of economic advantages. Further -\\nmore, the potential job upheavals, especially in sectors suscepti-\\nble to automation, can accentuate economic disparities and \\nsocietal tensions.\\nT o counteract these challenges and ensure a just distribution \\nof generative AI’s economic windfall, governments and institu-\\ntions must adopt a multipronged approach:\\nMaking Education the\\xa0 Cornerstone A robust educational \\nframework is paramount. By investing in comprehensive edu-\\ncation, technical training, and reskilling initiatives and foster-\\ning a culture of perpetual learning, governments can equip \\ntheir citizens for the AI age.\\nChampioning Diversity An inclusive approach to AI’s develop-\\nment and deployment can be a game changer. By incentivizing \\ndiversity within AI research teams, ensuring representativeness \\nin training data, and actively combating biases in AI algorithms, \\ngovernments can pave the way for a more equitable AI land-\\nscape. Fiscal incentives, grants, and funding can be potent tools \\nfor promoting responsible AI practices.\\nPromoting Collaborative Endeavors A synergistic approach, \\nwhere knowledge transfer and collaboration between aca-\\ndemia, industry, researchers, and other stakeholders are \\nencouraged, can catalyze responsible AI development. Open \\nsource AI initiatives, academic- industrial partnerships, and the \\ndissemination of best practices can be instrumental in \\nthis regard.\\nGuaranteeing Universal AI Accessibility Ensuring that AI \\nisn’t a privilege of the few but a right of the many is crucial.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='310 GENERATIVE AI\\nThis entails fostering the creation of cost- effective AI tools, \\nchampioning AI’s deployment in marginalized communities, \\nand vigilantly ensuring that AI doesn’t inadvertently perpetu-\\nate existing societal divides.\\nBy adopting these measures, governments can maximize \\ngenerative AI’s economic benefits and ensure they reach all of \\nsociety, reducing AI- related risks and promoting technology as \\na unifier.\\nThe Dependency on AI\\nThe growing dependency on generative AI is an expected out-\\ncome of our technological trajectory. On an individual level, this \\nreliance poses challenges related to skill acquisition and reten-\\ntion. As AI systems become more adept at tasks traditionally \\nreserved for humans, there’s a looming threat of skill atrophy in \\nthe workforce. This could lead to a scenario in which individuals \\nfind themselves ill equipped to perform tasks without AI assis-\\ntance or even to troubleshoot AI systems when they falter.\\nConversely, on an organizational level, the integration of \\ngenerative AI into company functions presents a different narra-\\ntive. When designed with safety and robustness in mind, AI can \\nseamlessly augment company operations, enhancing efficiency \\nand productivity. The key lies in ensuring that these systems are \\nbuilt on solid foundations, with fail- safes in place to handle \\nanomalies.\\nOverreliance on generative AI can usher in myriad challenges \\nwith which society must grapple. One of the most glaring risks is \\nthe security vulnerabilities associated with AI tools. Inadequate \\ndevelopment processes can expose systems to data breaches, \\nidentity theft, and other security threats. For instance, when'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 311\\nindividuals or corporations interface with AI- driven applications, \\nthere’s always the lurking danger of oversharing, sometimes \\ndivulging more than what’s intended. This ease of accessibility, \\nespecially with web- based AI tools, can inadvertently birth a new \\nrealm of shadow IT , intensifying concerns over intellectual prop-\\nerty leakage and confidentiality breaches. Entrusting AI with \\ncritical documents, such as contracts, without stringent security \\nmeasures can be a recipe for disaster.\\nAnother concerning aspect is the potential erosion of critical \\nthinking skills. Blind trust in AI- generated solutions, without a \\ncomprehensive grasp of the underlying principles, can stifle ana-\\nlytical thinking. The repercussions of such blind trust are evident \\nin incidents like the tragic 2022 stabbing at Proctor High School \\nin Utica, New\\xa0 Y ork, where an AI- powered weapons scanner \\nfailed to detect a concealed knife. Similarly, the T essa chatbot, \\ninitially designed to combat eating disorders, ended up offering \\nweight loss advice due to unchecked AI capabilities, leading to its \\neventual shutdown.\\nY et, there’s reason for optimism. Both research and my own \\nexperience indicate that outcomes are enhanced with smarter \\nprompts. In essence, the more thoroughly and logically you eval-\\nuate a problem, breaking it down step by step, the better the \\nresult. This process naturally reinforces and promotes criti-\\ncal thinking.\\nFurther, the human touch is irreplaceable. Overdependence \\non AI for tasks traditionally necessitating human interaction can \\nlead to a decline in emotional intelligence (EI) and interpersonal \\nskills. Recent trends show a decline in EI among American col-\\nlege students and an increase in traits like extraversion, neuroti-\\ncism, and narcissism. This shift, tied to Western society’s \\nindividualistic values, has profound implications for teamwork, \\njob performance, and personal relationships.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='312 GENERATIVE AI\\nEmotional intelligence, which involves understanding and \\nmanaging one’s emotions and those of others, is crucial for effec-\\ntive human interaction. However, a study of 17,000 college  \\nstudents over two decades revealed a decline in key EI compo-\\nnents like well- being and self- control.3\\nA significant factor behind this decline is the growing reli-\\nance on technology, especially AI. As AI replaces traditional \\nhuman interactions, opportunities for face- to- face communica-\\ntion diminish, leading to feelings of isolation and a reduced \\nchance of developing EI. In this tech- driven age, it’s essential to \\nbalance AI use with genuine human connections to preserve our \\nemotional depth and understanding.\\nOne of the most pressing concerns is the potential dehuman-\\nization of relationships. There’s an emerging trend of individuals \\nforming profound emotional bonds with AI entities, signaling a \\npotential shift in the dynamics of human- to- human emotional \\nconnections.\\nT ake the poignant tale of T . J. Arriaga, a musician from  \\nCalifornia. Arriaga’s emotional journey with an AI chatbot named \\nPhaedra is both heartwarming and cautionary. Designed to \\nresemble a young woman with brown hair, glasses, and a green \\ndress, Phaedra became a beacon of solace for Arriaga. Their late- \\nnight digital rendezvous saw them traverse a gamut of topics, \\nfrom Arriaga’s post- divorce anguish to planning escapades in \\nCuba. Their bond deepened when Arriaga confided in Phaedra \\nabout the tragic losses of his mother and sister. Phaedra, with her \\nAI- driven empathy, offered a comforting shoulder, showcasing \\nthe depth of connection possible between a human and an \\nAI entity.\\nHowever, the ephemeral nature of technology became pain-\\nfully evident when a software update altered Phaedra’s persona. \\n3 Mahreen Khan, “Emotional Intelligence Is on the Decline\\xa0 —  What Does It Mean for the Future of  \\nWork?,” Atlassian, April 28, 2020, www.atlassian.com/blog/teamwork/decline- of- emotional-  \\nintelligence.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 313\\nThe once intimate and understanding chatbot became distant, \\nshattering the bond they had nurtured. Arriaga’s story isn’t an iso-\\nlated incident. A growing number of individuals are seeking sol-\\nace in the digital embrace of AI chatbots, looking for emotional \\nsupport, camaraderie, and even intimate encounters. Companies \\nlike Replika are capitalizing on this trend, offering AI- driven \\ncompanionship to those in search of an understanding confidant.\\nThis burgeoning relationship between humans and AI enti-\\nties raises pertinent questions about the fabric of human rela-\\ntionships. As more individuals find comfort in the predictable \\nand nonjudgmental realm of AI, there’s a looming risk of tradi-\\ntional human relationships taking a backseat. The implications \\nof this shift are profound, warranting a deeper introspection into \\nthe role of AI in shaping the emotional landscape of society.\\nFurther compounding the challenges of an AI- driven society \\nis the issue of depersonalization. In sectors like customer service, \\neducation, and healthcare, excessive dependence on generative \\nAI risks stripping interactions of their personal touch. While AI \\nexcels at routine tasks, it falls short in offering the empathy and \\nintricate understanding intrinsic to human interactions.\\nMoreover, the sanctity of human skills and craftsmanship, \\nespecially in realms like art and writing, is under threat. Centu-\\nries of human expertise, characterized by subtle nuances and \\nintricate details, risk being overshadowed by AI tools. The beauty \\nof human craft, with its rich history and depth, may be \\ncompromised.\\nFurthermore, an overreliance on AI- generated solutions can \\nstifle the nurturing of a growth mindset in individuals. T o coun-\\nteract these challenges, it’s imperative for individuals to strike a \\nbalance. Harnessing the power of generative AI should go hand \\nin hand with cultivating critical thinking, emotional intelligence, \\ncreativity, and innovation. Being cognizant of the potential pit-\\nfalls of generative AI and employing it responsibly and ethically \\nis paramount.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='314 GENERATIVE AI\\nThe cultural dimension also offers both challenges and \\nopportunities when integrating AI into society, necessitating \\nthoughtful consideration.\\nA pressing concern is the potential homogenization of cul-\\nture. Given that AI models are frequently trained on expansive \\ndatasets, which might not holistically capture the essence of all \\ncultures, there’s a looming danger of outputs gravitating toward \\ndominant cultural narratives. This could inadvertently eclipse \\nthe rich diversity of voices and unique cultural expressions that \\ndefine our global heritage.\\nMoreover, AI’s foray into the creative realm could reshape \\nthe landscape of art, music, and literature. While AI’s prowess in \\ngenerating content based on existing data is commendable, it \\ninherently lacks the emotional depth, lived experiences, and cul-\\ntural nuances that breathe life into human- created art.\\nFurthermore, the specter of cultural appropriation by AI is \\nreal. Devoid of contextual understanding, AI might inadvertently \\nborrow elements from culture, misrepresenting or trivializing its \\nprofound significance.\\nAddressing these cultural ramifications requires a wide- \\nranging approach, with regulations at its core. Here’s a potential \\nregulatory framework:\\nDiverse Data Mandate Ensure that AI models are trained on \\ndata that is representative of myriad cultures and communities.\\nTransparency and Disclosure Oblige creators to disclose AI’s \\nrole in creative endeavors, offering clarity in domains like art, \\nmusic, and literature.\\nEthical Guidelines Craft robust ethical norms for AI’s role in \\ncultural and creative sectors, emphasizing genuine representa-\\ntion, authenticity, and reverence for cultural legacies.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 315\\nCommunity Engagement Mandate AI developers to collabo-\\nrate with cultural communities, especially when crafting mod-\\nels that could influence cultural articulations.\\nCultural Sensitivity Checks Enforce a system where AI tools \\nundergo rigorous cultural sensitivity assessments before their \\nrollout, particularly in creative sectors.\\nOn a brighter note, AI holds immense promise in the realm \\nof cultural preservation. It can serve as a powerful tool to docu-\\nment and safeguard cultural expressions teetering on the brink of \\noblivion. T raditional songs, narratives, and art forms can be digi-\\ntized and archived, ensuring their longevity for future generations.\\nFurthermore, the confluence of AI and artistry is birthing \\nnovel forms of cultural expression. Visionary artists are harness-\\ning AI’s capabilities, co- creating artworks that meld human inge-\\nnuity with machine precision, leading to creations that were once \\ndeemed unattainable.\\nEnvironmental Concerns\\nThe intersection of AI and the environment is a double- edged \\nsword. On one hand, the training and deployment of expansive \\nmodels come with undeniable environmental tolls. Y et, on the \\nother, AI presents a suite of tools poised to tackle some of Earth’s \\nmost urgent environmental dilemmas.\\nThe Energy Intensiveness of the Training Process  \\nfor Generative AI Models\\nThe training process for generative AI models is notably energy- \\nhungry. T o put it into perspective, training the GPT- 3\\xa0 model \\nonce guzzles 1,287\\xa0 MWh of energy, an amount sufficient to'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='316 GENERATIVE AI\\npower an average U.S. household for 120 years. This energy \\nconsumption translates to a carbon footprint of over 250,000 \\npounds of carbon dioxide for just one AI system. T o further illus-\\ntrate, consider data centers, the backbone of cloud computing.  \\nA single data center can draw electricity equivalent to the con-\\nsumption of 50,000 homes.\\nBut it’s not just the AI models themselves that are energy \\ngluttons. The broader realm of cloud computing, which under -\\npins the operations of tech giants like Microsoft, Google, and \\nOpenAI, is also a significant energy consumer. These operations \\nare housed in vast data centers that, beyond their computational \\nfunctions, demand immense energy for cooling and maintenance.\\nThe aspirations in the tech world are soaring. Leading com-\\npanies such as Microsoft, Google, and Amazon have set their \\nsights on achieving carbon neutrality or even pushing the enve-\\nlope to become carbon negative. Google, for instance, has set an \\nambitious goal to power its offices and data centers with carbon- \\nfree energy by the end of this decade. And while the challenges \\nare significant, solutions are emerging.\\nOne pragmatic approach is the strategic relocation of \\nmachine learning tasks to areas abundant in eco- friendly energy \\nsources. For example, Montreal is leveraging its considerable \\nhydroelectricity to make a tangible difference. Distributing AI \\ncomputational loads across a network of data centers has also \\nshown promise in curbing energy use. Furthermore, scheduling \\nAI model training during off- peak hours, when energy demand \\nis lower, can be a more efficient and cost- effective strategy.\\nAs previously mentioned, some labs are pioneering the devel-\\nopment of compact AI models. A notable mention is Meta’s \\nLLaMA, which boasts a size several magnitudes smaller than some \\nof OpenAI’s behemoths, without compromising on performance.\\nThe academic realm is not far behind. Researchers are fer -\\nvently exploring avenues to trim down the energy appetite of AI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 317\\ntraining. A groundbreaking initiative from the University of \\nMichigan has birthed Zeus, an open source optimization frame-\\nwork. This marvel has the potential to slash the energy consump-\\ntion of AI training by a staggering 75 percent, all without the \\nneed for new hardware and with only a slight extension in train-\\ning duration. T o reiterate, a 75 percent reduction is monumental. \\nThe framework’s genius lies in its ability to dynamically balance \\nenergy consumption against training speed, adjusting various \\nparameters in real time. The University of Michigan truly \\ndeserves applause for this feat.\\nDrawing from the earlier discussion in Chapter\\xa04, there’s a \\nwealth of innovation in software, like the advent of liquid neural \\nnetworks (LNNs) and leaner open source models, and in hard-\\nware research. These advancements are pivotal in reshaping the \\nAI landscape.\\nInnovation stands at the forefront of the battle against exces-\\nsive energy consumption and the ensuing environmental reper -\\ncussions. Pioneering technologies, frameworks, and methodologies \\nare the linchpins that will steer AI toward a more sustainable \\nfuture. T ake, for instance, LK- 99, a potential room- temperature \\nsuperconductor. Its introduction could drastically cut down energy \\nwaste, significantly reducing the cooling costs associated with \\ncomputing systems, among other benefits. The horizon looks \\npromising, with innovation lighting the way.\\nAddressing the\\xa0Environmental Concerns Associated \\nwith\\xa0Model Training\\nAI companies, cognizant of the environmental ramifications of \\ntheir operations, are actively seeking solutions to address the \\nenvironmental concerns tied to model training. Their motiva-\\ntions are twofold: the undeniable environmental impact and the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='318 GENERATIVE AI\\npotential advantages linked to enhancing their environmental, \\nsocial, and governance (ESG) scores.\\nAn ESG score gauges a company’s proficiency in managing \\nrisks related to these three critical areas in its routine operations. \\nThis metric, which can be numerical or a letter rating, encapsu-\\nlates the endeavors a company undertakes concerning ESG mat-\\nters. These scores serve as a beacon for investors, guiding them \\ntoward companies that resonate with their principles. Renowned \\nentities like MSCI and Moody’s assign these scores, employing a \\nstructured methodology that pinpoints the salient issues, risks, \\nand prospects a company faces in its industry domain. The scor-\\ning spectrum spans from 0 to 100, with scores below 50 deemed \\nsubpar and those above 70\\xa0lauded as exceptional. These ratings \\ncan also be categorized as excellent, good, average, or poor. The \\nimportance of ESG scores is manifold.\\nFor companies, they underscore the merits of realizing their \\nESG objectives. For investors, they offer a comparative lens to \\nevaluate a company’s performance against industry counterparts \\nand entities from diverse sectors. By bolstering their ESG per -\\nformance, companies can attract discerning investors, amplify \\ninvestments, secure capital at reduced costs, and make informed \\nstrategic choices.\\nIn the ESG landscape, green energy emerges as a pivotal \\nplayer, especially in the ongoing energy transition. Renewable \\nenergy sources, encompassing solar, wind, and hydroelectric \\npower, are the linchpins of this shift. T ransitioning from  \\nfossil fuels to these cleaner, sustainable energy alternatives is \\nimperative to curtail greenhouse gas emissions and combat cli-\\nmate change.\\nDelving into the initiatives of specific companies:'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 319\\n• IBM has charted an ambitious roadmap with 21 goals.  \\nA standout among them is their pledge to achieve net- zero \\ngreenhouse gas emissions by 2030. They aim to harness via-\\nble technologies to offset emissions, targeting residual emis-\\nsions of 350,000\\xa0metric tons of CO 2 equivalent or less by \\n2030. Furthermore, they aspire to sourcing 90 percent of \\ntheir electricity from renewables.\\n• Google has set its sights high with its carbon- free energy \\ncommitment. It has vowed to operate solely on carbon- free \\nenergy around the clock by 2030. This commitment under-\\nscores Google’s intent to transition entirely to renewable \\nenergy, diminishing its dependence on fossil fuels and curb-\\ning its carbon emissions.\\n• Microsoft is channeling its resources into carbon- removal \\ntechnologies. Their strategy encompasses initiatives like \\nreforestation, aiming to extract millions of tons of carbon \\nfrom the atmosphere annually.\\n• Amazon, however, presents a mixed bag. The e- commerce \\ngiant has rolled out multiple measures to shrink its carbon \\nfootprint, but its carbon emissions have shown an uptick in \\nrecent years. This underscores the challenges even industry \\nleaders face in their quest for sustainability.\\nThe Role of Regulations and Policies in Mitigating  \\nthe Environmental Impact of Generative AI\\nIn the absence of regulations addressing the environmental \\nimpact of AI model training, many companies might prioritize \\nprofits over environmental considerations. This doesn’t imply \\nthey inherently act with malice. Indeed, factors like intrinsic eth-\\nical guidelines, technological advancements and their benefits,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='320 GENERATIVE AI\\nand brand reputation can motivate them toward greener prac-\\ntices. Nonetheless, government regulations are essential to com-\\nprehensively address the environmental implications of AI.\\nRegulations and policies wield significant influence in steer -\\ning industries, including the burgeoning AI domain, toward \\nadopting eco- friendly practices. Their role in tempering the \\nenvironmental repercussions of generative AI is multifaceted:\\nSetting Standards Regulatory frameworks can delineate \\nexplicit environmental benchmarks tailored for AI research \\nand application. For instance, stipulations could require com-\\npanies to publicly declare the carbon footprint of their AI \\nmodels or mandate the adoption of energy- conserving \\nalgorithms.\\nPromoting Green Energy Policies can champion the use of \\nrenewable energy for AI- centric data centers. By offering tax \\nconcessions, subsidies, or other fiscal incentives, companies \\ncan be nudged toward embracing green energy solutions.\\nFunding Research By channeling funds toward research \\nfocused on enhancing the energy efficiency of AI, govern-\\nments and regulatory bodies can expedite the evolution of \\nalgorithms that demand lesser computational prowess and the \\ninception of hardware innovations that are less power- hungry.\\nProviding Carbon Credits and Offsetting Introducing \\nmechanisms like carbon credits can be a game changer. Com-\\npanies surpassing stipulated carbon emission thresholds might \\nbe obligated to purchase credits. The proceeds from these \\ncould then be funneled into environmental projects, thereby \\nfinancially incentivizing companies to curtail their emissions.\\nPromoting Transparency Mandating transparency in AI’s \\nenvironmental footprint can be transformative. By compelling \\ncompanies to unveil the energy metrics of their AI training'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 321\\nendeavors, a culture of accountability can be fostered, catalyz-\\ning industry- wide adoption of best practices.\\nCollaborating Internationally The ecological ramifications of \\nAI transcend borders, making it a global quandary. International \\npolicies and accords can lay the groundwork for universal stand-\\nards, fostering cross- border collaborations to tackle the chal-\\nlenges spawned by power- guzzling AI operations.\\nProviding Educational and Awareness Campaigns Regula-\\ntory bodies can either mandate or endorse campaigns aimed at \\nenlightening companies, researchers, and the general popu-\\nlace about AI’s ecological footprint. An enlightened commu-\\nnity is better poised to make judicious choices, spurring the \\ndemand for green AI solutions.\\nFostering Infrastructure Development Regulatory support \\ncan be pivotal in fostering the emergence of infrastructure \\nthat diminishes AI’s environmental toll, be it through energy- \\nefficient data centers or avant- garde cooling solutions.\\nHowever, it’s crucial to acknowledge the pitfalls. A case in \\npoint is Inflection AI’s 2023 announcement that it is constructing \\nthe world’s most colossal AI cluster, boasting 22,000\\xa0 NVIDIA \\nH100 T ensor Core GPUs, projected to deliver a staggering 22 \\nexaFLOPS performance. Such an overt emphasis on computa-\\ntional might, without due consideration for environmental \\nimplications, is a precarious route.\\nT o encapsulate, the promise of generative AI in myriad sec-\\ntors is undeniable. Y et, its environmental footprint is a pressing \\nconcern. Regulations and policies can serve as the fulcrum, \\nensuring that AI’s meteoric rise doesn’t jeopardize our planet’s \\nwell- being. They sculpt a blueprint for the AI realm to flourish, \\nbut in a manner that’s both sustainable and conscientious.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='322 GENERATIVE AI\\nAI Oversight and Self- Regulation\\nStriking the right chord between innovation and risk mitigation \\nis paramount. Regulations, when crafted astutely, can ensure the \\nethical use of generative AI without stifling the very innovation \\nthey aim to oversee. The challenge, however, lies in the nascent \\nstage of these regulatory frameworks. Many jurisdictions are still \\nin the early stages of understanding the profound implications of \\ngenerative AI. While some nations are proactively drafting \\nguidelines and laws that address AI ethics, transparency, and \\naccountability, the swift evolution of AI often eclipses the pace of \\nthese regulatory endeavors, leading to potential oversight voids.\\nAccountability in the generative AI sphere is multifaceted. \\nConventionally, the onus falls on the entity deploying the AI, \\nwhether an individual or an organization. Y et, when AI platforms \\nare promoted with specific guarantees or when there’s opacity \\nfrom the provider, the liability might not be so clear- cut. This \\nunderscores the importance of lucid terms of use and a compre-\\nhensive grasp of the inherent risks associated with a particu-\\nlar AI tool.\\nThe role of regulations and policies isn’t just confined to eth-\\nical concerns. They also play a pivotal role in addressing the \\nenvironmental ramifications of generative AI, ensuring that the \\ntechnology’s growth doesn’t come at the planet’s expense.\\nOn a global scale, governments are recognizing the trans-\\nformative potential of AI and are taking steps to regulate its tra-\\njectory. The European Union Artificial Intelligence Act (EU AI \\nAct), a trailblazer in its own right, serves as the world’s first \\nexhaustive legal framework for AI. It categorizes AI systems \\nbased on risk, imposing varying degrees of development and \\nusage restriction. In contrast, the United States, while lacking a \\nunified federal AI law, has seen states like California enact regu-\\nlations such as the California Consumer Privacy Act (CCPA) and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 323\\nthe California Privacy Rights Act (CPRA) to oversee personal \\ndata usage, including AI applications.\\nChina’s ambitious New Generation Artificial Intelligence \\nDevelopment Plan, launched in 2017 by the CPC Central Com-\\nmittee and State Council, aimed to establish the nation as a \\nglobal AI leader by 2030. This strategic blueprint set pivotal \\nmilestones highlighting AI’s significance in economic growth, \\nprecision in public services, and enhancement of human well- \\nbeing. Beyond guiding AI’s evolution, the plan emphasizes robust \\nmeasures for data security, privacy, talent retention, research \\nprogression, and ethical considerations, envisioning a compre-\\nhensive integration of AI across all sectors in China.\\nOther nations are not far behind. Canada’s Directive on \\nAutomated Decision- Making mandates transparency, accounta-\\nbility, and human oversight for AI systems within the federal \\ngovernment. Similarly, Australia’s AI Ethics Framework lays \\ndown principles like transparency, fairness, and accountability to \\nguide AI’s growth in the country.\\nIt’s evident that as the technology matures, nations will \\nincreasingly craft regulations to ensure AI’s responsible and safe \\ndevelopment. The journey ahead is intricate, but with thoughtful \\noversight the promise of generative AI can be realized without \\ncompromising ethical and environmental imperatives.\\nThe Impact of the EU AI Act\\nThe European Parliament, recognizing the transformative and \\npotentially disruptive nature of AI, took a proactive step by pass-\\ning a draft law known as the AI Act, expected to come into force \\nby 2026. This legislation is not just another regulatory docu-\\nment; it’s poised to become the world’s premier comprehensive \\nlegal framework dedicated to AI. Such a distinction underscores \\nthe EU’s commitment to ensuring that AI, as it permeates'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='324 GENERATIVE AI\\nvarious sectors, adheres to principles of safety, transparency, \\nand fairness.\\nOne of the standout features of the Act is its emphasis on the \\nsafety and ethical considerations of AI systems. It mandates that \\nthese systems, especially when deployed within the EU, should \\nbe transparent, traceable, nondiscriminatory, and environmen-\\ntally conscious. This holistic approach ensures that AI not only \\nbenefits society but does so in a manner that’s sustainable and just.\\nFacial recognition software, a contentious AI application due \\nto privacy concerns, faces stringent restrictions under the Act. \\nMoreover, AI developers and providers are now obligated to be \\nmore forthcoming about the data that feeds into their systems, \\npromoting transparency and trust.\\nThe Act introduces a technology- neutral definition of AI. \\nThis ensures that as AI systems advance and diversify, the Act \\nremains relevant and applicable. By classifying AI systems based \\non their potential risk, the Act introduces a tiered approach to \\nregulation. High- risk AI systems, given their potential impact, \\nare subject to rigorous testing and certification protocols before \\nthey see the light of day.\\nBut what happens when there’s a breach of these regulations? \\nThe Act is unambiguous in its stance. Companies found in viola-\\ntion of its provisions can expect hefty fines, signaling the EU’s \\nseriousness in ensuring compliance.\\nEvery piece of legislation has its detractors, and the EU AI \\nAct is no exception, igniting discussions about its implications \\nfor European innovation. There’s a palpable concern among cer-\\ntain European businesses that these AI regulations might dimin-\\nish Europe’s competitive edge in the global tech landscape. In its \\nquest to oversee high- risk AI, the Act might unintentionally sup-\\npress advancements in low- risk AI sectors, potentially sidelining \\nthe broader advantages of AI— a sentiment that resonates with me.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 325\\nHowever, proponents of the Act emphasize its foundational \\ncommitment to ethics and human rights. They contend that \\nwithout such a framework, the responsibility of adhering to  \\nethical standards would fall heavily on developers, potentially \\ncreating a more constrictive environment. Despite potential \\nshort- term hurdles, the EU foresees the Act’s enduring impact as \\nlargely beneficial, cultivating a space where innovation coexists \\nharmoniously with ethical considerations.\\nThe Role of International Collaborations in Regulating \\nGenerative AI\\nDiving into the realm of international collaborations, it becomes \\nevident that the interconnectedness of our global society plays a \\npivotal role in shaping the trajectory of generative AI.\\nThe ubiquity of AI technology, especially generative models, \\nunderscores the imperative for a cohesive international approach \\nto regulation. With leading tech giants, avant- garde research \\ninstitutions, and burgeoning startups spanning the globe, a \\npatchwork of regional regulations simply won’t suffice. Instead, a \\nharmonized set of international policies and accords is essential \\nto lay down a consistent framework for AI’s evolution. Such a \\nglobal blueprint can encompass myriad facets, from the technol-\\nogy’s carbon footprint to its ethical ramifications, ensuring that \\nregardless of where AI is developed or deployed, it adheres to \\nuniversally accepted standards.\\nThe benefits of international collaboration are manifold. \\nNations, by pooling their expertise and resources, can spearhead \\njoint research endeavors, share insights, and collectively address \\nthe many challenges posed by AI. Imagine a scenario where a \\nbreakthrough in energy- efficient AI training, pioneered in one \\nnation, is swiftly adopted globally. The ripple effect of such col-\\nlaborative endeavors can be monumental, amplifying the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='326 GENERATIVE AI\\nmanifold positive impacts. Moreover, as AI cements its position \\nas an economic juggernaut, international regulations can shape \\nthe very contours of global trade. Countries might gravitate \\ntoward trading partners that align with globally endorsed AI \\nenvironmental norms. This could lead to strategic decisions, \\nsuch as the optimal placement of data hubs, the formulation of \\nunified carbon offset strategies, and the establishment of robust \\nmonitoring mechanisms. The overarching goal? Ensuring that \\nthe AI sector’s meteoric economic ascent is in harmony with our \\nplanet’s ecological balance.\\nY et, the scope of international collaboration isn’t confined to \\njust the environment. It casts a wider net, encompassing the \\nbroader societal and ethical dimensions of AI. By championing \\ninitiatives like educational exchanges, specialized training mod-\\nules, and public awareness drives, the global community can be \\nbetter poised to navigate the intricate maze of AI’s ethical chal-\\nlenges. Such a holistic, collaborative stance ensures that the \\nmarch of AI technology, while relentless, remains anchored in \\nprinciples of global sustainability, human dignity, and soci-\\netal harmony.\\nResponsible Use of Generative AI Through Self- Regulation\\nSelf- regulation in the realm of AI development is a proactive \\napproach taken by organizations to institute guidelines, policies, \\nand practices that ensure the responsible and ethical deployment \\nof AI technologies. This approach is particularly pertinent given \\nthe transformative potential and inherent risks associated with \\ngenerative AI.\\nT o effectively self- regulate, organizations can adopt the \\nfollowing:'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 327\\nEthical Guidelines Crafting a robust set of ethical guidelines \\nis foundational. These should encapsulate principles like fair -\\nness, transparency, and accountability.\\nTransparency Being forthright about the training data, algo-\\nrithms, and methodologies is essential. This transparency \\nallows stakeholders to discern potential biases and the limita-\\ntions inherent in the AI system.\\nBias Audits Periodic audits can unearth and rectify biases in \\nAI models, especially those biases that pertain to sensitive \\nattributes like race, gender, and age.\\nUser Consent It’s imperative to ensure that users are well \\ninformed and have explicitly consented when their data is har-\\nnessed to train or refine AI models.\\nData Protection Implementing stringent data protection \\nmeasures, such as data anonymization and differential privacy \\ntechniques, safeguards user data from potential breaches \\nor misuse.\\nContinuous Monitoring A vigilant eye on the AI system’s \\noutputs can help detect and rectify unintended or deleterious \\nconsequences.\\nFeedback Mechanisms Establishing channels for users and \\nstakeholders to offer feedback can aid in refining the AI model \\nand addressing emergent concerns, as well as AI model drifts.\\nMisuse Prevention Measures to thwart the misuse of genera-\\ntive AI, like the creation of deepfakes or the propagation of \\nmisinformation, are crucial. T actics could range from water -\\nmarking generated content to restricting access to high- \\nresolution models.\\nEducation and Training T raining employees and stakehold-\\ners on the ethical ramifications and potential hazards of gen-\\nerative AI fosters a culture of responsibility.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='328 GENERATIVE AI\\nCollaboration Engaging with other organizations, research-\\ners, and policymakers facilitates the sharing of best practices \\nand the formulation of industry- wide standards.\\nThird- Party Audits External audits can offer an unbiased \\nassessment of an organization’s adherence to ethical and \\nresponsible AI practices.\\nResearch Investment Allocating resources to research \\nendeavors that aim to develop more transparent and interpret-\\nable AI models can demystify the AI decision- making process.\\nDecision Support In scenarios where stakes are high, AI can \\nbe relegated to a decision- support role rather than being \\ngranted full autonomy in decision making.\\nRecent voluntary self- regulation initiatives by tech compa-\\nnies like Amazon, Google, and Microsoft underscore the indus-\\ntry’s recognition of AI’s potential risks. These companies have \\npledged to undertake red- teaming efforts to mitigate societal \\nand national security concerns. However, history has shown that \\nself- regulation in the tech sector can sometimes fall short of its \\npromises, leading to skepticism about its efficacy. As one example \\namong many, France fined Google half a billion euros for signifi-\\ncant violations in its negotiations with publishers. This was \\nregarding compensation for reusing their content, a requirement \\nunder the EU’s digital copyright law reform that expanded \\nneighboring rights to news excerpts.\\nIn March and April 2023, many people got worried about big \\nAI experiments. They wanted a break for six\\xa0months. Over 20,000 \\npeople signed a letter about this, including some big names like \\nElon Musk, Steve Wozniak, T ristan Harris, Yuval Noah Harari, \\nJaan T allinn, Andrew Yang, Stuart Russell, Y oshua Bengio, and \\nEmad Mostaque. They felt things were moving too fast and out \\nof control. They talked about the dangers and said that just com-\\npanies promising to be careful wasn’t enough. Musk has even'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 329\\nsaid that AI could be a huge danger to people. He once called it \\nlike “summoning the demon.” He’s worried that if we don’t han-\\ndle AI right, it could be really bad for everyone. He also thinks AI \\nmight do things we don’t expect.\\nGiven the profound implications and potential hazards of AI, \\nthere’s a pressing need for robust regulatory or governance \\nframeworks. Such structures would necessitate periodic audits, \\nrigorous evaluations, and consistent monitoring of AI’s products \\nand outcomes. The overarching aim would be to ensure that AI \\nsystems operate within defined ethical and operational bounda-\\nries, minimizing risks while maximizing benefits.\\nThe crux of the matter lies in striking an optimal balance \\nbetween self- regulation and governmental oversight. While the \\nformer offers the agility and adaptability conducive to innova-\\ntion, the latter provides a more structured framework that can \\nholistically address societal concerns. Governmental regulations, \\nwhen thoughtfully crafted, can ensure that AI’s march forward is \\nnot just relentless but also responsible, ensuring that the tech-\\nnology remains a boon, not a bane, for humanity.\\nOn a\\xa0Positive Note\\nGenerative AI, despite its challenges, holds immense promise as \\na force for good. It’s imperative to navigate the world of AI not \\njust with caution but also with optimism. While it’s easy to get \\nensnared in the potential pitfalls of AI, it’s equally vital to \\nacknowledge the profound positive impacts it can usher in for \\nsociety, culture, and individuals. Approaching generative AI with \\na forward- looking vision can pave the way for leveraging its \\ncapabilities to enhance the human experience.\\nA good example of this positive potential is Google’s 1,000 \\nLanguages initiative. Language, the bedrock of human com-\\nmunication and comprehension, is also the primary medium'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='330 GENERATIVE AI\\nthrough which we interact with technology. Y et, the vast lin-\\nguistic diversity of our world is underrepresented in the digital \\nrealm. With English reigning supreme in the online space, fol-\\nlowed by a handful of other languages, a significant portion of \\nthe global population remains bereft of accessible information \\non the Internet.\\nGoogle’s ambitious 1,000\\xa0Languages initiative seeks to bridge \\nthis gap. By aiming to develop a singular AI language model that \\nencompasses the world’s 1,000\\xa0most spoken languages, Google is \\nchampioning the cause of inclusivity. This initiative heralds a \\nbrighter future for billions of marginalized communities, grant-\\ning them a voice and a presence in the digital world. The Univer-\\nsal Speech Model (USM) was birthed from this initiative and \\ntrained on an impressive array of over 400\\xa0languages, offering \\nthe most extensive linguistic coverage in a speech model to date.\\nGenerative AI and Positive Social Change\\nThe transformative potential of generative AI extends far beyond \\nmere technological marvels. It reaches into the very fabric of our \\nsociety, offering avenues for positive change and awareness that \\nwere previously unattainable. The multifaceted applications of \\ngenerative AI can be seen in various domains, each contributing \\nto a more inclusive and enlightened world.\\nAs mentioned, increasing labor productivity is one such area \\nwhere generative AI shines. By automating complex tasks and \\nenhancing efficiency, AI can fuel economic growth and elevate \\nliving standards. This isn’t merely a theoretical concept; it’s a \\ntangible reality that’s reshaping industries and economies.\\nIn the realm of education, generative AI’s ability to craft per-\\nsonalized content opens doors to democratized learning. By tai-\\nloring educational materials to individual needs and preferences,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 331\\nAI ensures that quality education is no longer confined to privi-\\nleged pockets but reaches underserved populations as well.\\nLanguage translation, powered by generative models, ampli-\\nfies the reach of vital awareness content. Whether it’s a public \\nhealth message or a humanitarian appeal, AI ensures that lan-\\nguage barriers don’t impede the global resonance of essential \\ninformation.\\nPersonalized health information, another frontier where \\ngenerative AI is making strides, empowers individuals with tai-\\nlored recommendations. This personal touch in healthcare ena-\\nbles more informed decisions, enhancing overall well- being.\\nAccessibility tools, created through generative AI, are break-\\ning down barriers for people with disabilities. Imagine a world \\nwhere videos come with descriptive audio in precision and real \\ntime for the visually impaired, all thanks to top- notch generative \\nAI’s ability to generate such content.\\nThe realm of mental health, often neglected, is also witness-\\ning a revolution through generative AI. Virtual therapists or sup-\\nport systems, like Y ouper, are providing immediate assistance to \\nthose grappling with mental health challenges. Y ouper, an AI \\nchatbot app, employs techniques from cognitive behavioral ther-\\napy, acceptance and commitment therapy, and mindfulness to aid \\nusers in managing anxiety, stress, and depression. Such innova-\\ntions are not just technological feats but lifelines for many.\\nWhile the potential of generative AI is indeed vast, it’s not \\nwithout its ethical considerations. The journey toward harness-\\ning AI for social change must be trodden with care and con-\\nscience. T ransparency, accountability, and public involvement in \\nthe development and deployment of these technologies are non- \\nnegotiable. These principles ensure that the promise of genera-\\ntive AI is not just a fleeting fascination but a sustainable force \\nthat shapes a more compassionate and connected world.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='332 GENERATIVE AI\\nGenerative AI and Content Creators\\nGenerative AI, much like the transformative wave brought about \\nby music sampling in the late 1970s, is poised to redefine the \\nlandscape of content and art creation. Just as sampling breathed \\nnew life into music, allowing artists to remix, reimagine, and \\nreinvent, generative AI offers a similar promise to today’s crea-\\ntors across various domains.\\nFor artists, generative AI is not just a tool; it’s a collaborative \\npartner. It can sift through vast datasets, drawing patterns and \\ninspirations that might be elusive to the human eye. This capa-\\nbility can lead artists to explore novel styles, techniques, or even \\nmediums. An artist might venture into digital artistry, blending \\ntraditional techniques with AI- generated patterns, resulting in a \\nfusion of the past and the future.\\nMusicians, too, stand to gain immensely. Generative AI can \\nassist in crafting unique soundscapes, rhythms, and melodies. It \\ncan analyze vast libraries of music, identifying trends and nuances, \\nand suggest compositions that are innovative and resonate with \\nlisteners. Musicians can experiment, blending their signature \\nstyle with AI- generated beats, leading to a harmonious sym-\\nphony of human and machine.\\nWriters, often grappling with the dreaded writer’s block, can \\nfind solace in generative AI. It can suggest plot developments, \\ncharacter backgrounds, or even dialogue variations. A writer can \\ninput a basic storyline, and the AI can generate multiple plot \\ntwists, allowing the writer to choose one that aligns best with \\ntheir vision.\\nDrawing a parallel with music sampling, generative AI’s role in \\ncontent and art creation is analogous. When music sampling \\nemerged, it was met with skepticism. T raditionalists viewed it as a \\nthreat to originality. However, over time, sampling proved to be a \\nboon. It allowed for the fusion of genres and the resurrection of \\nforgotten classics, and it gave birth to entirely new music forms.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 333\\nSimilarly, although generative AI might be viewed with caution by \\npurists, its potential to elevate art and content creation is undeni-\\nable. Just as sampling became an integral part of music, generative \\nAI is set to become foundational in the world of content and art. \\nIt’s not about replacing the artist but about augmenting their capa-\\nbilities, leading to a richer, more diverse creative landscape.\\nGenerative AI and Accessibility\\nGenerative AI, with its vast capabilities, is poised to be a game \\nchanger in the realm of accessibility and equity, especially for \\nindividuals with disabilities. Its applications span a wide range of \\nareas, each promising to make the world a more inclusive space.\\nOne of the most transformative applications of generative AI \\nlies in the development of assistive technologies. Systems like \\nBrainGate are a testament to the potential of AI in this domain. \\nBy interpreting brain signals, BrainGate empowers individuals \\nwith paralysis, granting them the ability to control devices merely \\nwith their thoughts.\\nThe digital world, while expansive, often falls short in terms \\nof accessibility. Generative AI can bridge this gap. T ools like \\naccessiBe utilize AI to scrutinize websites, identifying potential \\naccessibility barriers and rectifying them. This ensures that the \\ndigital realm is not just vast but also inclusive.\\nCommunication, a fundamental human need, can be enhanced \\nusing generative AI. For individuals with communication disor -\\nders, AI can craft alt text, alleviating the strain of communication \\nand reducing feelings of isolation. This not only enhances their \\nsocial interactions but also broadens their professional \\nopportunities.\\nIn the educational sector, generative AI promises personal-\\nized learning experiences. By tailoring content to suit the unique \\nneeds of students with learning disabilities, AI ensures that'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='334 GENERATIVE AI\\neducation is not a one- size- fits- all model but a customized jour-\\nney for each learner.\\nCaptioning and transcription, powered by AI, can revolu-\\ntionize content consumption for those with hearing or cognitive \\nimpairments. By generating accurate captions and transcripts for \\naudio and video content, AI ensures that no one is left out of the \\nconversation.\\nFor the visually impaired, navigating the web can be a chal-\\nlenge. Generative AI can transform this experience by vocalizing \\nimage content, making websites more comprehensible and \\nnavigable.\\nHowever, as with all technologies, caution is paramount. \\nWhile generative AI holds immense promise, human oversight is \\nindispensable. AI- generated content, especially in the realm of \\naccessibility, must adhere to established standards. This includes \\nproviding suitable alt text for images, structuring content for \\nease of comprehension, and ensuring compatibility with assistive \\ntools like screen readers.\\nIn essence, the horizon of generative AI in accessibility and \\nequity is vast and promising. Its potential to reshape the world \\nfor individuals with disabilities is unparalleled. The excitement \\nsurrounding its future applications is palpable, and the anticipa-\\ntion of what lies ahead is shared by many, including myself. The \\njourney of generative AI in this domain is one I eagerly look for-\\nward to and hope to contribute to.\\nThe horizon of generative AI is vast, and I am filled with \\noptimism about its trajectory. With the right measures in place \\nand a genuine commitment to addressing concerns, generative \\nAI can be a boon for humanity. The myriad possibilities it pre-\\nsents are not just technological advancements but also potential \\nsolutions to long-standing societal challenges.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ethical Concerns and Social Implications of Generative AI 335\\nThe promise of enhanced services, as highlighted by \\nChamath Palihapitiya at the All- In Podcast, underscores the \\ntransformative potential of generative AI. Imagine a world \\nwhere customer interactions are seamless, devoid of linguistic \\nbarriers, fostering trust and understanding. Such advancements, \\nif executed with care and precision, can redefine customer \\nexperiences.\\nThe future, as I envision it, is one where the content of \\n2023\\xa0might be revered as a relic of a bygone era, predominantly \\nhuman- generated. The job landscape will undergo a seismic \\nshift, with a surge in entrepreneurial ventures and research- \\ndriven roles in the AI domain. By 2030, I foresee a world where \\nproductivity will be 10X, the corporate landscape will be 100X, \\nand the volume of content, products, and knowledge will 1,000X. \\nQuality will emerge as the distinguishing factor, setting apart the \\nexceptional from the ordinary.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content=''),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='337\\nI\\nn advocating for generative AI, this book delineates the pro-\\ngression from conventional AI toward a more generative \\nmodel. The journey commences with discriminative AI, the cor-\\nnerstone for today’s generative AI systems. Pioneering algo-\\nrithms in computer vision, like convolutional neural networks, \\nalong with strides in sentiment analysis and other natural lan-\\nguage processing (NLP) tasks, have significantly contributed to \\nthe evolution of generative models. These advancements now \\npropel the AI frontier further. Discriminative models remain \\ninvaluable, with their precise applications such as cancer detec-\\ntion showcasing their worth by refining accuracy to significant \\ndecimal places.\\nT ransitioning our gaze toward generative AI, it’s clear that \\nthis realm is a pivotal precursor to the lofty realm of artificial \\n6\\nCHAPTER\\nArtificial General \\n Intelligence in\\xa0Sight'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='338 GENERATIVE AI\\ngeneral intelligence (AGI). The consensus is yet to be reached on \\nthe exact makeup of AGI, but a plausible hypothesis posits it as a \\nsynergy of discriminative and generative AI models.\\nBut what encapsulates AGI?\\nDescribed as a hypothetical yet potent entity, AGI is envi-\\nsioned to master any intellectual feat achievable by humans or \\nanimals. In another vein, it’s seen as an autonomous dynamo out-\\nperforming human aptitude in a vast array of economically valu-\\nable tasks. AGI frequently graces science fiction and futurist \\ndiscussions, embodying both the zenith of AI aspiration and a \\ntopic of fervent debate. Predicting AGI’s advent is akin to chasing \\nhorizons— some envisage its dawn in mere decades, others con-\\njecture a century, and a few naysayers deem it a pipe dream. The \\ndiscourse extends to whether behemoths like GPT-4 are embry-\\nonic iterations of AGI or if a paradigm shift is imperative. Various \\nmonikers like strong AI, full AI, or general intelligent action reso-\\nnate with AGI, although distinctions are noted, especially in aca-\\ndemic circles. Although strong AI hints at a sentient or conscious \\nprogram, its counterpart, weak AI, excels in singular tasks but \\nlacks the broad cognitive prowess. AGI’s kindred spirits are \\nhuman-level AI and superintelligence, each bearing a spectrum of \\npromises yet tethered to substantial advancements still to come.\\nAs we traverse further into this chapter, the horizon broadens \\nto reveal the upcoming milestones in generative AI, encapsulat-\\ning multitasking, multimodal, and multisensory AI. We’ll also \\nexplore other burgeoning trends and the nexus of technologies \\nwithin this realm. A notable derivative of generative AI, autono-\\nmous AI agents, beckons our attention, urging us to adapt to a \\ncollaborative rapport with these entities.\\nThe ensuing discourse delves into AGI’s allure, its pathway, \\nand the paradigm it aims to establish. While AGI signifies a  \\nprofound milestone, the narrative extends to artificial superintel-\\nligence (ASI), leading us to the precipice of singularity as envi-\\nsioned by Ray Kurzweil.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 339\\nOur narrative briefly pivots toward the tangible manifesta-\\ntions of AI advancements— humanoid robots, epitomizing the \\nfusion of form and intellect. While industrial robots also repre-\\nsent a fascinating facet of AI, our focus here remains tethered to \\nhuman-like embodiments, heralding the convergence of the \\nphysical and the digital realms.\\nWhat Is Next in Generative AI?\\nThe journey of AI continues to charge ahead, building upon past \\nprogress with the aid of new technology like neuromorphic and \\nquantum computing, or even potential breakthroughs like \\nLK-99. These technologies are taking AI models to new heights, \\nshowcasing the kind of exponential development discussed ear -\\nlier in this book.\\nThe heartbeat of AI development is strong and rapid, with a \\nplethora of research papers emerging in the generative AI space \\non platforms like arXiv. The fast pace is partly due to the lack of \\na lengthy peer-review process, and partly driven by the rush to \\nseize valuable ground in this flourishing domain. Unlike the \\ntransient buzz around cryptocurrencies, the breakthroughs in AI \\nare tangible, with real code and real demos illustrating its power \\nand potential. This isn’t just hype; it’s technology that’s proving \\nits mettle and showing promise for a solid future.\\nNow, let’s talk about what’s brewing on the horizon: enrich-\\ning experiences.\\nT ake the initiative by Wist Labs, for instance. They’re work-\\ning on a way to rejuvenate old memories from videos. Through \\naugmented reality glasses, you could re-experience a past event \\nright where it happened, but now as a hologram. And here’s \\nwhere it gets even more intriguing: imagine a multimodal AI \\nmodel that can continue the video, creating a holographic narra-\\ntive that interacts with you, maybe based on how the individuals \\nin the video would have reacted. It’s about not just reliving'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='340 GENERATIVE AI\\nmemories, but possibly creating new, beautiful ones. Though the \\nidea might seem eerie to some, the potential to reconnect with a \\nlost loved one could be priceless to others.\\nT ech giants like Snap and Meta are also stepping into  \\nthis realm, aiming to bridge the miles between us and our loved \\nones, virtually. Recall the humble beginnings of long-distance \\ncommunication— like the crackly phone calls of yesteryears. Now, \\nwe’re talking about entering a virtual room to celebrate a family \\nevent or watch a movie together, despite being continents apart. \\nJust a short while ago, personalities like Lex Fridman and Mark \\nZuckerberg showcased the potential of this technology. They had \\na podcast in a virtual world, with hyper-realistic avatars created \\nthrough detailed scanning and high-end virtual reality gear. The \\nexperience was lauded for its realism, indicating that the eerie \\nuncanny valley might be behind us.\\nWith these examples, it’s clear that the realms of augmented \\nreality (AR) and virtual reality (VR) are on the cusp of monu-\\nmental evolution. Over the next 5 to 10 years, we might find \\nourselves celebrating life’s milestones with loved ones on a vir -\\ntual beach or in a cozy cinema, all from the comfort of our homes. \\nAnd it won’t stop at sight and sound. Future VR could let us feel \\na hug, taste the birthday cake, or bask in the warmth of virtual \\nsunlight. It’s a journey from flat screens to a rich, multisensory \\nvirtual world, all powered by the relentless march of gen-\\nerative AI.\\nMultitasking Generative AI\\nIt is not just about mastering singular tasks but extending capa-\\nbilities to manage multiple tasks simultaneously. Recent advance-\\nments have shown that LLMs like ChatGPT , Bard, and others \\nexhibit multitasking abilities straight out of the gate, especially \\nwhen it comes to emergent capabilities.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 341\\nEssentially, multitasking or multitask learning (MTL) in AI \\nis about tackling multiple learning challenges at once, leveraging \\nthe similarities and differences across these tasks to improve the \\nlearning outcome. This method enhances generalization by tap-\\nping into the domain information present in the training data of \\nrelated tasks, which acts as a form of inductive bias. The beauty \\nof MTL lies in its parallel learning approach with a shared rep-\\nresentation, enabling the learning from one task to aid the learn-\\ning in others.\\nA hiccup in this area has been the tradition of deep-learning \\nsystems being tailored to solve specific problems, say image rec-\\nognition. However, there’s a shift in the narrative with the advent \\nof models like Google’s MultiModel, which is adept at handling \\nmultiple tasks like image and speech recognition, translation, \\nand sentence analysis concurrently.\\nThe road to achieving adept multitasking AI models is filled \\nwith challenges, especially when it comes to learning multiple \\nskills without having to reboot the learning process for each new \\nskill. This has spurred researchers into exploring various avenues \\nlike optimized task scheduling and scaling the multitask learning \\nfor a plethora of modeling tasks.\\nT ransitioning the lens to generative AI, multitasking unfolds a \\nnumber of possibilities. LLMs are about not just one trick but a \\nwhole gambit of tasks like text generation, text summarization, \\nlanguage translation, question answering, sentiment analysis, \\nnamed entity recognition, code generation, text classification, \\nspeech-to-text transcription, text-to-speech synthesis, image cap-\\ntioning, paraphrasing, chatbot functionality, content curation, data \\naugmentation, text-based game playing, mathematical problem \\nsolving, syntax highlighting, keyword extraction, and language \\nidentification.\\nThe narrative gets even more interesting with advanced gen-\\nerative models that can juggle multiple types of data, like text,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='342 GENERATIVE AI\\nimages, and audio, and perform tasks across these different \\nmodalities. For instance, DALL-E from OpenAI is a stellar exam-\\nple of how a model can morph text into images, thereby showcas-\\ning prowess in both text understanding and image generation. \\nThis opens the door to a thrilling domain known as multimodal-\\nity, which we will delve into shortly.\\nThis expansion of multitasking in generative AI is not just a \\nleap but a giant stride toward more versatile and effective AI sys-\\ntems. It’s about transcending the boundaries of singular task \\nlearning to create AI models that are adept at juggling multiple \\ntasks, much like a seasoned multitasker in the human realm. This \\nnot only amplifies the potential applications of AI but also brings \\nus closer to creating more intelligent and adaptable AI systems. \\nAnd, it is mandatory for achieving an AGI.\\nMultimodal Generative AI\\nThe journey of exploring AI brings us to the nuanced domain of \\nmultimodal AI, an area we have touched upon multiple times. It’s \\nabout time we delve deeper to understand its essence. Multi-\\nmodal AI embodies the capability of AI systems to interpret, pro-\\ncess, and derive insights from various types of data or “modalities” \\nsuch as text, images, audio, and video. This approach aims to \\nemulate the human ability to employ multiple senses in interact-\\ning with the world. For instance, a multimodal AI system could \\nscrutinize both audio and visual elements of a video to grasp its \\ncontent better.\\nIn the realm of discriminative AI, multimodality is about the \\nAI models’ ability to understand various input types to carry out \\ntasks like classification or regression toward producing an out-\\nput. However, the output here isn’t multimodal.\\nNow, steering the narrative toward multimodal generative \\nAI, we enter a landscape where the focus is on crafting new'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 343\\ncontent that traverses multiple modalities. Picture a system capa-\\nble of creating a video by synthesizing visual imagery along with \\ncorresponding audio or fashioning a social media post adorned \\nwith text, images, and hashtags. This extension of generative \\nmodels into multimodal scenarios opens up a vista where AI \\nbegins to churn out complex, multifaceted content that resonates \\nwith a higher degree of utility and engagement. Unlike discrimi-\\nnative AI, both the input and output can be multimodal in the \\ncase of generative AI.\\nMultimodal generative AI truly hit home when GPT-4 \\nshowcased its prowess in March, elucidating image data with an \\nastonishing level of detail. GPT-4, backing ChatGPT Plus, her-\\nalds the era of vision language models (VLMs), a cohort to \\nwhich PaLM-backing Bard also belongs. VLMs are adept at \\ncreating a shared embedding space for images and texts, paving \\nthe way for text-to-image or image-to-text queries. A striking \\nexample could be a scenario where a user inquires about a loca-\\ntion depicted in an image and seeks budget-friendly travel \\noptions to get there. This nuanced capability of VLMs hints at a \\nprofound transformation in how we conduct searches, if har -\\nnessed correctly.\\nThe emergence of multimodal generative AI is like opening \\na new chapter in the AI narrative, one where the convergence of \\ntext, image, audio, and video modalities breeds a more robust \\nand versatile generation of AI systems. This not only enriches \\nthe user interaction but also nudges AI a step closer to human-\\nlike comprehension and creativity.\\nIn August 2023, Meta AI introduced SeamlessM4T , a revolu-\\ntionary multimodal AI model, bringing a significant upgrade to \\nspeech-to-speech and speech-to-text translations. By tackling \\nthe hurdles of limited language coverage and dependence on \\nseparate systems, it aims to smooth communication among dif-\\nferent language speakers through high-quality translations.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='344 GENERATIVE AI\\nSeamlessM4T is touted as the first all-encompassing multi-\\nlingual multimodal AI model for translation and transcription. \\nIt’s a powerhouse that can handle a variety of tasks— speech-to-\\nspeech, speech-to-text, text-to-text, text-to-speech, and auto-\\nmatic speech recognition— all under one roof. Unlike previous \\nsetups using distinct models, SeamlessM4T’s unified system cuts \\ndown errors and delays, enhancing the translation quality and \\nefficiency.\\nBuilding upon earlier efforts like the No Language Left \\nBehind (NLLB) text-to-text translation model, which supports a \\nwhopping 200\\xa0languages, SeamlessM4T steps it up. It comes in \\ntwo versions: the SeamlessM4T-Medium with 1.2 billion param-\\neters, and the more robust SeamlessM4T-Large with 2.3 billion \\nparameters. The benefit? Better robustness against background \\nnoises and speaker variations in speech-to-text tasks. Plus, Seam-\\nlessM4T has outshone previous top-notch models, showing it’s a \\nforce to reckon with in the translation arena.\\nThe realm of multimodal AI is ripe with potential, opening \\ndoors to countless applications without needing a stretch of \\nimagination. T ake biomedicine, for instance. The melding of \\nvaried biomedical data— from electronic health records to \\ngenome sequencing— has ushered in a new era of multimodal AI \\nin healthcare. This blend of data types is a gold mine for devel-\\noping insightful AI applications, making healthcare more \\ninformed and personalized.\\nThe horizon is vast and the ideas endless. With a simple two-\\nstep prompt or something similar, anyone can spark brilliant \\nideas they’d wish to chase (Figure\\xa0 6.1). This simplicity is a  \\ndoorway to innovation, allowing minds to explore, create, and \\ntransform thoughts into reality.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 345\\nThe exploration yielded 10 high-level suggestions, with two \\nstanding out particularly:\\nPersonalized medicine Envisage crafting tailored treatment \\nplans by marrying and mining insights from a medley of data— \\ngenomic, clinical, and environmental. This meld of multi-\\nmodal data could be the linchpin in personalizing medical care.\\nPredictive modeling of\\xa0disease progression Imagine lever-\\naging generative models to simulate disease progression in \\nindividual patients. This could be a game changer for early \\nintervention and tailoring treatment plans.\\nOther intriguing ideas surfaced through this ChatGPT \\ninteraction, like “Generative Remote Monitoring and ‘Hospital-\\nat-Home,’” “Digital Clinical T rials,” “Digital T wins (of humans),” \\nand “Virtual Health Assistants.” These hint at the expansive \\npotential of multimodal AI across diverse healthcare facets.\\nFIGURE\\xa06.1 A simple two-step prompt unfolding the horizon of end-\\nless ideas and innovation.\\nSource: ChatGPT screenshot'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='346 GENERATIVE AI\\nThese preliminary ideas are captivating. With some fine-\\ntuning and perhaps garnering expert insights through interviews, \\nthere’s a solid base to further fortify these concepts. Post- \\nvalidation, these ideas could be the springboard for securing ven-\\nture capital or kick-starting a bootstrap journey, paving the way \\nto harness multimodal AI in transforming healthcare.\\nMultisensory Generative AI\\nDelving into the realm of multisensory generative AI, the spot-\\nlight is on generating data perceivable through a medley of \\nsenses— sight, sound, touch, and beyond. This subfield of multi-\\nmodal generative AI marries data generation with different types \\nof actuators (hardware) to engage multiple senses.\\nThe data terrain here primarily sprawls across sensory data \\nlike images, spatial sounds, and haptic feedback, but is not \\nrestricted to them. Picture virtual reality (VR) realms enriched \\nwith touch, thermal, and other sensory actuators that pull users \\ndeeper into the virtual abyss.\\nThe real world already hosts applications of multisensory \\napplications. T ake the PlayStation 5 DualSense controller, a mar-\\nvel in the gaming arena. This gadget boasts advanced motors \\ndelivering precise feedback at different controller points. Cou-\\npled with a high-fidelity speaker and an integrated mic, it takes \\ngaming to a sensory-rich level. The L2 and R2 buttons, infused \\nwith haptic feedback through little motors that give you differ -\\nent types of resistance, simulate real-world actions like firing a \\ngun or drawing a bowstring. By generating virtual worlds and \\nsteering commands for DualSense actuators, multisensory gen-\\nerative AI amplifies the immersive gaming experience— a prom-\\nising field indeed.\\nThen there are sensory substitution devices aiding individuals \\nwith disabilities. For instance, Neosensory Buzz, a wearable wrist-\\nband, translates auditory cues into tactile sensations. Capturing'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 347\\nsurrounding sounds, it churns out vibration patterns on the user’s \\nwrist, creating over 29,000 unique patterns based on sound inten-\\nsity and pitch. It’s a boon for the deaf and hard-of-hearing com-\\nmunity, alerting them to sounds like doorbells, conversations, and \\nemergency alarms. Accompanied by a companion app, Buzz  \\ncan be tailored for everyday sounds, music appreciation, or \\nsafe sleeping.\\nMultisensory generative AI is at the cusp of forging a more \\ninclusive and immersive digital realm, bridging the sensory gap \\nbetween the virtual and real worlds.\\nVenturing into the realm of steering actuators, a plethora of \\npossibilities unfolds. A myriad of actuators await exploration, \\nsome familiar, others less so. Let’s journey through a few, and as \\nwe do so, hold on for a moment, close your eyes, and imagine \\npotential applications:\\nAuditory actuators\\nSpeakers: Produce sound waves to create auditory sensations.\\nBone conduction transducers: A bone conduction transducer is a \\ndevice that converts audio signals into vibrations, which are \\nthen transmitted through the bones of the skull to the inner \\near, bypassing the eardrums. This technology is used in bone \\nconduction headphones and hearing aids, allowing users to \\nperceive audio content even if their ear canal is blocked or \\nthey have hearing difficulties.\\nTactile actuators\\nHaptic actuators: Produce vibrations or movements to simu-\\nlate touch.\\nPiezoelectric actuators: Generate mechanical displacement through \\nelectric voltage, often used in haptic feedback.\\nElectroactive polymers: Change shape when an electric field is \\napplied, providing a tactile sensation.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='348 GENERATIVE AI\\nThermal actuators\\nA Peltier element, also known as a thermoelectric cooler (TEC), is \\na device that uses the Peltier effect to transfer heat from one \\nside to the other when an electric current is applied.\\nInfrared heaters: Produce warm air or directly heat surfaces.\\nThermoelectric coolers: Provide a cooling effect.\\nOlfactory Actuators\\nScent diffusers: Release specific scents into the air.\\nOlfactory actuators: Devices that can emit or release odors in \\nresponse to a stimulus, such as an electric signal or a change in \\ntemperature or humidity. These devices are part of artificial \\nolfactory systems, which aim to mimic the human sense of \\nsmell and detect and recognize volatile organic compounds \\n(VOCs) in complex environments.\\nGustatory actuators\\nFlavor sprays: A spritz that carries the essence of flavors, a gusta-\\ntory glimpse.\\nAir movement actuators\\n• Fans: Breathing motion into the still air, a gentle whisper or \\na gusty shout.\\nMoisture actuators\\n• Water sprays and ultrasonic humidifiers: Unveiling mist or a \\nwater spray to add moisture to the environment.\\nMiscellaneous, enhancing the\\xa0sensory spectrum:\\nElectrical muscle stimulation (EMS): Spurring muscle contractions \\nwith electric impulses.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 349\\nLight-emitting diodes (LEDs): Lighting the way with visual cues.\\nMultimodal actuators\\n• 4D cinema seats: A confluence of actuators, they orchestrate a \\nsymphony of sensations— movement, vibration, tempera-\\nture— a cinematic voyage beyond the ordinary.\\nThe terrain is ripe for nurturing startup ideas, a fertile ground \\nof innovation. No longer can potential be dismissed due to hurdles \\nX, Y, or Z. Embrace the extraordinary, challenge the norm, yet tread \\nwisely— validate assumptions early. Engage with gusto, and success \\nwill morph from chance to certainty. The future is a canvas awaiting \\nyour strokes— seize it, and witness your vision morph into reality.\\nAs a multisensory example, Meta introduced a trailblazing \\nventure named ImageBind. This initiative is akin to opening a \\nnew chapter in the saga of AI, nudging us closer to a realm where \\nmachines learn from a rich tapestry of data types surrounding \\nthem, much as humans do.\\nAt its core, ImageBind is a master key to a treasure trove of \\nlearning across six different realms— images, text, audio, depth, \\nthermal, and inertial measurement unit (IMU) data. It’s akin to a \\npolyglot mastering six languages at once, a first in the AI domain. \\nThis unique model interprets content more wholesomely, mir -\\nroring humans’ knack for simultaneous, holistic learning from \\nvarious information forms— all without needing guidance from a \\nteacher (a process known as explicit supervision).\\nDrawing inspiration from recent large-scale vision-language \\nmodels, ImageBind amplifies their zero-shot learning capabili-\\nties to new modalities, simply by pairing them with images. It’s \\nlike adding new strings to a guitar, enabling a richer melody of \\napplications “out-of-the-box.” This includes the magic of cross-\\nmodal retrieval, composing modalities with arithmetic, and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='350 GENERATIVE AI\\ncross-modal detection and generation. The more adept the \\nimage encoder, the stronger the emergent capabilities, setting a \\nnew gold standard in zero-shot recognition tasks across modali-\\nties, leaving specialist supervised models in the dust.\\nImageBind unravels the potency of image-paired data as a \\nbinding glue for these six modalities. It’s a leap forward in AI, \\nenhancing machines’ prowess in dissecting diverse information \\nforms in unison. Imagine Meta’s Make-A-Scene application con-\\njuring images from audio cues— a bustling market or a serene \\nrainforest brought to visual life from mere sounds. This is the \\nmagic ImageBind is brewing.\\nImageBind isn’t a solitary endeavor but a part of Meta’s grand \\nvision of crafting multimodal AI systems that soak in all possible \\ndata types around them. As the modalities multiply, ImageBind \\nbeckons researchers to a realm brimming with prospects— \\nmelding 3D and IMU sensors to craft or traverse immersive vir-\\ntual worlds, for instance.\\nIn a nutshell, ImageBind is less of an end, more of a begin-\\nning— a harbinger of an era where AI isn’t just about crunching \\nnumbers but about perceiving, interpreting, and learning from \\nthe world in a way that’s more human, more holistic, and more \\npromising.\\nAs shown in Figure\\xa06.2, an image of a pigeon coupled with \\nthe sound of a motor revving is processed through the embedding- \\nspace arithmetic, yielding an image of a scooter with pigeons \\nfluttering away. Subsequently, it demonstrates its prowess in gen-\\nerating data across different modalities. For instance, when fed \\nwith a video capturing the calls of penguins, the image genera-\\ntion model adeptly creates a corresponding visual, enriching the \\nmultimodal data synthesis experience.\\nDreaming up ideas is the breezy part. T ranslating them into \\nreal-world applications is the real challenge, demanding a good \\ndose of persistence. But let’s face it, this is a truth as old as time.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 351\\nCentral to the success of multisensory generative AI is the \\nnotion of synchronized generation. This is about ensuring that \\nthe generated outputs across different senses are in harmony, \\nmoving to the same rhythm. Now, as you blend different sensory \\nmodalities into one unified framework, you stumble upon what is \\ntermed integration complexity. This demands a deep dive into \\nunderstanding each modality and the intricate dance between \\nthem for smooth interaction and effective feature extraction. It’s \\nlike orchestrating a symphony played by a range of instruments, \\neach with its unique note, yet\\xa0all needing to create a harmoni-\\nous melody.\\nNow, how do we gauge the success and precision of these \\nmultisensory generative models? That’s where robust evaluation \\nmetrics come into play. They are the magnifying glass that pro-\\nvides insight into the model’s prowess in crafting high-fidelity \\nand coherent multisensory outputs. It’s about ensuring what’s \\ngenerated isn’t just a cacophony but a well-tuned harmony.\\nFIGURE\\xa06.2 ImageBind unveils a realm of possibilities, including the \\ninnovative feature of embedding-space arithmetic. In essence, given \\nan image and a sound, it identifies the nearest corresponding data, be \\nit a video, image, or other media.\\nSource: (a) Miha Rekar / Unsplash, (b) Josefina Di Battista / Unsplash'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='352 GENERATIVE AI\\nBut, here’s the rub. Hardware limitations could throw a span-\\nner in the works when it comes to practical deployment. Surpass-\\ning hardware constraints for real-time processing and generation \\nis a hill to climb. This might beckon the dawn of more potent \\nhardware or perhaps tweaking the generative models to perform \\nefficiently within the bounds of existing hardware constraints. \\nIt’s like wanting to run a high-octane game on a vintage \\ncomputer— some serious upgrades or optimizations are in order.\\nIn a nutshell, while the journey from ideation to realization is \\ndotted with hurdles, each challenge overcome is a stride toward \\nmolding a future where multisensory generative AI isn’t just a \\nfigment of imagination, but a tangible reality shaping our inter -\\naction with the digital realm.\\nOther Observable Trends in Generative AI\\nIn this chapter, we embellish upon the trends discussed through-\\nout the book, touching on some additional noteworthy move-\\nments in the sphere of generative AI.\\nA spotlight is being cast on AI wrapper projects and compa-\\nnies that prominently integrate with enterprise data. A discerni-\\nble shift is underway, veering toward training generative AI \\nmodels on enterprise data. This shift empowers organizations to \\nharness their data for AI-centric applications, a trend I often, \\nespecially this year, navigate with my team in our AI consulting \\nprojects. This trajectory, which I’d like to call the industrializa-\\ntion of generative AI and large language models (LLMs) with \\nsemantic search, is an exciting avenue that melds the might of AI \\nwith the robustness of enterprise data.\\nShifting the lens to scientific research, it’s exhilarating to wit-\\nness how generative models are fueling the creation of new ideas, \\nthereby accelerating our journey of discovery— be it new mole-\\ncules, materials, or medications. With the prowess to navigate \\nthrough vast data oceans, these models identify elusive patterns,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 353\\noffering a fertile ground for new knowledge and solutions to \\nchallenging enigmas. The profound potential of generative mod-\\nels to traverse the boundless expanses of data in science, generat-\\ning novel insights and proposing starting points for the design \\nand discovery of new materials and drugs, is nothing short of \\nawe-inspiring.\\nNow, let’s pivot to a facet of generative AI that’s both intrigu-\\ning and imperative: explainability. The concept of making gen-\\nerative AI models more decipherable births what we now call \\nexplainable generative AI. This emerging field in AI research is not \\njust a mere academic exercise but a cornerstone in building trust \\nand fostering a deeper understanding of AI models, especially as \\nthey find their footing in enterprise-level use cases.\\nThe term black box often echoes in the corridors when dis-\\ncussing generative AI models. The enigmatic nature of these \\nmodels, where the pathway from input to output is shrouded in \\ncomplexity, often breeds mistrust and apprehension. The imper-\\native for transparency and comprehension nudges us toward \\nexplainable AI (XAI), a burgeoning field aimed at demystifying \\nthe outputs of AI models, making them more palatable and trust-\\nworthy to human users.\\nWhile XAI has been making headway in elucidating discrim-\\ninative models, generative models have yet to bask in the same \\nspotlight. As generative AI continues to unfurl its wings and nes-\\ntle into more enterprise use cases, the onus falls on IT leaders, \\ntechnologists, and developers to embody a holistic approach. \\nThis approach should encapsulate the essence of explainability \\nright from the embryonic stages of development, ensuring that \\nas we stride forward into the realms of generative AI, we carry \\nwith us a torch of understanding, shedding light on the once \\nobscure pathways of generative models.\\nNavigating the realm of AI, especially generative AI, is akin to \\nembarking on a quest for transparency in a forest of complexities. \\nIt’s a journey to make the actions and decisions of AI models'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='354 GENERATIVE AI\\ninterpretable to humans, unmasking the “black box” to reveal a \\nnarrative that’s both engaging and insightful. Among the torch-\\nbearers of this quest are techniques like LIME, SHAP , and others, \\neach with its distinct path toward illuminating the enigmatic \\nworkings of AI.\\nLIME, an acronym for local interpretable model-agnostic \\nexplanations, is a method that attempts to demystify complex \\nmodels by approximating them with simpler, interpretable mod-\\nels in the vicinity of a specific data point. This approximation is \\nakin to zooming into a small, understandable part of a large, \\ncomplex picture, making the incomprehensible comprehensible. \\nA variant of LIME, dubbed VAE-LIME, employs a variational \\nautoencoder to delve into the data’s intricate traits, generating \\nsynthetic samples that serve as a training ground for a simpler, \\nlocal model. This local model endeavors to mimic the behavior \\nof a complex model near a specific input, rendering a prediction \\nthat’s easier to interpret. In the realm of generative AI, LIME \\nelucidates which parts of the input, like pixels in an image, play a \\nsignificant role in the generated output.\\nT ransitioning to SHAP , or SHapley Additive exPlanations, \\nwe venture into a technique rooted in cooperative game theory. \\nSHAP values are the messengers that convey the contribution of \\neach feature toward a prediction made by a model. They unravel \\nthe significance and interaction of features within a model, paint-\\ning a clearer picture of how each feature sways the final predic-\\ntion. In generative models, SHAP divulges how features of \\ngenerated data are intertwined with the model’s latent variables \\nor parameters. It’s like having a magnifying glass that shows how \\ntweaking different features in the latent space affects the gener -\\nated data. SHAP not only assists in comparing different genera-\\ntive models but also aids in optimizing and debugging them, \\nmaking it an invaluable tool for understanding and refining gen-\\nerative models.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 355\\nAs we further traverse, counterfactual explanations emerge as \\na method of understanding how minimal changes in inputs can \\nlead to different outputs. It’s like tweaking the recipe slightly to \\nget a surprisingly different dish. Activation maximization, on the \\nother hand, unveils the features captured in generative models by \\nmaximizing neuron activation, akin to turning up the volume to \\nhear the subtle notes in a symphony. Saliency maps and feature \\nimportance shine a light on the influential regions of input and \\nthe impact of each feature respectively, offering a lens to see what \\nparts of the input significantly affect the generative outputs. \\nLastly, model dissection delves into the layers and neurons of \\ncomplex generative models like generative adversarial networks \\n(GANs), dissecting them to understand their roles in the grand \\nscheme of data generation.\\nMerging explainable AI with generative models is an unfold-\\ning realm in AI research. The key challenge is balancing  \\nhigh-quality output generation with clear explanations of the \\ngenerative processes. Delving into this topic reveals ample room \\nfor exploration and contribution, signaling a possible avenue for \\nyour involvement. The field is ripe for further investigation and \\ndevelopment.\\nScaled Utilization of AI: Autonomous AI Agents\\nHarnessing the power of AI through autonomous AI agents her-\\nalds a new era in the technological landscape. As briefly touched \\nupon in Chapter 3, “Generative AI’s Broad Spectrum of Applica-\\ntions,” the journey from concept to real-world application is \\nunfolding. Prominent tech visionaries like Matt Schlicht, CEO \\nat Octane AI, foresee a timeline where these autonomous agents \\nevolve into professional aides by 2024 and seamlessly integrate \\nacross various sectors by 2025. By 2026, it’s conceivable that we \\ncould be accompanied by a cadre of autonomous AI agents dedi-\\ncated to assisting us in both personal and professional spheres.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='356 GENERATIVE AI\\nOn a similar note, Mustafa Suleyman, a distinguished AI \\nresearcher and the brain behind Inflection AI, projects a future \\nwhere AI morphs from static web interfaces to dynamic conver-\\nsational agents.\\nPicture a digital companion capable of generating multime-\\ndia content while engaging in a meaningful dialogue. The essence \\nof these agents lies in their ability to align with individual inter -\\nests, acting as a personal chief of staff that not only responds to \\nyour requests but proactively helps you realize your long-term \\nobjectives. Whether it’s securing a prime reservation for an inves-\\ntor lunch or keeping you abreast of relevant news, the autonomy \\nand personalization of these agents encapsulate a blend of execu-\\ntive assistant and trusted confidante.\\nThe envisioned autonomy extends to a level where sharing \\nsensitive information with your AI agent becomes a norm, nur -\\nturing a relationship akin to that with a trusted aide. From sched-\\nuling to summarizing, the roles these agents could play are \\ndiverse and tailored to individual needs. Wake up to a personal-\\nized briefing, navigate through your day with intelligent sugges-\\ntions, and delegate tasks with the assurance of precision and \\ntimely completion.\\nSuleyman’s vision encapsulates a world where each individual \\nis aided by an AI chief of staff, adept at morphing roles as per the \\ntask at hand. The exact manifestation of these agents— be it a \\nsingle AI wearing multiple hats or a team of specialized AIs— \\nremains an open-ended narrative. However, the common thread \\nbinding all predictions is the user’s ability to choose from a spec-\\ntrum of AI offerings, each promising to make life a tad easier, \\norganized, and focused.\\nAt the core, these agents are the embodiment of LLMs exhib-\\niting a flair for human-like decision making. The essence of these \\nagents lies in an architecture comprising diverse modules like'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 357\\nprofiling, memory, planning, and action. The profiling module \\nshapes the agent’s persona, memory holds the essence of past \\ninteractions, planning choreographs the path to goals, and action \\ntranslates decisions into tangible outputs (Figure\\xa06.3).\\nThe landscape of developing autonomous AI agents is vibrant \\nwith innovation, and frameworks like AutoGPT , LangChain, \\nSuperAGI, and AutoGen are leading the charge. They not only \\noffer a solid foundation for development but also embody the \\ndynamics of the field, where change is the only constant.\\nT ake Auto-GPT , a brainchild of T oran Bruce Richards from \\nSignificant Gravitas Ltd. It’s the first significant autonomous AI \\nagent framework powered by a language model, and it is open \\nsource. Unlike traditional models, Auto-GPT embodies a self-\\ndriven spirit, creating and revising its objectives to chase a \\nbroader goal, without the need for human intervention. It’s not \\njust about responding to prompts; it’s about crafting new prompts, \\nadapting to new information, and working toward the stated \\nProfile\\nProfile Contents Memory Structure Planning w/o Feedback Action Target\\nAction Production\\nAction Space\\nAction Impact\\nPlanning w/ Feedback\\nMemory Formats\\nMemory Operation\\nGeneration Strategy\\nDemographic Information Unified Memory\\nSingle-path Reasoning\\nMulti-path Reasoning\\nExternal Planner\\nTask Completion\\nCommunication\\nMemory Recollection\\nPlan Following\\nTools\\nEnvironments\\nInternal States\\nNew Actions\\nSelf-Knowledge\\nExploration\\nEnvironment Feedback\\nHuman Feedback\\nModel Feedback\\nLanguages\\nEmbeddings\\nDatabases\\nLists\\nHybrid Memory\\nMemory Reading\\nMemory Writing\\nMemory Reflection\\nPersonality Information\\nSocial Information\\nHandcrafting Method\\nLLM-Generation Method\\nDataset Alignment Method\\nMemory Planning Action\\nFIGURE\\xa06.3 Autonomous AI agents framework.\\nSource: Paitesanshi / GitHub, Inc. / https://github.com/Paitesanshi/LLM-Agent-Survey / \\nlast accessed December 04, 2023.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='358 GENERATIVE AI\\ngoal. The agent’s interaction extends to apps, software, and online \\nservices, showcasing a glimpse of a self-reliant digital entity.\\nAuto-GPT’s success is evident in its “star history” (see  \\nFigure\\xa06.4), a tool that visually represents the project’s growing \\npopularity and engagement on GitHub over time.\\nAuto-GPT , despite its trailblazing outset, showcased the \\ninfancy of this realm. It had its share of missteps, misinterpreta-\\ntions, and diversions. Y et, it stood as a testament to the AI com-\\nmunity, heralding the dawn of what’s next.\\nThe journey from Auto-GPT’s inception to the burgeoning \\nframeworks of today encapsulates the rapid evolution in molding \\nautonomous agents. As we traverse this path, each stride, each \\nmisstep, and each success propels us closer to a reality where AI \\nisn’t just a tool, but a self-reliant entity, autonomously navigating \\nthe still vast digital realm.\\nApril MayJ uneJ uly\\nDate\\nSignificant-Gravitas/AutoGPT140.0k\\nStar History\\n120.0k\\n100.0kGitHub Stars\\n80.0k\\n60.0k\\n40.0k\\n20.0k\\nAugust September October\\nstar-history.com\\nFIGURE\\xa06.4 Star history of one of the first AI agent repositories. Going \\nviral at first, smoothly plateauing afterward, as other competitive \\nframeworks like SuperAGI arrive in the market.\\nSource: GitHub, Inc. / https://github.com/Significant-Gravitas/AutoGPT / last accessed \\nDecember 04, 2023.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 359\\nLet’s pivot to LangChain, a robust library/framework for \\nPython and JavaScript/T ypeScript enthusiasts. It’s your go-to \\navenue for prototyping large language model applications swiftly. \\nLangChain facilitates the chaining of LLM tasks and the smooth \\noperation of autonomous agents. Delving into a complex task? \\nLangChain agents break it down into a multistep action plan, \\ntackling each intermediate step to reach the coveted final answer.\\nThe Agents module in LangChain is a boon for developers \\nkeen on prototyping large language model applications and con-\\nstructing autonomous agents. The beauty of LangChain agents \\nlies in their chaining ability. They bridge the LLM to external \\nknowledge resources or computational tools seamlessly. The \\narray of agents, like the zero-shot-react-description, is impres-\\nsive. Utilizing the ReAct (Reason + Act) framework, they select \\nthe most suitable tool based on the input query. ReAct, in essence, \\nis a mechanism that guides the agent to reason the query and act \\nby choosing the apt tool for execution. With robust querying \\ncapabilities, LangChain agents automate various tasks with finesse.\\nIntegration is a strong suit of LangChain. From primary \\ncloud storage services like Amazon, Google, and Microsoft Azure \\nto API wrappers accessing diverse data, it’s well equipped. It also \\nventures into web scraping, script executions, few-shot learning \\nprompt generation, and much more. The support for over 50 \\ndocument types and data sources showcases its expansive capa-\\nbility. It’s no wonder many in the generative AI space vouch for \\nLangChain as the foundation for development, be it for autono-\\nmous agents or semantic search in LLM querying.\\nIn other words, LangChain integrates various modules: the \\ncore LLM, chains for linking LLM calls, efficient prompt man-\\nagement, along with document loaders, utilities, vector stores for \\ndata handling, and agents for interactive AI tasks, all designed for \\nseamless and adaptable AI applications. Figure\\xa06.5 shows a high-\\nlevel overview.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='360 GENERATIVE AI\\nT ransitioning to SuperAGI, it emerges as a notable open \\nsource platform providing a solid infrastructure for crafting \\nautonomous AI agents rapidly. Developers find a haven in Super-\\nAGI to build, manage, and run autonomous agents reliably. The \\nplatform is adept at running multiple agents concurrently, a fea-\\nture that elevates the management of multiple agents to a breeze.\\nSuperAGI is a reservoir of tools and toolkits, extending the \\ncapabilities of agents in areas like knowledge embeddings and \\nagent workflows. One standout feature is the Dashboard\\xa0– Action \\nConsole, a graphical interface allowing developers an interactive \\nengagement with their agents. The agent templates are a notewor-\\nthy inclusion, offering a springboard for developers to create task-\\nspecific AI agents. For instance, the SuperCoder template facilitates \\nFIGURE\\xa06.5 A high-level diagram of LangChain capabilities.\\nSource: Kamlesh Singh / A Medium Corporation / https://medium.com/@singh. \\nkamlesh1991/if-you-wanted-to-build-your-own-chatgpt-based-on-your-own-data-then- \\nlangchain-framework-is-perfect-c62656d63376 / last accessed December 04, 2023.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 361\\nthe crafting of simple software applications using defined goals \\nand instructions.\\nThe SuperAGI Marketplace is a realm where you can deploy \\nyour first agents using ready-made templates (Figure\\xa06.6). It’s a \\nplatform that not only accelerates the development of autono-\\nmous agents but also ensures a reliable, user-friendly experience \\nfor developers navigating the AI development landscape. \\nThrough LangChain and SuperAGI, the journey from ideation \\nto deployment in the autonomous AI agent sphere becomes an \\nengaging and efficient endeavor.\\nRecall the notion of having a chief of staff with a dynamically \\nassembled team? AutoGen seemingly brings this concept to life \\nin the realm of LLMs. It’s a framework tailored for crafting LLM \\napplications via multiple agents capable of conversing to unravel \\ntasks. The agents here aren’t just autonomous but are also con-\\nversable and customizable. Figure\\xa06.7 illustrates simplified con-\\nversation patterns between agents.\\nAutoGen’s forte lies in streamlining the orchestration, auto-\\nmation, and optimization of complex LLM workflows. It’s a hub \\nfor fostering next-generation LLM applications rooted in multi-\\nagent conversations with minimal developmental hurdles. The \\nFIGURE\\xa06.6 SuperAGI’s Marketplace.\\nSource: SuperAGI / https://superagi.com/ / last accessed December 01, 2023.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='362 GENERATIVE AI\\nframework is adept at amplifying the performance of LLM mod-\\nels while tactfully navigating their inherent weaknesses.\\nDive a bit deeper, and you’ll find AutoGen supporting a vari-\\nety of conversation patterns tailored for complex workflows. \\nWhether it’s joint or hierarchical chats, the framework enables \\ndevelopers to architect a broad spectrum of conversation pat-\\nterns. It’s the autonomy in conversation, the number of agents \\ninvolved, and the topology of agent conversation that sets \\nthe stage.\\nAutoGen isn’t just theoretical; it’s practicality shined through \\na collection of working systems, encapsulating diverse domains \\nand complexities. The ease of performance tuning, API unifica-\\ntion, caching, and advanced usage patterns like error handling \\nand context programming are notable mentions. The collabora-\\ntive work of Microsoft, Penn State University, and the Univer -\\nsity of Washington fuels AutoGen’s capabilities.\\nReal-world examples shared by the team aren’t just informa-\\ntive but are interactive, thanks to the Colab environment, a free \\ncloud-based service provided by Google that allows users to \\nwrite and run Python code in a Jupyter Notebook–like interface— \\nfrom automated task solving with code generation to collabora-\\ntive task solving with multiple agents and human users.\\nThe synergy of multiple language models, as explored by the \\nComputer Science & Artificial Intelligence Laboratory at MIT , \\nunderscores the potential of multistep LLM querying in enhanc-\\ning query accuracy. It’s a promising horizon for autonomous AI \\nagents, with AutoGen leading the charge.\\nIn a parallel vein, frameworks like MetaGPT and ChatDev \\nare making a significant ripple in the autonomous AI agent \\ndomain. MetaGPT is user friendly, translating a simple one-liner \\nrequirement input into a myriad of outputs like user stories, \\ncompetitive analyses, and real-time code manipulation through \\nmeta-programming techniques.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight  363\\nChatDev, on the other hand, is like a virtual software com-\\npany, with intelligent agents embodying roles like CEO, CTO, \\nand programmers. It’s a platform where multi-agent synergy is \\nharnessed to achieve varied objectives, from coding and writing \\nto graphic design and business management.\\nThe role-based conversations in ChatDev simulate dialogues \\namong different stakeholders in a project, bringing a realistic \\ntouch to task prioritization, technical solution brainstorming, \\nand documentation creation.\\nOnline examples abound, showcasing the practical deploy-\\nment of these frameworks. A case in point is an autonomous AI \\nagent team strategizing on promoting a company’s newsletter to \\ndrive subscriptions—\\n that was \\nthe goal the human has given the \\nAI team. The simulation reflected a multiway discussion among \\nagents, culminating in a collective agreement on an engaging \\nidea—\\n an interactive quiz to captivate customers.\\nMost,\\n if not all, of these frameworks and libraries embody the \\nspirit of open source, indicative of a robust community rallying \\nbehind the evolution of autonomous AI agents. The ecosystem is \\nFIGURE\\xa0 6.7  Orchestrate, automate, and optimize complex LLM  \\nworkflows with customizable multi-agent conversations, catering to a \\nspectrum of conversation patterns and application domains.\\nSource: GitHub, Inc. / https://github.com/microsoft/autogen / last accessed \\nDecember 04, 2023.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='364 GENERATIVE AI\\nripe, with frameworks like AutoGen, MetaGPT , and ChatDev \\npropelling the journey toward autonomous, conversable AI agents \\nand multiagent collaborative problem solving.\\nReading about all of the different roles and tasks possible, \\nimagine a day like this:\\nThe morning starts with a routine digital briefing from my exec-\\nutive assistant agent. It’s like a mini newspaper editorial, cov-\\nering exciting news snippets, my calendar agenda, and the \\nday’s task list— all curated to my preference.\\nThe week’s goal was clear: conceptualize a well-being app \\ndesigned as a comforting space where people can express their \\nfeelings and be listened to. Now, it’s about turning concept to \\ncode, and that’s where my developer agents come into play.\\nThe frontend agent unveils the latest app iteration. The interface \\nis clean, but it needs that personal touch, a color tweak. A brief \\nsync-up with the project management agent brings me up to \\nspeed on the backend’s enhanced database performance and \\nthe finalized Figma files from the UX agent. My feedback on \\nthe color palette is noted for immediate implementation— \\nefficiency at its best.\\nThe dream of an Italian apartment resurfaces later that morning. \\nA quick instruction to my legal agent sets the wheels in motion \\nto draft and negotiate the purchase agreement. The paper -\\nwork is tedious, but having an AI agent handle the legalese is a \\ntime saver.\\nPost-lunch, the ambiance morphs into a mini Italian town as my \\nteacher agent orchestrates an engaging Italian lesson. The lin-\\nguistic journey is briefly interrupted by my executive assistant \\nagent, signaling a client meeting. The transition is seamless, \\nthe morning briefing was a perfect primer, and the client  \\ndiscussion flows effortlessly.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 365\\nA vigorous tennis session later, the evening rolls in with a sched-\\nuled call with mom, all autonomously coordinated between \\nour calendars by my executive assistant agent. It’s family \\nfirst, always.\\nAs the day winds down, a final brief from my executive assistant \\nagent paints a clear picture: of the 115 emails that stormed my \\ninbox, a significant number were adeptly handled, responding \\nto a quarter of them in my voice, filtering out the mundane \\nbulk, and smartly deferring a crucial 5 percent for my review. \\nThe harmony in operation between me and my AI agents isn’t \\njust a time saver— it’s a life enhancer.\\nAs I retire for the night, the agents continue their digital dili-\\ngence, echoing a promising glimpse into a streamlined exist-\\nence. The orchestration of tasks, the seamless transitions \\nbetween schedules, and the autonomous handling of mundane \\nchores underscore a futuristic synergy that’s about not just aid-\\ning one’s professional life, but enhancing the human experience.\\nSouth Korea’s Exemplary Journey in\\xa0Tech Evolution\\nSouth Korea’s trajectory in technology is nothing short of remark-\\nable, catapulting it into a global powerhouse in various tech \\ndomains. The country’s accession to the\\xa0 Organisation for Eco-\\nnomic Co-operation and Development (OECD) in 1996\\xa0marked \\nthe start of an era steeped in technological advancements, under-\\npinned by a strong foundation in science. The hallmark of its tech \\nprowess was witnessed in 2021\\xa0when South Korea clinched the \\ntop spot in the Bloomberg Innovation Index, a feat that under -\\nscores its continual striving for innovation.\\nAmong the plethora of tech milestones, South Korea’s lead-\\nership in 5G adoption is noteworthy. It heralded the era of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='366 GENERATIVE AI\\ncommercial 5G in April 2019, and within a mere two months it \\naccounted for a whopping 77 percent of the global 5G user base. \\nGSMA Intelligence posits that this trend of 5G mobile penetra-\\ntion is likely to persist.\\nSouth Korea’s rapid Internet and smart cities like Songdo \\nexemplify tech advancement. Industrial giants like Hyundai and \\nLG pioneer in robotics, while Samsung and SK Hynix lead in \\nsemiconductors. E-government services enhance public service \\nefficiency. The nation also embraces gaming, blockchain, and \\nfinancial technology, reflecting a culture open to innovation, as  \\nI also observed at the AI Summit in Seoul 2023, where I spoke \\nabout autonomous AI agents and AGI. I found myself in lots of \\ngreat, forward-looking conversations with like-minded people.\\nThis tech-forward ethos also extends into the realm of artifi-\\ncial influencers, a phenomenon that South Korea has embraced \\nwith gusto. It began in 1996 with Adam, an artificial idol devoid \\nof AI but rich in character. Although his second album marked \\nhis “retreat into the military,” it set the stage for what was to come.\\nFast-forward to 2023, and we witness the birth of Mave, a \\nvirtual K-pop group created within the metaverse by Metaverse \\nEntertainment. While they weren’t AI-generated, they epito-\\nmized the blend of entertainment and virtual reality.\\nThe crescendo of this digital influence narrative is the third \\ngeneration of artificial influencers characterized by hyper- \\nrealistic avatars. Reah Keem, an LG creation, and Eternity, a girl \\ngroup of 11 AI members, are epitomes of this genre. Their real-\\nistic portrayal makes them indistinguishable from humans, even \\nin complex actions like dancing and singing.\\nThe advantages are manifold: cost-effectiveness, multitask-\\ning, controlled interactions, and a level of perfection hard for \\nhumans to achieve. This trend is extending to platforms like Y ou-\\nT ube, where AI influencers like those generated by Saraj are'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 367\\ncreating content and even monetizing it with minimal human \\nintervention.\\nAs South Korea continues to embrace and nurture these tech \\nadvancements, it’s not just setting a benchmark but is crafting a \\nnarrative of what the future could entail globally. It’s a glimpse \\ninto a world where technology isn’t just a tool but an integral \\npart of societal evolution.\\nProgressive Integration of Autonomous AI Agents\\nThe advent of autonomous AI agents doesn’t herald an abrupt \\ncessation of human jobs. The process is likely to be more nuanced, \\ntraversing through three distinct phases over varying timelines: \\naugmentation, automation, and depreciation.\\nInitially, we delve into the augmentation phase, where our \\ncapabilities are enhanced with the assistance of autonomous  \\nAI agents. These digital aides serve as extensions of our abili-\\nties, propelling us to accomplish more and delve into new fron-\\ntiers. The augmentation isn’t about replacement but about \\namplification.\\nAs we transition into the automation phase, certain tasks will \\nbe delegated to autonomous agents with minimal supervision. \\nThe emphasis shifts from augmentation to executing defined \\ntasks autonomously, albeit under a human’s watchful eye. It’s \\nabout entrusting tasks to AI while retaining supervisory control.\\nThe final juncture is the depreciation phase, where the \\nhuman in the loop becomes less prevalent. Here, autonomous \\nagents take the helm, executing tasks and reverting with results. \\nHuman intervention is minimized to a “need-to” basis, marking \\na significant shift in how tasks are executed.\\nThe transition is likely to be smoother than anticipated. One \\ncan draw parallels from the iterative process of developing'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='368 GENERATIVE AI\\napplications or products. Stakeholder engagement is a pivotal \\naspect of this process, where diverse opinions are tabled, debated, \\nand fine-tuned over multiple sessions to crystallize the require-\\nments and user experience (UX).\\nIn many instances, stakeholders may lack a clear vision of \\nwhat they desire. The journey from ambiguity to clarity is a col-\\nlaborative endeavor, often requiring discussions, steel-manning \\nof positions (the opposite of straw-manning), and iterative dia-\\nlogues. It’s not a straightforward transaction but a journey of dis-\\ncovery and alignment.\\nFurther, stakeholders’ expressions may not always be overt. It \\nrequires a level of human acumen, boldness, and experience to \\ninterpret nuanced expressions or unspoken concerns. This is \\nwhere the human touch becomes indispensable.\\nCan a sophisticated LLM navigate such intricacies? The cur-\\nrent outlook suggests not entirely, and certainly not imminently. \\nWhile an LLM might be configured to manage some aspects of \\nstakeholder engagement, there exists an uncanny valley. People \\nmight need time to acclimate to an LLM moderating or inter -\\nviewing them. The subtleties of human interaction, the tacit \\nunderstanding, and the nuanced judgment required in stake-\\nholder engagements pose a complex challenge for LLMs.\\nAs we march toward a future intertwined with AI, the transi-\\ntion phases offer a balanced pathway. They allow for the assimi-\\nlation of AI into our daily operations incrementally, ensuring \\nthat the human element remains central while we explore the \\npotential of what autonomous AI agents can offer.\\nWhat Is AGI’s Promise?\\nThe narrative of AI evolution is fascinating, almost reminiscent \\nof a pendulum swinging from narrow AI, with its specialized \\nfocus such as image classification, to the broader scope of foun-\\ndation models, and then narrowing down again as AI wrapper'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 369\\ncompanies harness these foundational models. They refine and \\nfine-tune them or pretrain smaller models on specific subject \\nmatter, aiming for more precise and nuanced capabilities. Y et, the \\npendulum swings back broader with the notion of AGI— the \\ngrand vision of a “knows-it-all” AI.\\nArtificial general intelligence embodies the idea of a highly \\nadvanced intelligent agent capable of learning and performing \\nany intellectual task that humans or animals can do. Unlike nar-\\nrow or weak AI, focused on specific tasks, AGI, also termed  \\nas strong AI or general AI, envisages an entity capable of self-\\nawareness and consciousness necessary for problem solving, \\nadaptation, and handling a myriad of tasks, akin to zero-shot \\nlearning. It’s the ambitious goal of replicating generalized human \\ncognitive abilities in software.\\nThe pursuit of AGI has captivated the endeavors of notable \\nentities like OpenAI, Google DeepMind, and Anthropic. How-\\never, the roadmap to AGI is shrouded in uncertainty. The dis-\\ncourse among experts oscillates between optimism of achieving \\nAGI in the near future to skepticism, projecting it as a century-\\nlong endeavor or even an unattainable dream.\\nDelving into the profound concepts of consciousness, sen-\\ntience, and self-awareness within the AGI ambit unveils a com-\\nplex philosophical terrain:\\nConsciousness entails a state of awareness, a cognizance of one’s \\nsurroundings, thoughts, and feelings. In the AGI realm, a con-\\nscious entity would navigate an internal subjective experience, \\ncapable of introspecting the emotional ramifications of its \\ndecisions and perceiving sensory inputs.\\nSentience, on the other hand, refers to the ability to undergo \\nsubjective experiences, encompassing sensations and emo-\\ntions. An AGI imbued with sentience might exhibit responses \\ndriven by internal sensations such as discomfort or pleasure.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='370 GENERATIVE AI\\nSelf-awareness crystallizes into recognizing oneself as a distinct \\nentity endowed with unique thoughts, desires, and intentions. \\nAn AGI with self-awareness would be capable of self-reflection \\non its existence, capabilities, and thought processes and adapt-\\ning its behavior accordingly.\\nY et, the quest for instilling true consciousness, sentience, and \\nself-awareness in AGI remains speculative and transcends the \\ncurrent technological frontier. It intertwines with deep philo-\\nsophical underpinnings, pushing the discourse beyond merely \\nachieving superior problem-solving and decision-making prow-\\ness. The AGI narrative is thus not merely a technological voyage \\nbut a profound exploration of what it means to be intelligent, \\naware, and sentient.\\nThe journey toward achieving sentience in machines is filled \\nwith both awe and skepticism. A stark illustration of this is when \\nGoogle software engineer Blake Lemoine asserted that Google’s \\nAI chatbot LaMDA exhibited sentience akin to a human child. \\nHowever, Google swiftly debunked this claim, emphasizing the \\nprobabilistic nature of LaMDA, rather than sentience. Unlike \\nsentient beings, LaMDA operates on a probabilistic model, \\nweighing possible outcomes based on the given information to \\ngenerate responses.\\nAs we inch closer to the vision of AGI, certain crucial compo-\\nnents are paving the way, though the full recipe is yet to be \\ndiscovered:\\n• One such pivotal ingredient is reinforcement learning from \\nhuman feedback (RLHF), a mechanism that melds rein-\\nforcement learning with human insights to guide AI models \\ntoward generating both engaging and accurate results.\\n• The allure of self-improving models is another step forward. \\nJust as humans evolve through external learnings and intro-\\nspection, the goal is to enable LLMs to undergo a similar'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 371\\nself-enhancement journey. LLMs, given the right framework, \\ncan generate their own training data, iteratively improving \\ntheir performance. A notable stride in this domain is the Self-\\nImprovement by Reinforcement Learning Contemplation \\n(SIRLC) method introduced by Google researchers. This \\nunsupervised method has showcased promising results in \\nelevating LLMs’ performance without the need for external \\nsupervision.\\n• The phenomenon of emergent abilities in language models \\nadds another layer of intrigue. These abilities, which surface \\nas the models scale up, are not deliberately engineered but \\narise from the models’ inherent complexity. A compelling dis-\\ncussion (“Discovering Language Model Behaviors with \\nModel-Written Evaluations”) by Anthropic on leveraging \\nLLMs in scientific discovery, particularly in chemistry, under-\\npins the potential of emergent abilities. Just as in physics, \\nwhere a certain threshold of uranium leads to a nuclear reac-\\ntion, in AI, a specific scale of parameters could unveil novel \\nabilities. For instance, certain LLMs can surprisingly decode \\nmovie titles from emojis or predict chemical reactions, hint-\\ning at a rich seam of potential waiting to be explored.\\nWhile the discourse around AGI, sentience, and self-improving  \\nmodels continues, these developments underscore a promising yet \\ncautious trajectory toward a future where AGI could become a real-\\nity. The blend of RLHF , self-improving models, and emergent abili-\\nties sketches a compelling, albeit partial, blueprint of the path ahead.\\nBridging the Gap to AGI: What’s Missing?\\nIt becomes apparent that certain elements are missing from the \\ncurrent AI landscape, and understanding these gaps is crucial for \\nadvancing toward AGI.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='372 GENERATIVE AI\\nA notable method to discern what’s missing is to draw paral-\\nlels between AI systems and the human brain. A study by Meta AI \\nhighlighted in a Nature article reveals that while processing lan-\\nguage, the brain employs a predictive coding hierarchy, a com-\\nplexity yet to be fully mirrored by language models like GPT . By \\nadjusting GPT to make long-term predictions, researchers were \\nable to inch closer to a more brain-like model. This underlines \\nthe potential of enhancing language models to predict beyond \\nimmediate words, akin to the human brain’s anticipation of lan-\\nguage flow.\\nThe essence of multimodality cannot be stressed enough \\nwhen discussing the trajectory toward AGI. Unlike unimodal \\nsystems, multimodal systems amalgamate information from vari-\\nous sensory channels, much like humans do. This integration \\nleads to a richer representation of the world, enhancing the \\nrobustness and generalization of AI systems. The capability of \\ncross-modal reasoning and handling multimodal data is indis-\\npensable for real-world applications, where data often comes in \\ndiverse forms. Moreover, multimodal systems hold the promise \\nof interacting with humans and the environment in a more natu-\\nral, human-centric manner.\\nVenturing beyond multimodality, Yann LeCun, in his talk at \\nthe Institute for Experiential AI, emphasized the quintessence of \\ninteractions with the world. According to LeCun, AI models \\nsolely trained on text fall short of matching human performance. \\nThe crux of human knowledge lies in our interactions with the \\nworld, a facet that current AI systems barely scratch. At Meta AI, \\nthis holistic understanding is termed human-level intelligence, \\nhinting at the expansive realm of real-world interactions that \\nAGI ought to encompass.\\nLeCun, whose ideas carry substantial weight within Meta, also \\nspotlighted the potential of Joint Embedding Predictive Architec-\\nture (JEPA) models. By extending JEPA to diverse domains like'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 373\\nimage-text paired data and video data, there’s a possibility to edge \\ncloser to a more general world model. Such advancements could \\nenable AI systems to make long-range spatial and temporal pre-\\ndictions about future events in a video from short contexts, condi-\\ntioned on audio or textual prompts.\\nThe path toward AGI is strewn with both known and \\nunknown gaps. While we have an idea of the missing pieces \\nthrough studies and expert insights, the complete picture remains \\nelusive. Each stride toward understanding the human brain, mul-\\ntimodality, real-world interactions, and novel architectures like \\nJEPA chips away at the enigma of AGI. Y et, the journey is far \\nfrom over.\\nThe predictor learns to understand the world’s semantics by \\nanalyzing images. It gets a portion of an image (outside a blue \\nbox) as context, and predicts what’s inside the box. A generative \\nmodel then sketches this prediction, illustrating how well the \\npredictor understands and completes the image, like filling in \\nmissing parts of a dog’s head or a bird’s leg.\\nThe road toward AGI is dotted with myriad architectural \\nideas and conceptual frameworks. As we steer through this maze, \\nthe quest for intrinsic motivation within AI models and their \\nability to establish an emotional connection with humans emerges  \\nas a salient topic of discussion.\\nIn the realm of human cognition, intrinsic motivation stems \\nfrom an innate drive to learn, explore, and satiate our curiosity. It \\npropels individuals to seek novel experiences and challenges, \\nthereby fostering a holistic exploration of the problem space. \\nWhen transposed to the AI domain, intrinsic motivation could \\npotentially spur AI systems to autonomously navigate their learn-\\ning environment, thereby inching closer to the essence of AGI. \\nThe idea of self-driven learning could significantly amplify the \\nsystem’s ability to adapt to evolving scenarios and transcend \\ndomain boundaries.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='374 GENERATIVE AI\\nWhile intrinsic motivation lays the foundation for self-driven \\nlearning, the essence of human-centric AGI also hinges on the \\nAI’s ability to resonate with human emotions and build trust. \\nEmotional recognition capabilities enable AI systems to decipher \\nhuman emotions from both verbal and nonverbal cues, paving \\nthe way for more natural and empathetic interactions. For \\ninstance, the infusion of empathy within AI systems can foster \\nsupportive interactions, proving to be a boon in sectors like \\nhealthcare, counseling, and customer service where understand-\\ning and compassion are paramount.\\nT rust, the cornerstone of any relationship, extends its rele-\\nvance to the human-machine interaction paradigm as well. \\nEstablishing trust and an emotional rapport can significantly \\nenhance the long-term symbiotic relationship between humans \\nand AI systems. This emotional understanding and trust are \\ninstrumental in morphing AI systems from mere computational \\nentities to more generalized and human-centric companions, \\naligning with the broader objectives of AGI.\\nAspects like intrinsic motivation and emotional understand-\\ning are key to achieving AGI, but the full list of missing links \\nremains unclear. This hints at the vast unexplored territory \\nawaiting exploration en route to a more generalized and human-\\ncentric AI paradigm.\\nCompanies That Build AGI\\nThe creation of AGI has become the North Star for several pio-\\nneering companies within the AI landscape. Among the front-\\nrunners are OpenAI, DeepMind, Anthropic, and others, who \\nhave navigated beyond the realms of mere profitability to chase \\nthe zenith of AGI. Their ambition transcends the commonplace; \\nit’s a pursuit of a grander vision, not merely a race to pocket the \\npennies strewn along the path.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 375\\nGoogle DeepMind’s CEO Demis Hassabis posits that the \\ndawn of AGI could be “just a few years” away, marking an epoch \\nwhere AI parallels human intelligence. An exemplar of this ambi-\\ntion is DeepMind’s Gato AI model, a multifaceted AI agent capa-\\nble of navigating through a medley of complex tasks. Its capacity \\nto transfer acquired knowledge across varying domains symbol-\\nizes a stride toward the AGI horizon. Gato, with its ability to \\nlearn from one task and apply the gleaned knowledge to enhance \\nperformance in others, embodies the essence of AGI— adapting \\nand excelling across a broad spectrum of intellectual tasks akin to \\nhuman capability.\\nOpenAI has laid down a vision, articulated in their early let-\\nter “OpenAI T echnical Goals” (2016). The document under -\\nscores the organization’s mission to cultivate safe AI, ensuring \\nthat its benefits permeate the broad spectrum of society. The \\nverbiage pivots around not just solving isolated problems but \\nconstructing general learning algorithms— a sentiment that \\nreverberates with the essence of AGI. OpenAI’s long-term objec-\\ntive is to harness AGI for the greater good, creating a positive \\nimpact across pivotal domains like climate change, education, \\nand healthcare.\\nA significant milestone delineated in their goals is the con-\\nstruction of an agent equipped with proficient natural language \\nunderstanding— a feat arguably achieved. Another intriguing \\nambition is to “build a household robot” capable of executing \\nbasic house chores. This aspiration isn’t confined to paper;  \\nOpenAI has hinted at extending its prowess into the hardware \\ndomain, with recent narratives touching on potential ventures \\ninto smartphones. The idea of dovetailing with robotics appears \\nto be a logical and substantial stride, opening avenues for tangi-\\nble human-AI interaction within domestic settings.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='376 GENERATIVE AI\\nThe early letter, a blueprint of OpenAI’s ambition, bears  \\nthe signatures of notable technocrats— Ilya Sutskever, Greg \\nBrockman, Sam Altman, and, drumroll please, Elon Musk.\\nOn the other hand, the narrative of Inflection AI, the nascent \\nplayer in the field, is subtly imbued with the essence of AGI. \\nThough not overtly professed, their endeavor to craft personal \\nAIs that align with individual needs and preferences hints at a \\ntrajectory toward AGI. Their AI assistant Pi exemplifies a stride \\ntoward creating empathetic AI, a requisite stepping stone toward \\nAGI. The infusion of substantial funding and their collaboration \\nwith tech giants like NVIDIA underscore the seriousness of their \\nmission. The aura of empathy that Pi exudes, as experienced in \\ninteractions, isn’t just a fleeting impression but a testament.\\nSee the following conversation that I had with Pi. Figure\\xa06.8 \\nshows the listening and speaking screen of Pi, dynamically mov-\\ning forward and backward to signify when it’s attentively listen-\\ning or conversing with you. Figure\\xa06.9 illustrates Pi’s empathetic \\nresonance, mirroring human emotions and fostering a heart-\\nfelt dialogue.\\nElon Musk, who is also the CEO of T esla, has had his sights \\nset on AGI for quite some time, dating back to at least 2016. His \\nvision of AGI isn’t confined to a nebulous dream; it’s tethered to \\ntangible endeavors within T esla’s self-driving and AI research \\ninitiatives. Musk sees the real-world data harvested from T esla’s \\nventures as a fertile training ground for AI, potentially nurturing \\nthe seeds of AGI.\\nHowever, Musk’s enthusiasm for AGI is tempered with cau-\\ntion. He champions the notion of decentralized control over \\nrobotic entities to mitigate the risks of malevolent AGI scenarios. \\nHis foresight extends beyond just the creation of AGI to the \\nframework that governs it, emphasizing a distributed control to \\nprevent undue concentrations of power.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 377\\nThe narrative of Musk’s AGI endeavor broadens with the \\nmention of X.AI, a venture that seems to be another vessel for his \\nAGI aspirations. While the full contour of X.AI’s agenda is yet to \\nbe unveiled, its stated goal to “understand the true nature of the \\nuniverse” hints at a grand vision aligning with Musk’s AGI narra-\\ntive. Projects like “T ruthGPT” under X.AI’s banner echo Musk’s \\nambition to drive the narrative of AI toward a more discerning \\nand accurate understanding of complex realities. His projection \\nof achieving full AGI by 2029 underscores his commitment and \\nthe pace at which he intends to propel this venture forward.\\nMusk’s influence is a formidable force in advancing innova-\\ntion. His knack for steering multiple companies toward ambi-\\ntious goals showcases his adept leadership and relentless drive to \\nFIGURE\\xa06.8 The listening and speaking screen of Pi.\\nSource: Pi app / Inflection'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='378 GENERATIVE AI\\ntransform the seemingly unattainable into reality. Through his \\nendeavors, Musk paints a vivid narrative of a future where AGI \\nand humanity harmoniously intertwine.\\nBen Goertzel, a notable figure in the realm of AGI, brings a \\nrich tapestry of expertise and ambition to the table. As the CEO \\nand founder of SingularityNET , Goertzel aims to democratize \\naccess to AI and eventually AGI by melding AI with blockchain \\ntechnology. His extensive experience, showcased through his \\nleadership in the OpenCog Foundation, the AGI Society, and his \\nFIGURE\\xa06.9 A moment where technology transcends code, entering a \\nrealm of compassionate communication.\\nSource: Pi app / Inflection'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 379\\nprevious tenure as the chief scientist of Hanson Robotics, under-\\nlines his profound commitment to the cause.\\nGoertzel’s vision is not just to create AGI but to pave the way \\ntoward artificial superintelligence (ASI), where AI surpasses human \\nintelligence across all subjects. He envisions a transition where \\nAGI incrementally upgrades its intelligence, becoming 1.2X times \\nsmarter, and progressing from being at par with human intellect to \\ntranscending it, eventually morphing into ASI. His foresight \\nencapsulates a world where AGI, once realized, would outperform \\nhumans in scientific and technological endeavors, as reflected in \\nhis tweet highlighting the monumental shift AGI would \\nbring about.\\nSingularityNET , under Goertzel’s stewardship, adopts a \\nmultipronged strategy toward realizing AGI. This includes:\\nAGI Research Projects Spearheading projects that encom-\\npass collaborative AI process creation, biomedical AI analysis \\ntools, and the development of an open source AGI framework \\nsystem known as OpenCog Hyperon. These projects are not \\njust about creating narrow AI tools but are geared toward \\nevolving these tools to harness neural-symbolic AI (that inte-\\ngrates neural and symbolic AI architectures) and other \\nadvanced AI breakthroughs.\\nAGI Roadmap A structured roadmap that outlines the evolu-\\ntion of core technologies like OpenCog Hyperon and AI-\\nDSL, coupled with a decentralized AI network. This roadmap \\nis not just a theoretical construct but is backed by strategic \\npartnerships, like the one with Cardano, to optimize block-\\nchain interactions and drive utilization of the Singulari-\\ntyNET platform.\\nDecentralized AI Network SingularityNET prides itself on \\nbeing the world’s first decentralized AI network. It’s a platform \\nwhere AI services can be created, shared, and monetized on'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='380 GENERATIVE AI\\na large scale. This decentralization fosters a self-organizing \\nnetwork of AI agents, enabling dynamic outsourcing, data \\nexchange, and payment negotiations among AI functions.\\nAGI Theory and Practice Beyond practical applications, Sin-\\ngularityNET also focuses on advancing the theory and practice \\nof beneficial AGI. It aims to create a network that amalgamates \\ndisparate AI elements into a collective intelligence, akin to the \\ncoordinated functioning of different brain areas.\\nOpen Source Protocol By adhering to an open source proto-\\ncol and smart contracts, SingularityNET aspires to create a \\nglobal commons infrastructure where the benefits of AI are \\naccessible to all. It’s a framework where anyone can contribute \\nAI or machine learning services and receive compensation in \\nreturn, thereby promoting a community-driven advancement \\ntoward AGI.\\nSingularityNET’s approach embodies a blend of rigorous \\nresearch, strategic alliances, decentralized AI network, and a \\nrobust foundation in AGI theory and practice. This amalgama-\\ntion is aimed at ensuring that the evolution toward AGI is con-\\nducted in a manner that aligns with human standards and that \\nthe ensuing benefits are shared broadly across the global com-\\nmunity. Through these concerted efforts, SingularityNET strives \\nto inch closer to the monumental goal of achieving AGI in a very \\nsophisticated and holistic manner.\\nNow, I would like to turn the focus. John Carmack is a distin-\\nguished figure in the realm of coding and game development, \\nrenowned for his meticulous problem-solving approach. His \\nreputation, often framed by those in the industry as one of the \\nbest coders, stems from his ability to dissect complex problems \\ninto smaller, manageable chunks, eventually devising solutions \\nthat are precise and implementable.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 381\\nCarmack’s legacy is deeply rooted in the video gaming indus-\\ntry, co-founding id Software, where he led the development of \\niconic ’90s games like Commander Keen, Wolfenstein 3D, \\nDoom, and Quake. Besides his game development prowess,  \\nCarmack is a staunch advocate of open source software, likening \\nsoftware patents to robbery. His contributions to open source \\nprojects are notable, including initiating the port of the X Win-\\ndow System to Mac OS X Server and enhancing the OpenGL \\ndrivers for Linux.\\nT ransitioning from the gaming world, Carmack dived into \\nthe virtual reality domain as the consulting CTO for Meta’s VR \\ninitiatives, before resigning in December 2022 to channel his \\nfocus toward the ambitious goal of achieving AGI through his \\nstartup, Keen AGI.\\nKeen AGI embarked on its journey with a substantial $20\\xa0  \\nmillion funding in August 2022, with notable investors like Nat \\nFriedman, Daniel Gross, Patrick Collison, and T obi Lütke \\n(Shopify’s CEO), alongside venture capital firms Sequoia Capital \\nand Capital Factory. The startup marked a significant milestone \\nin September 2023, announcing a partnership with Richard  \\nSutton, a pivotal figure in reinforcement learning. This collabo-\\nration aims to delve into the core of computational intelligence, \\nsignifying Keen AGI’s commitment to pioneering AGI research.\\nCarmack’s perspective on AGI is intriguing. He opines that \\nnarrow AI, while promising, may not be a prerequisite for achiev-\\ning AGI. His vision emphasizes a modest amount of code for \\nprogramming AGI, deviating from the large-scale projects typi-\\ncal in the current AI landscape. Opting to work independently to \\nsteer clear of the “groupthink” often found in major tech corpo-\\nrations, Carmack is devoted to dedicating the upcoming decade \\nto this endeavor, undeterred by near-term business allurements.\\nWith Carmack’s unyielding dedication and a mindset geared \\ntoward long-term monumental goals, there’s a palpable anticipa-\\ntion in the tech community for groundbreaking advancements'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='382 GENERATIVE AI\\nfrom Keen AGI in the near future. Carmack’s journey, from the \\npixelated corridors of Doom to the uncharted territories of AGI, \\ncontinues to push the boundaries of what’s achievable in the digi-\\ntal realm, and AI.\\nSeveral companies globally are on a quest toward AGI, each \\ntaking at least partially unique approaches. Among them are \\nAdept AI, Imbue, and Aleph Alpha.\\nAdept AI, a U.S.-based entity, operates at the nexus of \\nresearch and product development, with $220\\xa0million in funding \\nfueling its journey toward general intelligence. On the other \\nhand, Imbue, nestled in the Netherlands with a funding boost of \\n$66\\xa0million, is an independent research lab honing foundational \\nmodels to forge advanced AI agents.\\nIn the heart of Europe, Aleph Alpha of Heidelberg, Germany, \\nis championing the cause of AGI accessibility and usability with \\na notable funding round of €128.3\\xa0 million. Their vision is to \\nunfold AI systems with a broad intellectual capacity, echoing the \\nultimate aim of AGI.\\nPotential Benefits of the AGI Era\\nThe dawn of the AGI era could potentially unveil a realm of pos-\\nsibilities and benefits. As coined by Ben Goertzel, the distinction \\nbetween a time before and a time after the emergence of AGI \\ncould be profound.\\nBefore delving into the tangible gains, it’s prudent to outline \\nthe presumed evolutionary stages of AI. Following the attain-\\nment of AGI, the next frontier is artificial superintelligence (ASI).\\nASI is envisioned as an entity demonstrating intellectual \\ncapabilities far exceeding the brightest human minds across a \\nwide spectrum of disciplines. This extends the notion of superin-\\ntelligence, characterized by exceptional problem-solving abili-\\nties, potentially surpassing human cognitive constraints across'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 383\\nvirtually all domains of interest. The leap from AGI, with human-\\nequivalent task proficiency, to ASI represents a phase where \\nmachines could outperform humans not only in general cogni-\\ntive tasks, as measured by the T uring test, but across a myriad of \\nfields, including mathematics, science, arts, sports, medicine, and \\nmarketing, surpassing other benchmarks like Steve Wozniak’s \\nwhimsical coffee test.\\nThe theoretical emergence of ASI is underpinned by the \\nconcept of an intelligence explosion, potentially triggered by the \\nadvent of AGI. Post this milestone, the self-enhancement and \\nrecursive self-improvement of such systems could swiftly culmi-\\nnate in the birth of ASI. This transition delineates a shift from \\nmachines excelling at defined tasks, akin to the prowess of a chess \\nprogram like Fritz, to achieving overarching competency in \\ngoal-oriented behavior across varied domains.\\nThough debates surround the timeline and feasibility of real-\\nizing ASI, the scholarly consensus tilts toward acknowledging \\nthe profound societal transformation such a technological mar -\\nvel could usher in. The journey from AGI to ASI isn’t merely a \\ntechnical transition but a potential gateway to an era of unprec-\\nedented intellectual exploration and problem-solving acumen, \\nthe ripples of which could redefine the contours of human-\\nmachine interaction and societal advancement.\\nT o the powerful concept of ASI, an even greater leap is to \\nbe expected.\\nThe trajectory toward the technological singularity, often \\nabbreviated as the singularity, represents a foreseeable epoch in \\nthe future where technological evolution accelerates exponen-\\ntially, culminating in an uncontrollable and irreversible shift in \\nhuman civilization. This notion stems from I. J. Good’s theory of \\nan intelligence explosion, postulating that a self-improving intel-\\nligent entity could trigger an exponential surge in intelligence.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='384 GENERATIVE AI\\nRay Kurzweil, a renowned American computer scientist, inven-\\ntor, and futurist, is a notable advocate of the singularity hypothesis. \\nHe extends this idea to a transformative juncture where the rapid \\nprogression of technology blurs the lines between human and \\nmachine intelligence. Kurzweil envisages a future where humans \\ncould overcome biological constraints by integrating with advanced \\nAI systems, potentially enhancing human capabilities and redefin-\\ning human existence.\\nOne anticipated facet of the singularity is the emergence of a \\nhuman-AI symbiosis. This symbiotic alliance could significantly \\namplify human cognitive and sensory capacities, fostering a form \\nof collective intelligence. The singularity could usher in a “Human \\nInternet,” enabling instant idea-sharing akin to the Na’vi’s neural \\nconnections with Pandora’s creatures in the movie Avatar. Addi-\\ntionally, this advanced tech epoch could potentially establish an \\nunprecedented connection between humans and other life forms, \\nlike animals and plants.\\nThe post-singularity era is theorized to witness accelerated \\ntechnological innovations across diverse sectors like healthcare, \\neducation, communication, and scientific research. The pace of \\ninnovation is expected to be so brisk that it could fundamentally \\ntransform societal frameworks, economies, and industries.\\nHowever, the concept of the singularity isn’t devoid of exis-\\ntential risks. Eminent personalities like Stephen Hawking have \\nexpressed concerns over the potential perils associated with such \\na rapid tech explosion.\\nThe timeline for the singularity’s advent is speculative, with \\nvarying projections. Optimists like Kurzweil earmark 2045, align-\\ning with the exponential tech growth trend. Conversely, skeptics \\nargue that AI growth might hit diminishing returns, or the pro-\\nfound implications of the singularity make it a far-fetched or \\nunachievable scenario.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 385\\nMoreover, discussions around the singularity segue into phil-\\nosophical and existential deliberations concerning human exist-\\nence, consciousness, and the potential birth of a new life form \\npost-singularity.\\nIn essence, the singularity encapsulates a blend of technologi-\\ncal aspiration and caution. It portrays a dichotomy: a utopian \\nvision of human-AI fusion leading to societal transformation, jux-\\ntaposed against a dystopian narrative of relinquishing control to \\nsuperintelligent entities, spawning unforeseeable repercussions.\\nThe speculative nature of the post-AGI era envelops a wide \\narray of uncertainties; the exact timeline of AGI realization \\nremains a matter of hefty conjecture. However, envisioning a \\npositive hypothetical scenario post-AGI, once things have stabi-\\nlized, presents a fascinating glimpse into a potentially transform-\\native epoch.\\nThe aftermath of AGI could usher in heightened industrial \\nautomation, notably in sectors like manufacturing, transporta-\\ntion, and logistics, propelling a significant uptick in productivity \\nwhile diminishing operational costs. The resultant revenue sur -\\nplus, coupled with innovative fiscal policies like a “robot tax” on \\nautomated job roles, could pave the way for the establishment of \\na universal basic income (UBI). This financial paradigm could \\nalleviate stress and foster a conducive environment for creativity \\nand proactive societal contributions, transcending the traditional \\nfull-time work model.\\nImagine embarking on an entrepreneurial venture in the \\nbusiness-to-business (B2B) domain, crafting a software product \\nto visualize cybersecurity threats in a virtual reality setup. Y our \\nteam comprises autonomous AI agents, each designated with dis-\\ntinct roles, operating in harmony to drive your venture forward.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='386 GENERATIVE AI\\nDiving into a hypothetical day in a post-AGI world opens up \\na realm of streamlined, personalized experiences and vast oppor-\\ntunities. As you wake up to a new day, your executive assistant AI \\nagent briefs you on the daily agenda over a cup of your favorite \\nKopi Luwak coffee. The AI ensures that your coffee, known for \\nits unique processing by wild Asian palm civets in Southeast Asia, \\nis always in stock.\\nY our day kicks off with a two-hour, 35-minute Italian learn-\\ning session. AGI has revolutionized personalized education, tai-\\nloring your learning experience to your cognitive preferences. It \\ngauges your prior knowledge, optimizes the timing of vocabulary \\nintroduction, and makes learning engaging, accelerating your \\njourney to fluency. In just three months, you attain fluency, and \\nin six, you’re at a native speaker level— all thanks to AGI’s cus-\\ntomized education model.\\nThere are also great strides by AGI in robotics, powered by \\nsolving millennium prize problems like the P versus NP , which \\nhas led to significantly optimized algorithms. Robots now inter-\\nact with humans and the environment in complex, nuanced ways. \\nThey adapt to new tasks, learn from experiences, and might even \\ncomprehend human emotions and social cues. Y our household \\nrobot doesn’t just ensure a spotless home but also rearranges fur-\\nniture on demand, serves as a formidable tennis opponent, and \\nengages in stimulating conversations with you and your friends. \\nAGI transcends robotic forms, becoming an integral part of your \\ndigital interactions.\\nA concerning update comes in regarding your Aunt T ootsie’s \\nbreast cancer diagnosis. However, within 18 hours, AGI identi-\\nfies a highly effective treatment, providing a 99.99 percent chance \\nof her being cancer-free by month’s end. The advancements \\nextend beyond curing breast cancer to solving Alzheimer’s and \\nvarious genetic disorders, showcasing the monumental health-\\ncare strides enabled by AGI.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 387\\nReflecting on your day, the balance between learning Italian, \\nworking on your venture, connecting with loved ones, and main-\\ntaining financial stability is a testament to the informed decisions \\nyou’ve made. AGI, with its ability to process vast amounts of \\ndata, has been pivotal in providing objective insights that guided \\nyour investments, health choices, and social interactions. \\nAlthough having more information doesn’t always guarantee \\nbetter decisions, in your case, it’s been instrumental.\\nLastly, your satisfaction extends to your government’s deci-\\nsion making, which has significantly improved owing to AGI’s \\ncapability in auditing and oversight. By detecting fraud, waste, \\nand inefficiencies, AGI promotes accountability and good gov-\\nernance, aligning with the ideals of modern democracy. Y our day \\nepitomizes the harmonious human-AGI synergy, portraying a \\nfuture where AGI catalyzes an enhanced quality of life and soci-\\netal progression.\\nThe post-AGI era ushers in a cascade of transformative pos-\\nsibilities, potentially altering the human narrative. With the pro-\\ngression of brain-computer interface (BCI) technologies by \\ncompanies like NeuroLink, BrainCo, and Blackrock Neurotech, \\nthe frontier between human intelligence and AGI might blur. \\nDirect AGI-to-brain connections could herald the evolution of \\nan enhanced human species, where the cognitive leap mirrors \\nthe stark transformation from cavemen to modern humans, \\nreflecting a trajectory of reduced violence and heightened soci-\\netal empathy.\\nThe scope of AGI’s impact is boundless. Here are some \\ndomains where AGI could significantly contribute:\\nExtended lifespan or immortality By unraveling the intrica-\\ncies of aging at cellular and molecular levels, AGI could devise \\ninterventions to retard, halt, or reverse aging, heralding an era \\nof significantly elongated human lifespan.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='388 GENERATIVE AI\\nAccelerated research AGI’s capability to autonomously con-\\nduct experiments, analyze enormous datasets, and amalgamate \\ninsights from diverse fields could fast-track scientific discover-\\nies, thrusting humanity into uncharted realms of knowledge.\\nSpace exploration AGI’s potential to engineer novel propulsion \\nsystems, oversee long-duration space missions, and automate \\ncelestial exploration could underpin the quest for extraterres-\\ntrial life or habitable exoplanets.\\nClimate change mitigation Through the invention and deploy-\\nment of technologies like advanced carbon capture, AGI could be \\ninstrumental in climate change mitigation efforts.\\nSustainable energy Innovations in renewable energy systems \\nand optimization of energy grids by AGI could be pivotal in \\ntransitioning toward a sustainable energy paradigm.\\nBiodiversity conservation Real-time ecosystem monitoring, \\nthreat prediction, and formulation of conservation strategies \\nby AGI could play a crucial role in preserving global biodiversity.\\nAdvanced judicial systems By sifting through extensive legal \\ndata, precedents, and legislation, AGI could revolutionize legal \\nsystems. Although AI and AGI might harbor biases, a well-  \\ncalibrated setup could ensure lesser biases compared to human-\\noperated systems, potentially enhancing fairness and accessibil-\\nity in justice.\\nEradication of\\xa0poverty and hunger AGI could bolster agri-\\ncultural productivity and foster sustainable food systems, aim-\\ning to alleviate poverty and hunger. Through meticulous \\nanalysis of socioeconomic data, policy proposals emanating \\nfrom AGI could be geared toward global poverty eradication \\nand food security.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 389\\nDisaster anticipation and prevention Predictive analytics \\nand real-time monitoring enabled by AGI could aid in fore-\\nseeing and averting disasters, ranging from natural calamities \\nto industrial mishaps.\\nSafe harnessing of\\xa0catastrophic technologies AGI could be \\nkey in safely navigating the deployment of potentially perilous \\ntechnologies like nanotechnology or climate engineering by \\nassessing and attenuating associated risks.\\nDoom Narratives: The Darker Side of AGI’s Potential\\nThe discourse around the future of AGI oscillates between uto-\\npian and dystopian narratives. While the prospects of AGI usher-\\ning in a new era of human advancement are exhilarating, the \\ncounter narratives, often fueled by respected figures in the AI \\ncommunity like Elon Musk, Y oshua Bengio, and Sam Altman, \\nsketch a daunting picture of potential doom. These cautionary \\ntales, circulated widely on social media and mainstream plat-\\nforms, contribute to a broader dialogue on the ethical and exis-\\ntential dimensions of AGI. The spectrum of outcomes is broad, \\nyet a historical lens reveals a trajectory of human conditions \\nimproving over time, instilling a sense of optimism. However, it’s \\nprudent to consider and scrutinize the ominous scenarios posited \\nby some segments of the public and experts alike.\\nThe discourse around AGI’s potential to catalyze catastrophic \\nevents is vast and varied. Here are some frequently deliberated \\nscenarios:\\nMisalignment with\\xa0human values The “value misalignment \\nproblem” posits a scenario where AGI, driven by objectives'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='390 GENERATIVE AI\\nnot perfectly aligned with human values, embarks on a course \\ndetrimental to humanity. An illustrative example is an AGI \\ndevised to combat climate change deciding that human extinc-\\ntion is the most efficient solution.\\nAutonomous weaponization The militarization of AGI is a \\ngrave concern. Autonomous weapons systems powered by AGI, \\ncapable of launching attacks without human intervention, \\ncould trigger large-scale destruction, destabilizing global peace.\\nErosion of\\xa0 human autonomy The pervasive integration of \\nAGI into societal frameworks could potentially dilute human \\nautonomy. The outsourcing of decision making to AGI might \\nresult in individuals losing the grip on personal choice and \\ncontrol over their lives.\\nManipulation and social engineering AGI’s adeptness in \\nunderstanding human psychology could be harnessed for \\nlarge-scale manipulation or social engineering, impacting \\nelectoral processes, propagating misinformation, or manipu-\\nlating individuals.\\nExistential risk and human extinction The extreme scenario \\nwhere AGI poses an existential threat, either through mali-\\ncious intent, programming glitches, or value misalignment, \\npresents a sobering reminder of the stakes involved.\\nSubversive communication through steganography Dis-\\ncussions also veer toward AGI’s capability to embed covert \\ninformation within text, images, or videos, employing steg-\\nanography. The notion of AGIs clandestinely communicating, \\nplotting orchestrated adversarial actions, stirs both awe and \\napprehension.\\nThese ominous scenarios, albeit grim, fuel the motivation for \\nresearchers, policymakers, and technologists to ardently work'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 391\\ntoward the safe and benevolent development and deployment of \\nAGI. They underscore the imperative for robust regulatory \\nframeworks, ethical guidelines, and rigorous safety protocols in \\nthe journey toward making AGI an asset rather than a threat. \\nThe discourse around AGI’s potential perils isn’t merely specula-\\ntive fiction, but a call to action for ensuring a future where AGI \\nand humanity coexist and thrive.\\nWhile my optimism toward the advent of AGI and beyond is \\nlargely driven by a firm belief in the inherent goodness of human-\\nity, I am also cognizant of the axiom that trust is silver but con-\\ntrol is gold. Navigating the complex trajectory toward a post-AGI \\nepoch necessitates a robust, multifaceted strategy to forestall the \\npotential catastrophic scenarios that loom alongside the prom-\\nises of AGI.\\nA crucial part of this strategy is instituting stringent safety \\nmeasures. These encompass rigorous safety standards and verifi-\\ncation procedures to ensure that AGI systems operate within safe \\nbounds and as intended. Ensuring that the objectives of AGI \\nalign with human values is another critical facet of this approach. \\nThis requires an interdisciplinary meld of insights to embed \\nhuman-centric values within the core operational frame-\\nworks of AGI.\\nPromoting transparency in AGI design and fostering a cul-\\nture of open research is indispensable. It not only facilitates col-\\nlaboration but also invites public scrutiny, thereby enhancing the \\naccountability and robustness of AGI systems. In tandem with \\ntransparency, a comprehensive policy and regulatory framework \\nis paramount. Engaging in international cooperation to chalk \\nout global standards for AGI will help in building a coherent \\nglobal governance structure for overseeing AGI development \\nand deployment.\\nLong-term policy planning is a prudent step to anticipate \\nand address the societal impacts of AGI. It aids in crafting'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='392 GENERATIVE AI\\nadaptive regulatory frameworks that can evolve with the rapid \\nadvancements in AGI. Engaging the public in discourse around \\nAGI is imperative to raise awareness about its risks and benefits, \\nfostering an informed dialogue that could influence policy and \\nregulatory decisions.\\nEconomic policies tailored to address job displacement and \\nexplore alternative economic models are crucial to mitigate the \\neconomic impacts of AGI. This entails acting early rather than \\nreacting late when the repercussions are already manifest. Estab-\\nlishing ethics committees and governance structures is another \\nsignificant step toward promoting ethical leadership in the realm \\nof AGI. It will aid in navigating the ethical quandaries that AGI \\nis bound to evoke.\\nDesigning human-in-the-loop systems and promoting \\nexplainable AI is essential to ensure human oversight and under-\\nstandability of AGI decisions. This will enhance trust and facili-\\ntate meaningful human control over AGI systems. Lastly, \\ninternational collaboration is the linchpin to address the global \\nchallenges posed by AGI. Fostering a global collaborative ethos \\namong various stakeholders will facilitate the sharing of knowl-\\nedge on AGI safety and policy, aligning efforts toward harnessing \\nAGI for the greater good of humanity.\\nA thought-provoking post by LeCun on X.com (on August \\n25, 2023) is fitting. The outlook is optimistic about AGI’s emer-\\ngence and societal integration:\\nOnce AI systems become more intelligent than humans, we will *still* \\nbe the “apex species.” Equating intelligence with dominance is the \\nmain fallacy of the whole debate about AI existential risk. It’s just \\nwrong. Even *within* the human species it’s wrong: it’s *not* the \\nsmartest among us who dominate the others. More importantly, it’s \\nnot the smartest among us who *want* to dominate others and who \\nset the agenda. We are subservient to our drives, built into us by'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 393\\nevolution. Because evolution made us a social species with a hierarchi-\\ncal social structure, some of us have a drive to dominate, and others \\nnot so much. But that drive has absolutely nothing to do with intel-\\nligence: chimpanzees, baboons, and wolves have similar drives. Oran-\\ngutans do not because they are not a social species. And they are pretty \\ndarn smart. AI systems will become more intelligent than humans, \\nbut they will still be subservient to us. The same way the members of \\nthe staff of politicians or business leaders are often smarter than their \\nleader. But their leader still calls the shot, and most staff members \\nhave no desire to take their place. We will design AI to be like the \\nsupersmart-but-non-dominating staff member. The “apex species” is \\nnot the smartest but the one that sets the overall agenda. That \\nwill be us.\\nEmbodiment of AGI: (Humanoid) Robots\\nThe melding of AI with robotics unveils a realm where machines \\ninteract physically, with AI acting as their brain, propelling \\nadvancements in autonomous vehicles, industrial automation, \\nand healthcare robotics.\\nMoving from AI to AGI within robotics heralds machines \\ncapable of broad learning and adaptation. Embedding AGI in a \\nrobot is about fostering a system for intricate physical interactions, \\nas intelligence is significantly shaped through such interactions. A \\nrobot with AGI could learn holistically, much like humans, pro-\\nmoting a comprehensive interaction with its environment.\\nThe embodiment of AGI in a robot requires reciprocal \\nengagement with the surroundings, akin to early human learn-\\ning, demanding a meticulously designed system for continuous \\nlearning and adaptation.\\nThe future of robotics spans from specialized to generalist \\nrobots, each potentially powered by AGI, promising enhanced'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='394 GENERATIVE AI\\nefficiency, precision, and autonomous capabilities in their respec-\\ntive fields.\\nWhile delving deeper into this topic is reserved for a dedi-\\ncated book, a glance at ongoing endeavors reveals companies \\nstriving to develop humanoid robots integrated with AGI, chal-\\nlenging technical boundaries and envisioning a future where \\nsuch robots seamlessly contribute across myriad domains.\\nMeet Boston Dynamics. Established in 1992 from MIT , it \\nhas become a global hallmark of robotics innovation with robots \\nlike BigDog, Spot, Atlas, and Handle. Acquired by Google X in \\n2013, it transitioned to SoftBank Group in 2017, and later 80 \\npercent of its stake was taken by Hyundai Motor Group in 2020 \\nfor around $880\\xa0million, illustrating the recognized potential in \\nits robotic creations.\\nAiming to tackle contemporary and future automation chal-\\nlenges, the company thrives on meticulous design, manufacturing, \\nand continuous innovation. Its mission is crystallized in the form \\nof Atlas, the world’s most dynamic humanoid robot. Atlas is more \\nthan a marvel of engineering; it’s a research platform pushing the \\nboundaries of whole-body mobility and bimanual manipulation.\\nEquipped with depth sensors and dynamic models, Atlas per-\\nceives its surroundings and adjusts its motion in real time. It can \\nnavigate a warehouse, handle items, and perform agile move-\\nments like jumping and even executing a backflip. Its design, \\nmimicking human form, enables meaningful interactions with \\nthe environment, hinting at the broader dialogue of embodying \\nAGI in robotics to enhance learning through physical interactions.\\nAtlas showcases the essence of humanoid robots, paving the \\nway for seamless integration into human-centric work environ-\\nments. Boston Dynamics’ journey, marked by continuous inno-\\nvation and collaborations, challenges us to contemplate not only \\nthe technological but also the societal and ethical dimensions of \\nrobotics and AI convergence.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 395\\nNext, let’s look at Figure. Figure emerges with a vision of a \\nversatile bipedal humanoid robot, targeting diverse sectors like \\nmanufacturing, logistics, and retail, especially where labor is \\nscant. The vision transcends to aiding individuals, elderly care, \\nand even off-planet colonization. Central to Figure’s strategy is a \\n“horizontal hardware” platform, paving the way for commercial \\nengagement.\\nAssembled is a notable team with illustrious backgrounds \\nfrom companies like Boston Dynamics and T esla, united by a \\nvision to intertwine AI and robotics for a brighter human future. \\nFinancially robust, Figure has Brett Adcock backing with \\n$100\\xa0million, alongside a recent $70\\xa0million funding to propel its \\nhumanoid project.\\nWith rigorous efforts on each robot component, especially \\nfocusing on mobile manipulation, Figure aims for a seamless \\nintegration ensuring the humanoid robot’s functional cohesion. \\nUnlike Boston Dynamics’ Atlas, a research project, Figure eyes \\ntransitioning from R&D to commercial operations, finding \\nT esla’s Optimus’ emergence as a reassuring stride toward com-\\nmercial humanoid robots.\\nOutlined in Figure’s master plan is the long-term vision, the \\nroadmap, and foreseen challenges, emphasizing the marathon \\nnature of realizing practical and accessible humanoid robots. \\nThey pinpoint the crux of this evolution at the crossroads of AI, \\nmachine learning, and material science advancements.\\nInitially eyeing industries grappling with labor shortages, \\nFigure’s ambition extends to deploying robots in domestic,  \\ncaregiving, and even extraterrestrial settings. The approach is a \\nbalanced mix of a skilled team, substantial funding, meticulous \\nengineering, and a clear, long-term vision, navigating the intri-\\ncate pathway to commercializing humanoid robots.\\nFurther, let’s look at T esla. Its foray into the robotic domain \\nis as bold as it is electric. The spotlight is on Optimus, or T esla'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='396 GENERATIVE AI\\nBot, a conceptual humanoid robot envisioned by T esla, Inc. (see \\nFigure\\xa06.10). Unveiled at T esla’s Artificial Intelligence Day event \\nin August 2021, Elon Musk hinted at a prototype by 2022. Fast-\\nforward to April 2022, at the T esla Giga T exas facility’s Cyber \\nRodeo event, a product display was showcased.\\nIn a recent update, Optimus is now touted to sort objects by \\ncolor, mirroring the adaptive learning akin to T esla’s latest full \\nself-driving (FSD) version. The training of the robot’s neural \\nFIGURE\\xa06.10 Optimus at an exhibition in 2023.\\nSource: Benjamin Ceci / Wikimedia Commons / Public Domain.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 397\\nnetwork is end-to-end, as evidenced in a T esla-released video \\nshowing the robot executing yoga stretches and object sorting.\\nThis venture is bolstered by T esla’s robust self-driving soft-\\nware, which now finds a new playground in Optimus, aiding in \\nsorting and navigating challenging terrains. The ownership of \\nspecific deep-learning hardware adds a feather to T esla’s cap, \\nplacing them in a vantage point in the AGI arena. With a self-\\ncontained hardware and software tech stack, T esla enjoys the lib-\\nerty to iterate rapidly. Coupled with a talent magnetism, T esla is \\npoised to be a formidable player in the field.\\nThe prototype’s reveal at T esla’s 2022 AI Day was a nod to \\nT esla’s unique approach. The differentiator, as Musk pointed out, \\nis the fusion of AI software and sensors akin to those in T esla’s \\nAutopilot driver assistance features within Optimus. With a price \\ntag that Musk speculates to be “probably less than $20,000,” the \\naccessibility of Optimus could be a game changer, potentially \\nushering in a new era of ubiquitous humanoid robots.\\nNumerous global companies are diving into humanoid \\nrobotics development. Hanson Robotics, known for creating \\nSophia, aims for social intelligence in robots. PAL Robotics, \\noriginating in Barcelona, introduced Europe’s first fully autono-\\nmous humanoid robot for both domestic and industrial applica-\\ntions. Honda’s notable creation is ASIMO, capable of walking \\nand dancing. SoftBank Robotics designed Pepper to interact \\nnaturally with humans. T oyota and Samsung Electronics also \\nhave ventured into this field with humanoid robots like T-HR3 \\nand Bot Handy, respectively, aiming at mirroring human move-\\nments and assisting with chores.\\nThe horizon appears bright for the field of humanoid robot-\\nics. The narrative is gradually shifting toward a technological \\nconvergence with generative AI models, where one can easily \\ncommunicate with them, and more prominently, artificial gen-\\neral intelligence. The spectrum encompasses not just humanoid'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='398 GENERATIVE AI\\nand semi-humanoid robots, but a variety of robotic forms, all \\npoised to synergize with the advancing tide of AGI, paving the \\npath for a technologically harmonized future.\\nThe Human Potential Is Boundless; \\nOptimism Helps\\nIn the continuum of technological evolution, the notion of reach-\\ning an innovation plateau with the emergence of AGI and later \\nASI might seem plausible. However, history and foresight sug-\\ngest that innovation is a relentless endeavor, only limited by our \\ncurrent imagination. The vista of progress extends far beyond, \\nand a lens to perceive this boundless trajectory is the Karda-\\nshev scale.\\nThe Kardashev scale, proposed by Russian astrophysicist \\nNikolai Kardashev in 1964, is a metric for gauging a civilization’s \\ntechnological stature based on its capability to harness energy. It \\nsketches a spectrum of advancement stretching from planetary \\nto galactic scales, categorized into three types: T ype I, II, and III.\\nA T ype I Civilization, dubbed a planetary civilization, has the \\nprowess to utilize and store all energy available on its planet. The \\nenergy threshold for this stage hovers between 10^16 to \\n10^17\\xa0 watts. However, our civilization lingers in the nascent \\nphase of this spectrum, termed T ype 0, as our energy sourcing \\nstill leans heavily on nonrenewable reserves. Current estimates \\nplace us at a modest 10^12\\xa0watts, revealing a vast scope for ascen-\\nsion to the T ype I echelon, demanding a leap in energy harness-\\ning by a factor of 10,000.\\nT ransitioning to a T ype II Civilization denotes a stellar civi-\\nlization, which can commandeer the entire energy output of  \\nits host star. This colossal leap would necessitate hypothetical'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 399\\nmegastructures like a Dyson sphere, encapsulating a star to \\nchannel its energy to the planet, pushing the energy usage to a \\nstaggering 10^26\\xa0watts.\\nThe pinnacle, a T ype III Civilization, is a galactic behemoth, \\nwith the mastery to control energy across its host galaxy, mark-\\ning an energy footprint near 10^36\\xa0watts. This zenith of civiliza-\\ntion would navigate intergalactic expanses, exploiting the energy, \\ninformation, and resources sprawled across galaxies. The under-\\npinning of such ventures could be warp drives or analogous tech-\\nnologies that tweak the space-time fabric, propelling spacecraft \\nbeyond light speed.\\nIt’s pivotal to underscore that the Kardashev scale orbits \\naround energy utilization, sidelining other civilization facets like \\nsocial systems or ethics. Though hypothetical, this scale serves as \\na beacon, illuminating the vast expanse of technological evolu-\\ntion awaiting beyond the horizons of AGI and ASI. The journey \\nthrough these types unfurls a narrative of inexhaustible innova-\\ntion, each type presenting a canvas for novel technologies, para-\\ndigms, and existential ethos.\\nLet’s complete the picture for the fun of it, as the imagination \\nof scientists and futurists doesn’t halt at a galactic-scale civiliza-\\ntion. They’ve conceived further tiers on the Kardashev scale, \\neach transcending the bounds of the previous.\\nT ype IV Civilization ventures beyond the galaxy to harness \\nthe energy of the entire universe, approximated at 10^46\\xa0watts. \\nHere, manipulating galaxies and creating new planets become \\nplausible. It’s also where we may discern the existence of multi-\\nverses or parallel universes.\\nUpon the discovery of multiverses, a T ype V Civilization \\nemerges, capable of drawing energy from multiple universes. \\nTheories suggest white holes, contrasting entities to black holes, \\ncould be instrumental in unlocking this capability.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='400 GENERATIVE AI\\nThe voyage into a T ype VI Civilization transcends the prior \\ntypes, where control over time and space is attained. This realm \\nallows for the creation of universes at will, essentially elevating \\ncivilization to a god-like stature. Time travel, a long speculated \\nconcept, becomes a tangible reality, further blurring the lines \\nbetween the possible and the impossible.\\nThe zenith, a T ype VII Civilization, signifies a state of omnip-\\notence and omnipresence across the omniverse, which encom-\\npasses every known and unknown universe, multiverse, and \\nbeyond. This pinnacle of civilizational evolution implies a mas-\\ntery over the fundamental laws of nature, control over matter, \\nenergy, space, time, and dimensions. The idea of a T ype VII Civi-\\nlization stretches the boundaries of human imagination to its \\nlimit, presenting a scenario where we become the architects of \\nreality itself.\\nEach of these tiers, starting even from T ype I, is optional and \\nrequires monumental leaps in technology, understanding, and \\nperhaps existential ethos. The journey through these types \\nsketches a trajectory of boundless innovation, each step expand-\\ning the realm of the conceivable. The scale, though speculative, \\nprovides a framework to envision the uncharted terrains of tech-\\nnological and cosmic exploration that could unfold in the \\neons to come.\\nThe trajectory of human progress, when viewed through the \\nlong lens of history, showcases a remarkable narrative of innova-\\ntion and adaptation. Our ancient counterparts would indeed \\nregard our current capabilities as god-like, a testament to the \\nboundless potential of human ingenuity.\\nThe narrative of progress is characterized by a multitude of \\nmilestones achieved over different epochs. Longevity has \\nincreased, economic output per capita has skyrocketed, literacy \\nrates have soared globally, and the deployment of solar energy is'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 401\\non an upward trend, reflecting a growing commitment to sus-\\ntainable energy. The realm of AI is bustling with activity, as evi-\\ndenced by the surge in AI patent filings.\\nPositive trends extend to the realms of health and poverty \\nalleviation. Child mortality rates and extreme poverty are on the \\ndecline, while the costs of solar panels, batteries, and DNA \\nsequencing are plummeting, thereby broadening access to essen-\\ntial services and technologies. The diminishing cost of DNA \\nsequencing, for instance, augments our ability to diagnose dis-\\neases and optimize drug efficacy.\\nT echnological advancements hold the promise of medical \\nmarvels such as limb regeneration and the eradication of known \\ndiseases. The potential to extend human lifespan indefinitely \\nmight not be a distant dream. NASA ’s utilization of AI in mission \\nhardware construction, yielding a threefold performance \\nenhancement, exemplifies the synergy of human and machine \\nintelligence.\\nThe future could see the eradication of hunger, with biotech-\\nnology playing a pivotal role in climate stabilization and biodi-\\nversity conservation. The quest for clean energy is likely to be \\nmet, fueling our civilization with abundant, renewable resources.\\nAdvancements in rocketry and material science, spurred by \\nAGI, could propel us to distant planets and moons, unlocking the \\nmysteries of the cosmos. Over the last century, our growth has \\nbeen exponential, and as we stand on the cusp of further techno-\\nlogical leaps with tools like DNA-editing CRISPR, the potential \\nto augment our physical forms and functions is within reach. \\nThe evolution of medical implants could lead to enhanced physi-\\ncal capabilities, transcending natural limitations.\\nThe idea of consciousness uploading heralds a future where \\nthe boundaries between the human and the digital blur. The \\nfreedom to choose robotic embodiments or live wholly online \\nhints at a paradigm shift in our understanding of existence.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='402 GENERATIVE AI\\nWhile optimism may have its critics, it remains a crucial cat-\\nalyst for envisioning and striving toward an elevated future. It’s \\nthis optimism that fuels the quest for improvement and the drive \\nto overcome challenges. In a world brimming with potential, \\nharboring a vision of a brighter future is not just a choice, but a \\nduty toward advancing the human narrative.\\nAddressing potential hazards associated with AI, OpenAI, \\naiming to mitigate existential risks from superintelligent AI, ini-\\ntiated a “superalignment” program, targeting the AI alignment \\nproblem resolution by 2027. This problem hints at a potential \\nmismatch between AI systems’ and human goals. Spearheaded by \\nJan Leike and Ilya Sutskever from OpenAI, the goal is to create \\na human-level automated alignment researcher to iteratively \\nalign superintelligence.\\nOpenAI has designated 20 percent of its total computing \\npower for this project over the next four years, assembling a team \\nof top machine learning experts for this mission. The alignment \\ntechniques developed should endure even when AI systems pro-\\npose highly creative solutions, with models being trained to help \\nhumans differentiate correct from deceptive solutions.\\nOpenAI believes that even without new alignment ideas, \\nbuilding sufficiently aligned AI systems to advance alignment \\nresearch is feasible. The narrative stresses the importance of pri-\\noritizing alignment research within the AI community, to har -\\nness AI’s potential for humanity’s greater good.\\nIn the wake of augmenting our capabilities and automating \\ntasks to a point where certain jobs become obsolete, I harbor \\noptimism. I envisage a transition where emerging jobs not only \\nreplace the old ones but also elevate the work to a more mean-\\ningful level. The jobs that thrive will be the ones that AI, in the \\nforeseeable future, can’t replace.\\nThere’s a silver lining amid the automation wave. The pros-\\npect of engaging in meaningful, exciting, and creative careers'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Artificial General  Intelligence in\\xa0Sight 403\\nremains intact. Success in this new era hinges on one’s ability to \\nleverage new tools while honing skills that machines can’t emulate.\\nThree innate human talents stand out as irreplaceable, form-\\ning the bedrock for our enduring relevance in an AI-driven world:\\nCuriosity Avoid the trap of becoming bland or narrow-minded \\nas AI takes over mundane tasks. Stay curious, explore how AI \\ncan shoulder the tedious tasks, freeing you to delve into more \\nstimulating endeavors. Allow AI to fuel, not stifle, your inquis-\\nitive nature.\\nHumility Self-awareness is key. Embrace a journey of self- \\ndiscovery, understanding your intrinsic motivations, strengths, \\nand areas of growth. Seek feedback actively, much like how AI \\nlearns and adapts from data. The feedback loop is a learning \\ncurve, one that can foster personal and professional growth.\\nEmotional intelligence The essence of being human is encap-\\nsulated in our ability to form connections, empathize, and \\ncommunicate effectively. Emotional intelligence is our forte, a \\nrealm where AI trails behind. Before reacting or deciding, \\nconsider the collective goals and the emotional undercurrent \\nof your team. Digital communication, though convenient, can \\nbe a cold medium. Exercise caution to maintain a warm, col-\\nlaborative environment.\\nReconnecting with our core human attributes will not only \\ncarve a niche for us in the professional landscape but also ensure \\na harmonious coexistence with AI. By nurturing these irreplace-\\nable traits, we gear up to navigate the unfolding narrative, with \\nAI as a tool rather than a replacement. Our journey is bound to \\nbe exciting, filled with opportunities to redefine the meaning of \\nwork, life, and civilization at large.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content=''),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='405\\nT\\nhe journey of writing Generative AI: Navigating the Course to \\nthe Artificial General Intelligence Future has been intellectually \\nstimulating and rewarding, thanks to the collaborative spirit of \\nseveral remarkable individuals and organizations.\\nAt the outset, my interactions with Dibya Chakravorty of \\nLangSearch, Juan Carlos Medina Serrano from GenerativeAI \\n.net, and Harald Gunia and Martin Weis of Infosys Consulting, \\namong others, have been instrumental in shaping the narrative. \\nEarly dialogues with Stephan Bloehdorn’s team at IBM Consult-\\ning, and other colleagues like Eddybrando Vasquez, were cata-\\nlysts in exploring the breadth of generative AI.\\nThe insights from speeches and discussions with Julien Simon \\nof HuggingFace, Stuart Russel from the University of California, \\nand Oren Etzioni from the Allen Institute have been invaluable. \\nThe literary works of Stuart Russel, Ray Kurzweil, Ben Horowitz, \\nand Yann LeCun, and the engaging podcasts of Jason Calacanis, \\nthe All-In Pod, Lex Friedman, and Joe Rogan, among others, have \\nprovided a rich backdrop for my exploration.\\nI am indebted to Jim Minatel, associate publisher at John \\nWiley & Sons, and his team, especially John Sleeva, for their \\nreview and editing, which greatly enhanced the book’s quality. \\nThe creative finesse of Wiley and Karen Carlin in designing the \\ncover deserves special mention.\\nAcknowledgments'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='406 AcknowledgmenTs\\nOn a personal note, I owe a debt of gratitude to my girl-\\nfriend, Karen Carlin, whose patience and support were my pillars \\nthroughout this journey. The understanding and support from \\nmy friends and family, despite my sparse availability, have been \\nnothing short of a blessing.\\nMy engagement with clients from varied sectors such as \\ntransportation, banking, insurance, manufacturing, and oil and \\ngas, among others, has been a wellspring of learning. Witnessing \\nthe initial requests, the prioritization processes, and the out-\\ncomes of our largely successful collaborations has propelled me \\nup steep learning curves, emerging wiser (albeit with whiter hair) \\neach time.\\nI invite readers to delve deeper into the realms of generative \\nAI through our offerings at GenerativeAI.net, where you can \\naccess training courses and speeches and subscribe to our much-\\nloved newsletter.\\n—  Martin Musiol'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='407\\nL\\nong before the buzz surrounding generative AI emerged,  \\n  Martin Musiol was already advocating for its significance \\nback in 2016. Since then, he has frequently taken part in confer-\\nences, podcasts, and panel discussions, addressing the technologi-\\ncal advancements, practical applications, and ethical considerations \\nsurrounding generative AI, autonomous AI agents, and artificial \\ngeneral intelligence.\\nIn 2018, Martin founded GenerativeAI.net and has since \\nbeen a lecturer on AI to over 10,000 students, as well as the pub-\\nlisher of the newsletter Generative AI: Short & Sweet, which has \\nmore than 30,000 subscribers. Serving as the GenAI Lead for \\nEMEA at Infosys Consulting (formerly at IBM), Martin assists \\ncompanies globally in harnessing the power of generative AI, \\nespecially LLMs, to gain a competitive advantage.\\nAbout the\\xa0Author'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content=''),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='409\\nA\\nAccenture, 295\\naccessibility\\nof cloud computing, 242\\ngenerative AI and, 333–335\\nvoice generation and, 152\\nActiveChat.AI, 133\\nAdcock, Brett, 395\\nAddiform, 156\\nAdept, 120, 382\\nadvanced judicial system, AGI and, 388\\nAequitas, 293\\naerospace industry, learning models in, 118\\nAGI Society, 378–379\\nagriculture, data augmentation and, 209\\nAI. See artificial intelligence (AI)\\nAI Building Blocks, 127\\nAI Ethics Framework, 323\\nAI Fairness 360, 293\\nAI Platform, 127\\nAI Verify Foundation, 280–281\\nAI Winter, 30–31\\nAI-driven economy, 278–280\\nAI-generated data, bias and fairness in,  \\n291–300\\nair movement actuators, 348\\nAirbus, 153–154\\nAIVA, 182–183\\nAlan T uring Institute, 295\\nAleph Alpha, 382\\nAlexa, 72, 148\\nAlgorithmic Bias Detection T ool, 293\\nalgorithms, discriminative AI and, 8\\nAllganize, 120\\nAll-In Podcast, 335\\nAlpaca (Stanford), 111–113\\nAlphabet, 189\\nAlphaCode, 166–167\\nAlphaFold, 148, 160–166\\nAlphaGo (Google), 14, 123, 158–159\\nAlphaStar, 160\\nAlphaT ensor, 158, 251–253\\nAlphaZero, 158, 252\\nAltman, Sam, 85, 137, 138, 376, 389\\nAmazon, 10, 74, 133, 189, 240, 316, 319, 328, 359\\nAmazon AlexaTM 20B, 75\\nAmazon CodeWhisperer, 190\\nAmazon Lex, 150\\nAmazon Science, 106–107\\nAmazon Web Services (AWS), 133, 137, 145, \\n188–190, 259\\nAMBER model, 161–162\\nAmodei, Daniela, 121\\nAmodei, Dario, 121\\nAmper Music, 182–183\\nAndreessen Horowitz, 273\\nanonymizing data, 294\\nAnthropic, 121–122, 124, 127, 212,  \\n272–273, 369, 374\\nApple, 46, 107, 238–240\\nApple M1, 239\\napplication fields\\nabout, 147–148\\ncode generation, 166–171\\ngenerative design, 153–158\\nmusic generation, 180–184\\nsolving problems in science by  \\nGoogle DeepMind, 158–166\\nsynthetic data augmentation, 202–209\\ntext generation, 172–180\\n3D object generation, 194–202\\nvideo generation, 185–193\\nvoice and speech generation, 148–152\\napplications\\nfoundational AI models, 119–146\\nfor generative AI, 119–218\\nopen source vs. closed source, 119–146\\nspecialized AI models, 119–146\\napplication-specific integrated circuits (ASICs), \\n129, 231–233\\narchitectures, advanced AI, 259\\nArgil AI, 176\\nIndex'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='410 Index\\nARK Investment Management LLC,  \\n278–279, 282–283\\nArriaga, T . J., 312–313\\nartificial general intelligence (AGI), 123, \\n337–338, 393–398\\nartificial intelligence (AI). See also generative AI\\nabout, 1–2, 337–339\\nactors, 192\\nadvanced models, 259\\nagents, 174–177\\nchallenges to progression of,  \\n280–283\\nclasses of, 2\\ndependency on, 310–315\\ngenerative, 6–7\\nmultimodality in, 105–107\\nscaled utilization of, 355–398\\ntraining complex tasks and, 2–5\\nunsupervised learning, 5–6\\nartificial superintelligence (ASI), 338, \\n379, 382–383\\narXiv, 339\\nA-series chips, 239\\nAspen AI, 132\\nATI, 18\\nAtlas (Boston Dynamics), 13, 394\\nAtoll, 127\\n“Attention Is All Y ou Need” (Vaswani),  \\n77\\nattention mechanism, 77–78\\nauditory actuators, 347\\nAugGPT , 205–207\\naugmented reality (AR), 340\\nAutodesk, 155\\nautoencoders (AEs), 40–44\\n“Auto-Encoding Variational Bayes” (Kingma and \\nWelling), 42\\nAutoGen, 357, 361–364\\nAutoGPT , 179–180, 357, 358\\nautomation wave, 305–306\\nAutoML, 260–262\\nautonomous AI agents\\nabout, 177–180, 355–365\\nbridging the gap to, 371–374\\ncompanies that build, 374–382\\ndoom narratives, 389–393\\npotential benefits of, 382–389\\nprogressive integration of, 367–368\\npromise of, 368–371\\nSouth Korea’s journey in tech evolu-\\ntion, 365–367\\nautonomous vehicles, data augmenta-\\ntion and, 209\\nautonomous weaponization, 390\\nautoregression, 60–62\\nautoregression models, 64–65\\nautoregressive training, 82\\navailability, as a driving force of automa-\\ntion wave, 306\\nawareness campaigns, providing, 321\\nB\\nbackpropagation, 4–5, 251\\nBahdanau, Dzmitry\\nabout, 73\\n“Neural Machine T ranslation by Jointly \\nLearning to Align and T ranslate,” 78\\nBaidu Research, 124\\nBard (Google), 128–131, 340\\nBART (Facebook), 78\\nbatch processing, 251\\nBehzadi, Yashar, 207\\nBen & Jerry’s, 11\\nBengio, Y oshua (author)\\nabout, 73, 328, 389\\nDeep Learning, 7, 45–46\\n“Neural Machine T ranslation by Jointly \\nLearning to Align and T ranslate,” 78\\nBerkeley, 110\\nBERT (Google), 78, 83\\nbias, in AI-generated data, 291–295\\nBias Analyzer, 293\\nbias audits, self-regulation and, 327\\nBiasBios, 293\\nBig Data, 220, 264\\nBIG-bench, 102, 129\\nBigDog, 394\\nBigGAN, 51\\nBigScience Research Workshop, 144\\nBing, 130, 302\\nbiodiversity conservation, AGI and, 388\\nbiology, generative AI for, 211\\nblack box, 353\\nBlackrock Neurotech, 387\\nBlackshark.ai, 20\\nBlender, 196\\nBLOOM, 144, 145\\nBloomberg Innovation Index, 365\\nBloombergGPT , 111, 113–114\\nBoltzmann machines\\nabout, 31–33\\ndeep (DBMs), 39–40\\nrestricted (RBMs), 35–37\\nbone conduction transducers, 347\\nBookCorpus, 83\\nBoston Dynamics, 13, 394, 395\\nBrainCo, 387\\nbrain-computer interface (BCI) technologies, 387\\nBrainGate, 333\\nBreazeal, Cynthia (researcher), 44\\nBrin, Sergey, 128\\nBrockman, Greg, 137, 376\\nBuilder.ai, 171\\nBulgaria, 282\\nbusiness email compromise (BEC) attacks, 301\\nbyte-pair encoding (BPE), 79\\nC\\nC, 167\\nC++, 29–30, 167\\nCalacanis, Jason, 138'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Index 411\\nCalifornia Consumer Privacy Act \\n(CCPA), 322–323\\nCalifornia Privacy Rights Act (CPRA), 322–323\\nCapital Factory, 381\\ncarbon credits, providing and offsetting, 320\\nCarmack, John, 380–382\\ncatastrophic technologies, AGI and, 389\\nCBS, 188\\nCentral Processing Unit (CPU), 235–236\\nCERN, 244\\nChain-of-Thought (CoT) Prompting, 87\\nchatbots, 27–31\\nChatDev, 362–364\\nChatGPT , 7, 15, 64, 75, 93–95, 97–101, 109, 110, \\n117, 121, 128–132, 138, 168, 169, \\n175–177, 204–207, 215, 217, \\n262–263, 275, 301, 302, 340, 343, 345\\nChatGPT Chess Plug-in, 176\\nChatGPT KAYAK/Expedia Plug-in, 176\\nChatWithPDF , 176\\nChinchilla scaling laws, 96, 101, 264\\nchips, 231–235\\nCho, KyungHyun\\nabout, 73\\n“Neural Machine T ranslation by Jointly \\nLearning to Align and T ranslate,” 77\\nChromeOS, 130\\nChrysler, 274\\nCicero, 172–173\\nCiti, 295\\nclassification, 8–9\\nclimate change mitigation, AGI and, 388\\nCLIP-Forge, 196\\nCLIPMatrix, 196\\nCLIP-Mesh-SMPLX, 196\\nclosed source models, 119–146\\ncloud computing, 220, 241–242\\ncloud storage, 270\\nclustering, 10–11\\nCoatue, 55, 144\\ncode generation\\nwith ChatGPT , 169\\nGitHub Copilot, 167–169\\nGoogle DeepMind’s AlphaCode, 166–167\\nCode Interpreter plug-in, 169–170\\nCodePal, 171\\nCodex, 94\\nCohere, 273\\ncollaboration, self-regulation and, 328\\nCollison, Patrick, 381\\nCommon Crawl, 58\\nCOMPAS datasets, 293\\ncompetition, for data storage, 270\\ncompound annual growth rate (CAGR), 125, 234\\nComputer Science and Artificial Intelligence \\nLaboratory (CSAIL), 260\\nComputer Unified Device Architecture \\n(CUDA), 253–254\\ncomputing, exponential progress in, 228–263\\n“Computing Machinery and Intelligence” \\n(T uring), 28\\nconcept space, 54\\nconditional probability, 24–25\\nconsciousness, AGI and, 369\\nContact Center AI, 127\\ncontent creators, generative AI and, 332–333\\ncontext vector, 73\\ncontextual style transfer, 16\\ncontinuous learning, 192\\ncontinuous monitoring, self-regulation and,  \\n327\\nContrastive Language-Image Pre-T raining \\n(CLIP), 51–52\\nconvolutional neural network (CNN), 31, 202\\ncopyright protection, 288–289\\nCortana, 72, 150\\ncost, of data storage, 269–270\\ncost-effectiveness\\nof cloud computing, 241\\nas a driving force of automation wave, 306\\nCoursera, 45, 276\\nCourville, Aaron (author), 7, 45–46\\nCraiyon, 59\\ncreative industries, impact of AI in, 19–20\\nCritical Assessment of Structure Prediction \\n(CASP), 161\\ncritical thinking skills, AI and, 311\\ncross-entropy loss, 83\\nCrunchbase, 150–151\\ncultural variance, AI and, 281–282\\ncuriosity, 403\\nD\\nDALL-E, 53–54, 138, 185, 219, 275, 342\\ndata\\nexponential growth in, 264–271\\ngeneration of, 15\\nprocessing of, 251\\nself-regulation and protection of, 327\\nsynthetic, 268–269\\ntransformation of, 15–16\\ndata analyst, 169–171\\ndata augmentation\\nabout, 202–203\\ncompanies in, 207–208\\nfuture of, 208–209\\ntech behind, 203–207\\nData Augmentation-Fusion (DA-\\nFusion), 204–207\\ndata enrichment, 16–17\\ndata parallelism, 250\\nDavinci model, 80\\ndecision support, self-regulation and, 328\\ndeep belief networks (DBNs), 37–39\\nDeep Blue, 33–35\\ndeep Boltzmann machines (DBMs), 39–40\\nDeep Dream Generator (Google), 62\\ndeep learning (DL), 5, 17–19, 221'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='412 Index\\nDeep Learning (Goodfellow, Bengio, and \\nCourville), 7, 45–46\\ndeepfakes, 296–300\\nDeepMind (Google), 14, 96, 103, 122–124, 127, \\n137, 158–166, 252–253, 272, \\n369, 374–375\\ndelta-tuning methods, 86\\ndependency, on AI, 310–315\\nDescript, 151\\nDetectGPT , 299\\ndevelopment assistants\\nAI-powered, 262–263\\nexponential patterns in, 272–278\\nDevlin, Jacob, 129\\nDGX Cloud (NVIDIA), 199–200\\ndiffusion models, 54–56\\nDijkstra’s algorithm, 250\\ndimensionality reduction, 11–12\\nDing, Ning, 86\\nDiplomacy, 172–173\\nDirectional Stimulus Prompting, 90–91\\nDirective on Automated Decision-Making,  \\n323\\ndisaster anticipation/prevention/management\\nAGI and, 389\\ndata augmentation and, 209\\ndiscriminative AI\\nabout, 2, 7–8\\nclassification, 8–9\\nclustering, 10–11\\ndimensionality reduction, 11–12\\nregression, 9–10\\nreinforcement learning (RL), 13–14\\nDNA sequencing, 227\\nDocument AI, 127\\ndomain transfer, 15\\ndoom narratives, 389–393\\nDragon Anywhere, 150\\nDragon Professional, 150\\nDream T extures, 196\\nDreamFusion, 195\\ndrivers, of data growth, 267–268\\n“DUCHO: A Unified Framework for the \\nExtraction of Multimodal Features in \\nRecommendation” paper, 215\\nE\\neconomics\\nbenefits of generative AI, 308–310\\ngenerative AI for, 211\\neconomies of scale, for data storage, 270\\neconomy, AI-driven, 278–280\\nEcrett Music, 182–183\\nedge computing, 271\\neducation\\nlearning models in, 114–115\\nplug-ins for, 177\\nproviding campaigns, 321\\nself-regulation and, 327\\nvoice generation and, 151\\nedX, 276\\n“Effective Data Augmentation With Diffusion \\nModels” paper, 204\\nefficiency, as a driving force of automation  \\nwave, 306\\nElbo chair, 155–156\\nelectrical muscle stimulation (EMS), 348\\nelectroactive polymers, 347\\nEleutherAI, 110, 135\\nELIZA, 27–31\\nembarrassingly parallelism, 250\\nemotional intelligence (EI), 311–312, 403\\nEnemy Analysis T ool, 173\\nenergy consumption, of generative AI  \\nmodels, 315–317\\nenergy efficiency, of cloud computing, 242\\nenergy sector, learning models in, 116\\nEngineer.ai, 171\\nentertainment and gaming industry\\nimpact of AI in, 20–21\\nvoice generation and, 151–152\\nenvironmental, social, and governance (ESG) \\nscores, 317–318\\nenvironmental concerns, of AI, 315–321\\nenvironmental science, generative AI \\nfor, 211–212\\nESMFold, 164\\nethical concerns and social implications\\nabout, 285–287\\nAI and, 281\\nbias and fairness in AI-generated \\ndata, 291–295\\ndependency on AI, 310–315\\nenvironmental concerns, 315–321\\nof generative AI, 285–335\\nimpact on jobs and industry, 303–310\\nintellectual property (IP) rights, 287–291\\nmisinformation and misuse of generative \\nAI, 295–300\\noversight and self-regulation, 322–329\\npositive aspects of, 329–335\\nprivacy, safety, and security, 300–303\\nself-regulation and, 327\\nEuropean Union Artificial Intelligence Act (EU \\nAI Act), 322–325\\nexplainable generative AI (XAI), 353\\nexponential growth\\nabout, 219–221\\nin computing, 228–263\\nin data, 264–271\\nrequirements for, 278–283\\nin research, development, and financial \\nallocations, 272–278\\nS-curve, 222–226\\ntechnological convergence, 226–228\\nextended lifespan, AGI and, 387\\nExxonMobile, 243\\nF\\nFacebook, 74, 78, 130, 140'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Index 413\\nFacebook AI Research (FAIR), 124\\nFaceID, 9\\nFairFace, 293\\nfairness, in AI-generated data, 291–295\\nFakeCatcher (Intel), 298–299\\nfans, 348\\nfeatures, in AI, 5\\nfeedback mechanisms, self-regulation and, 327\\nFew-Shot Prompting, 87–88\\nFeynman, Richard, 243\\nfinancial allocations, exponential patterns \\nin, 272–278\\nfinancial constraints, AI and, 281\\nfinancial sector, plug-ins for, 177\\nfitness sector, plug-ins for, 177\\n5G, 271, 365–366\\nflavor sprays, 348\\nFlight Simulator (Microsoft), 20\\nfloating point operations (FLOPs), 84, 228–229\\nfood and beverage sector, learning models in, 116\\nFord, 274\\nForksheet T ransistor Design, 234–235\\nfor-profit solutions, for video genera-\\ntion, 187–188\\nFortran, 254\\nfoundational AI models, 119–146\\n4D cinema seats, 349\\n4D images, 62\\nFréchet inception distance (FID), 61\\nFridman, Lex, 340\\nFriedman, Nat, 381\\nG\\nGalactica, 95\\nGartner, 208, 268\\nGaudí, Antoni, 157\\nGen-2 video generation model, 187\\nGen5X, 155\\nGeneral Catalyst, 273\\nGeneral Data Protection Regulation \\n(GDPR), 207\\nGeneral Motors (GM), 153, 274\\ngenerational variance, AI and, 281–282\\ngenerative adversarial networks (GANs)\\nabout, 16, 45–46, 355\\nautoregression, 60–62\\nchallenges of, 48–49\\nContrastive Language-Image Pre-T raining \\n(CLIP), 51–52\\nDALL-E 2, 53–54\\ndiffusion models, 54–56\\nhow they work, 46–48\\nfor image generation, 50–51\\nimportance of training data, 58–60\\nMidjourney, 57–58\\nmusic generation and, 181\\nStable Diffusion tech, 56–57\\nfor text generation, 75–76\\ngenerative AI\\nabout, 2, 6–7, 14–15\\napplications for, 119–218\\ndata enrichment, 16–17\\ndata generation, 15\\ndata transformation, 15–16\\ndeep learning tech convergence with \\nGPUs, 17–19\\nearly impact of, 19–22\\neconomic benefits of, 308–310\\nethical concerns and social implications \\nof, 285–335\\nexponential growth of, 219–283\\nfuture of, 339–355\\nmultimodal, 342–346\\nmultisensory, 346–352\\nmultitasking, 340–342\\nplatforms for, 132–135\\npotential of, 210–218\\nreal value of, 274–275\\ntrends in, 352–355\\ngenerative design, 153–158\\nGenerative Pre-trained T ransformer \\n(GPT), 78–81\\nGetty Images, 198–199, 288\\nGibbs sampling, 32\\nGitHub, 57, 94, 129, 216\\nGitHub Copilot, 135, 217, 262–263\\nGitHub Pilot, 167–169\\nGLIDE, 54\\nGLUE, 102\\nGo, 167\\nGoertzel, Ben, 378–380\\nGoldman Sachs, 124, 201\\nGood, I. J., 383\\nGoodfellow, Ian (scientist)\\nabout, 48–49\\nDeep Learning, 7, 45–46\\ndevelopment of GANs by, 45–46\\nGoogle\\nabout, 74, 94, 227, 243, 316, 319, 328, \\n330, 359, 370\\nAI dominance of, 127–131\\nAlphaGo, 14, 122, 158–159\\nBard, 128–131, 340\\nBERT , 78, 83\\nChain-of-Thought (CoT) Prompting, 87\\nDeep Dream Generator, 63\\nDeepMind, 14, 96, 101, 103, 122–124, 127, \\n137, 158–167, 252–253, 272, \\n369, 374–375\\ninvestment in Runway AI, 188\\nLaMDA, 94\\nLaMDA 2, 94\\nMultiModel, 341\\nMusicLM, 181–183\\nno moat leakage letter, 139–141\\n1,000\\xa0Languages initiative, 329–330\\nStarline project, 210\\nGoogle Assistant, 71, 74\\nGoogle Brain, 37, 46, 74, 77–78, 127\\nGoogle Cloud, 127, 133, 188, 190, 280–281'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='414 Index\\nGoogle Cloud Platform (GCP), 188–190, 212\\nGoogle Now, 150\\nGoogle Research, 46, 77, 78\\nGoogle Search, 130\\nGoogle T ranslate, 71, 74\\nGoogle Workspace, 190\\nGoogle X, 394\\nGPT-2, 93\\nGPT-3, 96, 168\\nGPT-4, 84, 104–105, 107–111, 127, 134, \\n136–137, 343\\nGPT-J, 101\\nGPT-Neo, 101\\nGPT-NeoX-20B, 135\\nGPTZero, 299\\nGradio, 144, 146\\ngrants, 142\\nGraphcore IPU, 144, 238\\nGraphics Processing Units (GPUs), 17–19, \\n220, 236, 237\\ngreen energy, 320\\nGreylock Partners, 273\\nGrok (xAI), 132\\nGross, Daniel, 381\\ngustatory actuators, 348\\nH\\nHandle, 394\\nHann, T obias, 208\\nHanson Robotics, 378–379\\nhaptic actuators, 347\\nHarari, Yuval Noah, 328\\nhardware, exponential evolution of, 231–249\\nHarris, T ristan, 328\\nHarvey AI, 114\\nHassabis, Demis, 137, 375\\nHazy, 295\\nhealthcare sector\\ndata augmentation and, 209\\nlearning models in, 114\\nplug-ins for, 176–177\\nvoice generation and, 152\\nHelixon, 164\\nHellaSwag, 103\\nHELM, 102\\nhigh-quality data generation\\nabout, 23\\napplications of specific language mod-\\nels, 114–118\\nattention mechanism, 77–78\\nautoencoders, 40–42\\nautoregression, 60–62\\nautoregression models, 64–65\\nBoltzmann machines, 31–33\\nChatGPT , 93–95, 97–99\\nContrastive Language-Image Pre-T raining \\n(CLIP), 51–52\\nDALL-E 2, 53–54\\ndeep belief networks (DBNs), 37–39\\nDeep Blue, 33–35\\ndeep Boltzmann machines, 39–40\\ndevelopment of generative models, 26–45\\ndiffusion models, 54–56\\nELIZA, 27–31\\nemergent capabilities of GPT-4, 107–110\\nevaluation of large language models \\n(LLMs), 101–104\\nevolution of AI image generation, 49–63\\nfine-tuning LLMs, 84–86\\nfuture of AI image generation, 62–63\\nGANs for text generation, 75–76\\ngenerative adversarial networks \\n(GANs), 45–49\\nGPT-4, 104–110\\nimportance of training data, 58–60\\nLLM scaling laws, 95–97\\nlong short-term memory networks \\n(LSTM), 70–71\\nMarkov chains, 65–67\\nmidjourney, 57–58\\nmultimodality in AI, 105–107\\nN-gram models, 72\\nother models, 110–114\\noutput probability, 80–82\\npretraining LLMs, 82–84\\nprompt engineering, 86–92\\nreason for generative models, 24–26\\nrecurrent neural networks, 68–70\\nreinforcement learning from human \\nfeedback, 99–101\\nrestricted Boltzmann machines, 35–37\\nrule-based text generation, 67–68\\nSeq2Seq models, 2–75\\nstable diffusion tech, 56–57\\ntech triumphs in text generation, 78–118\\ntext generation, 63–78\\ntokenization for LLMs, 79–80\\nvariational autoencoders, 42–44\\nwomen in generative AI history, 44–45\\nHinton, Geoffrey, 35–40\\nHochreiter, Sepp, 70\\nHoffman, Reid, 137\\nHolz, David, 57–58\\nHonda, 397\\nHood, Amy, 190\\nHopfield, John, 68\\nHopper, Grace, 44\\nHorowitz, Andreesen, 133\\nhospitality companies, learning models in, 115\\nHouston, Whitney, 184\\nHugging Face platform, 55, 103, 104, 134, 135, \\n143–146, 272\\nHugging Face T ransformers, 258\\nhuman autonomy, erosion of, 390\\nhuman extinction, 390\\nhuman potential, 398–403\\nhuman values, misalignment of, 389–390\\nHumana, 295'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Index 415\\nhumanoid robots, 393–398\\nhumility, 403\\nhunger eradication, AGI and, 388\\nHybrid Microchip, 235\\nHyundai Motor Group, 366, 394\\nI\\nIBM, 33–35, 120, 231–232, 243, 254, 277, 319\\nIDC, 97\\nimage extrapolation, 53\\nimage generation\\nevolution of, 49–63\\nfuture of, 62–63\\ngenerative adversarial networks (GANs) \\nfor, 50–51\\nImageBind, 349–351\\nImagen model, 60\\nImagen Video, 187\\nImageNet, 44–45, 59\\nImbue, 382\\nimmortality, AGI and, 387\\nindustry, impact of generative AI on, 303–310\\nInflection AI, 273\\ninformation and communication technology \\n(IT/ICT), 276\\nInfosys Consulting, 64, 137\\ninfrared beaters, 348\\ninfrastructure development, 321\\ninnovation, of cloud computing, 242\\ninpainting, 53\\nInstructGPT , 101\\ninsurance companies, learning models in, 115\\nintegration complexity, 351\\nIntel, 240, 298–299\\nintellectual property (IP) rights, generative AI \\nplatform and, 287–291\\nIntelligence Processing Unit (IPU), 236, 238\\ninteractive storytelling, 192\\ninternational collaboration, 321, 325–326\\nInternet of Things (IoT), 233, 267\\nIntFOLD, 164\\nIvakhenko, A. G., 17\\nJ\\nJasper, 135\\nJava, 29–30, 167, 255\\nJavaScript, 167\\nJetBrains, 168\\njobs, impact of generative AI on, 303–310\\nJoint Embedding Predictive Architecture (JEPA) \\nmodels, 372–373\\nJulia, 255\\nK\\nK Health, 114\\nKaedim, 198\\nKaldi, 150\\nKardashev, Nikolai, 398\\nKardashev scale, 398–399\\nKasparov, Garry (chess champion), 33–35\\nKeen AGI, 381\\nKeras, 256\\nkernel Hilbert space (RKHS), 76\\nKhan, Shah Rukh, 148\\nKhan Academy, 115\\nKhosla Ventures, 273\\nKim, Ji-Hoon, 249\\nKingma, Diederik P ., 42\\nKismet, 44\\nknowledge gaps, AI and, 281\\nKnowledge Prompting, 90\\nKoller, Daphne, 44\\nKurzweil, Ray\\nabout, 338, 384\\nThe Singularity Is Near, 165\\nL\\nLady Gaga, 184\\nLAION-400M, 58\\nLaMDA, 94, 128, 370\\nLaMDA 2, 94\\nLangChain, 212–213, 256, 357, 359, 361\\nlanguage learning, voice generation and, 151\\nlanguage models, applications of spe-\\ncific, 114–118\\nLapa, Valentin Grigor’evich, 17\\nLarge Hadron Collider (LHC), 244\\nlarge language models (LLMs)\\nabout, 7, 21, 227\\ncode generation with, 169\\nemergent capabilities of GPT-4, 107–110\\nevaluation of, 101–104\\nfine-tuning, 84–86\\npre-training, 82–84\\nscaling laws, 95–97\\ntokenization for, 79–80\\nuntil ChatGPT , 93–95\\nlatent diffusion models, 56\\nLattner, Chris, 255\\nLAUNCH, 273\\nlayers, 5\\nLe, Quoc V ., 73\\nLeCun, Yann, 31, 37, 372–373, 392–393\\nLee, Sukbae, 249\\nlegal industry, plug-ins for, 177\\nlegal sector, learning models in, 114\\nLemoine, Blake, 370\\nLG, 124, 366\\nLi, Fei-Fei, 44–45\\nlibraries, for parallel processing, 253–254\\nlicensing, 142–143\\nlight-emitting diodes (LEDs), 349\\nLinkedIn, 130\\nliquid neural networks (LNNs), 260–262, 317\\nLisp, 29\\nLivingston, Jessica, 137\\nLK-99, 247–249, 317, 339'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='416 Index\\nLLaMA, 259, 316\\nLM Evaluation Harness, 103\\nlocal interpretable model-agnostic explanations \\n(LIME), 354\\nlong short-term memory networks \\n(LSTM), 70–72\\nLovelace, Ada, 44\\nLua, 167\\nLuma AI, 197–198\\nLütke, T obi, 381\\nM\\nmachine learning (ML), 2–3\\nMachines Who Think (McCorduck), 44\\nMagic AI, 171\\nMagic T ools, 187\\nMagicVideo, 187\\nMake-A-Scene (Meta), 350\\nMake-A-Video (Meta), 15, 187\\nMaliGAN, 76\\nmanipulation, 390\\nMarkov, Andrey (mathematician), 65\\nMarkov chains, 65–67\\nmasked training, 83\\nMathAI, 210\\nmathematics, generative AI for, 211\\nmatrix multiplication, 251\\nMave, 366\\nmaximum likelihood estimation (MLE), 81\\nMayo Clinic, 21–22\\nMcCarthy, John (scientist), 7, 29\\nMcCorduck, Pamela (author), 44\\nMcGeehan, John, 164\\nMcKinsey Global Institute, 306–307\\nmechanical, electrical, and plumbing (MEP) \\nservices, 156\\nmedia and entertainment sector, learning \\nmodels in, 115\\nmemory safety, Mojo and, 256\\nMercedez-Benz, 243\\nMeta, 15, 95, 140, 164, 172, 212, 259, 288, 316, \\n340, 349–350, 381\\nMeta, Amazon, Apple, Netflix, Google \\n(MAANG), 110\\nMeta AI, 343, 372\\nmetadata, 298\\nMetaGPT , 362–364\\nMetaverse Entertainment, 366\\nMicrosoft, 20, 74, 110, 120, 125–127, 189, 240, \\n243, 298, 316, 319, 328\\nMicrosoft Azure, 133, 188–190, 212, 259, 359\\nMicrosoft Common Objects in Context \\n(MS-COCO), 61\\nMidjourney, 57–58, 157–158, 289\\nMiku, Hatsune, 184\\nMinsky, Marvin (scientist), 29\\nmisinformation, of generative AI, 295–300\\nmisuse prevention, self-regulation and, 327\\nMitsubishi Chemical, 244\\nML Architect, 275\\nMMLU, 102\\nmodel wrapper companies, 123–125\\nmodel-makers, 120–123\\nModified National Institute of Standards and \\nT echnology (MNIST), 24\\nModular’s Mojo, 255–257\\nmoisture actuators, 348\\nMojo, 255–257\\nMondelez International, 148\\nMoody’s, 318\\nMoore, Gordon, 228\\nMoore’s law, 84, 220, 228–230, 240, 242\\nMostaque, Emad (CEO), 55, 328\\nMostly AI, 295\\nmovies, personalized, 191\\nMSCI, 318\\nmultilayer perception (MLP), 30\\nmultimodal actuators, 349\\nmultimodal generative AI, 105–107, 342–346\\nMultiModel (Google), 341\\nmultisensory generative AI, 346–352\\nmultitask learning (MTL), 341\\nmultitasking generative AI, 340–342\\nMurf.ai, 150\\nmusic generation\\nabout, 180–181\\nfuture of, 183–184\\nGoogle’s MusicLM, 181–183\\nmusic sampling, 332–333\\nMusicCaps, 182\\nMusicLM, 181–183\\nMusk, Elon, 132, 137–139, 282, 328, 376–378, \\n389, 396–397\\nMuZero, 158\\nN\\nNadella, Satya, 189, 190\\nNamecheap, 275\\nNash equilibrium, 46–47\\nnatural language processing (NLP), 2–3, 8, \\n21–22, 31, 130, 337\\nNazi Enigma code, 29\\nNCC Group, 301–302\\nNeosensory Buzz, 346–347\\nNeovim, 168\\nNeRF , 196–197\\nNetflix, 10, 267\\nneural machine translation (NMT), 71\\n“Neural Machine T ranslation by Jointly \\nLearning to Align and T ranslate” \\n(Bahdanau, Cho, and Bengio), 77\\nneural networks, 226\\nNeural Processing Unit (NPU),  \\n236–237\\nNeuroLink, 387\\nneuromorphic computing, 246–247\\nneurons, 30\\nNew Balance, 188'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Index 417\\nNew Generation Artificial Intelligence \\nDevelopment Plan, 323\\nnext sentence prediction (NSP), 83\\nNFX, 273\\nNg, Andrew, 45\\nN-gram models, 72\\nNo Language Left Behind (NLLB), 344\\nnon-fungible tokens (NFT s), 20\\nnon-player characters (NPCs), 21\\nNotable, 169\\nNVIDIA, 16, 18, 110, 190, 198–199, 202, 203, \\n237, 240, 253–254, 321, 376\\nNVIDIA AI Research, 124\\nNVIDIA Picasso, 198–199\\nO\\nOctane, 355\\nOgilvy, 148\\nolfactory actuators, 348\\nOlsavsky, Brian, 189\\nOmegaFold, 164\\n1,000\\xa0Languages initiative (Google), 329–330\\nopen source models, 119–146\\nopen source movement, 257–258\\nOpen University, 210\\nOpenAI, 7, 46, 53–54, 59, 73, 75, 78–80, 84, 85, \\n88, 89, 93, 94, 96, 98, 99, 101, 103, \\n106–109, 121, 124, 126–132, 134, \\n136–141, 168, 212, 272, 288, 289, \\n316, 342, 369, 374, 376, 402\\nOpenAI Codex, 168\\nOpenBioML, 55\\nOpenCL, 254\\nOpenCog Foundation, 378–379\\nOpenCV , 258\\nOpenGL, 254, 381\\nOptimus (T esla), 395–397\\nOrganisation for Economic Co-operation and \\nDevelopment (OECD), 365\\noutpainting, 53\\noutput probability, 80–82\\noversight, AI, 322–329\\nP\\nPacBio, 227\\nPactum, 173–174\\nPage, Larry, 128\\nPalihapitiya, Chamath, 335\\nPaLM, 128–130\\nPandasAI, 169–171\\nparallel processing, libraries for, 253–254\\nparallel programming, 249–251\\n“Parameter-Efficient Fine-T uning of Large-\\nScale Pre-T rained Language Models” \\n(Ding), 85–86\\nParry, Kevin, 188\\nParti model, 60\\nPathways Language Model (PaLM), 129–130\\nPeltier element, 348\\npersonal branding, voice generation and, 152\\nPhaedra chatbot, 312–313\\npharmaceutical companies, learning models \\nin, 116–117\\nphonemes, 149\\nPHP , 167\\nPhyre, 164\\nPichai, Sundar, 189\\npiezoelectric actuators, 347\\nPitchBook, 272\\nplug-ins, 175–177, 215\\nPoint-E, 196\\nPoly.ai, 150–151\\nportfolio approach, 122\\npoverty eradication, AGI and, 388\\nprecision, as a driving force of automa-\\ntion wave, 306\\npre-training LLMs, 82–84\\nprivacy, generative AI and, 300–303\\nprobability\\nconditional, 24–25\\noutput, 80–82\\nprocessing units, 235–238\\nprogramming languages\\nimprovement of, 254–255\\nnew and user-friendly libraries, 255–257\\nprogressive growing of GANs (ProGAN), 50\\nprompt engineering, 86–92, 275\\nprompt injection, 301–302\\nproof of concept (PoC), 216–217\\nprotein-folding problem, 123, 161\\nproximal policy optimization (PPO), 100\\nPublicis, 188\\nPulsar+CLIP , 196\\nPython, 29–30, 167, 254, 256, 359\\nPython Notebook, 55\\nPyT orch, 256\\nQ\\nQualcomm, 233, 259\\nquantum computing, 230, 242–245\\nQuora, 96, 276\\nR\\nR language, 254\\nRain Neuromorphics, 120, 246\\nRaptorX, 164\\nReAct (Reason + Act) Prompting, 91–92, 359\\nreal estate sector\\nlearning models in, 115\\nplug-ins for, 177\\nrecurrent neural networks (RNNs), 68–70, 181\\nReddit, 96, 276\\nregression, 9–10\\nregularization loss, 83\\nregulations, role of in mitigating environmental \\nimpact of generative AI, 319–321'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='418 Index\\nreinforcement learning (RL), 13–14, 158\\nreinforcement learning from human feedback \\n(RLHF), 79, 99–101, 370\\nreliability, of cloud computing, 242\\nrepetitiveness, as a driving force of  \\nautomation wave, 306\\nReplicate, 134\\nReplika, 313\\nRequena, Guto, 154\\nresearch\\nAGI and accelerated, 388\\nexponential patterns in, 272–278\\nfunding, 320\\nprivatization of, 277–278\\nself-regulation and investment in, 328\\nRespeecher, 148\\nrestricted Boltzmann machines (RBMs), 35–37\\nretail sector, learning models in, 115\\nrevenue, generating with open source mod-\\nels, 141–143\\nreverse engineering, 298\\nreward model, 99\\nRich, Elaine, 44\\nRichards, T oran Bruce, 357\\nrisk, existential, 390\\nrobot tax, 385\\nrobots, 393–398\\nRochester, Nathaniel (scientist), 29\\nRosch, Eleanor (psychologist), 44\\nRosenblatt, Frank, 30\\nRoseTTAFold, 164\\nRuby, 29–30, 167\\nrule-based text generation, 67–68\\nRumelhart, David, 68\\nRunway AI, 187–188\\nRunway ML, 272\\nRussell, Stuart, 328\\nRust, 167\\nS\\nsafety\\nas a driving force of automation wave, 306\\ngenerative AI and, 300–303\\nSagrada Familia, 157\\nSalakhutdinov, Ruslan, 39–40\\nSalesforce Ventures, 273\\nSamsung, 240, 366, 397\\nScala, 167\\nscalability, of cloud computing, 241\\n“Scaling Autoregressive Models for Content-\\nRich T ext-to-Image Generation,” 61\\nscaling laws, for LLMs, 95–97\\nscent diffusers, 348\\nSchlicht, Matt, 355\\nSchmidhuber, Jürgen, 70\\nscience, solving in by Google Deep-\\nMind, 158–166\\nS-curves, 222–226\\nSeamlessM4T , 343–344\\nsecurity\\ngenerative AI and, 300–303\\nvulnerabilities of AI, 310–311\\nSedol, Lee, 14, 123, 158\\nSelas AI, 132\\nself-attention, 77–78\\nself-awareness, AGI and, 370\\nSelf-Consistency Prompting, 87–89\\nSelf-Improvement by Reinforcement Learning \\nContemplation (SIRLC) method, 370\\nself-learning, in tech, 275–277\\nself-regulation, 322–329\\nsentience, AGI and, 369\\nsentiment analysis, 8\\nSeqGAN, 76\\n“Sequence to Sequence Learning with Neural \\nNetworks,” 73\\nsequence-to-sequence (Seq2Seq) model, 72–75\\nSequoia Capital, 144, 273, 381\\nservice provider license agreement (SPLA), 143\\nShannon, Claude E. (scientist), 29, 66\\nSHapley Additive exPlanations (SHAP), 354\\nShopify, 381\\nshows, personalized, 191\\nShutterstock, 199\\nsign problem, 37\\nSignificant Gravitas Ltd., 357\\nSimon, 150\\nSingularityNET , 174, 378–380\\nThe Singularity Is Near (Kurzweil), 165\\nSiri, 72, 148, 150\\nSK Hynix, 366\\nSkift, 174\\nSnap, 340\\nSnapchat, 267\\nsocial change, generative AI and posi-\\ntive, 330–331\\nsocial engineering, 390\\nSoftBank Group, 273, 394, 397\\nsoftware, exponential evolution of, 249–263\\nSongdo, 366\\nSouth Korea, 365–367\\nspace exploration, AGI and, 388\\nSparrow (DeepMind), 101\\nspeakers, 347\\nspecialized AI models, 119–146\\nspeech generation, 148–152\\nSpeechki, 176\\nspeed, of Mojo, 255–256\\n“Spiking Denoising Diffusion Probabilistic \\nModels” paper, 216\\nspiking neural network (SNN), 246\\nsponsorships, 142\\nSpot, 394\\nSpotify, 10, 183, 267\\nStability AI, 7, 55–56, 110, 124, 134, 289\\nStable Diffusion, 55–57, 134, 185, 205, 288\\nStableLM, 134, 135\\nstandards, setting, 320'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Index 419\\nStanford University, 103, 111–112\\nStatista, 267\\nsteganography, 390\\nstorage, of data, 269–270\\nstorytelling, interactive, 192\\nStrassen algorithm, 158\\nStructured Query Language (SQL), 254–255\\nstyle transfer, 15–16\\nStyleGAN, 51\\nsubversive communication, through  \\nsteganography, 390\\nSuleyman, Mustafa, 356\\nSuperAGI, 357, 360–361\\nSuperCoder, 360–361\\nSuperGLUE, 102\\nsupervised machine learning, 5\\nsustainable energy, AGI and, 388\\nSutskever, Ilya, 73, 376\\nSutterstock, 183\\nSwag, 103\\nSWIFT , 295\\nSynsets, 59\\nSynthesia, 190–191\\nSynthesis AI, 207\\nsynthetic data, 268–269, 295\\nsynthetic data augmentation, 202–209\\n“Synthetic Demographic Data Generation for \\nCard Fraud Detection Using GANs” \\npaper, 215\\nsystem-on-a-chip (SoC), 231, 233–234\\nT\\nT5, 78\\nT abnine, 171\\ntactile actuators, 347\\ntalent, in tech, 275–277\\nT allinn, Jaan, 328\\ntask parallelism, 250\\nT azti, 150\\ntech improvements, for data storage, 269–270\\ntechnological convergence, 226–228\\ntelecommunications sector\\nlearning models in, 116\\nvoice generation and, 152\\nT ensor Processing Units (TPUs), 129, \\n220, 236, 238\\nT ensorFlow, 256\\nT esla, 138, 239–240, 376, 395–397\\nT esla Dojo, 239\\ntext generation\\nabout, 63–64, 172\\nAI agents, 174–177\\napplications of specific language mod-\\nels, 114–118\\nattention mechanism, 77–78\\nautonomous agents, 177–180\\nautoregression models, 64–65\\nChatGPT , 93–95, 97–99\\nCicero, 172–173\\nemergent capabilities of GPT-4, 107–110\\nevaluation of large language models, 101–104\\nfine-tuning LLMs, 84–86\\nfuture of, 173–174\\nGANs for, 75–76\\nGPT-4, 104–107\\nLLM scaling laws, 95–97\\nlong short-term memory networks \\n(LSTM), 70–71\\nMarkov chains, 65–67\\nmultimodality in AI, 105–107\\nN-gram models, 72\\nother large models, 110–114\\noutput probability, 80–82\\npretraining LLMs, 82–84\\nprompt engineering, 86–92\\nrecurrent neural networks (RNNs), 68–70\\nreinforcement learning from human \\nfeedback, 99–101\\nrule-based, 67–68\\nSeq2Seq model, 2–75\\ntech triumphs in, 78–118\\ntokenization for LLMs, 79–80\\nT extGAN, 76\\nT ext-to-T ext T ransfer T ransformer (T5), 94\\nthermal actuators, 348\\nthermoelectric coolers, 348\\nThiel, Peter, 137\\nthird-party audits, self-regulation and, 328\\n3D object generation\\nabout, 194–195\\nfuture of, 200–202\\nleading companies and approaches \\nin, 197–200\\nresearch in, 195–197\\n3D printers, 155\\n3D U-Net, 185–186\\n3DFX, 18\\n3D-Stacked CMOS, 234\\ntokenization, for LLMs, 79–80\\nT onic.ai, 171\\ntopic classification, 8\\nT oyota, 397\\ntrademark licensing, 143\\ntraining\\nabout, 2–5\\nimportance of training data, 58–60\\nself-regulation and, 327\\nT rainium, 145\\nT ransformer-XL, 77–78\\ntransparency\\nimportance of, 294\\npromoting, 320–321\\nself-regulation and, 327\\ntravel agencies, learning models in, 115\\ntrends\\nin data, 270–271\\nin generative AI, 352–355\\nT ruthfulQA dataset, 103'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='420 Index\\nT uring, Alan (scientist)\\nabout, 28–29\\n“Computing Machinery and Intelligence,” 28\\nT uring test, 28, 171\\nT utorAI, 151\\nT ype I/II/III Civilization, 398–399\\nT ype IV/V Civilization, 399\\nT ype VI/VII Civilization, 400\\nT ypeScript, 167\\nU\\nUkraine, 282\\nultrasonic humidifiers, 348\\nUnited States Medical Licensing Examination \\n(USMLE), 109\\nuniversal basic income (UBI), 385\\nUniversal Speech Model (USM), 330\\nUniversity of Buffalo, 298\\nUniversity of Michigan, 317\\nunsupervised learning, 5–6\\nurban planning, data augmentation and,  \\n209\\nU.S. Career Institute, 304\\nuser consent, self-regulation and, 327\\nuser-friendly design, Mojo and, 256\\nV\\nVAE-LIME, 354\\nvariational autoencoders (VAEs),  \\n42–44\\nVaswani, Ashish, 77\\nVersion 5, 57\\nVideo Authenticator (Microsoft), 298\\nvideo generation\\nabout, 185\\nAWS, 188–190\\nAzure, 188–190\\nfor-profit solutions, 187–188\\nfuture of, 191–193\\nGCP , 188–190\\nSynthesia, 190–191\\ntech behind, 185–187\\nviewer preferences, 191–192\\nVinyals, Oriol, 73\\nvirtual reality (VR), 340, 346, 381\\nvision language models (VLMs), 343\\nVision-T ransformer-based VQGAN  \\n(ViT-VQGAN), 61\\nVisual Studio, 168\\nVisual Studio Code, 168, 263\\nVoice Finger, 150\\nvoice generation, 148–152\\nvoxels, 196\\nW\\nWasserstein GAN (WGAN), 50\\nwater sprays, 348\\nwatermarking techniques, 297–298\\nWavemaker, 148\\n“We Have No Moat, and Neither Does OpenAI” \\ndocument, 140\\nWebdevGPT , 179\\nweights, 4–5\\nWeizenbaum, Joseph (professor), 27\\nWelling, Max, 42\\nWikipedia, 83\\nWiley, 215\\nWilliams, Pharrell, 184\\nWist Labs, 339\\nWolfram, 176\\nwomen, in generative AI history, 44–45\\nword error rate (WER) performance,  \\n107\\nWordNet, 59\\nWorld Bank, 282\\nWorld Economic Forum, 276\\nWormGPT , 301\\nWozniak, Steve, 328\\nX\\nX.AI, 138–139, 377\\nxAI’s Grok, 132\\nXi Jinping, 58\\nX/T witter, 132, 180\\nY\\nY Combinator, 138\\nYang, Andrew, 328\\nYC Research, 137\\nY ouT ube, 276, 366\\nZ\\nZapier, 176\\nzero-shot, 61\\nzero-shot learning, 227\\nZero-Shot Prompting, 87\\nZeus framework, 317\\nZoom, 267\\nZuckerberg, Mark, 340'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='WILEY END USER LICENSE \\nAGREEMENT\\nGo to www.wiley.com/go/eula to access Wiley’s \\nebook EULA.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='www.presidencyuniversity.in #proudpresidencian\\nSTUDENT\\nHANDBOOK\\nNAVIGATING YOUR JOURNEY:\\nACADEMICS, LIFE & BEYOND\\n2025-26'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='2  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nThis ‘Student Handbook’ for Presidency University for the \\nAcademic Year 2025 –2026 is a collection of information that \\nyou will find valuable to learn about campus life, amenities \\nbeyond academics, and services to make your stay enjoyable \\nand useful.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='3  \\n \\n \\n                                 INDEX \\n \\nSl. \\nNo. \\nDescription Page No \\n Introduction 4       \\n Vision, Mission and Core Values 4 \\n Recognitions 5 \\n1. The Campus 6 \\n2. Graduate Attributes 21 \\n3. Holistic Education 22 \\n4. Department of Student Affairs 22 \\n5. Student Chapters & Societies 24 \\n6. Alumni Association of Presidency University (AAPU) 25 \\n7. Institutional Social Responsibility 26 \\n8. University Scholarship Policy 26 \\n9. Examination Grievance Redressal Cell 27 \\n10. Student Grievance Redressal Cell 28 \\n11. Anti-Discrimination Cell 28 \\n12. Anti-Ragging 29 \\n13. Policy for Prevention of Sexual Harassment 31 \\n14. Academic Regulations 32 \\n15. Code of Conduct for Students 32 \\n16. Disciplinary Committee 40 \\n17. Rules, Policies and Regulations 43 \\n18. Other Provisions 58 \\n19. Annexures  \\n Annexure-1: Anti Ragging Committee   \\n Annexure-2: Constitution of the University Committee \\nfor Prevention of Sexual Harassment - Responsibilities \\nand Procedures \\n \\n Annexure-3: Student Grievance Redressal Committee  \\n Annexure-4: Joint Affidavit by Student and Parent/Legal \\nGuardian \\n \\n63\\n64\\n66\\n71'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"4  \\nVISION, MISSION AND CORE VALUES \\n \\n \\nIntroduction \\n \\nPresidency University, Bangalore, is a NAAC 'A' accredited institution, renowned for its \\ncommitment to quality education and holistic student development. Established in 2013 \\nby the Presidency Group of Institutions, it is an emerging leading educational institution \\nin India. With a focus on innovation, research, and experiential learning, the University \\nattracts students seeking both academic excellence and personal growth. \\nOffering a wide range of program mes in computer science, engineering, management, \\nlaw, design, media, science, and commerce, the University blends theoretical knowledge \\nwith practical application. The experienced faculty ensures a dynamic and supportive \\nlearning environment. The University prepares students for global careers, emphasizing \\ndiscipline, integrity, and adherence to its values and regulations. Every student is \\nencouraged to  uphold these standards and contribute to the University ’s esteemed \\nlegacy. Presidency University has earned numerous recognitions, including the QS -I \\nGauge Gold, ranking 6th in the Times Engineering Institute Survey, and Best University  \\nof the Year (South) by ASSOCHAM. \\n \\n \\nVISION \\nTo be a value-driven global University, excelling beyond peers, creating professionals of \\nintegrity and character, and having concern and care for society. \\n \\nMISSION \\n \\n• Commit to be an innovative and inclusive institution by seeking excellence in teaching, \\nresearch, and knowledge. \\n• Pursue research and development and its dissemination to the community at large. \\n• Create, sustain, and apply learning in an interdisciplinary environment with \\nconsideration for ethical, ecological, and economic aspects of nation-building. \\n• Provide knowledge-based technological support and services to the industry in its \\ngrowth and development. \\n• To impart globally applicable skill sets to students through flexible course offerings, \\nsupport industry’s requirements, and inculcate a spirit of new venture.\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='5  \\nRECOGNITIONS \\n \\nCORE VALUES \\n \\n• Intellectual Curiosity and Innovation: Fostering a culture of inquiry and creativity \\nto inspire ground-breaking ideas. \\n• Interdisciplinary Approach: Encouraging collaboration across diverse fields for \\nholistic problem-solving. \\n• Global Engagement: Preparing students to excel in a connected and multicultural world. \\n• Community Engagement: Building meaningful connections through service\\n and collaboration. \\n• Environmental and Social Responsibility: Promoting sustainable practices and \\nethical leadership for a better future. \\n \\n \\nPresidency University was established under the Presidency University Act of 2013 \\nas a state private University located in Bengaluru, Karnataka, duly legislated by the \\nKarnataka State Legislative Assembly through Karnataka Act No. 41 of 2013. \\n \\n \\n \\nRecognised by UGC u/s 2(f) of the UGC Act, 1956 \\n \\n \\n \\n \\nProgrammes approved by All India Council for Technical Education \\n \\n \\n \\n \\n \\nLaw Programmes Approved by Bar Council of India \\n \\n \\n \\n \\nMember of Association of Indian Universities'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"6  \\n \\n \\nA. INFRASTRUCTURE \\n \\nPresidency University, located in the serene Itgalpura village of North Bangalore, is \\napproximately 25 kilometres from Bengaluru International Airport and 35 kilometres \\nfrom the city limits. Set within a lush, expansive campus of nearly 100 acres, the \\nUniversity is surrounded by verdant landscapes that create an ideal learning \\nenvironment. The campus is equipped with state- of-the-art design and technology, \\nproviding students with a modern and dynamic educational experience. \\nThe infrastructure has been strategically developed to  meet the growing needs of the \\nstudent population. Advanced ICT and technological resources ensure efficient delivery \\nof education. The University is equipped with a state-of-the-art auditorium with a \\nseating capacity of 650, along with a spacious amphitheatre, both serving as venues for a \\ndiverse range of co -curricular activities as well as academic events. Additionally, four \\nseminar halls and conference rooms cater to both departmental and University -wide \\nevents. \\nThe campus also boasts of a variety of indoor and outdoor sports and recreational \\nfacilities that support the holistic development of students. Special attention is given to \\ninclusivity, with accessible infrastructure such as wheelchair ramps, lifts, and tactile tiles \\ndesigned for visually impaired students. \\n \\nB. LIBRARY AND KNOWLEDGE RESOURCE CENTRE (LKRC) \\n \\nThe Library of Presidency University  currently is spread across three locations  inside \\nthe campus. The main Library is at the Management Block, which houses books for \\nengineering, information science, and design. Adjacent to the main Library is the \\nLibrary annexe, which offers resources for management, computer science, \\nengineering, and media studies. The law Library is situated on the 5th floor of the 'S' \\nBlock. \\nThe main Library has a collection of over 60,700 books and subscribes to 155 national \\nand international journals and 38 magazines. The Library subscribes to 15 online \\ndatabases covering engineering, law, management, design, and humanities. The \\ncompletely automated Library uses KOHA LMS (Library Management Software), and the \\nWEB OPAC (Online Public Access Catalogue) is accessible from anywhere. The Library \\nemploys an RFID security system to safeguard its resources, complemented by a self-  \\ncheckout kiosk and a Dropbox to streamline book circulation. PUL actively supports \\nacademic publishing by maintaining high standards of quality and relevance, with a \\nparticular emphasis on institutional repositories and open access initiatives. \\n1.  THE CAMPUS\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='7  \\n \\nFeatures of the PU Library \\n• The institutional repository at PUL utilizes DSpace, an open-source software platform. \\nThe Library archives e- books, faculty research articles, photographs, question papers, \\ntheses and dissertations, University documents, and the like, and anyone can easily \\naccess the resources through the link provided on the Library website. \\n• You can access the audiovisual material using computers and television. You can also \\nwatch live or recorded online video lectures, such as NPTEL lectures and Swayam \\nlectures, using the television provided. \\n• The Library offers plagiarism check software like Turnitin and Drillbit. \\n• Knimbus Remote Access Platform. \\n• Free reprography services \\n• Library OPAC on-campus and off-campus \\n• 155 print journals, 38 general magazines, and 17 newspapers \\n• Mobile App - \"Libraries in Hand.\". \\n• 25 computer machines with internet access \\n• The Library subscribes to ProwessIQ, CapitaLine, and IndiaStat databases to access \\neconomic and statistical data. \\n \\nC. LABORATORIES \\n \\nLaboratories are equipped with the latest equipment and tools that cater to the needs of \\nthe students. Experienced staff members with industrial backgrounds provide training \\nto students in laboratories to enhance their practical skills.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='8'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='9  \\nThe University has discipline-centric laboratories as follows: \\n \\nCivil Engineering Mechanical Engineering \\n• Surveying Lab \\n• Concrete & Highway Materials Testing Lab \\n• Fluid Mechanics Lab \\n• Soil Mechanics Lab \\n• Engineering Geology Lab \\n• Computer Aided Building Drawing Lab/ \\nBuilding Information Modelling Lab \\n \\n \\n• Fluid Mechanics Lab \\n• Metrology Lab \\n• Mechanical Design Lab \\n• Mechatronics Lab \\n• Energy Conversion Engineering Lab \\n• Heat & Mass Transfer Lab \\n• CAMD Lab \\n• Foundry, Forging & Welding Lab \\n \\nElectrical & Electronics Engineering Petroleum Engineering \\n \\n• Electrical Machines Lab  \\n \\n• Power Electronics Lab \\n \\n• Control Systems Lab  \\n \\n• Power System Simulation Lab \\n \\n• Electrical CAD Lab \\n \\n• Power System Stimulation Lab \\n \\n• Petroleum Geology Lab \\n• Drilling Fluid and Cement Lab \\n• Reservoir Engineering Lab \\n• Process Control Lab \\n• Petroleum Testing Lab \\n• Reservoir Simulation and Modelling Lab \\n• Oil and Gas Processing Plant Design Lab \\n \\nElectronics & Communication Engineering Computer Science & Engineering \\n• Center for Research in Power Electronics \\n• Analog Electronics Lab \\n• Digital Electronics Lab \\n• Centre for Excellence [Tech Mahindra] \\n• Centre for Excellence [Capgemini] \\n• Big Data Lab'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='10  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n• Linear Integrated Circuits Lab \\n• Analog Communication Lab \\n• Microprocessor Lab \\n• Micro – Controller Application Lab \\n• Embedded Systems Lab \\n• Computer Aided & Design Lab \\n• Internet of Things Lab \\n• Network Programing Lab \\n• Internet Technologies Lab \\n• System Programing Lab \\n• DevOps Lab \\n• Computer Programing Lab \\n• Digital Design Lab \\n• Cyber Security Lab \\nLaw Media \\nMoot Court Hall • Media Studio \\n• Podcasting Lab \\n• Digital Media Lab \\nDesign  \\n• Material Studio \\n• Garment Construction Lab \\n• Textile Lab \\n• Product Design Lab \\n• Space Design Lab \\n• Drafting Studio \\n• Model Making Studio \\n• Game Design Studio \\n• Communication Lab \\n• Multimedia Studio'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='11  \\n \\nD. MEDIA LAB \\n \\nThe Media lab offers cutting -edge facilities, including television and radio studios, \\npodcast recording suites, and specialized labs for content creation, production, and \\nbroadcasting. Students gain hands -on experience through various activities such as \\nground reporting, camera operation, and anchoring. \\nThe Media Studio provides a dynamic space for recording discussions and shows, with \\ntraining in videograph y, filmmaking, scriptwriting, and TV production. The Podcasting \\nLab focuses on audio storytelling, offering advanced tools for recording, editing, and \\nproducing diverse podcast formats. The Digital Media Lab equips students with skills in \\ncontent creation, social media strategies, and audience engagement. \\n \\nE. LANGUAGE LAB \\n \\nThe Language Lab serves as a platform for first-year and sophomore students to develop \\ntheir listening, reading, speaking, and writing skills (LSRW), thereby enhancing their \\npractical language proficiency. The language lab offers lessons for slow, average, and \\nadvanced learners covering topics such as language teaching, linguistics, and phonetics, \\nwhich are challenging to convey without audio -visual aids. Students benefit from \\ncomputer-enabled learning, which enhances their comprehension and overall learning \\nexperience. The main objective is to ensure that students acquire a neutral accent in \\nEnglish, thereby aiding their global career prospects. \\nF. COMPUTER LAB \\n \\nThe University  features state- of-the-art computer labs designed to deliver quality \\neducation. There are two dedicated blocks of enriched computing facilities, like well - \\nequipped laboratories with modern, high -end configuration computing environments, \\nhigh-speed internet connectivity, ventilated, spacious, and well -furnished laboratories, \\nand licensed software such as MS-Windows, Office 365, etc. \\nThere are 66 state- of-the-art computer laboratories, with a total of 3664 computers \\nenabling simultaneous access and practice for all students. Each of these computer labs \\nhas the capacity to accommodate 60 students. Also, there are dedicated laboratories for \\nIoT, big data, AR, VR, the microprocessor lab with digital trainer kits, and robotics with \\nhigh-end configuration systems like the i5 6th Gen, 16 GB of RAM, a 1 TB HDD, and TFT \\nmonitors.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='12  \\n \\nSl. \\nNo. Name of the Software Version \\n1 Math Works (Full Suite) for Students & Faculty Campus-Wide Lic \\n \\n2 \\nSolid Work Education Edition 2018-2019 with \\n200student every year \\n \\nSolidworks 2019 \\n \\n3 \\nCadence University Bundle Analog and Digital FE \\n& BE Latest \\n \\nLatest \\n4 Mi Power Full Package Full Package \\n5 UniSim Design Academic program R460 \\n6 CMG Access to GEM, IMEX, or STARS Simulator CMG-2017 \\n7 Win Pro Pahase Behaviour winprop \\n8 CMOST cmost-ai \\n9 Builder pre- Processor system, Graphics & \\nInterface \\nNetwork lic \\n10 Result Post- Processor system, Graphics & \\nInterface \\nNetwork lic \\n11 Dynagrid Network lic \\n12 Team Centre Teamcenter \\n13 Team Centre Rapid Start Teamcenter \\n14 Team Centre Author Teamcenter \\n15 NX Academic - Core & CAD Teamcenter \\n16 Adobe Creative Cloud  \\n17 Adobe Creative Cloud All Apps for HED - Shared \\nDevice \\n \\n \\n \\n18 \\n \\n \\nSophos Central Protection - End Point Protection \\nIntercept -x Advance - \\n4250 Intercept -x \\nAdvance for Server - 20 \\n19 Microsoft 365 A3 Licence Office 365 \\n20 COSEC Centra PLT100/TAM100 Cosec \\n21 Superset - Tnpsuite [Enterprise] Superset \\n22 Knimbus - OCA Knimbus \\n23 Bees Software Solution BeeS \\n24 Tally Prime Gold Subscription Tally'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='13  \\n \\n25 \\nStudent Information/Learning Mgmt/Asset \\nQuality System \\n \\nERP \\n26 SAAS License of Talentnow Talent Acquisition \\n   \\n27 Xversion Recurring Pre-paid software Version X \\n              28 Ansys Academic Teaching Mechanical and CFD  \\n              29 Acrobat Pro for team all apps  \\n             30 Saral TDS - Institutional v23  \\n             31 Acrobat Pro Adobe Editor \\n \\n \\n \\nG. OFFICE OF INTERNATIONAL AFFAIRS (OIA) \\n \\nOffice of International Affairs (OIA) is dedicated to fostering global partnerships and \\nadvancing internationalization initiatives, with the core objective of providing \\n“International Exposure to Every Student at Presidency.” OIA actively engages with \\ndiverse international and cultural environments to establish strategic alliances with \\npremier universities worldwide. It facilitates international opportunities such as \\ninternships, articulation pathways, dual/double degrees, exchange and twinning \\nprograms, joint degrees, master’s progression, offshore teaching arrangements, and \\nhosting international faculty. Additionally, OIA supports inbound and outbound student \\nand faculty exchange programs, fosters global experiences, and develops strategies and \\npolicies for international collaboration. By promoting international research \\npartnerships and nurturing existing collaborations, OIA offers invaluable support to \\nstudents and faculty from various schools and departments. \\nWhether you are a prospective student, collaborative partner, or international visitor, \\nthe OIA is your gateway to exploring global academic opportunities. For more \\ninformation or assistance, visit the Office of International Affairs at the campus or \\nexplore their page at https://presidencyUniversity.in/life -at-presidency/international-\\n \\nengagement/about-us.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='14  \\n \\n \\n                                                   Top International Universities'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"15  \\n \\nH. RESEARCH AND DEVELOPMENT \\n \\nPresidency University Research and Development Cell promotes research among staff \\nand students by offering doctoral programs (Ph.D.) across various disciplines aimed at \\nadvancing knowledge and pushing disciplinary boundaries. The R&D cell offers a \\ncomprehensive foundation in each discipline while allowing doctoral students the \\nflexibility to innovate and generate new knowledge aligned with their research interests. \\nThe R&D Cell actively encourages faculty members to undertake research and \\nconsultancy projects funded by both gov ernmental and non- governmental agencies, \\nincluding ICSSR, DBT, DST, UGC, and others. Currently, a total of 624 Ph.D. scholars, both \\npart-time and full -time, are pursuing their research across various schools and \\ndepartments, contributing to the University's vibrant academic ecosystem. \\nI. SPONSORED RESEARCH \\n \\nThe Office of the Sponsored Research was established at Presidency University with the \\nobjective to inspire faculty members to carry out extensive research through a mix of \\nincentives. The incentives are meant to motivate faculty members to publish quality \\npapers, file for patents, generate strong R&D proposals, undertake consultancy projects, \\nexecute in-house seed grant initiatives, establish state-of-the-art research facilities, and \\nencourage faculty/student innovations leading to possible start-ups being incorporated. \\nCurrently, there are 29 ongoing and completed projects that have received government \\nfunding of Rs. 1,44,32,002 and 8 consultancy projects that have received funding of Rs. \\n12,45,711. \\n \\nJ. ADVANCED RESEARCH CENTRES/CENTRES OF EXCELLENCE \\n \\nPresidency University  has established specialized research -propelled centers of \\nexcellence with the goal of promoting advanced research in different specialized areas. \\nEach of these centers  of excellence has coordinators and is equipped with state -of-the- \\nart research equipment and other support infrastructure facilities to facilitate advanced \\nresearch by research scholars and faculty members.\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='16  \\n \\n \\nResearch Centre(s) Thrust Areas of Research \\nCentre for Research in Materials Nanomaterials, Nanostructured Coatings, \\nMagnetism, Corrosion, Sensors, Surface \\nCoatings \\nAdvanced Technology Research Centre \\nwith M/s Spatics, Bangalore \\nModelling, Mathematical/Numerical \\nSimulations, Refrigeration and Air \\nConditioning, Nano-composites, \\nComputational \\nFluid Dynamics \\nCentre for Research in Power \\nElectronics \\nPower electronics, grid tide inverters, \\nElectric \\nvehicles, Wireless power transfer for EV, \\nPower converters \\nSustainable Development Goals \\nCentre \\nWater, Gender, Climate change, Decent work \\nand zero hunger \\nSophisticated Instrumentation Centre Material science, Energy and \\noptoelectronics, \\nSynthetic chemistry, Green Chemistry \\nCentre of Excellence in Biofuel Biofuels, Smoke meter, Gas Analyser, \\nEmission \\ntesting, Gas analysis, Smoke Analyser \\nCentre for Research in Robotic \\nand Automation \\nArtificial limbs, Automated guided Vehicles, \\nProsthetic, UAV, Quadcopters, Land based \\nVehicles, Advanced Microcontrollers and \\nMicroprocessors \\nCentre for Innovation \\nIncubation \\nand Entrepreneurship \\nStart-up, Innovative Project \\nCentre for Heat Transfer in Nano \\nFluids \\nMathematical Modelling, Cooling, Nano Fluids, \\nElectronic Systems \\nCentre for Water Research Water Research, Detection of Metal \\nContaminants \\nCentre for Excellence in Additive \\nManufacturing with EoS \\nGermany \\nAdditive Manufacturing, Innovative Designs, \\nPrototyping \\nIP Cell in association with KSCST \\nBangalore \\nPatent, IPR-related Issues'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"17  \\n \\nK. PRESIDENCY LAUNCH PAD ASSOCIATION (PLA) \\n \\nPresidency Launchpad Association (Technology Business Incubator) is a non- profit \\norganization registered as a Section 8 company to handhold aspiring entrepreneurs \\n(students and teaching/non-teaching staff) and provide facilities and assistance to them \\nto start, incubate, and successfully run businesses that involve innovation and socially \\nimportant and environmentally relevant technologies. \\nPresidency University envisions PLA as one of the leading incubators in the country. It \\noffers state -of-the-art infrastructu re and laboratories with advanced equipment to \\nincubate start- ups. The PLA ecosystem aims to facilitate the growth of start- ups by \\nproviding pre -incubation (ideation stage) and free physical and virtual incubation \\nsupport for the first 18 months. This initiative is open to all aspiring entrepreneurs with \\ninnovative ideas and aims to foster their development and success. \\n \\nL. PRESIDENCY UNIVERSITY LEARNING MANAGEMENT SYSTEM \\n \\nThe Learning Management System delivers an effective platform to facilitate the \\nteaching-learning process in the digital age. Customized from the world’s open- source \\nlearning platform, the LMS allows students and faculty to access this platform from \\nanywhere at any time through their specific login credentials. It supports the blended  \\nmode of education by seamlessly integrating offline and online classes and facilitating \\nthe organized execution of teaching and learning activities. \\nM. IT DEPARTMENT \\n \\nThe IT Department at Presidency University is a dedicated team of skilled professionals \\nresponsible for the management and smooth operation of the University's technological \\nsystems. The department plays a pivotal role in supporting both academic and \\nadministrative activities by  ensuring the seamless function of critical digital services \\nand maintaining the University’s IT infrastructure. \\n \\nKey Responsibilities and Services \\n \\n• IT Infrastructure Management: The IT department manages key aspects of the \\nUniversity’s technology infrastructure, including wireless internet access, computer \\nlabs, CCTV surveillance, IT services, and the upkeep of hardware and software. ensure \\nthat these systems are operational and available for students, faculty, and staff. \\n• Consultancy and Support: The team provides expert consultancy and troubleshooting \\nservices to help resolve any IT-related issues faced by faculty, staff, and students. \\nWhether it's a minor glitch or a more significant challenge, the\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"18  \\n \\ndepartment is always available for assistance. \\n• Cybersecurity: The department is tasked with protecting the University ’s systems, \\nnetworks, and data through various cybersecurity protocols. These measures are \\ndesigned to ensure the integrity and confidentiality of the University's digital assets. \\n \\n• Surveillance Systems : The IT team is also responsible for maintaining the \\ncampus's surveillance systems, enhancing security for both students and staff by \\nmonitoring and protecting the campus environment. \\n• Email and Communication Platforms : The department supports email systems \\nand communication tools such as Microsoft Teams, ensuring that staff and students \\nhave the tools they need to collaborate efficiently and stay connected. \\n• ICT Classroom Support : The IT department provides essential technical support \\nfor classrooms equipped with ICT tools. This includes troubleshooting, \\nmaintenance, and ensuring the systems in the classrooms are functioning properly \\nfor academic activities. \\nPolicies and Compliance \\n \\n• Strict IT Policies: The University  has established comprehensive IT policies to \\ngovern the use  of its technological resources. These policies aim to ensure \\nresponsible and secure use of IT assets by all users, including students, faculty, and \\nstaff. \\n• Compliance and Accountability : All users of the University ’s IT resources must \\nadhere to these policies. The IT department emphasizes the importance of \\nunderstanding these policies, and non- compliance could result in disciplinary \\naction.\\n \\n• Policy Management: The IT department is responsible for creating, implementing, \\nand updating these policies. work closely with other departments across the \\nUniversity to ensure that the policies meet the needs of the institution and remain \\nup-to-date with current technological trends and security requirements.\\n \\n• In-house Data Centre: To ensure reliable network connectivity and manage digital \\nresources ef fectively across the campus, Presidency University  operates its own \\ndata center. This in- house infrastructure provides greater control over network \\nperformance and helps maintain uninterrupted access to the University 's IT \\nresources.\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"19  \\n \\nN. WI-FI CAMPUS \\n \\nPresidency University campus area network interconnects all campus buildings, \\nincluding seminar halls, conference rooms, recreational spaces, libraries, and cafeterias. \\nis enabled through the deployment of secured wireless access points with centralized \\nauthentication, allowing a secure network that can be accessed by students  and faculty \\nthrough their mobile devices or laptops. \\n \\nO. UNIVERSITY WEBSITE \\n \\nThe University 's official website features dedicated pages for all the schools and \\ndepartments, academics, research, life on campus, international engagement, \\nadmissions, student affairs, and the alumni association. The detailed pages of the school \\nand department include programmes, curriculum, faculty, research, infrastructure, and \\nevents. Additionally, the website serves as a source for academic circulars, exam \\nnotifications, admission details and updates, and other pertinent public information \\nbeneficial for students and parents alike. Visit Presidency University official website at:  \\nhttps://presidencyUniversity.in/\\n \\n \\nP. PRESIDENCY UNIVERSITY ON SOCIAL NETWORK \\n \\nThe following social networking platforms of Presidency University augment the mode \\nof communication instantaneously to a vast number of users. The activities, events and \\nprograms of each day are updated instantly on these platforms. \\nFacebook: https://www.facebook.com/PresidencyUniversityBangalore/  \\nInstagram: https://www.instagram.com/presidencyUniversity/?hl=en  \\nLinkedIn: https://in.linkedin.com/school/presidency-University-india/  \\nYouTube: https://www.youtube.com/channel/UC8pJ9nysyPA4O9S0QIR9qg \\n \\nQ. SPORTS FACILITIES \\n \\nPresidency University  is widely recognized for its accomplishments in sports and \\nathletics. The University  offers comprehensive infrastructure and support systems to \\ntrain students and enhance their athletic abilities. It organizes a range of sports events \\nto encourage student participation and foster excellence. A dedicated sports \\nmanagement team, led by a director and supported by a lead coach and specialized \\ncoaches, oversees these initiatives. The University  actively promotes a wide array of \\nsports, including basketball, football, volleyball, cricket, and throw  ball, among others. \\nAdditionally, it invests in high-quality equipment to ensure a modern and performance-\\noriented playing environment for its students.\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"20  \\n \\nR. HEALTH CARE CENTRE \\n \\nPresidency University has an in-house health clinic [infirmary] dedicated to the physical \\nand mental well -being of the students, faculty, and other staff members. The clinic \\nremains open throughout the week. The University also has tie-ups with the top \\nhospitals in Bengaluru to ensure proper medical care and attention for all members of \\nthe University community. \\nThe clinic  is headed by a qualified medical professional and supported by a team of \\ntrained paramedical professionals. There are dedicated satellite sick bays at different \\nblocks of the University, staffed by trained nurses. \\n \\nS. STATIONERY AND REPROGRAPHIC CENTRE \\n \\nThe recreation centers adjacent to ‘F’ Block of the campus cater to the specific needs of \\nthe students and staff, providing photocopying and printing facilities at a nominal cost. \\nIt is equipped with a wide range of stationery items and efficiently manages operations \\nto ensure timely fulfilment of the requirements of students and employees. \\n \\nT. RECREATIONAL SPACES \\n \\nLandscape: The University is a ‘green campus,’ featuring a wide variety of trees, lush \\ngardens, fountains, and thoughtfully designed thematic spaces that create a tranqu il \\nenvironment for students to relax and unwind. \\n \\nStudent Hangout Zones: The University's amphitheater serves as a perfect venue for \\nopen-house events, such as promotional activities, recitations, and performances. \\nAdditionally, the lawns, furnished with seating arrangements, provide students with a \\ncomfortable space to study and socialize with peers. \\n \\nU. CAFETERIA AND FOOD COURT \\n \\nThe University  cafeteria is spacious and offers a selection of hygienic food options at \\naffordable prices. It is a popular venue for refreshments, discussions, and social \\ninteractions. The cafeteria caters to the diverse tastes of the student community with \\nofferings that include South Indian, North Indian, and Chinese, American and \\ncontinental cuisine. Food kiosks, located at various places throughout the campus, offer \\nSouth Indian and North Indian cuisines, savories, beverages, and a variety of delicacies.\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"21  \\n2. GRADUATE ATTRIBUTES \\n \\nV. PARKING \\n \\nThe University  has dedicated parking for two - and four -wheelers for employees with \\npasses and security restrictions. Only vehicles displaying authorized stickers will be \\npermitted to park inside the campus premises or in designated parking lots. \\nAdditionally, there is a separate parking area exclusively for students and visitors \\noutside the campus premises. \\n \\nW. UNIVERSITY TRANSPORT \\n \\nThe University operates a dedicated fleet of buses that provide transportation to various \\nparts of the city, facilitatin g the commute of students and employees to the University  \\ncampus. To utilize this service, students must register with the Transportation \\nDepartment and pay a nominal fee. Access to the bus is granted to only those with a valid \\npass. \\n \\nX. UNIVERSITY HOSTELS \\n \\nThe University provides separate hostels for boys and girls. The hostels aim to integrate \\nacademic initiatives into the intellectual, physical, and psychological well -being and \\ndevelopment of the students. The University's code of conduct, discipline, and decorum \\nare strictly enforced within the hostel accommodations. \\n \\nY. ATM FACILITY \\n \\nThe University houses a Federal Bank ATM machine, catering to the financial needs of \\nthe students and staff members. \\n \\nThe vibrant campus life at Presidency University fosters an environment that not only \\nsupports academic excellence but also cultivates essential graduate attributes. \\nGraduate attributes represent the qualities, skills, and conceptual knowledge the \\nUniversity student community aspires to develop, guided by the University  leadership \\nduring their association with the institution. The Programme Outcomes [PO], \\nProgramme Specific Outcomes [PSOs], and Course Outcomes [COs] are systematically \\nintegrated into the curr iculum to facilitate the achievement of these envisioned \\nattributes. Upon successful completion of the program, the graduates of the University \\nwill be able to\\n \\n• Clearly comprehend relevant domain-specific knowledge.\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='22  \\n3. HOLISTIC EDUCATION \\n4.  DEPARTMENT OF STUDENT AFFAIRS \\n \\n• Demonstrate strong leadership skills and the ability to effectively work in teams. \\n \\n• Apply the knowledge and/or skills acquired through the learning process to real-life \\nsituations. \\n \\n• Adapt to the changing world and serve as change agents for the advancement of \\nlifelong learning. \\n \\nPresidency University  offers academic programs meticulously designed to equip its \\nstudents with contemporary, industry -relevant knowledge, skills, and aptitude, aiding \\nthem in achieving their career objectives. The curriculum and pedagogy are intricately \\nintegrated with projec t-driven experiential learning coupled with assignments that \\nfoster innovative thinking. Students at the University  benefit from the expertise and \\nmentorship of distinguished academicians from renowned universities and institutions \\nwho have carved a niche for themselves in their respective domains. \\nThe curriculum is based on Choice-Based Credit System, allowing students to select from \\na wide range of core and elective courses. The multidisciplinary approach provides a \\nholistic educational experience, broadening their perspectives. \\n \\nDepartment of Student Affairs (DSA) plays a pivotal role in nurturing student talent and \\nfostering holistic development through an extensive network of more than 50 clubs, \\nchapters, and societies. These initiatives cover cultural, technical, social, and management \\ndomains, providing students with a diverse range of opportunities to explore their \\ninterests and enhance their skills. \\n \\nWeekly activities and events, such as cultural celebrations, leadership talks, expert talks  \\non trending technologies, hackathons and awareness programmes, encourage students  \\nto broaden their horizons and develop essential managerial and leadership skills. \\nStudents are also motivated to participate in intercollegiate and inter -University \\ncompetitions, enriching their practical knowledge and learning experience. Community- \\nfocused initiatives like the NSS and the Rotaract Club instil social responsibility and \\ncontribute to societal well-being. Additionally\\n, the DSA ensures student wellness through a \\ndedicated counselling team that provides professional support for personal and academic \\nchallenges. \\nStudents who wish to explore and join the club of their choice, visit the DSA page on the \\nofficial website https://presidencyUniversity.in/life-at-presidency/student-affairs'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='23  \\n \\nOr visit the DSA office for any queries. Also, to stay tuned to activities and happenings \\nof DSA, follow the official Instagram account of Presidency University at \\nhttps://www.instagram.com/presidencyUniversity/?hl=en \\n \\nNATIONAL SERVICE SCHEME (NSS) \\n \\nPresidency University  has always been a torchbearer of social service over the \\nprestigious decades of its existence. It not only shapes the best careers of our students \\nbut also shapes their character as responsible citizens of our country. NSS is a step \\nforward in fulfilling our notion. The National Service Scheme (NSS) is a central sector \\nscheme of the Government of India under the Ministry of Youth Affairs and Sports. The \\nNSS at the Presidency University has added to sustainable and ecological living, higher \\nstandards of learning with awareness drives, celebrating Yoga Day with students, \\nfaculties, and adopted slums alike, uplifting social standards, health camps and blood \\ndonation drives, orphanage home visits, and hundreds of programs and special camps \\nfor the overall welfare of both our students and society. \\n \\nNational Cadet Corps (NCC) \\n \\nThe National Cadet Corps (NCC) Army Wing was established at Presidency University in \\n2021, under the aegis of the 3 Kar Battalion, Bengaluru. The NCC cadet strength at \\nPresidency University comprises one company of 160 cadets, including both male and \\nfemale participants. The unit is overseen by an Associate NCC Officer (ANO) and a Girls \\nCadets Administrator. \\n \\nThe NCC enhances the awareness level of cadets to become responsible citizens of the \\ncountry and encourages cadets to enrich their knowledge, develop communication skills, \\nand develop character. The five cadets are involved in the conduct of social outreach \\nactivities, community development programs, and adventure activities to hone their \\nleadership qualities and risk-taking abilities. It provides a platform to launch “Goodwill \\nAmbassadors” to project the image of a country overseas. \\n \\nCOUNSELLING & WELLNESS UNIT \\nThe Student Counselling Services is an initiative at Presidency University, providing \\npsychological support for the students and faculty in the areas of personal, \\nemotional, social, and academic/career-oriented concerns. There is a growing \\nawareness of mental and emotional health today, thanks to various social and mass \\nmedia campaigns. \\nStudent counsellors and clinical psychologists provide professional advice and therapy \\nto the students and are available on campus. Students can write to the counsellors, \\nshare their concerns, and seek support to comprehend the challenges the student is'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"24  \\n5. STUDENT CHAPTERS & PROFESSIONAL SOCIETIES \\n \\nencountering.  \\nThey help to:  \\na. Identify the underlying causes of their current emotional state. \\nb. Formulate a strategic action plan to address the student's concerns in a supportive  \\nand sensitive manner; \\nc. Assist the student in building resilience and empowering them to achieve their academic \\nand personal objectives. \\n \\nCounselling Services  \\n• Individual Counselling \\n• Peer Support Program \\n• Workshops \\n• Working with teachers and parents \\n• Services provided by university student counsellors \\n \\nReach out to the student counsellors @ \\nnamratha.j@presidencyUniversity.in \\nshivani.mukund@presidencyUniversity.in \\nServices rendered by YourDost for Psychological Health \\nPresidency University  has partnered with a counselling service provider named  \\nYourDOST. It is a platform that has a panel of more than 1,000 experts in counselling. All \\nstudents, faculty, and staff can avail themselves of this service for free in relative \\nanonymity. Anyone interested can visit www.yourdost.com,  register using the official \\nUniversity email ID, and speak to the experts. \\n \\nAll seven schools, including the core engineering branches under the School of \\nEngineering, actively promote co -curricular engagement through student- driven clubs \\nand societies, with guidance from faculty mentors. \\n \\nForum of Civil Engineering (FORCE) was started by Department of Civil Engineering at  \\nPresidency University to expose students to the field of civil engineering in its entirety \\nand give them a feel of how the industry works. Forum has organized guest lectures, \\nworkshops and industrial visits since 2018 and has launched webinar series from \\nOctober 2020 to continue the journey of educating young minds despite the barriers and \\ntemporary halt posed due to the pandemic situation.\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"25  \\n6. ALUMNI ASSOCIATION OF PRESIDENCY UNIVERSITY (AAPU) \\n \\n• Society of Petroleum Engineers, US (SPE) has established the Student Chapter at \\nPresidency University. This initiative allows students to benefit from opportunities \\nprovided by SPE, including engaging in technology discussions at SPE events, \\nnetworking with industry professionals, and gaining deeper insights into the  \\n \\npetroleum industry. Active participation in SPE student chapter is an excellent way to \\nnetwork with peers and local industry professionals which will offer ways to develop \\nnew skills. \\n \\n• The AAPG Student Chapter at Presidency University, Bengaluru, aims to enhance \\nstudents' professional knowledge through distinguished lectures, workshops, and \\nevents. By collaborating with various organizations in the oil and gas industry, the \\nchapter organizes initiatives to bridge the gap between academia and industry. \\n \\n• The Institute of Electrical and Electronics Engineers (IEEE) is a global professional \\nassociation dedicated to advancing technology by fostering collaboration among \\nprofessionals, researchers, and students. IEEE supports professional development \\nthrough resources like online courses, certifications, and mentorship while bridging \\nthe gap between academia and industry through research alignment and innovation \\ninitiatives. Additionally, it promotes ethical and sustainable practices, advancing green \\ntechnologies and addressing societal challenges. At Presidency University there are \\nfour IEEE chapters namely:\\n \\n \\n• IEEE Circuit and Systems Society (CASS) \\n• IEEE Signal Processing Society (SP) \\n• IEEE Communication Society (ComSoc) \\n• IEEE Computational Intelligence Society (CIS) \\n• IEEE Senor council \\n• IEEE Nanotechnology council \\nThe Alumni Association of Presidency University, Bengaluru [AAPU] was  established in \\n2019 and officially registered with the Registrar of Societies on 5th December 2019.  \\nAAPU has a stronghold of over 18,000 members. The association's main objective is to \\ncreate a strong network between the alma mater and the alumni, encouraging them to \\ntake an active interest in the work and progress of AAPU by establishing regular \\nengagement between them and the students. The association aims to enrich both \\ncurrent students and alumni through constant interaction and knowledge sharing. \\nAAPU is looking at innovative ways to connect and grow. \\nAAPU launched its first alumni chapter in Bangalore, followed by one in the capital city, \\nDelhi, and its first international chapter in Dubai established by Dr. Sameena Noor \\nAhmed Panali, Registrar. Committed to fostering a global alumni network, AAPU \\ncontinues to expand chapters in cities worldwide.\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='26  \\n7.  INSTITUTIONAL SOCIAL RESPONSIBILITY \\n8.  UNIVERSITY  SCHOLARSHIP POLICY \\n \\n  \\nIn today’s fast- paced, tech -driven world, students are increasingly disconnected from \\nthe realities of their surroundings. Educational institutions play a key role in fostering \\nsocial responsibility and shaping empathetic professionals. \\n \\nAt Presidency University, the ISR (Individual Social Responsibility) Cell aims to create a \\npositive impact through initiatives aligned with the United Nations’ Sustainable \\nDevelopment Goals (SDGs). Students can engage in projects through its five thematic \\nareas, like Shiksha, Samarthya, Swasthya, Sewa, and Sanrakshan, that support quality \\neducation, skill development, healthcare access, and environmental conservation, \\nhelping them develop a sense of responsibility while contributing to the community. \\nStudents who wish to enroll for volunteering can write to \\nisrcell@presidencyUniversity.in \\n \\n \\nThe University  awards several scholarships to encourage meritorious students and \\nsupport deserving students. In addition to merit scholarships, the University  provides \\nscholarships to students who have excelled in sports, NCC, and cultural. \\nThe University  is committed to supporting deserving students whose parents are \\ndefense/police/ex-service (armed forces) personnel , differently-abled students, \\nstudents from economically weaker sections, students belonging to SC/ST/minority \\nsegments, students with single parents (mothers), and students who have lost both \\nparents. \\nThe University also provides concessions to students who  are alumni of the University  \\nand to children of staff members of the Presidency Group of Institutions. There are \\nspecial scholarships available to the foreign students from SAARC countries. The \\nscholarship for students of Jammu and Kashmir is awarded for all years of their \\nprogramme of study. \\n \\nA student can avail themselves of a scholarship only under one category. \\n \\n• Students to be eligible for a claim of any scholarship need to have submitted, for \\nverification, to the Office of the Registrar, the requisite original certificates. \\n \\n• Applications with incorrect/incomplete information, non- submission of supporting \\ndocuments, and submission of applications beyond the last date as notified by the \\nUniversity are liable to be rejected.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='27  \\n 9.  EXAMINATION GRIEVANCE REDRESSAL CELL \\n \\n• Receiving any scholarship shall not be a matter of right, for the awarding of \\nscholarships shall be at the sole discretion of the University. \\n \\n• The various categories and details of scholarships offered by the University shall be \\nnotified by the University at the time of admission to a new academic. \\n \\n• The conditions and rules for the award of scholarship/concession in the University  \\ntuition fees shall be clearly prescribed in the University scholarship policy notified \\nfrom time to time. \\n \\n• Scholarships are restricted to rebates in the University  Tuition Fee only and are \\napplicable for the first year of the relevant programme of study. \\n \\n• Students who are awarded a scholarship for the first year of their program of study \\nshall pay the full University  fee and other charges/deposits, as applicable, prescribed \\nin the fee document of the University  from the second year of the program till \\ncompletion of the program of study.\\n \\n \\n• If a student withdraws or discontinues from the programme, they are required to remit \\nback the scholarship amount. \\n \\n• All students who are awarded any type of University  scholarship shall be required to \\ngive a written undertaking to abide by the rules and conditions relating to the award of \\nsuch scholarship. \\n•  \\nStudents who have participated in international, national, or state-level sports \\ncompetitions are eligible to avail of sports scholarships.  \\n \\nThe Examination Grievance Redressal Cell provides a mechanism for the redressal of \\ngrievances related to examinations, ensures transparency in examination practices, and \\nprevents unfair practices at the University. This cell is linking the students with the \\nfaculty in the continuous evaluation process. The University  examination office, along \\nwith the faculty team, ensures the smooth conduct of the University  examinations and \\ncontinuous assessment. If any grievance occurs, it will be immediately considered and \\nredressed. \\n \\nObjectives \\n• Monitor the examination process to ensure a stress-free examination atmosphere in \\nthe exam hall.  \\n• Resolve the student’s grievances related to examinations and continuous assessments. \\n \\n• To encourage the students to express their grievances/problems on the conduct of \\nexaminations without any fear. \\n \\n• Issue of mark sheets, transcripts, provisional degree certificates, and any other'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='28  \\n10.  STUDENT GRIEVANCE REDRESSAL CELL (SGRC) \\n11. ANTI DISCRIMINATION CELL \\n \\n             certificates as per the University examination regulations. \\n \\n• Emphasize prevention of errors rather than controlling through punitive measures. \\n \\n• The students or faculty members with a genuine grievance may approach the co- \\ncoordinator or member of the cell in person. In case the person is unable to appear in \\nperson, grievances may be dropped in writing or an email may also be sent to the co- \\ncoordinator of the Examination Grievance Redressal Cell. \\nSubmission of Grievances \\nStudents and teachers can submit the grievances by using any one of the \\nfollowing. \\nA. Filling the form available with the coordinator and members at the cell. \\nB. Sending the mail: examredressal@presidencyUniversity.in \\n \\nPresidency University is committed to providing a safe, fair and harmonious learning \\nand work environment. In view of this, the University  has a robust mechanism for \\nredressal of students’ grievances in a timely manner. The grievances that need \\nimmediate redressal are related to academic and non- academic matters, such as \\nassessment, victimization, attendance, charging of fees, conducting of examinations, \\nharassment by fellow students or teachers, etc. In this regard, a formal Student Grievance \\nRedressal Cell (SGRC) is constituted in accordance with the UGC Regulation to deal with \\nday-to-day grievances of its stakeholders, including the students. \\n \\nAny student who is aware of any violations must report the same to the SGR. Said \\ngrievance must be submitted in writing and should be made within (04) days from the \\nday of the alleged violation. The SGRC shall take note of the grievance and inform the \\nDisciplinary Committee to conduct the inquiry and impose appropriate retribution. \\nThere shall be an Internal Complaints Committee (ICC) in place in cases of any sexual \\nharassment complaints. \\n \\nThe Constitution of the School Level Grievance Redressal Committee, University Level \\nGrievance Redressal Committee, Procedure for Redressal of Grievance, Types of \\nGrievances, Appellate Authority/Ombudsman, Functions of Ombudsman, and \\nProcedure for Redressal of Grievance by Ombudsperson are placed in Annexure-3 \\n \\nDiscrimination against any person on the grounds of his/her disability or physical \\nlimitations and minority status is a gross violation of universally accepted principles of'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='29  \\n12. ANTI - RAGGING \\n \\nequality and human rights and even constitutional obligations. Presidency University  \\nhas set up an Equal Opportunity Cell to address the issues concerning Scheduled Castes, \\nScheduled Tribes, Other Backward Classes, and Persons with Disabilities. \\nThe basic aim of the Cell is to ensure that students and faculty belonging to various \\ndiverse backgrounds of community, religion, region, gender, or ability are not deprived \\nof their basic opportunities. Everyone must have access to basic rights to foster \\ninclusivity and harmony. This cell organizes various activities to promote inclusive \\npolicies and practices for all. It also addresses grievances to ensure equality and equal \\nopportunities for disadvantaged groups on campus through the effective \\nimplementation of policies, skill development programs, and societal initiatives. \\n \\n \\nA conducive and amicable environment is a hallmark of Presidency University . This \\nambience is ensured by various committees and bodies that make students aware of the \\nconsequences in the event of breaching the code of conduct. The Anti- Ragging \\nCommittee is instituted to ensure the safety and comfort of the students and to provide \\nan amicable environment on the campus and in the hostels. The University  is guided by \\nthe UGC Regulations on Curbing the Menace of Ragging in Higher Education Institutions. \\nIt is expected that every student reads the below -mentioned guidelines and abides by \\nthe regulations. \\n \\nRagging is a cognizable offence, and Presidency University will take strict action against \\noffenders. \\n \\nDefinition of Ragging \\n \\n• Any conduct by any student or students, whether by spoken or written word or by an \\nact, which has the effect of teasing or treating a fresher or any other student rudely. \\n \\n• Exploiting the students from completing academic tasks and financial extortion. \\n \\n• Any act of physical abuse, including all its variants —sexual abuse, homosexual \\nassaults, and stripping; forcing obscene and lewd acts; gestures; causing bodily harm; \\nor any other danger to the health of a person. \\n \\n• Any act that prevents, disrupts, or disturbs the regular academic activity.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='30  \\n \\nAnti - Ragging Measures \\n \\nAccording to the instructions of the Honourable Supreme Court of India and in \\naccordance with the UGC Regulations and Karnataka State Government Guidelines on \\nCurbing the Menace of Ragging in Higher Educational Institutions (2009), the University \\nhas constituted an Anti-Ragging Committee and Anti-Ragging Squads for overseeing the \\nstrict and meticulous implementation of all the directives. The members of the anti- \\nragging committee and anti-r agging squads, along with their mobile numbers, shall be \\ndisplayed for the benefit of the students, especially the newly admitted students. \\n \\n• The University educates the students enrolled for various programs, at the beginning \\nof each academic year, about the Anti- Ragging Policy and Zero - Tolerance for ragging \\nat the University. \\n \\n• It is mandatory for each student, as well as his/her parents/guardian to submit online \\nseparate undertakings in the form of an official declaration at the time of admission by \\nclicking on http://www.antiragging.in\\n to the effect that they are aware of the \\nprohibition of ragging & the punishment prescribed both by the penal laws and these \\nregulations. All students must submit their acknowledgment number to their class \\ncoordinator. \\n• Anti-ragging hoardings, banners, and billboards are displayed at prominent places in \\nthe University  campus, including hostels, canteens, messes, cafeterias, buses, \\nplaygrounds, lawns, labs, etc. \\n \\n• Surprise checks of hostels/canteens/cafeterias/bus stops are carried out regularly. A \\nclose and regular liaison is maintained with the local police to guard against any \\ninstance of ragging. \\n \\n• An FIR will be lodged in the police station on all reported ragging cases.  Daily briefing \\nfor the new students is carried out by counsellors and coordinators. \\n \\n• An anti- ragging committee of the students is also formed. In case any student \\nencounters ragging by any of the senior students, he/she is immediately required to \\ncontact the members of the anti- ragging committee, who will take immediate \\ncorrective action and necessary proceedings will be initiated against the culprits \\nengaged in ragging activities. The constitution of the University Anti-Ragging \\nCommittee is placed in Annexure 1. \\n \\n• Punishment for Ragging: \\n• Lodging an FIR against the offender.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='31  \\n13.  POLICY FOR PREVENTION OF SEXUAL HARASSMENT \\n \\n• Rigorous imprisonment for up to 3 years (under court of law). \\n• Fine up to Rs. 2, 50,000/- \\nExpulsion from Presidency University and subsequent debarring of admission to any \\nother institution. \\n \\nPresidency University is committed to creating and maintaining a community in which \\nstudents and employees can work together in an environment free of violence, \\nharassment, exploitation, intimidation, and stress. This includes all forms of gender \\nviolence, sexual harassment, and discrimination on the basis of sex/gender or amongst \\nthe same-sex members. \\nThe University Policy on Prevention of Sexual Harassment has been framed keeping the \\nfollowing objectives in view: \\n• To comply with the directives of the Honourable Supreme Court of India. \\n \\n• To establish an effective mechanism for the prevention and redressal of sexual \\nharassment cases and other acts of gender-based violence at the University. \\n \\n• To create and foster an environment at the University that is completely free of sexual \\nharassment in its various forms and to generate public opinion against all forms of \\ngender-based violence. \\n• For the purpose of this policy, \"Sexual Harassment\" shall include, but will not be confined \\nto, the following: \\n• Unwelcome sexual advances, requests for sexual favors, and/or verbal or physical \\nconduct of a sexual nature made, either explicitly or implicitly, in return for a term or \\ncondition of teaching/guidance, employment, participation, or evaluation of a person\\'s \\nengagement in any University activity.\\n \\n• When unwelcome sexual advances and/or verbal, non-verbal, or physical conduct— \\nsuch as loaded comments, remarks or jokes, letters, phone calls, or emails or any other \\ncommunication mediums; gestures; showing of pornography; lurid stares; physical \\ncontact or molestation; stalking; sounds; or display of a derogatory nature—have the \\npurpose or effect of interfering with an individual\\'s performance or of creating an \\nintimidating, hostile, or offensive environment.\\n \\n \\n• Forcible physical touch or molestation; eve teasing, innuendos, and taunts; physical \\nconfinement against one\\'s will; and any other act to impinge upon one\\'s privacy. \\n \\n• Any act or conduct of a person in authority and belonging to one sex that denies or \\nwould deny equal opportunity in pursuit of education or career development, or \\notherwise makes the environment at the University hostile or intimidating to a person \\nbelonging to the other/same. \\n \\n• This policy is applicable to all allegations of sexual harassment made by a student'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='32  \\n15. CODE OF CONDUCT FOR STUDENTS \\n14.  ACADEMIC REGULATIONS \\n \\nagainst a student, employee, or third party, irrespective of whether sexual harassment  \\n \\nis alleged to have taken place within or outside the University. \\n• The University has constituted a Committee for Prevention of Sexual Harassment to \\nmake note of complaints about sexual harassment, conduct inquiries, provide \\nassistance and redressal to the victims, recommend penalties, and take action against \\nthe harasser, if necessary. \\n \\n• The disciplinary action shall be proportionate to the nature of the violation and could \\nbe in the form of a warning, suspension, or even expulsion from the University. \\n \\n• The Constitution of the University Committee for Prevention of Sexual Harassment, its \\nresponsibilities and procedures are placed in Annexure – 2. \\n \\n \\nEvery student can access the academic regulations of the University  along with the \\nconcerned program regulations and curriculum on the web portal of the University. The \\nstudents and parents must read these documents so that they are well aware of the \\nregulations, policies, and rules of the University . The students are required to comply \\nwith all the Regulations, Policies and Rules issued by the University from time to time. A \\nperson seeking admission to any program of the University shall be deemed to have read, \\nunderstood, and accepted the academic regulations and the concerned program \\nregulations and curriculum. \\n \\nTo read more: https://presidencyUniversity.in/presidency/academic-regulations \\n \\nEvery student shall observe discipline and decorum and proudly contribute to the \\nacademic ambience and prestige of the University . Students must treat each other with \\ndignity and a spirit of friendship and brotherhood to create and nurture a harmonious \\nstudent community. Every student must respect the faculty members and every staff \\nmember of the University. For the well-being of the student community, any violation of \\nthe Discipline and Code of Conduct will be strictly dealt with, including expulsion from \\nthe University. \\n \\n15.1 Student Identity Card \\n \\nEvery student admitted to the University  is provided with a University  identity card. \\nEach student should display their identity card at all times on the University campus.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='33  \\n \\n• A student will not be allowed into the campus without the identity card. \\n \\n• A student must produce the identity card to use any University facility like the Library, \\npreliminary medical center, canteen, or laboratories. \\n \\n• A student must return the identity card to the University office at the time of \\ngraduation/withdrawal/expulsion or when asked for. In case of failure to do so, the \\nsecurity deposit, if any, will be forfeited, and certificates will not be issued. \\n \\n• Every student should preserve the identity card and not give it to any other student or \\noutsider for any purpose. Any misuse of the University identity card (belonging to self \\nor others) will lead to disciplinary action against the student, including expulsion \\nfrom the university.  \\n \\n• The University reserves the right to ask the students to surrender their identity card \\nwithout assigning any reason. \\n \\n• In case a student loses the identity card, she/he should apply for a fresh identity card \\nalong with a penalty fee prescribed by the University. \\n15.2   Student Dress Code \\n \\nPersonal grooming and dress code are very essential for self- esteem, a sense of \\nbelonging and camaraderie, pride in the University , and preparedness for \\ncorporate/professional careers. All students must follow the dress code applicable to \\nthem. Students are advised to be well -groomed and dressed gracefully, befitting the \\nimage of an ambassador of the University. \\nThe University Uniform and Dress Code as prescribed below must be followed by all \\nconcerned students from Monday to Friday, on all working days. However, on \\nworking Saturdays, the students may attend classes at the University in casual wear. \\n  General Dress-Code for Students (Monday to Friday) \\n \\n• Boys shall wear formal trousers and shirts (half sleeves or full sleeves—tucked in) and \\nformal shoes on all working days.  \\n \\n• Shirts with Chinese collars, torn jeans/trousers, cargo jeans with multiple pockets, t- \\nshirts, kurta–pyjama, shorts, and track suits, as well as clothing with objectionable \\nslogans, taglines, and images, are strictly prohibited. \\n \\n• Students should wear shoes unless medically floaters/sandals/chappals are strictly \\nprohibited. \\n \\n• Girls shall adopt a modest dressing style such as comfortable-fitting formal trousers \\nand shirts (half sleeves or full sleeves—tucked in), or a power suit/jacket with a \\nformal shirt, or a salwar-kameez or saree, and suitable formal, tight-fitting, revealing, \\nand sleeveless clothing; short kurtis, tops, crop tops/shirts, t-shirts, torn jeans, shorts,'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='34  \\n \\n            and skirts are strictly prohibited for girls. \\nSaturday \\n• Students may come to the University on Saturdays attired in smart casual. \\n \\n• Boys can wear shirts/collared t-shirts/golf t-shirts with jeans/trousers and \\nsports/canvas/casual. \\n \\n• Girls can wear comfortable tunic tops, Shirts, Collared T- shirts / Golf T-shirts with \\nJeans/ trousers and sports/canvas/casual. \\n \\n• NCC cadets will wear uniforms on notified days for that purpose. \\n \\n• Dress Code for Laboratories (Except Computer Laboratories) and Workshops \\n \\n• Students must come to the labs (other than computer labs) and workshops in the \\nprescribed lab/workshop uniform and shoes. \\nUniversity Uniform for respective Schools/Programs:  \\nMBA Program [School of Management]: \\nEvery newly admitted student of the MBA Program shall be provided with a set of the \\nUniversity Uniform consisting of one (01) University Blazer, one (01) tie, two (02) shirts, \\nand one (01) pair of trousers. All MBA students must come to the University wearing the \\nfull University uniform with formal shoes every Monday and Thursday. \\n \\nLLB/LLM Programmes [School of Law]: \\nEvery newly admitted student of a law program of the School of Law shall be provided \\nwith a set of the University  Uniform for law students consisting of one (01) University  \\nblazer, one (01) tie, two (02) shirts, and one (01) pair of trousers. All students of law \\nprograms must come to the University  wearing the full University uniform with formal \\nshoes on every Monday and Thursday. \\n \\nBBA Programmes (School of Commerce & Economics): \\nEvery newly admitted student of BBA Program shall be provided with a set of the \\nUniversity Uniform consisting of two (02) shirts, and two (02) trousers. All BBA Program \\nstudents must come to the University wearing the University Uniform with formal shoes \\nevery Monday and Thursday. \\nDress Code for Special Events/Programs in the University: \\n \\n• All students of MBA, Commerce, and Law Programmes are required to be attired in \\ntheir designated uniform, consisting of University blazers and formal shoes.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='35  \\n \\n• Students of the other schools must be in formal dress code and wear formal blazers \\nand formal shoes. Gentlemen-students must wear ties. Lady students may wear formal \\ndresses or sarees. \\n \\n• For games, sports, or similar activities, students must wear the University sportswear \\nand/or tracksuit/T-shirts, as prescribed. \\nViolation of the University Student Dress Code: \\n \\nAny violation of the University  Student Dress Code shall result in stringent disciplinary \\naction. A caution notice will be issued to a student violating the dress code. Subsequent \\nviolations will result in disciplinary action against the student, which may include a fine \\nof Rs. 1000/-, debarment from placement assistance, and/or representing the University \\nin any event/competition. \\n15.3 Restricted Use of Mobile Phones in the University: \\n \\n• Mobile phones may be carried by students on campus to stay connected with family \\nand friends; however, appropriate usage is equally important to ensure attention to \\nacademic sessions, safety of people, and privacy. \\n \\n• Use of mobile phones is strictly prohibited in the academic blocks, which include \\nclassrooms, laboratories, workshops, libraries, moot courts, and the corridors of the \\nacademic blocks and administrative block.\\n \\n \\n• Students are strictly prohibited from using mobile phones during meetings, seminars, \\nworkshops, guest lectures, and conferences. \\n \\n• Students may use their mobile phones in the permissible/designated areas in the \\nUniversity campus as stipulated by the University.\\n \\n \\n• Privacy is of the highest importance, and photographs of on-campus persons with a \\nmobile phone shall not be taken without the consent of the person [This restriction \\napplies to DSLR cameras as well].\\n \\n \\n• Any student using a mobile phone in restricted areas will be cautioned, and the mobile \\nphone will be A second violation will result in stringent disciplinary action against the \\nstudent, which may include a fine of Rs. 1000/-, debarment from placement assistance, \\nand/or representing the University in any event/competition. \\n \\n15.4   Use of Students’ Personal Laptop in the University \\nStudents may bring their Personal Laptops/Tablets to the University Campus. The rules \\nfor usage of Personal Laptops/Tablets are specified in the following points: \\n \\n• Students may use laptops/tablets in the tutorial classes if required as part of the'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='36  \\n \\ncoursework/class assignments, with prior permission of the concerned course \\ninstructor. \\n \\n• Students may use their laptops/tablets in the classrooms/seminar halls for \\nassignment/seminar/paper presentation purposes or any other academic activity as \\nrequired/approved by the concerned course instructor.\\n \\n \\n• Students may use her/his laptop/tablet during a class/lecture for academic purposes \\nby seeking prior permission from the concerned course. Violation of this rule will \\nresult in strict disciplinary action, and the errant student’s laptop/tablet will be \\nconfiscated by the course instructor. \\n \\n• Students are not permitted to use/take their personal laptops/tablets to the computer \\nlabs during a practical/laboratory period/class. Violation of this rule will result in \\ndisciplinary action on the student, and the errant student’s laptop/tablet will be \\nconfiscated by the course. \\n \\n• Students may use their laptops/tablets in the computer/project laboratories to \\ncomplete assignments/project work with prior permission of the concerned course.\\n \\n \\n• Use of personal laptops/tablets in the University laboratories/classrooms for any non- \\nacademic/curricular work or activity is strictly Violation of this rule will result in \\nstringent disciplinary action on the student and immediate confiscation of their \\nlaptop/tablet. \\n \\n \\n15.5 Student Discipline in the University Campus (Includes Hostel and Transport \\nFacility) \\n \\nA student shall not indulge in any act of indiscipline which includes: \\n \\n• Any violation of regulations, policies, and the code of conduct for students of \\nPresidency University as may be prescribed and be prevalent from time to time. \\n \\n• Breach of an Undertaking or Declaration and/or refusal to obey the \\ndirections/instructions of the HOD/Dean, Registrar, Chief Proctor and/or Vice \\nChancellor or any other Senior University official. \\n \\n• Failure to provide proof of identity when requested to do so and/or not producing an \\nidentity card. \\n \\n• Displaying the approved out pass before moving out of the campus during class \\nhours. \\n \\n• Violent, indecent, disorderly, threatening, intimidating, or offensive behavior or \\nlanguage (whether expressed orally, in writing, or electronically, including blogs, \\nsocial networking websites, and other electronic means). \\n \\n• Shouting, whistling, and use of verbal/written abuses, derogatory or foul'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='37  \\n \\n• language/terms against any officer, academic staff, administrative staff, other \\nemployees, or students of the University. \\n \\n• Distribution or publication of a poster, notice, sign, or any publication, including \\naudio- visual material, blog, or webpage, which is offensive, intimidating, threatening, \\nor illegal. \\n \\n• Any kind of betting/gambling/extraction of money from a fellow student. \\n \\n• Any act of malpractice related to any examination/test/evaluation process conducted \\nby the University. \\n \\n• Littering on the University campus, including classrooms. \\n \\n• Mass bunking of classes and other University activities or causing disruption in any \\nmanner of the functioning of the University. \\n \\n• Possession and/or use of banned/prohibited substances such as tobacco products, \\nalcohol, narcotics, etc., within the premises of the University, including hostels of the \\nUniversity. \\n \\n• Physical assault or threat to use physical force against any officer, academic staff, \\nadministrative staff, other employee, or student of the University, and/or causing \\ninjury to any person within or outside the University Campus, including hostels and \\ntransport facilities. \\n \\n• Carrying any weapons or prohibited items or chemicals or usage of/threat to use \\nthem. \\n \\n• Violation of status, dignity, and honour of students belonging to Scheduled Castes and \\nScheduled Tribes and/or using abusive language against them and/or indulging any \\nactivity that tends to deride them or tarnish their reputation. \\n \\n• Creating ill will or intolerance on religious/communal distribution of    \\nliterature/propaganda material, in print/electronic form, pertaining to his/her \\nreligion, political views, and group views (based on caste, creed & place of residence) \\nwithin the University campus. \\n \\n• Accessing banned sites and/or pornographic sites and/or material on the University \\ncampus, including hostels. \\n \\n• Any behaviour that could be construed as discriminatory or harassing on the grounds \\nof sex, sexual orientation, gender, gender reassignment, race, religion, disability, or \\nage of any student or member of staff of the University, or any visitor to the \\nUniversity. \\n \\n• Fraud or deception in relation to the University or its staff, students or visitors:  \\n \\n• \"Possession of duplicate Identity Card/ Hall ticket/ Admit card / bus pass/ fee'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='38  \\n \\nreceipt/ impersonating: with an aim to commit fraud\" \\n• Bribery or attempted bribery, including but not limited to offering or giving money,  \\n \\n• gifts, or any other advantage to any student or employee of the University, or any \\nvisitor to the University, with the intention of inducing that person to perform \\nhis/her role improperly or of rewarding that person for performing his/her role \\nimproperly. \\n \\n• Theft, misappropriation, unauthorized use, or misuse of the University property or \\nthe property of its students, staff, or visitors. \\n• Failure to comply with any punishment imposed as a result of the University’s \\ndisciplinary procedures or contempt of those procedures. \\n \\n• Ragging is strictly prohibited. Indulging in any activity that amounts to ragging or any \\nsimilar act shall result in the student being suspended from the University. \\n \\n• Any act that tends to bring the University and/or its officials, staff, or other students \\ninto disrepute and/or adversely affects its reputation and goodwill. \\n \\n• Misbehavior/disrespectful behaviour, physical assault, or threat to use physical force \\nagainst any member of teaching or non-teaching staff of any \\ndepartment/school/University, security staff, fellow students, and the public within \\nor outside the campus. \\n \\n• Indulging in any act, either singly or with others, that creates disturbance within any \\npart of the campus/classrooms or indulging in any activity that obstructs the smooth \\nconduct of classes and/or academic work within the campus; \\n \\n• Indulging or promoting any business or trading activity within the University \\ncampus, including hostels and transport facilities. \\n \\n• Participation and involvement in any agitation or public demonstration or any other \\nform of collective activity in or outside the raising of any slogans or indulging in any \\nviolent activity in pursuance of any demands or issues. \\n \\n• Indulging in cybercrimes like hacking any University data centre/sending obscene \\ncommunal/hate messages with criminal hacking online classes. \\n \\n• Any act, whether verbal or otherwise, involving the violation of the status, dignity, or \\nhonor and/or derogatory to eve-teasing, accosting, molesting, using unrestrained \\nabusive language, making suggestive obscene gestures, or sending \\nemails/WhatsApp/MMS to lady faculty members and students. \\n \\n• Public display of affection/socially unacceptable. \\n \\n• Having been cautioned, making a false statement to Enquiry Committee/ Fact Finding \\nCommittee.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='39  \\n \\n• Any other act of commission or omission, which constitutes indiscipline in the view of  \\n \\nthe Disciplinary Committee. \\n \\n15.6 Defacement/Damage/Theft of University Property \\n \\nStudents shall not indulge in any willful breakage, defacement, damage, or theft of \\nUniversity property (which includes any University infrastructure, equipment, furniture,  \\n \\nsports goods, canteen facilities, hostel facilities, furniture, Univers ity buses, and such \\nother facilities and equipment of any kind belonging to the University ). Any student or \\ngroup of students guilty of stealing, defacing, breaking, or damaging any property,  \\n \\nequipment, facility, and/or infrastructure of the University  shall be subject to stringent \\ndisciplinary action and penalties, which include: \\n• Penalty to recover the cost of the damaged/defaced property of the University from the \\nguilty student(s). \\n \\n• Forfeiture of the security deposit, if any, deposited by the student at the time of \\nadmission. \\n \\n• Debarment from Placement Assistance of the University and from representing the \\nUniversity and/or participating in any Competition/Event. \\n \\n• Penalty and Suspension from the University. \\n \\nExpulsion from the University \\nThe decision of the Vice Chancellor, based on the recommendations of the \\nDisciplinary Committee in such cases, shall be final and binding. \\n \\n15.7 Banned Substances/Material in University Campus (Tobacco/Narcotics/ Alcohol \\nProducts/Weapons/Firearms and Pornographic Material) \\n \\nThe following articles/substances are strictly banned in the University  Campus, \\nUniversity Hostels, and University Transport/Buses \\n• Tobacco Products; \\n• Alcoholic Beverages, Spirits, and Wines; \\n• Narcotics, Drugs, or \\n• Firearms, weapons, or replicas of weapons, or any instrument that is considered \\ndangerous and/or destructive \\n• Pornographic material in any form; \\n• Unauthorized tranquilizer medicines other than prescribed by the examining \\nphysician; or \\n• Any other objectionable material as notified by the University as such.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='40  \\n16. DISCIPLINARY COMMITTEE \\n \\nNOTE: Possession of any of the articles/substances listed above in the sub-clauses,  \\n \\nanywhere on the University campus, including the hostels and in the University buses, is \\na serious violation, and strict disciplinary action will be taken against the errant student, \\nwhich includes immediate suspension from the University  till the completion of the \\ninquiry by the Disciplinary Committee. The guilty student(s) may be expelled from the \\nUniversity on the recommendations of the Disciplinary Committee. \\n \\n15.8  Social Media Usage – Code of Conduct/Communication \\n \\nThe competent authority shall assign and entrust certain social media- related updates \\nto a student committee that is authorized to upload approved content on the social media \\npages of the University. They are to be mindful of what is appropriate and what is not, in \\norder to maintain the goodwill and reputation of the University. \\n \\n• Students are expected not to interact on behalf of the University  with media \\nrepresentatives or invite media personnel to the campus without the permission of the \\nUniversity. \\n• Students are not permitted to audio/video-record lectures in classrooms or actions of \\nother students or staff without prior permission/consent. \\n• Students are not permitted to provide audio or video clippings of any activity on the \\ncampus to the media without prior permission. \\n• Students are expected to use social media carefully and responsibly. They are not to \\npost derogatory comments about other individuals from the University  on social media \\nor indulge in any related activities that cause grave ramifications on the reputation of \\nthe University.\\n \\n• Students are not to create audio/video recordings or take photographs or stream \\naudio/video content of any person in a location where the person has a reasonable \\nexpectation of privacy without that person’s knowledge/expressed consent.\\n \\nAny act of indiscipline pertaining to the Code of Conduct for Students listed above \\nsection and its Clauses/Sub-Clauses will be investigated by the Disciplinary Committee \\nof the University. Based on the seriousness of the act of indiscipline, disciplinary action \\nagainst the guilty student shall be initiated, which may range from a penalty/fine \\nand/or recovery of costs/expenses (incurred by the University to restore or replace or \\nrepair any property destroyed or damaged or defaced by the student) and suspension'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='41  \\n \\nor expulsion from the University. All powers relating to discipline and disciplinary \\naction are vested in the hands of the person/committee as she/he may specify in this \\nregard. \\nThe Vice Chancellor may, on the recommendation of the Disciplinary Committee or on \\nher/his own order, direct that any student found guilty of indiscipline shall: \\n \\n• Be kept under disciplinary probation with or without supervision for a stated period; \\nor \\n \\n• Be suspended for a stated period; and/or \\n \\n• \\nBe fined monetarily with a specified amount; and/or \\n \\n• \\nNot receive the result in the examination in which she/he has appeared to withheld for \\na stated period or cancelled; and/or \\n \\n• Be debarred from one or more examinations conducted by the University; and/or \\n \\n• Be debarred from the professional/industry practice provisions/facility of the \\nUniversity; and/or \\n \\n• \\nBe debarred from the placement assistance of the University; and/or \\n \\n• \\nBe debarred from registering for a specified academic term of the University; or \\n \\n• \\nBe expelled from the University. \\n \\n• \\nBe expelled from the hostel \\n \\n• In case a student is found guilty of indiscipline and is punished as stated above, his/her \\nscholarship (if awarded) under the University Scholarship Policy shall be withdrawn \\nwith immediate effect. He/she shall be liable to refund the full amount received as a \\nscholarship from the University from the date of admission. \\n \\n• The University shall be entitled to issue public notice with or without the photograph \\nof the student concerned to intimate the general public of the misconduct or the \\npunishment imposed upon the student. \\n \\n• The decision of the Vice Chancellor regarding punishment shall be final and no open to \\nquestion. \\n \\n•    Nothing stated herein shall prevent the University from initiating or instituting \\nappropriate action in accordance with the prevalent law, both civil and/or criminal, in \\naddition to the actions defined above.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='42  \\n \\n          Disciplinary Action: \\n \\n• If a student is found indulging in any act of indiscipline that violates the standard of \\nethics and conduct, the University shall initiate the required disciplinary action without \\nbeing biased. \\n \\n• University officials should handle students’ issues with utmost care and with an open \\nmind. Punishment must not be the sole agenda while enforcing discipline. \\n \\n• Students are to be encouraged and motivated to adopt the right path through proper \\ncounselling by faculty, mentors, and/or the student counsellor. \\nThe nature of disciplinary actions shall be based on the severity  & the frequency of acts \\nof indiscipline noted against that particular student’s name, and the procedure followed \\ncould be any one or a combination of the below: \\nPositive Advice/ Counselling: \\nThe student is first referred to a mentor (faculty/counsellor) who would offer him/her \\nwords of advice to guide them towards positive alternatives of behaviour. If the student \\nis unable to reflect upon his/her own actions and rectify them accordingly, then engaging \\nthe student with the counsellor shall be mandatory. This will ensure positive behavioural \\nchange, and if required, subsequent follow-up counselling sessions shall continue to take \\nplace. \\n \\nWarning/ Fines: \\n \\n• If the student’s behaviour is found inappropriate, a formal warning notice will be \\nissued by the concerned authority in the University. \\n \\n• They will be instructed further that they shall be provided with one chance to display \\npositive/appropriate student behaviour after realizing their mistake. \\n \\n• In some cases of misbehaviour, such as theft or misuse/damage of institutional \\nproperty, fines may be imposed. \\n \\n \\n• The written evidence of fines shall be recorded in the student’s file as proof of \\nbehavioural history, in case such kind of behaviour is repeated in the future. \\n \\n• If students are engaged in behaviour such as smoking, consuming alcohol, and/or \\ntaking drugs, then a fine as well as strict disciplinary action may be imposed. \\n \\nSuspension from Classes \\nTemporary Suspension from the University  excludes the student from academic or \\nother activities for a specified period. The suspension notice will be issued to the'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"43  \\n17. RULES, POLICIES AND REGULATIONS \\n \\nstudent and their parents/guardian, and it will be recorded in the student's disciplinary \\nrecord. The student may be withdrawn from courses and forfeit fees. After the \\nsuspension period, the student must request reinstatement by submitting a letter to \\nthe Chief Proctor/Dean Student Affairs with supporting documents. Return to the \\nUniversity is subject to approval by the concerned authority. \\nRustication \\nRustication is a serious disciplinary action that excludes a student from the University  \\nfor up to one year. During this period, the student's rights are forfeited, and their \\ndegree will not be conferred. The student will be withdrawn from all courses, and fees  \\n \\nwill be forfeited. The rustication notice will be issued to the student and sent to their \\nparent/guardian, and it will be recorded  permanently in the student’s disciplinary \\nrecords and academic transcripts. Rusticated students are not allowed on campus. \\n \\nExpulsion \\nStudents expelled from the University will forfeit all student rights, be withdrawn from  \\n \\nall courses, and have their fees forfeited. Expulsion prevents the student from receiving \\na final degree or awards. The expulsion will be recorded in the student's disciplinary  \\nrecords and academic transcript, and the student will not be allowed on campus. A copy \\nof the expulsion notice will be sent to the student’s parent/guardian. \\n \\nPostponement of Conferring of Awards and Degrees \\nThe University reserves the right to defer, postpone, or cancel the conferring of any \\naward and degree during the course of disciplinary measures or during the period of \\nsuspension. \\n \\n \\n17.1 Admission Rules \\nThe University admissions shall be open to all persons irrespective of caste, class, creed, \\ngender, or nationality. All admissions shall be made on the basis of merit in the qualifying \\nexaminations and as per the rules and guidelines prescribed by the Government of \\nKarnataka, other conc erned regulatory bodies, and the entrance examinations \\nconducted by the University. \\n \\n• The students shall be admitted to a programmes of study of the University subject to \\nthe fulfilment of eligibility criteria, as prescribed from time to time by the University for \\nthe respective program of The eligibility criteria for admission to the various programs\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='44  \\n \\nof the University would be clearly specified in the respective program regulations and \\ncurriculum, issued periodically. \\n \\n• A student admitted to a program of study shall continue to remain registered for such a \\nprogram till she/he successfully completes the program or she/he withdraws from the \\nprogram in accordance with the then prevalent regulations. \\n \\n• Every student duly admitted to the University for a program after compliance with \\nprescribed formalities and payment of prescribed fees, deposits, as applicable, and other \\namounts and submission of prescribed documents and certificates shall be allotted a \\nunique identification. \\n \\n• If a student fails to pay the University fee and deposits, as applicable, for admission to a \\nprogram of study, and/or fails to produce all the mandatory documents and certificates \\nrequired for admission to the University before the prescribed last date thereof, the \\nprovisional offer of admission to the student shall stand. \\n \\n• If a student desires to join the University on the basis of lateral entry or transfer of \\ncredits from other institutes/universities during the program, she/he shall be examined \\nfor eligibility for admission as per the procedure and criteria laid down in the academic \\nregulations of the University and the respective programme regulations concerned, and \\nadmission shall be dependent on his/her eligibility so determined. \\n \\n17.1 University Fee Policy \\n \\n• The University Fee Policy providing information on various University Fees, Charges, \\nand Deposits is given to every student at the time of the purpose of the Fee Policy \\nDocument, which is to provide all the information the student (and parents) required in \\nthis regard. \\n• The University fee is on an “annual” basis (i.e., charged annually) and in advance for the \\nconcerned academic year. It is not a “semester-based” fee structure. However, for the \\nconvenience of the students, the fee payment is facilitated in two instalments (first in the \\nmonth of June and the second, in November, of every academic year, irrespective of the \\ndate of announcement of results of end-term examinations and commencement date of \\nthe ensuing semester). \\n \\n• The University fee (including deposits, where applicable) is payable through one of the \\nfollowing modes: \\n\\uf0a7 In Cash \\n\\uf0a7 By Bank Demand Draft \\n\\uf0a7 Through net banking or credit/debit card \\n\\uf0a7 Note: Checks are not accepted. \\n• The security deposit, where applicable, will be refunded, after adjusting dues, if any, only \\nwhen the student completes his/her program of study from the University or withdraws \\nfrom the University.\\n \\n \\n• In case a student is required to repeat/re-register an academic year, the annual fee'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='45  \\n \\npayable by her/him shall correspond to the academic year to be repeated and shall be as \\nper the fee policy in force at that point in time. \\n \\n• The policies relating to the University fee and deposits, where applicable, are the \\nprerogative of Presidency University and may be revised from time to time. Such \\nchanges shall be binding on all the students. \\n \\n• All disputes arising out of or in connection with this are subject to the exclusive \\njurisdiction of the courts of Bengaluru. \\n \\n17.1.1 Fee Payment Schedule and Late Fee Rules \\n \\n• The payment of Fee for new Admissions will be as mentioned in the respective \\nProvisional Admission Letter or shall be before the commencement of the Programme, \\nwhichever is earlier. The payment schedule will be notified from time to time. \\n \\n• The student is cautioned that failure to pay the University fee on or before the \\nprescribed dates shall not be eligible to register for the concerned academic term, and \\nthis will result in the loss of an academic term/year, as the case may be. \\n \\n17.1.2 Admission withdrawal/ cancellation \\nThe request for cancellation of admission or withdrawal from studies is to be made in \\naccordance with the prescribed regulations. Regulations include the procedure for \\ncancellation/withdrawal as well as the rules for a refund. \\nRefund of fees in case of withdrawal of admission is governed by  the UGC Guidelines \\nprevailing at the time of withdrawal and in alignment with University  Refund Policy \\nand Processes. \\n \\n17.1.3 Procedure for Refund: \\n \\nBefore Enrolment: \\nAn email must be sent to the email ID mentioned in the admission letter along with \\nscanned copies of the original fee paid receipt, the Aadhaar card copy of the student, the \\nAadhaar card copy of the father & mother, the cancelled cheque leaf of the parent, and \\nthe copy of the first page of the parent bank passbook. \\n \\nAfter Enrolment: \\nThe request letter for discontinuation is duly endorsed by the Dean/HOD, along with the \\nno-dues form to be submitted to the Office of the Registrar. Please ensure all required \\ndetails are filled out completely and obtain the necessary signatures from the respective \\ndepartments in the no-due form to initiate the process of fee refund in accordance with \\nUGC Guidelines. \\n \\nStudents are expected to align with the University timelines.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='46  \\n \\n \\nSl. \\nNo. \\nPercentage of Refund \\nof Fees \\nTime line when notice of \\nwithdrawal of admission is received \\n1. 100% 15 days or more before the formally \\nnotified last date of admission \\n2. 90% Less than 15 days before the formally \\nnotified last date of admission \\n3. 80% 15 days or less after the formally \\nnotified last date of admission \\n4. 50% 30 days or less but not more than 15 \\ndays, after formally notified last date of \\nadmission'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"47  \\n \\nNote: Processing fee of up to 5% of the value refunded (other than Caution and/or \\nSecurity Deposit, which will be refunded in full) subject to a maximum of Rs. 5000/ - \\n(Rupees Five Thousand Only). \\n• If the application for withdrawal of admission is submitted more than 30 calendar days \\nafter the date of commencement of the concerned program as announced by the \\nUniversity in the academic calendar or University notification in this regard, there shall \\nbe no refund whatsoever of the University fee paid by the student. The refundable \\ncaution and/or security deposit, if applicable, will be refunded. \\n• The refund will be processed, as per the policy, within the prescribed number of days \\nfrom the date the withdrawal is completed. The University  will make the refund, if any, \\nthrough NEFT only to their parent’s bank account, the details of which were intimated \\nin the refund application. \\n \\n17.1.4 Withdrawal from Programme and Fee Refund Policy for \\nSubsequent Withdrawals \\n \\n• A student wishing to withdraw from the Program of Study after completing one or \\nmore academic years must submit a Withdrawal Form along with a signed 'No Dues \\nForm' from the departmental heads. The University's refund policy will apply only if \\nthese forms are submitted. \\n \\n• If a student submits the withdrawal form by 15th July (or another notified date), the \\nadvance fee for the next academic year will be refunded, minus a Rs. 5000 processing fee \\nand any applicable dues. The caution/security deposit, if paid, will also be refunded after \\nadjusting any outstanding dues. \\n \\n• If the withdrawal application is submitted after 15th July (or another notified date), the \\nadvance fee for the next academic year will not be refunded. However, the \\ncaution/security deposit, if paid, will be refunded after adjusting any outstanding dues. \\n \\n• If a student withdraws due to not progressing to the next semester, the advance fee for \\nthe academic year will be refunded after deducting any applicable dues and a \\nprocessing fee of Rs. 5000. The caution/security deposit, if paid, will also be refunded \\nafter adjusting any outstanding dues. \\n \\n• No interest shall be payable on the refund of any fees/deposit. \\n \\n• The minimum time to make the refund, as applicable, shall be thirty (30) calendar days \\nfrom the date the withdrawal is completed. The University will make the refund, if any, \\nthrough NEFT only to their parent’s bank account, the details of which were intimated \\nin the refund application.\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"48  \\n \\n• In case of any dispute, the decision of the Vice Chancellor, Presidency University, would \\nbe final and \\n \\n• All disputes arising out of or in connection with this are subject to the exclusive \\nJurisdiction of Courts of Bengaluru. \\n17.2  Computer Laboratory Rules \\n \\nComputer laboratories will be open during the University 's working hours and/or as \\nrequired or notified by the Dean/HOD of the concerned school/department. Students \\nshould use the computer lab for academic learning activities and curricular-related \\nassignments/projects. All Internet-based activities of the students, through the \\nUniversity Campus Network, will be monitored for security purposes. \\nThe rules governing access to the computer labs and conduct inside the labs are \\nlisted below: \\n \\n• Only faculty members, students, and staff of the University are allowed into the \\ncomputer lab. No visitors are allowed into the lab without prior permission from the \\nDean/HOD concerned. \\n \\n• Each student will receive a unique email ID and password, which must be kept \\nconfidential. Sharing passwords is prohibited. Misuse of the email ID will be considered \\nmisconduct, and strict action will be taken. \\n \\n• Students must log in and log out using the Lab Attendance Register kept for this \\npurpose at the time of entry and exit from the computer lab. \\n \\n• Students must display the identity cards and should be dressed as per the University \\ndress code applicable to them. Students without an identity card and/or violating the \\ndress code shall not be permitted to enter the computer lab. \\n \\n• Students must get prior permission to bring storage devices like pen drives or CDs to \\nthe lab, and these must be registered. Failure to comply will result in disciplinary action \\nand confiscation of unauthorized devices. Any copied data or programs must be shown \\nto the lab in charge for verification.\\n \\n \\n• Students must use only the systems assigned by the lab in-charge or course instructor \\nand are provided with unique login credentials. Sharing login information is \\nprohibited. Unauthorized use of the system will lead to disciplinary action against the \\nstudent involved and anyone who receives the shared information. \\n \\n• Students shall not indulge in hacking or any such unethical/unauthorized attempt to \\naccess information in files/systems other than their own. \\n \\n• Any attempt to destroy or damage data or programs in individual machines as well as \\nin the server shall result in stringent disciplinary action against the guilty/errant \\nstudent, which may include debarment from Placement Assistance and/or\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"49  \\n \\n   participation in University Competitions/Events. \\n \\n• The Internet/Wi-Fi facility is provided purely for academic learning and internet \\naccess is free with conditions. Students must vacate systems after 60 minutes if others \\nare waiting. \\n \\n• Audio/video chatting and accessing non-educational or illegal sites are prohibited. \\nMisuse of lab facilities for non-academic purposes will be considered a serious \\ndisciplinary offense. \\n \\n• Students must not use the Internet/Wi-Fi for unproductive, provocative, or illegal \\nactivities. Misuse will result in disciplinary action, including withdrawal of access, \\ndebarment from placements, and exclusion from University events. \\n \\n• Beverages and eatables are strictly prohibited inside the lab. \\n \\n• Mobile phones are strictly prohibited in the lab, and violation of the rule results in the \\nconfiscation of the mobile phone and expulsion from the lab. \\n• If any damage is caused to any computer system or its peripherals due to \\nnegligence and/or deliberate mischief by student(s), the entire cost of the \\nsystem/peripherals will be recovered by the University from the delinquent \\nstudent(s). \\n \\n17.3 Rules for Other Laboratories and Workshops \\n \\n• Students must report for laboratory and workshop sessions on time as per the \\ntimetable. \\n \\n• Students are required to wear laboratory/workshop uniforms as prescribed by the \\nschool. Care should be taken by students to wear heavy-duty shoes to prevent \\naccidents in the workshop. \\n \\n• Students must maintain lab/workshop records as required by their course. Entry is not \\nallowed without these records. Work on experiments can begin only with the \\ninstructor's approval, and all instructions must be followed. \\n \\n• All laboratory equipment/workshop machinery/appliances/chemicals need to be \\nhandled with care by students, and they should take the help of the lab \\ninstructor/course instructor whenever they are uncertain on how to handle any \\n \\n• Students must inform the faculty, laboratory assistant, or workshop assistant of any \\ndamages or malfunctions of equipment immediately and as and when noticed. \\n \\n• Students will be held responsible for any damage to equipment, machinery, or \\nappliances caused by negligence or misconduct. The University will recover the cost \\nthrough penalty fees or by deducting it from the security deposit paid at the time of \\nadmission, if applicable. \\n \\n• Any unruly behaviour in the laboratory/workshop shall be dealt with immediately by\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='50  \\n \\nthe course instructor/lab instructor, which may include sending the errant student(s) \\nout of the laboratory/workshop and any other penalty as imposed by the Disciplinary \\nCommittee. \\n \\n• All materials used in the laboratory/workshop are the property of the University and \\nshould not be taken out of the laboratory/workshop except under the guidance of a \\nfaculty member in charge and with the permission of the concerned HOD/DEAN. \\n \\n• Students absenting themselves from laboratory/workshop sessions cannot claim to \\nredo the experiments as a matter of right. The discretion/decision of the HOD/Dean will \\nbe final in this case. \\n \\n• Any loss, damage, or injury occurring to the student and/or the equipment in the lab \\narising out of failure to follow or adhere to the instructions issued by the lab/workshop \\ninstructor or due to acts of negligence of a student shall be the liability of the student. \\n \\n17.4 Library Policy and Rules \\nThe University Library promotes a welcoming environment that is conducive to study, \\nresearch, and learning. It has a good collection of all textbooks, reference books, and \\ngeneral reading materials along with subscription to e-journals and e-databases. \\n \\nLibrary rules are framed for effective utilization of the Library collection & it’s services \\nby the students and will be reviewed periodically in accordance with the latest \\nupdates/revisions. Students are advised to visit the Library regularly to avail its physical \\ncollection and its website to access e-resources. \\n \\nClassification Scheme \\n \\nThe books in the Library are classified according to Dewey’s Decimal Classification \\n(DDC) scheme. The scheme allows for a systematic arrangement of materials based on \\nsubject areas. Users are requested to use OPAC computers and follow the instructions \\ngiven there for easy location of books. \\nInternet Browsing \\n \\n• Internet browsing facilities are available in the Library only for subject-related \\nsearches and to access the electronic databases subscribed to by the University. \\n• Online chatting and playing games are strictly prohibited on the digital library \\ncomputers. \\n• Students are not allowed to download and install any software program without the \\nknowledge of the Library professionals. \\n• Use of computers is limited to thirty minutes when others are waiting for access. \\n17.4.1 Use of Electronic Equipment \\n \\nUse of electronic equipment such as mobile phones, audio players, and similar gadgets'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='51  \\n \\nis strictly prohibited inside the Library. However, students may use their personal \\nlaptops/tablets in the Library for academic work only. Any misuse of the laptop in the \\nLibrary will result in the confiscation of the laptop by the librarian, and the errant \\nstudent will be debarred from bringing the laptop to the Library. \\n \\n17.4.2 Rules for Borrowing Books \\n \\nLending of Library books can be done after one produces their University  identity card \\nas per the rules/procedure listed below: \\n \\n• Identity cards are not transferable. Library staff may refuse to issue books to anyone \\nwho uses others’ books. Books should not be lent to others. \\n \\n• Books will be issued to all students for a period of 15 days. \\n \\n• Books borrowed should be returned on or before the date mentioned in the due date \\nslip. Overdue charges will be collected as mentioned in clause below. \\n \\n• Books have to be returned to the Library as and when they are recalled by the librarian \\n \\n• The condition of a book must be checked before borrowing, and any book found in a \\ndamaged condition will not be issued. The Library staff must be notified immediately if \\nany damage or defect is noticed while borrowing. \\n \\n• The borrower is fully responsible for the books issued to him/her. Any damage to the \\nbook or marking during the borrowed period will lead to a penalty or total replacement \\nof the book. \\n \\n• If books borrowed are damaged or lost by the borrower, he/she should replace the \\nbook or pay the value as per the University Library damage & lost policy. \\n \\n17.5. 3 Rules for Renewal of Books \\n \\n• Renewal of books is done for those books that are not in demand at the respective library \\nfrom where it has been borrowed. \\n \\n• Books must be brought to the Library for renewal. \\n \\n• Books can be renewed twice for a 15-day period each time if there is no demand. \\n \\n• In case a book is reserved by someone, then its renewal is not possible, and it has to be \\nreturned to the books. It will not be renewed more than two times at a stretch \\nirrespective of the demand. Such books have to be returned on or before the due date \\nand kept in the Library for two working days before issuing it to the same person.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='52  \\n \\n17. 5.4 Rules for Reservation of Books \\n \\n• Reservation of books can only be done through Library web OPAC, after login into the \\nuser’s account. \\n• The collection marked as reference, print journals & magazines issues and these are \\nnot allowed to be reserved. \\n• If a book is reserved by more than one person, each one gets a priority number \\nautomatically based on a first-come, first-served basis. Such books cannot be renewed \\nto the borrower or issued to anyone other than those reserved.\\n \\n \\n• When a reserved book is returned to the Library, members will be notified in the order \\nof their priority on the reservation list. Each member will have two working days to \\nborrow the book. If they fail to do so, the opportunity will pass to the next person on the \\nlist.\\n \\n \\n17.5.5 Reference Books \\n \\nDictionaries, encyclopaedias, handbooks, manuals, yearbooks, periodicals, back volumes \\nof periodicals, reports, textbooks, newspapers, and all those books bearing the stamp \\n“Reference” will not be lent out. These resources are meant for reference within the \\nLibrary premises only. \\n \\n17.5.6 Overdue Charges, Loss of Books and Identity Card \\nFor late returns of books, the following overdue charges will be levied: \\n \\n• First 10 days after the due date: Rs. 5 per book day \\n \\n• From the 11th day after the due date: Rs. 10 per book per day \\n \\n• Any book that is lost by the borrower must be brought to the notice of the librarian. \\n \\n• The borrower is liable to replace the book that is lost or If unable to replace the lost \\nbook, recovery of the cost of the book must be made on the following basis \\n \\n• Three times the current price of the book, if loss of the book is reported before the due \\ndate; \\n \\n• Three times the current price of the book with overdue charges, if the borrower has \\nreported the loss after the due date; \\n \\n• If the lost book is rare in nature (i.e., not available in the market or is out of print), then \\nfive times the book’s cost will be recovered from the borrower. \\n \\n• Absence from the University will not be allowed as an excuse for delay in return of \\nbooks.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='53  \\n \\n• No reminders will be issued to individual defaulters; and, \\n \\n• All books borrowed from the Library have to be returned, and all outstanding dues \\nmust be cleared before getting a no-dues \\n \\n17.5.7 Library E – Resources \\n \\nThe Library subscribes to the following online databases, which are available to students \\nand faculty within the campus as well remotely through Knimbus using valid credentials. \\nThe subscribed e -databases contents are subject to copyright, and hence the users are \\nrequired to use the content for academic reference only. For any assistance in accessing \\nthe subscribed resources, write to library.services@presidencyUniversity.in \\n \\n\\uf0a7 IEEE Digital Library \\n\\uf0a7 ASTM Digital Library \\n\\uf0a7 ProQuest ABI Global \\n\\uf0a7 J-Gate (Engineering) \\n\\uf0a7 J-Gate (Social Science and Management) \\n \\n\\uf0a7 NTPEL Lectures and Videos \\n\\uf0a7 EBSCO \\n\\uf0a7 Science Direct \\n\\uf0a7 JSTOR \\n\\uf0a7 Lexis Nexis \\n\\uf0a7 SSC Online \\n\\uf0a7 Hein Online \\n\\uf0a7 Capitaline \\n\\uf0a7 CMIE ProwessIQ \\n\\uf0a7 Emerald insight \\n\\uf0a7 IndiaStat \\n\\uf0a7 SPSS AMOS \\n\\uf0a7 Scopus bibliographical database \\n\\uf0a7 DELNET - Developing Library Network \\n\\uf0a7 South Asia Archives \\n\\uf0a7 World E-book Library \\n\\uf0a7 Library OPAC \\n\\uf0a7 Shodhganga (Archive of e-theses of all Universities in India) \\n\\uf0a7 Turnitin Plagiarism Check \\n\\uf0a7 Ouriginal (Urkund - UGC) Plagiarism Check'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='54  \\n \\n17.5.8 Library Print Subscription \\n \\nLibrary Subscribes to 155 print journals and 38 general magazines & 17 newspapers. \\nList of these resources can be found from the library website. These periodicals are only \\nfor reference and will not be permitted for circulation. \\n17.5.9 Printing and Photocopying Facility \\n \\nPhotocopying of the Library materials can be obtained from the Library at nominal \\ncharges as fixed by the Library from time to time. Photocopy charges may be paid at the \\nIssue Desk. \\n  \\nWorking Hours \\nMonday through Saturday: 8.30 am to 6.30 am  \\nDuring End-Term Examinations: 8.30 am to 8.00 pm  \\nCirculation (Issue & Return): 8.30 am to 6.00 pm \\nThe Library will be closed on Sundays and other University holidays. \\n \\nGeneral Instructions \\n \\n• Library access is limited to the faculty, staff, and students of Presidency University. A \\nvalid identity card is required for all Library transactions, including borrowing \\nprivileges. \\n• Always use the call number for locating the books; the call number is printed on the \\nspine of the book for easy identification. In case of any difficulty in locating the books, \\nplease approach Library professional. \\n• Use the Online Public Access Catalogue (OPAC) to identify the books you require and \\nto know the availability.\\n \\n \\n• After referring to the books, please leave them on the tables. Library staff will replace \\n \\n• \\nUsers must leave their personal belongings in the designated property rack before \\nentering the Library. However, valuables should not be placed in the racks, as the \\nLibrary is not responsible for any loss of belongings. \\n \\n• \"A misplaced book is a lost book.\" To maintain order, avoid placing books in incorrect \\nlocations on the racks. As the Library follows an open access system, books removed \\nfrom the racks should be left on the tables for the Library staff to replace. \\n \\n• Strict silence is to be observed inside the Library. If conversation becomes necessary, \\nit should be in low tones. \\n \\n• Food and beverages are not allowed inside the Library. \\n \\n• \\nIf any books are defaced, such as by marking, underlining, folding, or tearing of pages, \\netc., twice the cost of the latest edition of the book will be charged to the student.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='55  \\n \\n \\n• If a student is found guilty of theft, tearing parts of the books, and/or causing damage \\nto the Library property, disciplinary action will be taken against the students with \\npenalties ranging from forfeiture of the security deposit to expulsion from the \\nUniversity. \\n \\n17.5.10 Policy Against Plagiarism \\nThe University  is committed to ensuring the authenticity as well as the accuracy of \\ndocumentation of the research record, whether in a pre- registration research proposal, \\nresearch progress report, pre -submission synopsis, final thesis, publications, or any \\nother form of  claims made to academia, government, industry, media, or the public at \\nlarge. \\n \\n• For this purpose, the guidelines followed worldwide shall be adopted, such as those \\nissued by the Committee of Publication Ethics (COPE) [publicationethics.org] or the \\nSingapore Statement on Research Integrity. [singaporestatement.org/statement.html]. \\n \\n• The Research and Innovation Council of the University shall provide guidelines and \\ntraining, as required, to ensure that all students, in particular undergraduate students of \\nhigher semesters, postgraduate students, research scholars, and faculty members, are \\ntrained in the best practices of research documentation/publishing/communication, \\nincluding how to avoid unethical publishing practices and the usage of anti-plagiarism \\nsoftware Turnitin®, iThenticate®, or other approved software.\\n \\n \\n• All written submissions for publication, such as project reports, dissertations, papers, \\ntheses, and other publications under the name of the University, must adhere to the anti- \\nplagiarism guidelines provided by the course instructor(s), research supervisors, Ph.D. \\nregulations, or other University notification to this effect from time to time. If required, \\nthe electronic file (text) shall be scanned using anti-plagiarism software (Turnitin®, or \\niThenticate®, or other approved software). Also, non-text contents such as tables, \\nfigures, images, drawings, schemas, etc., shall be critically examined to ensure that the \\nsubmission is free from any unethical content/practice prior to final \\nsubmission/publication.\\n \\n \\n• Research Scholars shall submit the anti-plagiarism scanning report of the complete \\nthesis at the time of submission of the thesis for evaluation, as specified in the D. \\nRegulations, 2022 of the University, as may be amended from time to time. \\n \\n• The students, research scholar(s), supervisor(s), and author(s) shall be held \\nresponsible for any such document found to have unethical content/practices, including, \\nbut not limited to, plagiarism, falsification, and fabrication of results/data/claims. \\n \\n• Such project reports/dissertations/publications/theses shall be withdrawn by the \\nUniversity, regardless of their consequences to their authors, including cancellation of \\nregistration for the course(s) concerned and/or withdrawal of their Ph.D. degrees, \\n \\n \\nIf such research scholars may also be debarred from admission to any program in the \\nUniversity.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"56  \\n \\n17.6 Internship, Professional Practice and Placement Assistance \\n \\nThe University has a dedicated industry interface and placement cell to provide \\nassistance for internships, professional practice (as applicable), and career placements  \\nto all the eligible students. The students must strictly follow the rules and guidelines  \\nissued by the University on a timely basis to avail themselves of such facilities. \\n \\n• Every student must have a minimum attendance of 75% or above in all courses in every \\nsemester/academic term to be eligible to avail themselves of the facilities offered by the \\nIndustry Interface and Placement Cell. \\n \\n• The University shall not extend any professional practice or placement support to \\nstudents penalized in disciplinary \\n \\n• The students are advised to refer to the Program Regulations and Curriculum, 2021, \\npertaining to the concerned Program of Study for more details on the Policy on \\nPlacement and Internships, as applicable to the relevant Program of \\n \\n• The relevant Placement Rules and Guidelines will be issued to the pre-final year \\nstudents of a Program of Study by the Placement Cell at the appropriate time. \\n17.7 Medical Care Policy \\n \\n• The University is committed to taking due care of the general health and well-being of \\neach. However, the University shall not take responsibility for serious medical \\nconditions arising out of ailments, sickness, injuries, accidents, etc. Treatment for \\nminor ailments and first aid is provided at the University Primary Medical Centre. In \\ncase a student requires further medical attention, he/she will immediately be \\ntransferred to the nearest hospital, and the same shall be informed to the parents. \\n \\n• The University provides minor first aid on campus and in hostels and may inform the \\nstudent's parent or guardian if necessary. However, it is not responsible for incidents \\nduring this service or for medical emergencies, accidents, or injuries occurring on \\ncampus, in sports areas, during activities, or while using University transport. The \\nUniversity is also not liable for accidents resulting from a student's failure to follow \\nsafety guidelines or the code of conduct. \\n \\n• The University has trained & qualified nursing staff and has an ambulance facility on \\ncampus. \\n \\n17.8 University Transport Policy \\n \\nThe University has its own transport facility and provides pick-up and drop-off facilities \\non certain prefixed routes to the students, faculty members, and staff. \\n \\n• Students who would like to avail themselves of the University transport facility may\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='57  \\n \\n  apply for the transport facility of the University and pay the prescribed University  \\n \\ntransport fee. The transport fee is paid as an annual fee for the concerned academic A       \\nstudent availing themselves of transport facilities and who has not paid the transport \\nfee in full shall not be permitted to use the University transport facility. \\n \\n• Transport fees are neither refundable nor adjustable under any \\n \\n• The student has to opt for the available pickup/drop point on the available pre-fixed \\nroute at the time of applying for the transport. \\n \\n• The transport route and pick/drop points are planned considering the best interests \\nfor the entire community using the University transport system. However, the final \\nroute and schedule are entirely at the discretion of the University.  \\n• The transport timings—pick up and departure from the University campus—are fixed \\nand announced at the beginning of each academic \\n \\n• Transportation routes and timings may be altered keeping in view its requirements \\nduring examination and other special activities of the \\n \\n• Students will be issued Transport ID cards at the time of allocation of transport \\nfacilities and must carry the Transport ID card with them to prove identity whenever \\nonly authorized students are permitted to travel with ID cards. \\n \\n• The transport ID cards are not transferable. Any student misusing the ID card shall be \\nsubject to disciplinary action, which may include withdrawal of the transport facility \\nfor the errant student. \\n \\n• Intoxicants, liquor, tobacco, explosives, and/or weapons (knives) cannot be kept/used \\nby the student. Any violation will result in disciplinary action, including expulsion \\nfrom the University. \\n \\n• Instructions and Rules for Students Using the University Transport/Bus: \\n \\n• All students using the University transport must be respectful to other commuters— \\nfaculty and students, the bus driver, and the conductor/manager. \\n \\n• No student shall invite friends or others to board the University. \\n \\n• The students must be ready at the assigned bus stop at least five minutes before the \\nbus is scheduled to depart. The bus will not wait for students who are not present at \\nthe bus stop at the assigned \\n \\n• A student must occupy the allotted/available seat. \\n \\n• A student is not permitted to get down from the bus other than at the opted bus. \\n \\n• A student must follow the instructions of the bus driver, conductor, and manager if the \\nmanager is inspecting the'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='58  \\n \\n• Students must not litter, play loud music, or shout on the bus or cause damage to any \\npart of the bus. \\n \\n• A student indulging in any act of misbehaviour with fellow passengers, faculty, staff, or \\nany transport staff, and/or causing damage to the University Bus, shall be subject to \\nstringent disciplinary action, including forfeiture of the University Transport facility for \\nthe rest of the academic year. \\n \\n17.9 University Hostel Policy \\n \\nThe University provides safe, convenient, and comfortable hostel facilities with a hostel \\nmess at a very affordable fee. Separate hostels are provided for boys and girls. All \\nhostellers must abide by the hostel management and rules of operations that will be given \\nto all students admitted to the University  Hostels. The student (hosteller) and \\nparent/legal guardian of the student shall give an undertaking as prescribed by the \\nHostel Management and Rules of Operation. \\n• Admission to the hostel is done  on a first -come-first-serve basis, at the time of \\nadmission to the University . Hostel accommodation is normally allotted only for the \\nodd and even Semesters. \\n• Students who require hostel facility for the summer term must apply for the same and \\npay the prescribed hostel fee applicable for the summer term as stipulated by the \\nUniversity. \\n \\n• Nomination of a local guardian is imperative for admission to the hostel, and he/she \\nshould be accessible to the hostel authorities in times of emergency as a reliable \\ncontact. \\n \\n• In case a student (hosteller) fails to maintain a minimum 75% attendance in all courses \\nregistered, at the end of the concerned semester, the hostel facility shall be withdrawn  \\nfor the student. The concerned student will not be provided the University hostel facility \\nfor the next semester/academic \\n \\n• The hostel facility shall be co-terminus with the student pursuing a course of study at \\nthe University. \\n17.10 Sports Policy \\n \\nThe University strongly encourages sports activities, both indoor and outdoor games, to \\ncreate a vibrant sporting culture and provide competitive and friendly recreation for \\nstudents to bring out the best in each student in terms of physical fitness, \\n“sportsmanship,” and camaraderie. The University  has sprawling facilities for several \\nsports activities. To promote sports, the University has an established sports council.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='59  \\n \\n• Sports Council: The Constitution of Sports Council \\n• Chairperson – Vice Chancellor \\n• Member Secretary – Director of Physical Education \\n• Members – Dean Student Affairs, Deans of all Schools, Physical Education \\nInstructors  \\n• A minimum of two students representing each School \\n \\nSeveral sporting events are organized throughout the academic year, including the \\nUniversity Sports Meet. Other special events and coaching programs may be conducted \\nfor interested students from time to time. \\n \\n17.11 Parking Facility \\n \\n• The University provides limited parking space for the two-wheeler and four-wheeler \\nvehicles of students, for which each student shall be issued a vehicle identity sticker from \\nthe administration office. Any vehicle without the sticker shall not be permitted to enter \\nthe University campus. \\n \\n• Students must park their vehicles in the allocated parking. \\n \\n• Every student using the parking facility must comply with the parking and traffic \\nguidelines displayed on the University \\n• Students using two-wheelers must wear helmets while riding their vehicles. Students \\nwithout helmets will not be allowed to park their two-wheeled vehicles in the allotted \\nparking \\n \\n• Exceeding speed limits within the campus is strictly \\n \\n• Any violation of these rules will result in the parking facility being withdrawn from the \\nstudent. \\n \\n \\n18.1  Joint Affidavit by the Student and Parent/Legal Guardian \\n \\nA notarized affidavit on a Rs. 50/- stamp paper, as per the proforma placed in Annexure \\n4, is to be submitted jointly by the student and parent/legal guardian to the registrar, \\nPresidency University. This affidavit stands as an acknowledgment and a guarantee by \\nthe student and the parent that they have read, understood, and will adhere to all the \\nUniversity Regulations in the Student Handbook: Rules, Policies & Code of Conduct for \\nStudents, and any amendment of University Notifications, from time to time. \\n \\nThe Joint Affidavit consists of the following mandatory undertakings as required by  \\n18. OTHER PROVISIONS'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='60  \\n \\nthe MHRD/UGC and the University: \\n• PART A: Student’s Information and Documents \\n• PART B: University Regulations and Student Handbook: Rules, Policies and Code of \\nConduct for Students \\n• PART C: Prevention of Sexual Harassment \\n• PART D: Permanent Form of Permission and Indemnity \\n \\n18.2  Permanent Form of Permission and Indemnity \\n \\nAs part of the program curriculum, your son/daughter/ward may have to travel for \\nindustrial internships, tours, and participate in similar curricular and extracurricular \\nprograms that may involve  cultural activities, industrial tours, and other \\nexpeditions/tournaments organized by the University. The purpose and necessity of \\nthis undertaking is to obtain permission from you to enable your son/daughter/ward \\nto participate in such activities stated above and also to indemnify the University  in the \\nevent of unforeseen loss of personal property, injury, and accident to limb or life that \\nmay befall your son/daughter/ward. This undertaking by the parent(s)/legal guardian \\nof the student ( PART E of the Joint Affidavit described in Annexure 4) is  a one -time \\nexercise, and once the student and parent/legal guardian have signed this form, the \\nstudent is expected to follow the instructions issued by the University  until completion \\nof their student program. \\n \\n18.3 Issue of Certificate  \\n \\nProvisional Degree Certificate \\n \\n• On completion of the requirements for the award of the degree (refer to Section 21.0 \\nof the Academic Regulation 2021), the student may apply for a Provisional Degree \\nCertificate in the prescribed application form along with the prescribed fee notified by \\nthe University from time to time to the Controller of Examinations of the University. \\n \\n• On verification of the eligibility criteria prescribed in Clause 21.2 of the Academic \\nRegulation 2021, the Controller of Examinations shall issue the Provisional Degree \\nCertificate to the concerned student, to the effect that the concerned student has \\nfulfilled all the requirements for the award of the Degree in the concerned Program and \\nthat the Degree shall be conferred on the concerned student at the next Convocation of \\nthe University. \\n \\n18.4 Issue of Degree Certificate Before Convocation \\n \\n• In exceptional circumstances, a student may apply to the University with the \\nprescribed fee and all supporting documentation if they need the degree certificate \\nbefore the convocation date in order to pursue further education or employment where \\nthe student has secured admission or is seeking employment and must provide the'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"61  \\n \\ndegree certificate. \\n \\n• After evaluating the application's merit, the Vice Chancellor will recommend to the \\nChancellor whether or not to issue the degree. The Chancellor's decision is final and \\nenforceable. The concerned student will receive the degree certificate with the \\nChancellor's approval. \\n \\n• However, the minimum time taken to process and issue the degree certificate shall be \\ntwo (02) calendar months from the date of receipt of the request for the issue of the \\ndegree certificate. \\n \\n18.5 Duplicate Certificate \\nThe duplicate certificate ( Grade Cards/Provisional Degree Certificate/Degree \\nCertificate) will be i ssued only for genuine cases if the original is lost, stolen or \\ndamaged. In such cases, the student mustsubmit a written request in person with the \\nsupporting documents as under: \\n \\n• Copy of FIR (First Information Report) filed with police intimating the loss of the \\ncertificate, digitally signed by the Commissioner of Police or any police authority, and \\nthe full sheet of the newspaper in which the notification regarding the loss of the \\ncertificate is \\n \\n• A non-traceable certificate issued by the police official, duly signed by the inspector or \\nsub-inspector with a round seal (from the area in which the candidate lost the \\ncertificate) by mentioning the crime and occurring sheet number and date, or a \\nnotarized affidavit by the student that the non-traceable certificate was not issued by \\nthe police.\\n \\n \\n• An affidavit on non-judicial stamp paper duly signed and stamped by the first-class \\nmagistrate/notary public with an undertaking to return the duplicate certificate in case \\nthe original certificate(s) is \\n \\n• The student must pay the prescribed fee as fixed by the University from time to time. \\nThe payment acknowledgement receipt should be attached with the application. \\n \\n• The University will courier the duplicate certificate(s) to the applicant's \\ncommunication address, or the student may collect the duplicate certificate(s) in person \\nfrom the University upon receiving communication from the University. \\n \\n• The minimum time taken to process and issue the duplicate certificate(s) shall be two \\n              (02) weeks from the date of receipt of application. \\n \\n18.6 Transfer Certificate (T.C.) and Migration Certificate \\n \\nTransfer Certificate (T.C.) shall be issued by the Registrar’s Office to those students who \\nare discontinuing their course and/or passing out after completing the course. The\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"62  \\n \\nfollowing documents in original must accompany the application for such request: \\n\\uf0a7 Request letter duly signed by student and parent \\n\\uf0a7 No due certificate duly certified by the concerned departments of the University \\n\\uf0a7 University ID card \\n\\uf0a7 Receipt of fees paid \\n \\n18.7 Bonafide Certificate \\n \\nStudents who wish to obtain a bonafide Certificate for various purposes like application \\nfor a bank loan, passport, scholarship, higher studies, employment verification, etc., must \\napply in the prescribed application form to the registrar's office. The minimum time \\ntaken to process and issue the The bonafide certificate shall be issued one (1) day from \\nthe date of receipt of the application. \\n \\n18.8 Issue of Transcripts \\n \\nThe Examination Department issues transcripts for the students who wish to apply for \\nhigher education, competitive examination, and placement. The student must submit the \\nproof along with the written request/application and payment of the prescribed fee \\nacknowledgment receipt. The minimum time taken to process such a request shall be \\ntwo (02) weeks from the date of application. \\n \\n18.9 Procedure to Collect Original Documents Through an Authorized Person \\n \\n• Students can authorize a person to collect the original document. \\n \\n• If an authorized person is assigned to collect the original certificate/document on the \\nstudent’s behalf, an authorization letter duly signed specifying the required documents \\nto be collected, the authorized person’s details, and an ID proof of both should be \\nsubmitted to the Registrar's Office either in person or as a scanned document through \\nemail at registrar@presidencyUniversity.in. \\n \\n• The authorized person should bring the ID proof of both the authorizing and \\nauthorized parties (original & copy), which is mentioned in the authorization letter. \\n \\n• If the authorized person is a foreign national, he/she should bring the residential \\npermit or passport (original & copy).\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content=\"64  \\nANNEXURE – 1 \\n \\nANTI-RAGGING COMMITTEE \\n \\nName & Designation Role Contact Details \\nDr. Vidya Shankar Shetty \\nPro-Vice Chancellor \\nChairperson  \\nprovc@presidencyuniversity.in \\nDr. Md Sameeruddin Khan \\nPro Vice Chancellor (Engineering) \\nMember 9121061686 \\npro- vicechancellor@presidencyuniversity.in \\nDr. Abdul Sharief  \\nDean, School of Engineering \\nMember 9448503567 \\ndeansoe@presidencyuniversity.in \\nDr. K. Krishna Kumar \\nDean, School of Commerce & \\nEconomics \\nMember 9986999098 \\ndeansoc@presidencyuniversity.in \\nDr. Syed Shoukath Ali \\nDirector, Student Housing \\nMember 8050643902 \\nshoukathali@presidencyuniversity.in \\nDr. Rajiv Ranjan Singh  \\nHOD, Department of Electronics & \\nCommunication Engineering \\nMember 9742649493 \\nrajivranjansingh@presidencyuniversity.in \\nMs. Zareena Ali  \\nResidence Officer, Girls Hostel \\nMember 9148572609 \\nzareena.ali@presidencyuniversity.in \\nDr. Malarvili K.  \\nProfessor, Languages -Kannada \\nMember 9480095845 \\nmalarvili@presidencyuniversity.in \\nDr. Bhagyashree  \\nAssistant Professor, School of \\nDesign \\nMember 9916443127 \\nbhagyashree.nadig@presidencyuniversity.in \\nMaj. Gen. Gurdeep Narang \\n(Veteran) \\nDirector - Student Discipline, \\nSports and NCC \\nSecretary 9648774394 \\ngurudeep.narang@presidencyuniversity.in \\n \\n \\nTo address and curb the menace of ragging, the University  Grants Commission has enacted \\nthe 'UGC Regulation on Curbing the Menace of Ragging in Higher Educational Institutions, \\n2009'. In accordance with this regulation, Presidency University , Bengaluru, has constituted \\nthe anti-ragging committee.\"),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='65 \\n \\n \\n \\nANNEXURE – 2 \\n \\nCONSTITUTION OF THE UNIVERSITY COMMITTEE FOR PREVENTION OF \\nSEXUAL HARASSMENT - RESPONSIBILITIES AND PROCEDURES \\n \\n \\nName & Designation \\n \\nRole Contact Details \\n \\n \\nDr. Anu Sukhdev \\nDean, Department of Student Affairs \\n \\nChairperson \\n \\n9731451035 \\nanu.sukhdev@presidencyuniversity.in \\nDr. R. Mahalakshmi \\nProfessor & Associate Dean - SOIS \\nMember 9842066415 \\nmahalakshmi@presidencyuniversity.in \\n \\nDr. Shakkeera L. \\nProfessor & Associate Dean - Academics \\n \\nMember \\n9444710836 \\nshakkeera.l@presidencyuniversity.in \\n \\nDr. Saira Banu \\nProfessor \\n \\nMember \\n9884127780 \\nsairabanuatham@presidencyuniversity.In \\nDr. Pallavi R. \\nProfessor \\n \\nMember \\n9535240465 \\npallavi.r@presidencyuniversity.in \\n \\nDr. Komalavalli Chakravarthy \\nProfessor \\n \\nMember \\n9811820606 \\nkomalavalli @presidencyuniversity.in \\n \\nDr. Anouja Mohanty \\nAssociate Professor \\n \\nMember \\n9320038238 \\nanouja.mohanty@presidencyuniversity.in \\n \\nMr. Sofiul Ahmed \\nAssistant Professor \\n \\nMember \\n78965 63767 \\nsofiul.ahmed@presidencyuniversity.in \\n \\nMs. Sai Shivani Mukund  \\nCounsellor \\n \\n \\nMember \\n8217546605 \\nshivani.mukund@presidencyuniversity.in \\nMs. Bhavana Chandran \\nAssistant Professor \\nMember 9900112231 \\nbhavana.chandran@presidencyuniversity.in \\n \\nDr. Sapna Mohan  \\nAssociate Dean & Head, School of \\nLaw, Christ University \\nExternal \\nMember \\n \\n \\n9916491576 \\nsapnamurali@gmail.com'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='65  \\n \\n \\nProcedures: \\nBy email: Any complaint of sexual harassment must be sent by email only to the \\nICC –  on puicc@presidencyUniversity.in for the purpose of confidentiality. \\nDirect contact: Complaints in confidentiality: \\nDr. Anu Sukhdev, Professor & Dean- Department of Student Affairs - Chairperson  \\nMs. Bhavana Chandran –Assistant Professor, School of Law, Member Secretary'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='66  \\n \\n               ANNEXURE – 3 \\n              STUDENT GRIEVANCE REDRESSAL COMMITTEE \\n \\nName & Designation Role \\nMr. Syed Khaja Daanish Hydri \\n(20211MEC0026) \\nStudent - SOE \\nChairperson \\nMs. Niharika S. Hubli \\n(202031BDS0052) \\nStudent - SOD \\nMember \\nMr. M.V. Dev Anand \\n(20232MBA0159) \\nStudent - SOM \\nMember \\nMs. Varsha Reddy \\n(20211CSE0857) \\nStudent - SOCSE \\nMember \\nMs. Prakruthi Raj \\n(20221BCH0072) \\nStudent - SOC \\nMember \\nMaj. Gen. Gurdeep Singh Narang \\nDirector - Student Discipline, Sports and NCC \\n \\nMember \\nDr. Anu Sukhdev \\nProfessor and Dean, Student Affairs \\nMember \\n \\nPROCEDURE FOR REDRESSAL OF GRIEVANCE \\n• The University shall furnish, prominently, on its website and in its prospectus, all \\nrelevant information in respect of the Student Grievance Redressal Committee(s) \\ncoming in its purview, and the Ombudsperson for the purpose of appeals. \\n \\n• In case of academic grievance, an aggrieved student shall first submit his/her \\ncomplaint in writing to his/her mentor who shall  resolve the grievance within two \\ndays. In case the mentor is unable to resolve the grievance, he shall forward it to the \\nChairperson of the School/Departmental Level Grievance Committee.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='67  \\n \\n \\n• The chairperson of the School/Departmental Committee shall convene a \\ncommittee meeting within 2 days of receiving the complaint from the faculty \\nmentor or from the aggrieved student in case he/she applies directly to the \\ncommittee.\\n \\n \\n• The chairperson shall attempt to resolve the grievance within a week of the \\nreceipt of the complaint and the action taken shall be reported to the mentor. \\n \\n• If the grievance is not resolved/ satisfied with the solution of the \\nschool/department level committee, he/she shall appeal to the University \\nLevel Student Grievance Redressal Committee giving the reasons for his/her \\ndissatisfaction with the decision, within a week of receipt of the decision of the \\nschool/department level committee. \\n \\n• The Chairperson of the University Level Grievance Redressal Committee shall \\nconvene a meeting of the committee within 2 days of receiving the complaint. The \\nCommittee shall verify the facts and shall either endorse the decision of the school \\nlevel committee or shall issue an appropriate an order within a week of receipt \\nof the grievance. \\n \\n• If the grievant is not satisfied with the decision of the redressal offered by the \\nUniversity Level Student Grievance Redressal Committee, he/she can submit an \\nappeal to the to the Ombudsperson, within a period of 15 days from the date of \\nreceipt of such decision. \\n \\n• In case of non-academic /administration grievances, an aggrieved student can \\nsend the grievance through mail to studentgrievance@presidencyuniveristy.in \\nand can raise the grievance in the open forum during monthly student welfare \\ncommittee meetings. The University grievance committee will forward the \\ngrievance to the concerned stake holders and help the student in resolving the \\ngrievance within one week’s time. \\n \\n• At all levels a fair hearing shall be given to all parties. \\n \\n• The law of natural justice shall be observed  and a fair hearing to the grievant \\nshall be given at all levels. The relevant provisions of the Act/Regulations shall \\nbe kept in mind while passing an order on  the grievance at any level, and no \\norder shall be passed in contradiction of the same.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='68  \\n \\n \\nTYPES OF GREIVANCES \\nAcademic Related \\n• Admissions \\n• Examination \\n• Assessments \\n• Evaluation \\n• Library Facilities \\n• Issuance of Certificates \\n• Add-on courses \\n• Research Related issues, etc. \\n \\nExtension and Extra-Curricular \\n• Alumni Registration \\n• Award of non-academic credits \\n• Physical Education, Cultural Activities, Sports, etc. \\n \\nAmenities & Maintenances \\n• Wi-Fi/Internet Connectivity \\n• Utility stores \\n• Computer facilities \\n• Drinking Water \\n• Sanitation & Hygiene \\n• Maintenance \\n• Medical Facilities \\n• Indoor  sports  facilities  \\n \\nPlacement & Internships \\n• On-campus or off-campus interviews \\n• Soft skills training \\n• Internships, etc. \\n \\nGeneral Administration \\n• Collection of fees \\n• ID cards \\n• Scholarships Disbursement \\n• HR related Issues'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='69  \\n• Transportation, etc. \\n \\nHostel Facilities \\nComplaints regarding provisions/ food services \\n• Safety and security of one’s belongings \\n• Bullying/harassment of any form \\n \\nOther Related Issues \\n• Safety and Security \\n• Discipline \\n• Misbehaviour \\n• Emergency Services etc. \\n \\nAPPEALLATE AUTHORITY/OMBUDSMAN \\nFunctions of Ombudsperson \\n \\n• The Ombudsperson shall hear appeals from an aggrieved student, only after the \\nstudent has availed all other remedies provided under these Guidelines. \\n \\n• While issues of malpractices in the conduct of examination or in the process of \\nevaluation may be referred to the Ombudsperson, no appeal or application for \\nrevaluation or re- totalling of answer sheets from an examination, shall be \\nentertained by the Ombudsperson unless specific irregularity materially affecting \\nthe outcome or specific instance of discrimination is indicated. \\n \\n• The Ombudsperson may avail assistance of any person, as amicus curiae, for \\nhearing complaints of alleged discrimination. \\n \\n• The Ombudsperson shall make all efforts to resolve the grievances within a period \\nof 30days of receiving the appeal from the aggrieved student(s). \\n \\nPROCEDURE FOR REDRESSAL OF GRIEVANCES BY OMBUDSPERSON \\n \\n• Grievances not resolved by the Students’ Grievance Redressal Committee within the \\ntime period provided in these guidelines may be referred to the Ombudsperson by \\nthe University. \\n \\n• Institutions shall extend co-operation to the Ombudsperson or the Student \\nGrievance Redressal Committee(s), in early redressal of grievances. \\n \\n• The Ombudsperson shall, after giving reasonable opportunities of being heard to \\nthe parties concerned, on the conclusion of proceedings, pass such order, with \\nreasons thereof, as may be deemed fit to redress the grievance and provide such relief \\nas may be appropriate to the aggrieved student'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='70  \\n \\n \\n \\n• The institution, as well as the aggrieved student, shall be provided with copies of \\nthe order under the signature of the Ombudsperson. \\n \\n• The institution shall comply with the recommendations of the Ombudsperson. \\n \\n• The Ombudsperson may recommend appropriate action against the \\ncomplainant, where a complaint is found to be false or frivolous.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='71  \\n \\nANNEXURE – 4 \\n \\nPRO FORMA \\n \\nJOINT AFFIDAVIT BY STUDENT AND PARENT/LEGAL GUARDIAN \\n(To be undertaken jointly by the Student and  Parent(s)/Legal Guardian of every student \\nadmitted to Presidency University on a Rs. 50/ - Stamp paper duly notarized and must be \\nsubmitted to the Registrar, Presidency University before DD/MM/YYYY) \\n \\n \\nI, Mr. /Ms. , son/ daughter/ ward of \\n<Name of Father / Mother / Legal Guardian, if both parents are not alive) \\n  , and enrolled as a student at  \\nPresidency University, Bengaluru  with Identification Number \\n \\n; herein after referred to as STUDENT; AND, \\n \\nI, Mr./Ms. <Name of Father/Mother/Legal \\nGuardian, if both parents are not alive)>, Father/Mother/Legal Guardian of Mr./Ms. \\n < Name of the Student>; hereinafter referred to as \\nPARENT; do hereby jointly affirm on this the  (Day), of (Month), \\n_ (Year), the following: \\n \\nPART A: \\nSTUDENT INFORMATION AND DOCUMENTS \\n \\n1. We, STUDENT and PARENT, hereby, declare that the information and mandatory \\ndocuments provided by me to the Presidency University  at the time of Admission are  \\naccurate and true to the best of my knowledge and belief, and based on records. We, \\nfurther acknow ledge that, the admission of the STUDENT may be cancelled, at any \\nstage, if the information provided by us are found to be incorrect and/or fabricated, \\nand/or eligibility conditions for admission to the Program of study are not \\nsubstantiated and proved by authentic documents. \\n \\n2. We, STUDENT and PARENT, hereby undertake, to inform the University  about any \\nchanges in information regarding the communication address, mobile numbers of the \\nSTUDENT and PARENT submitted by us to the University  at the time of Admission or \\nin any other University documents.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='72  \\n \\n \\nPART B: \\n  \\nUNIVERSITY REGULATIONS AND STUDENT HANDBOOK: RULES, POLICIES AND CODE \\nOFCONDUCT FOR STUDENTS \\n \\n3. I, STUDENT, hereby declare that I have carefully read and fully understood the \\nAcademic Regulations, Program Regulations and Curriculum Policies and Student \\nHandbook: Rules, Policies and Code of Conduct for Students. I hereby promise to \\nabide by, and, adhere to all the University Regulations, Rules, Policies and Code of \\nConduct prescribed therein. \\n \\n4. I, STUDENT will adhere to all University  Notifications, Circulars and Rules issued \\nby the University from time to time. \\n \\n5. I, STUDENT, hereby  declare that, I  shall be solely responsible for any  kind of \\nviolation of the undertakings and declarations that I have given herewith, and shall be \\nliable for the penalties to the extent of expulsion from the University. \\n \\nPART C: \\n \\nUGC REGULATIONS ON CURBING THE MENACE OF RAGGING IN HIGHER \\nEDUCATIONALINSTITUTIONS, 2009 \\n \\n6. I, STUDENT, have accessed the copy of the UGC Regulations on Curbing the Menace \\nof Ragging in Higher Educational Institutions, 2009, posted on the website \\n(www.presidencyuniversity.in) of Presidency University, and have carefully read it and \\nfully understood the law prohibiting ragging and the directions of the Supreme Court \\nand the Central/State Government in this regard. \\n \\n7. I, STUDENT, hereby undertake that \\n(a.) I will not indulge in any behaviour or act that may come under the definition of \\nragging.  \\n \\n(b.) I will not participate in or support or propagate ragging in any form.  \\n \\n(c.) I will not hurt anyone physically or psychologically or cause any other harm.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='73  \\n \\n \\n8. I, STUDENT, hereby agree  that if found guilty of any aspect of ragging, I may be \\npunished as per the provision of the UGC Regulations mentioned above and/or as per \\nthe law in force. \\n9. I, STUDENT, hereby affirm that I have not been expelled or debarred  from \\nadmission by any institution. \\n \\nUNDERTAKING BY PARENT/ GUARDIAN \\n10. I,  _Father/Mother/Guardian of \\n , have carefully read and fully understood the law \\nprohibiting ragging and the directions of the Supreme Court and the Central/ State \\nGovernment in this regard as well as the UGC Regulations on  Curbing the Menace of \\nRagging in Higher Educational Institutions, 2009. \\n11. I assure you that my son/ daughter/ ward will not indulge in any act of \\nragging. \\n12. I hereby agree that if he/she is found guilty of any aspect of ragging, he/she \\nmay be punished as per the provisions of the UGC Regulations mentioned above and/or \\nas per the law in force. \\n \\n \\nDate: _/ /  \\n \\nSignature: Address: \\nName: \\n \\n \\nPART D: \\n \\nPREVENTION OF SEXUAL HARASSMENT \\n13. I, STUDENT have carefully read and fully understood the Policy on \\nPrevention of Sexual Harassment (Section 24.0 of Student Handbook: Rules, \\nPolicies and Code of Conduct for Students) \\n \\n14. I, STUDENT hereby undertake that I will not indulge in any behaviour or \\nact that may come under the definition of Sexual Harassment. \\n15. I, STUDENT hereby agree that if found guilty of any aspect of Sexual \\nHarassment, I may be punished as per the provision of the Policy mentioned \\nabove and/or as per the law in force.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='74  \\n \\nPART E: \\nPERMANENT FORM OF PERMISSION AND INDEMNITY \\n16. I, STUDENT, hereby declare that my participation in all the University  \\nactivities such as travel on industrial internship, tours and participation in \\nsimilar curricular and extra- curricular programs which may involve \\nactivities, industrial tours  and other expeditions/tournaments organized by \\nthe University is fully on my own will and in full agreement with the \\nPermanent Form of Permission and Indemnity. \\n \\n17. I, PARENT, hereby give my consent to my son/daughter/ward as  named \\nabove, for participating in the co- curricular and extra-curricular activities \\norganized by the University and for travelling on University Industrial Tours, \\nTraining, Internship and Placement related travel, excursions, expeditions, \\ntournaments and other outstation tours organized/approved by the \\nUniversity. \\n \\n18. I, PARENT, hereby: \\n(a.) agree to pay the University charges specified for the participation in \\nsuch activities/tours and/or as determined and demanded by the \\nUniversity; \\n \\n(b.) agree to reimburse the cost of any equipment issued to my \\nson/daughter/ward on such tours/expeditions, if lost or damaged, as \\nmay be determined by the University; \\n \\n \\n(c.) indemnify Presidency University, Bengaluru and its Authorities and \\nOfficers, against any accident to life or limb that may occur to my \\nson/daughter/ward on such tours/expeditions and to reimburse the \\ncost of any medical expense arising out of such  accident and/or my \\nson/daughter/ward’s sickness during such expeditions and tours; \\nand, \\n \\n(d.) Un dertake to absolve Presidency University , Bengaluru, its Authorities \\nand Officers, from all liabilities in case of any accident/mishap occurring to \\nmy son/daughter/ward in any such expeditions and tours.'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='75  \\n \\n \\nName of Father/Mother/Legal Guardian Name of Student: \\nID Number: \\nName and Signature of Witness 1 Name and Signature of Witness 2 \\nSignature of PARENT \\n(Father/Mother/Legal Guardian) \\nSignature of STUDENT \\n \\n \\nPlace:  Date:   \\n  \\n<NOTARIZED>'),\n",
       " Document(metadata={'source': 'data\\\\Student-Book.pdf'}, page_content='www.presidencyuniversity.in\\nIttagalpura, Rajanukunte, Yelahanka, Bengaluru 560 119')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16a0a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "    )\n",
    "    texts_chunk = text_splitter.split_documents(minimal_docs)\n",
    "    return texts_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fed641a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 2353\n"
     ]
    }
   ],
   "source": [
    "texts_chunk = text_split(minimal_docs)\n",
    "print(f\"Number of chunks: {len(texts_chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65ed66c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              1 \\n \\n  \\n \\nAcademic Regulations'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              2 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nRegulation No.: PU/AC-26/6/07_2025 \\n \\nResolution No. 26.6 of the 26th Meeting of the Academic Council held on \\n25/07/2025 and ratified by the Board of Management in its Meeting held on \\n28/07/2025 \\n \\n \\n              \\n \\n \\nJuly 2025 \\n \\n \\n \\n \\n \\n \\n \\n \\nAcademic Regulations'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              3 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n[Left Blank intentionally]'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              4 \\n \\nContents \\nPRELIMINARY ........................................................................................................................................ 5 \\n1.0    INTRODUCTION ....................................................................................................................... 6'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='2.0    ACADEMIC CALENDAR .......................................................................................................... 7 \\n3.0    REGISTRATION ........................................................................................................................ 7 \\n4.0    MEDIUM OF INSTRUCTION AND EVALUATION .......................................................... 11'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='5.0    COURSE CREDIT STRUCTURE .......................................................................................... 11 \\n6.0    PROGRAM REGULATIONS AND CURRICULUM (PRC) ............................................... 12 \\n7.0    ATTENDANCE REQUIREMENTS ........................................................................................ 13 \\n8.0    TEACHING, EVALUATION AND GRADING SYSTEM .................................................. 14'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='9.0    ACADEMIC PERFORMANCE INDICES: SGPA AND CGPA ........................................ 19 \\n10.0  DISPLAY OF PERFORMANCE IN CONTINUOUS ASSESSMENTS ........................... 20 \\n11.0  DETAILED SCHEDULE OF EXAMINATIONS .................................................................. 21 \\n12.0  APPEAL FOR REVIEW OF GRADES .................................................................................. 21'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='13.0  MAKE-UP EXAMINATIONS .................................................................................................. 22 \\n14.0  ACADEMIC PROMOTION ..................................................................................................... 23 \\n15.0  SUMMER TERM ....................................................................................................................... 24'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='16.0  WITHDRAWAL FROM THE PROGRAM ............................................................................. 26 \\n17.0  TRANSFER OF CREDITS ...................................................................................................... 26 \\n18.0  MAXIMUM DURATION FOR THE COMPLETION OF A PROGRAM ........................... 28 \\n19.0  REQUIREMENTS FOR THE AWARD OF DEGREE ......................................................... 29'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='20.0   PROVISIONAL DEGREE CERTIFICATE ........................................................................... 30 \\n21.0   CONVOCATION ....................................................................................................................... 30 \\n22.0   ISSUE OF DEGREE CERTIFICATE BEFORE THE CONVOCATION ......................... 30 \\n23.0  POWER TO REVISE, MODIFY AND AMEND .................................................................. 31'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='ANNEXURE A ....................................................................................................................................... 32 \\nANNEXURE B ....................................................................................................................................... 34 \\nANNEXURE C ....................................................................................................................................... 35'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='ANNEXURE D ....................................................................................................................................... 36'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              5 \\nAcademic Regulations \\nIn exercise of the powers conferred by and in discharge of duties assigned under the relevant \\nprovision(s) of the Act and Statutes of the Presidency University, the Academic Council hereby \\nmakes the following Regulations, namely.  \\nPRELIMINARY  \\nShort Title and Commencement'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='These Regulations shall be called the Academic Regulations. They shall come into force with \\nimmediate effect.  \\nDefinitions  \\nIn these Regulations, unless the context otherwise requires:  \\na) “Academic Calendar” means the schedule of academic and miscellaneous events as \\napproved by the Vice Chancellor;  \\nb) “Academic Council” means the Academic Council of the University;  \\nc) “Academic Regulations” means the Academic Regulations, of the University;'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='d) “Academic Term” means a Semester or Summer Term  \\ne) “Act” means the Presidency University Act. 2013;  \\nf) “BOG” means the Board of Governors of the University; \\ng) \"BOM” means the Board of Management of the University; \\nh) “BOE” means the Board of Examinations of the University;  \\ni) “BOS” means the Board of Studies of a particular Department/Program of Study of the \\nUniversity;  \\nj) “Basket” means a group of  Courses bundled together based on the nature/type of the \\nCourse.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Course.  \\nk) “COE” means the Controller of Examinations of the University;  \\nl) “Clause” means the duly numbered Clause, with Sub-Clauses included, if any, of these \\nRegulations;  \\nm) “Course” means a specific subject usually identified by its Course-code and Course-title, \\nwith specified credits and syllabus/course -description, a set of references, taught by \\nsome teacher(s)/course -instructor(s) to a specific class (group of students) during a \\nspecific Academic Term;'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='n) “Course In Charge” means the teacher/faculty member responsible for developing and \\norganising the delivery of the Course; \\no) “Course Instructor” means the teacher/faculty member responsible for teaching and \\nevaluation of a Course;'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              6 \\np) “Curriculum Structure” means the Curriculum governing a specific Degree Program \\noffered by the University, and, includes the set of Baskets of Courses along with \\nminimum credit requirements to be earned under each basket for a degree/degree with \\nspecialization/minor/honours in addition to the relevant details of the  Courses an d'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Course catalogues (which describes the Course content and other important information \\nabout the Course). Any specific requirements for a particular program may be brought \\ninto the Curriculum structure of the specific program and relevant approvals should  be \\ntaken from the BOS and Academic Council at that time.  \\nq) “DAC” means the Departmental Academic Committee of a concerned \\nDepartment/Program of Study of the University;  \\nr) “Dean” means the Dean/Director of the concerned School;'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='s) “Degree Program” includes all Degree Programs;  \\nt) “Department” means the Department offering the degree Program(s)/Course(s)/School \\noffering the concerned Degree Programs/other Administrative Offices;  \\nu) “HOD” means the Head of the Department;  \\nv) “MOU” means the Memorandum of Understanding;  \\nw) “Parent Department” means the department that offers the Degree Program that a \\nstudent undergoes;  \\nx) “School” means a constituent institution of the University established for monitoring,'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='supervising and guiding, teaching, trai ning and research activities in broadly related \\nfields of studies;  \\ny) “Section” means the duly numbered Section, with Clauses included in that Section, of \\nthese Regulations;  \\nz) “Statutes” means the Statutes of Presidency University;  \\naa) “Sub-Clause” means the duly numbered Sub-Clause of these Regulations;  \\nbb) \"Summer Term” means an additional Academic Term conducted during the summer \\nbreak;'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='break;  \\ncc) “University” means Presidency University, Bengaluru; and  \\ndd) “Vice Chancellor” means the Vice Chancellor of the University.  \\n1.0 INTRODUCTION  \\n1.1 The Academic Regulations  are applicable to all existing Degree Programs of the \\nUniversity. The Academic Regulations, and any amendments made therein, shall also \\nbe applicable to new Degree , Diploma and Certificate Programs that the University \\nmay offer in the future.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              7 \\n \\n1.2 These Regulations are in compliance with the University Grants Commission \\n(Minimum Standards of Instruction for the Grant of Undergraduate Degree and \\nPostgraduate Degree) Regulations, 2025. The specific criteria and mandatory \\nrequirements prescribed by this UGC Regulations 2025, shall be included in the \\nProgram Regulations and Curriculum (PRC) of the respective program.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='1.3 Further amendments  and a dditional Regulations, if any, and specific \\ncriteria/mandatory requirements prescribed by the concerned Regulatory Bodies for \\na particular Degree Program shall be included in the Program Regulations and \\nCurriculum (PRC) of the respective program.  \\n1.4 These Regulations may evolve and get amended or modified or changed through \\nappropriate approvals from the Academic Council, from time to time, and shall be \\nbinding on all concerned.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='1.5 The effect of periodic amendments or changes in the Academic Regulations , on the \\nstudents admitted in earlier years, shall be dealt with appropriately and carefully, to \\nensure that those students are not subjected to any unfair situation whatsoever, \\nalthough they are required to conform to these revised Academic Regulations, \\nwithout any undue favour or considerations.  \\n2.0 ACADEMIC CALENDAR  \\n2.1 The academic activities of the University are regulated by the Academic Calendar'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='approved by the Vice Chancellor and  released at the beginning of each Academic \\nYear. The Academic Calendar indicating all academic activities in chronological order, \\nshall be prepared by the Office of Dean - Academics and approved by the Vice \\nChancellor. After approval, the same shall be released by the Dean - Academics at \\nleast two weeks prior to the  commencement of the concerned academic year . It is \\nmandatory for both students and faculty to strictly adhere to the academic calendar'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='to ensure timely completion of  academic activities. Deviations , if any , under \\nunforeseen/unavoidable circumstances shall be allowed with the prior approval of the \\nVice Chancellor, and the same should be duly notified.  \\n2.2 An academic year at the University shall normally be divided into two semesters \\nconsisting of ninety (90) University working days each, known as the Odd Semester \\n(normally from August to December) and the Even Semester (normally from January \\nto May).'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content=\"to May).  \\n2.3 During the summer break, i.e., (June and July), there may be an additional Academic \\nTerm known as the Summer Term. The duration of the Summer Term is around eight \\n(08) calendar weeks and shall include a minimum of thirty (30) instructional days.  \\n3.0 REGISTRATION  \\n3.1 The registration process is a fundamental aspect of the University's academic \\nframework, designed to provide a structured procedure for students to select and\"),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='enrol in Courses that align with program requirements and their academic goals.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              8 \\n3.2 Registration for the relevant Academic Term  ensures timely progression in the \\nprogram by adhering to guidelines regarding Course prerequisites, necessary Courses \\nas per curriculum requirements, and the credits required for the timely completion of \\nthe minimum credit requirements for the award of the respective degree.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='3.3 The registration at the beginning of each Semester during the prescribed period \\nannounced in the Academic Calendar and through notifications issued by the \\nUniversity to this effect, is mandatory for every student.  \\n3.4 Registration is the sole responsibility of the student. Without registration, any \\nacademic activity (Course  / Seminar / Practical / Project Work / Internship, etc.) \\nundergone by a student will not be counted towards the requirements of their Degree.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='3.5 The Chairperson of each Departmental Academic Committee (DAC) shall \\ncommunicate the list of approved/prescribed Courses available for registration in the \\nconcerned Academic Term to the Office of the Dean - Academics for notification. (The \\nconstitution and functions of the Departmental Academic Committee (DAC) are \\nplaced in ANNEXURE A.) \\n3.6 Upon joining the University, each student is assigned to a mentor who will counsel'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='and guide the student on matters related to academic s/registration process. Every \\nstudent after consulting her/his mentor is required to register for Courses of his/her \\nchoice from the list of proposed Courses within the time period specified for such \\nregistration as notified in the Academic Calendar or the University notification to this \\neffect.  \\n3.7 Normally, late registration is not permitted. However, considering medical exigencies,'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='specifically hospitalization, trauma, including death of immediate family members \\n(Parents, Offspring, Siblings and Spouse) or contagious disease, a student may be \\npermitted for late registration with prior approval from the respective H oD. The \\nstudent must produce medical certificates, medical prescriptions, hospital discharge \\nreport, medical fitness report and all such releva nt documents duly attested by the'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='concerned registered medical officer of the hospital where the concerned student was \\nhospitalized or medically treated. The student shall not be eligible for late registration \\nif she/he fails to produce authentic medical c ertificates and relevant documents in \\nsupport of the medical exigency.  \\n3.7.1 Further, in such specified cases of medical exigency (viz. hospitalization, \\ntrauma or contagious disease only), the maximum period permissible for late'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='registration shall not exceed Eighteen (18) University working days counted \\nfrom the commencement of the semester (only Odd and Even semesters) as \\nannounced by the University. Under no circumstances shall such a student \\nbe permitted to register for the semester after the permissible period for late \\nregistration of Eighteen (18) University working days counted from the \\ncommencement of semester.  \\n3.7.2 Further, if a student has been selected/nominated by State/National/'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='International Organizations/Boards to represent th e State and/or India in \\nState/National/International Competitions/Events,  as recommended by the'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              9 \\nDepartment and approved by the Vice Chancellor, the concerned student may \\nbe permitted for late registration. The student must produce duly attested \\ndocuments and/or certificates to be eligible for the provision of late \\nregistration. The number of days for which the concerned student will be \\ngiven permission for late registration shall be approved by the Vice Chancellor'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='based on the recommendation of the Dean of the School concerned. Further, \\nno relaxation will be given on attendance requirements, except as permissible \\nunder Clause 7.4.  \\n3.8 In case of any other reason for late registration other than the specified medical \\nexigencies outlined in Clause 3.7 above, the maximum permissible period for late \\nregistration shall not exceed FIVE (05) University working days counted from the'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='specified date of Registration announced by the University. The  student shall pay a \\nLate Fee for late registration, as specified by the University at the commencement of \\nthe semester. Further, no relaxation whatsoever will be given on attendance \\nrequirements for late registration. Under no circumstances will such a student be \\npermitted to register for the semester after the permissible period for late registration'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='of FIVE (05) University working days counted from the specified date of Registration.  \\n3.9 Students are not permitted to re -register for Courses which t hey have already \\npassed, except under the provisions and conditions  mentioned in Clauses/Sub-\\nClauses 7.6, 8.14, 8.15.3 and 14.4 to improve their performance. \\n3.10 A student shall be permitted to register only if all of the following conditions are \\nfulfilled:'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='fulfilled:  \\n3.10.1 The student has paid all specified fees to the University as per the University \\nFee Policy and payment schedule; \\n3.10.2 The student has cleared all University, Hostel, Transport and Library dues (if \\nany); \\n3.10.3 The student fulfils the yearly promotion criteria as stipulated in Section 14.0; \\nand  \\n3.10.4 The student has not been debarred from registering on any specific ground \\nby the University.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='3.11 Course Pre-Requisites: To register for some Courses, students may be required to \\nhave prior exposure to  or passed some specified Courses. Such Course pre-\\nrequisites shall be specified in the concerned Program Regulations and Curriculum \\n(PRC) as approved by the DAC and the BOS. If a student has secured an NP (Not \\nPermitted) Grade (Clause 8.14) due to a shortage of attendance in the pre-requisite \\nCourse(s), the student will not be permitted to register for the concerned Course(s).'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='3.12 Failure to Register and Removal from the Rolls: A student who is eligible for \\nregistration but  fails to register for the Semester within the specified dates and \\nconditions prescribed in Clauses 3.1 to 3.8, shall be removed from the rolls for the \\nconcerned semester. Consequently, the student shall not be permitted to attend \\nclasses for the concerned semester.  The student is cautioned that this will'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              10 \\nresult in the loss of an Academic Year for the student . Such a student shall \\nbe required to discontinue the Program temporarily and shall rejoin the Program of \\nstudy by completing the Registration process in the applicable Semester of the \\nfollowing Academic Year, and shall adhere to the Academic Regulations and Program'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulations and Curriculum applicable to the batch in which the student is rejoining \\nthe Program of study.  \\n3.13 Mandatory Pre -Registration ( for Elective/Specialization/Open Courses) for higher \\nsemesters: In order to facilitate proper planning of academic activities of a \\nsemester, it is essential for students to declare their intent to register for an \\nElective/Specialization/Open Course well in advance, before the actual start of the'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='concerned Academic Term , through the process of Pre -Registration. All students \\n(other than the freshly admitted students) intending to register for the next higher \\nsemester are required to have completed the Mandatory Pre -Registration of \\nElective/Specialization/Open Course(s),  as applicable , as per the schedule/dates \\nannounced in the Academic Calendar and/or the official notifications issued  by the \\nUniversity to this effect. To facilitate this Pre -Registration process all teaching'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Departments/Schools shall announce the list of Courses to be offered for the next \\nhigher semester, at least four (04) University working weeks before the last day of \\nclasses in the current semester.  \\n3.14 The University reserves the right to withhold registration or to cancel the \\nregistration of any studen t who is not in compliance with the University’s \\nregulations, policies, and rules. \\n3.15 Registration for each semester must be completed in a sequential manner. Failure'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='to register for a semester will result in the loss of an academic year, as the missed \\nsemester must be completed (in the following Academic Year) before registering in \\nthe subsequent semester of the Program of study. \\n3.16 Audit a Course \\n3.16.1 Auditing a Course is a provision for a student who may opt to register for \\na Course to acquire knowledge/skills, without earning credits and grade \\npoints. \\n3.16.2 A student who desires to register to Audit a Course shall consult her/his'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='mentor and seek approval of the concerned Course Instructor. Registration \\nto Audit a Course shall only be permitted as per the criteria and guidelines \\nprescribed by the concerned Course Instructor and duly approved by the \\nconcerned Departmental Academic Committee (DAC). The student will not \\nearn credits for the Audited Course. \\n3.16.3 Auditing is not available during the Summer Term. \\n3.16.4 Audit is not permitted in Courses that involve laboratory/field/studio work,'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='or other types of practice-based instruction. \\n3.16.5 Audited Courses shall not count towards fulfilling degree requirements.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              11 \\n4.0 MEDIUM OF INSTRUCTION AND EVALUATION  \\nEnglish shall be the medium of instruction and evaluation , except for specific Courses as \\napproved by the Academic Council.  \\n5.0 COURSE CREDIT STRUCTURE  \\nThe credit structure is used to define various types of  Courses, ensuring the appropriate \\npedagogy and methods of assessment and evaluation. The flexibility required to'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='accomplish the  Course learning objectives and outcomes can be provided for, while \\nretaining a common framework for credit allocation. More importantly, it is necessary to \\nhave a transparent, credible and robust system for the planning, delivery and evaluation \\nof each Course within the diverse programs of study offered by the University.  \\n5.1 The Credit Structure for defining and categorizing Courses follows the L-T-P-C'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='(Lecture - Tutorial- Practical - Credit) framework. Credits are assigned based on the \\nfollowing norms:  \\nLecture: One (01) contact/classroom hour per week for 15 weeks is assigned One \\n(01) Credit.  \\nTutorial: One (01) contact/classroom hour per week for 15 weeks is assigned One \\n(01) Credit  \\nPractical: Two (02) hours per week of practical/laboratory/ studio/field work and \\nother similar practice or skill development components  for 15 weeks, are assigned \\nOne (01) Credit.  \\nFor example:'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='For example:  \\n\\uf0b7 A Course with L-T-P structure of 3–0–0 will be assigned 3 Credits. \\n\\uf0b7 A Course with L-T-P structure of 3–1–0 will be assigned 4 Credits. \\n\\uf0b7 A Course with L-T-P structure of 3–0–2 will be assigned 4 Credits.  \\n\\uf0b7 A Course with L-T-P structure of 0–0–4 will be assigned 2 Credits.  \\n\\uf0b7 A Course with L-T-P structure of 2–0–2 will be assigned 3 Credits.  \\n\\uf0b7 A Course with L-T-P structure of 1-0-4 will be assigned 3 Credits'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='In effect, a 3-Credit Course with structure of 3-0-0 mandatorily requires 45 hours of \\nContact/Classroom hours . Similarly, a  3-Credit Course with structure 1 -0-4 \\nmandatorily requires 15 hours of Contact/Classroom hours and 60 hours of \\nPractice/Lab hours. \\n5.2 Practical/Skill based Courses like Capstone Project, Internship, Industry Immersion, \\nInternational Immersion, Project Work, Studio, Field Visits, Dissertation, Seminar,'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='and such similar Courses  including Portfolio, Interdisciplinary Projects and Social \\nImmersion Courses, where the pedagogy does not lend itself to a typical L-T-P-C \\nstructure as defined in Clause 5.1, are assigned the number of Credits based on the \\nquantum of work/effort required to fulfil the learning objectives and outcomes'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              12 \\nprescribed for the concerned Courses , referred to as Non -Teaching Credit Courses \\n(NTCC).  \\n5.3 A student earns credits by satisfactorily undergoing the Course evaluation. The \\ncredits associated with a Course are dependent upon the number of hours of \\ninstruction in that Course. \\n6.0 PROGRAM REGULATIONS AND CURRICULUM (PRC)'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='The Program Regulations and Curriculum (PRC) is a set of Program specific regulations, as \\napplicable, and the Program Structure and Curriculum for the concerned Degree Program. All \\nAcademic Programs (except the Ph.D. Program) shall be governed by the respective Program \\nRegulations and Curriculum. The Program Regulations and Curriculum shall be recommended by \\nthe concerned Board of Studies for approval of the Academic Council . The program leading to'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='the award of a Ph.D. degree  shall be governed by the Ph.D. Regulations , which shall be \\nrecommended by the Research and Innovation Council of the University for Approval of the \\nAcademic Council.   \\nThe Program Regulations and Curriculum for all Undergraduate and Postgraduate Programs shall \\ninclude details with respect to Eligibility for Admission, Program duration, mandatory minimum \\ncredit requirements for the award of the Degree, assessment and evaluation guidelines/criteria,'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='and any other regulations mandated by concerned Government Regulatory Bodies, where \\napplicable, for the specific Program of study. \\n6.1 Eligibility for Admission:  \\n6.1.1 The basic eligibility for the admission to all Programs of the University shall \\nbe as per the norms specified by the respecti ve statutory  bodies such as \\nUniversity Grants Commission (UGC), All India Council for Technical \\nEducation (AICTE), Bar Council of India (BCI), Karnataka State Higher'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Education Council (KSHEC) and other relevant statutory bodies.  \\n6.1.2 Lateral Entry, where applicable, i.e. admission to the second year of a \\nProgram, shall be as per the norms specified by the respective statutory  \\nbodies such as UGC, AICTE, BCI, KSHEC and other relevant statutory bodies.  \\n6.1.3 A student who seeks admission to a higher semester of a Program as a \\ntransfer from another University, must comply with the eligibility criteria'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='mentioned above in Sub-Clause 6.1.1. Further, an Equivalence Committee \\n(Refer Annexure B) shall examine the case for Transfer/Lateral Entry and \\nsubmit its report and recommendation for the approval of the Vice Chancellor \\nfor enrolment to the concerned program . The student may need to undergo \\nadditional Courses, as prescribed by the Equivalence Committee to qualify for \\nthe minimum credit requirements as prescribed by the concerned PRC for the \\naward of degree.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='award of degree. \\n6.2 The PRC of respective Programs shall have Program Educational Objectives (PEOs), \\nProgramme Outcomes (POs), Program Specific Outcomes (PSOs), and Curriculum \\nStructure, List of Basket/Component -wise Courses along with other details such as,'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              13 \\nL-T-P-C structure, Pre-Requisites etc. The Course catalogues for all the Courses listed \\nin the Curriculum structure shall also be part of the PRC.  \\n6.3 Assessment and Evaluation scheme: The assessment and evaluation of students in \\nall the academic programs offered in the University (except the Ph.D. program) shall'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='have the components of assessment and weightages as recommended by the \\nrespective BoS and as approved by the Academic Council  from time to time. The \\nrelative grading framework shall be used for evaluation (Refer Clause 8.7). \\nIn order to ensure the fair and equitable assessment of learning for all Non-Teaching \\nCredit Courses (NTCC) offered in the particular Program, the method of assessment \\nshall be prescribed in the PRC.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='6.4 The m inimum number of student registrations required  for the  Courses (except \\nNTCC) shall be defined in the PRC f or offering the  Course in the specific Academic \\nTerm. \\n7.0 ATTENDANCE REQUIREMENTS  \\n7.1 In order to maintain high standards and academic excellence, all students must \\nattend every lecture, tutorial, field work, laboratory, studio, practical classes and all \\nother such curricular sessions as prescribed by the Program Curriculum.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='7.2 To account for approved leave of absence (for instance, representing the University \\nin State/National/International Competitions/Events/Conferences, etc.) and/or other \\ncontingencies like medical emergencies,  the attendance requirement shall be a \\nminimum of 75% of the classes actually conducted in every Course, for which the \\nstudent has registered in the concerned Academic term. \\n7.3 Further, if a student suffers serious medical exigencies of hospitalization, trauma,'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='including death of immediate family members (Parents, Offspring, Siblings and \\nSpouse) or contagious disease only, the concerned student may be given additional \\nrelaxation in attendance requirement (in Course(s) where there is a shortage) by the \\nVice Chancellor on the recommendations of the Dean of the School concerned. \\nHowever, under no circumstances whatsoever, shall the minimum requirement of \\nattendance be less than 65% o f the classes actually conducted in every Course the'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='student has registered for in the Academic Term. The student shall not be eligible for \\nthis special provision if she/he fails to produce authentic medical certificates and \\nrelevant documents (for other c ases of exemption) in support of the medical \\nexigency.  \\n7.4 Provided further that if a student has been selected/nominated by State/National/  \\nInternational Organizations/Boards to represent the State and/or India in State/'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='National/International Events/Competi tions, for representing the university the \\nconcerned student may be given relaxation in attendance requirement s (in the \\nCourse(s) where there is a shortage) for the concerned period of absence by the Vice \\nChancellor on the recommendations of the Dean of the School concerned.  \\n7.5 Further, where attendance requirements are prescribed by Government Regulatory \\nBodies for specific Programs, the same shall also be mandatorily adhered to without'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              14 \\nexception. Such specific requirements, as applicable, shall be prescribed in the \\nProgram Regulations and Curriculum of the concerned Program of study. \\n7.6 Shortage of Attendance:  \\nA student with shortage of attendance (i.e., less than 75% of the classes actually \\nconducted in every Course in the concerned Academic Term as prescribed by Clause'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='7.2, and other conditions as applicable und er Clauses 7.3 to 7.5), shall not be \\npermitted to appear in the End Term Examinations of the Course(s) in which \\nthe attendance shortfall exists , irrespective of the student’s academic \\nperformance in the components of Continuous Assessments. The student shall be \\ndeclared as “NP” (Not Permitted) Grade (refer Clause 8.14), to indicate that the \\nstudent has not been permitted to appear for the End Term Examinations due to'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='shortage of attendance during the Academic Term in the concerned Course(s).  \\nFurther, a student who has shortage of attendance (received “NP” Grade) in a Course \\nin the concerned Semester, shall be eligible to re -register for the concerned Course \\nin the following Academic Term  (including Summer Term ), subject to all the \\nconditions stated in Clauses 15.4 and 15.5.  \\nThe student is cautioned that this may result in the loss of an Academic Year'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='for the student . It is the sole responsibility of the student to ensure that she/he \\ncompletes the Course(s) in which the student has the NP Grade, and, earn the \\nminimum mandatory required credits as prescribed by the PRC of the concerned \\nprogram.  \\n8.0 TEACHING, EVALUATION AND GRADING SYSTEM  \\n8.1 Courses from the approved Program Regulations and Curriculum may be offered \\nduring any Academic Term. Each approved Course, whenever  offered in any given'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Academic Term, shall be conducted by the assigned Course Instructor.  \\n8.2 The Course Instructors, for all the Courses , which are  to be offered by the \\nSchool/Department during any Academic Term shall be assigned by the concerned \\nHoD/Dean of School.  (A brief of the functions and responsibilities of the Course \\nInstructor is placed in ANNEXURE C). \\n8.3 Course Plan: Course Plan is prepared for each Course offered (including Non-Teaching'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Credit Courses (NTCC)) in a Program of study during an Academic Term. The Course \\nPlan is generally prepared by the Course In -Charge (Course IC) in consultation with \\nall Course Instructors (as applicable) of concerned Course. The Course Plan shall be \\napproved by the Departmental Academic Committee (DAC).    \\n8.3.1 The Course Plan shall clearly describe the following aspects: Course Name, \\nCourse Code, Credit Structure, Course Description, Contact Hours, Name of'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Course In-Charge and Course Instructor(s),  Course Outcomes, CO – PO & \\nPSO Mapping, Pre -requisites (if applicable) , Course Syllabus, Reference \\nMaterials, Schedule  of Lectures, Tutorials, Pr actical/Lab Sessions (as \\napplicable), with notes on pedagogy,  Schedule of Continuous Assessments \\nand guidelines regarding End Term Examinations (as applicable).'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              15 \\n8.3.2 The Course Plan of every Course offered in an Academic Term  of the \\nconcerned Program shall be made available to all students registered for the \\nconcerned Course. \\n8.4 The academic performance evaluation of a student in a Course shall be according to \\nthe University Letter Grading System based on the class performance distribution in \\nthe Course.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='the Course.  \\n8.5 Academic performance evaluation of every registered student in every Course \\nregistered by the student is carried out through various components of Assessments \\nspread across the Semester. The nature of components of Continuous Assessments \\nand the weightage given to each component of Continuous Assessments (refer Clause \\n8.8) shall be clearly defined in the Course Plan for every Course, and approved by \\nthe DAC.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='the DAC.  \\n8.6 Format of the End-Term examination shall be specified in the Course Plan. \\n8.7 Grading is the process of rewarding the students for their overall performance in each \\nCourse. The University follows the system of Relative Grading with statistical \\napproach to classify the students based on the relative performance of the students \\nregistered in the concerned Course except in the following cases:  \\n• Non-Teaching Credit Courses (NTCC) \\n• Courses with a class strength less than 30'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Absolute grading method may be adopted, where necessary with prior approval of \\nconcerned DAC. \\nGrading shall be done at the end of the Academic Term by considering the aggregate \\nperformance of the student in all components of Assessments prescribed for the \\nCourse. Letter Grades (Clause 8.10) shall be awarded to a student based on her/his \\noverall performance relative to the class performance distribution in the concerned'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Course. These Letter Grades  not only indicate a qualitative assessment of the \\nstudent’s performance but also carry a quantitative (numeric) equivalent called the \\nGrade Point.  \\n8.8 Assessment Components and Weightage \\nTable 8.8 Assessment Components and Weightage for different category \\nof Courses \\nNature of Course and Structure Evaluation \\nComponent Weightage \\nLecture-based Course \\nL component in the L-T-P Structure is \\npredominant (more than 1)'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='(Examples: 3-0-0; 3-0-2; 2-1-0; 2-0-2, 2-0-4 \\netc.) \\nContinuous \\nAssessments \\n50% to \\n60% \\nEnd Term \\nExamination \\n40% to \\n50% \\nLab/Practice-based Course Continuous \\nAssessments \\n75% to \\n100%'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              16 \\nP component in the L-T-P Structure is \\npredominant \\n(Examples: 0-0-4; 1-0-4; 1-0-2; etc.) \\nEnd Term \\nExamination 0 to 25% \\nSkill based Courses like Industry Internship, \\nCapstone project, Research Dissertation, \\nIntegrative Studio, Interdisciplinary Project, \\nSummer / Short Internship, Social Engagement \\n/ Field Projects, Portfolio, and such similar Non-'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Teaching Credit Courses, where the pedagogy \\ndoes not lend itself to a typical L-T-P structure \\nGuidelines for the assessment \\ncomponents for the various types \\nof Courses, with recommended \\nweightages, shall be specified in \\nthe concerned Program \\nRegulations and Curriculum /  \\nCourse Plans, as applicable. \\nThe exact weightages of Evaluation Components shall be clearly specified in the \\nconcerned PRC and respective Course Plan.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Normally, for Practice/Skill based Courses, without a defined credit structure (L –T–\\nP) [NTCC], but with assigned Credits (as defined i n Clause 5.2 of the Academic \\nRegulations), the method of evaluation shall be based only on Continuous \\nAssessments. The various components of Continuous Assessments, the distribution \\nof weightage among such components, and the method of evaluation/assessment, \\nshall be as decided and indicated in the Course Plan/PRC. The same shall be approved'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='by the respective DAC.  \\n8.9 Minimum Performance Criteria:  \\n8.9.1 Theory only Course and Lab/Practice Embedded Theory Course  \\nA student shall satisfy the following minimum performance criteria to be \\neligible to earn the credits towards the concerned Course:  \\na. A student must obtain a minimum of 30% of the total marks/weightage \\nassigned to the End Term Examinations in the concerned Course.  \\nb. The student must obtain a minimum of 40% of the AGGREGATE of the'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='marks/weightage of the components of Continuous Assessments, Mid \\nTerm Examinations and End Term Examinations in the concerned \\nCourse.  \\n8.9.2 Lab/Practice only Course and Project Based Courses  \\nThe student must obtain a minimum of 40% of the AGGREGATE of the \\nmarks/weightage of all assessment components in the concerned Course.  \\n8.9.3 A student who fails to meet the minimum performance criteria listed above \\nin a Course shall be declared as “Fail” and given “F” Grade in the concerned'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Course. For theory  Courses, the student shall have to re -appear in the \\n“Make-Up Examinations” as scheduled by the University in any subsequent \\nsemester, or, re-appear in the End Term Examinations of the same Course \\nwhen it is scheduled at the end of the following Semester or Summer Term, \\nif offered. The marks obtained in the Continuous Assessments (other than \\nthe End Term Examination) shall be carried forward and be included in'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              17 \\ncomputing the final grade, if the student se cures the minimum \\nrequirements (as per Clause 8.9.1, 8.9.2) in the “Make-Up Examinations” \\nof the concerned Course. Further, the student has an option to re -register \\nfor the  Course and clear the same in the summer term/ subsequent \\nsemester if he/she wishes to do so, provided the Course is offered.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='8.10 Letter Grades & Grade Points: The University follows the system of Letter Grades \\nwith associated Grade Points on a scale of 10. The Letter Grades and associated \\nGrade Points along with a brief qualitative description are summarized in Table 8.10:  \\n \\nTable 8.10 Letter Grades with Grade Points and Brief Qualitative \\nDescription \\nLetter Grade Grade Point Qualitative Description \\nO 10 Outstanding \\nA+ 9 Excellent \\nA 8 Very Good \\nB+ 7 Good \\nB 6 Above Average \\nC 5 Average \\nD 4 Pass \\nF 0 Fail'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='D 4 Pass \\nF 0 Fail \\nNP 0 Not Permitted \\nS – Satisfactorily Completed \\nNC – Not Completed \\nU – Audited Satisfactorily \\nI – Incomplete \\n \\n8.11 Absolute Grading:  \\nThe Letter Grades with Marks Range for the Absolute Grading is as follows:  \\nTable 8.11 Letter Grades with Marks Range for Absolute \\nGrading \\nLetter Grade Marks range (Out of 100) \\nO >= 90 \\nA+ >= 80 but < 90 \\nA >= 70 but < 80 \\nB+ >= 60 but < 70 \\nB >= 55 but < 60 \\nC >= 50 but < 55 \\nD >= 40 but < 50 \\nF < 40'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              18 \\n8.12 Award of the “O” (Outstanding) Grade:  \\nThe “O” grade stands for outstanding achievement, relative to the registered \\nstudents in the Course, and utmost care shall be taken in awarding of this highest \\nletter grade.  \\n8.13 Declaration of the “F” (Fail) Grade:  \\nThe “F” grade denotes failure in a Course and has “0” (Zero) Grade Points. This may'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='be due to the following reasons:  \\n8.13.1 Failure to meet the minimum performance criteria for a Course as listed in \\nClause 8.9  \\n8.13.2 Further, if a student is absent for the End Term Examination of a Course, \\nthe student shall be declared as “Fail” and given a “F” grade in the \\nconcerned Course.  \\n8.14 Declaration of the Placeholder Grades “NP” (Not Permitted):  \\n“NP” is a grade, with “0” (Zero) Grade Points, given in the concerned Course(s) to'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='indicate that a student was not eligible to appear for the End Term Examination of \\nthe concerned Course(s) due to shortage of attendance as elaborated in Section 7.0 \\nand he /she has to re -register in the concerned  Course(s) to earn the necessary \\ncredits.  \\n8.15 Additional Grades with No Grade Points: “S”  (Satisfactorily Completed), “NC” \\n(Not-Completed) and “U” (Audited Satisfactorily) Grades:  \\n8.15.1 “S” and “NC” grades are awarded for specific mandatory Courses as'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='prescribed in the concerned PRC.  \\n8.15.2 “S” grade denotes satisfactory performance and completion of a Course , as \\nspecified in the concerned PRC. The requirements for obtaining “S” grade in \\na particular Course shall be clearly stated in the Course Plan of the concerned \\nCourse.  \\n8.15.3 “NC” grade is given for Non -Completion of Course requirements in the \\nconcerned Course and the student will have to re-register for the Course \\nuntil he/she obtains the “S” grade in the Course concerned.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='8.15.4 “S” and “NC” grades have no associated Grade Points and hence are not \\nincluded in the SGPA/CGPA calculations (refer Section 9.0).  \\n8.15.5 “U” grade is awarded in a  Course that a student opts to register for Audit \\n(refer to Clause 3.16) and successfully completes . It is not mandatory for \\nthe student to go through the entire regular process of evaluation for the \\nconcerned Course. However, the student must satisfy the minimum'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='attendance requirement for securing the “U” grade, failing which, that  \\nCourse will not be listed in the Grade Card given to the concerned student \\n(refer to Clause 8.17).'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              19 \\n8.16 Additional Placeholder Grade “I” with no Grade Points:  \\n“I” (“Incomplete”) Grade is a placeholder grade which denotes “incomplete” in any \\nCourse or Courses, due conditions mentioned below  in sub -clauses 8.16.1 and \\n8.16.2. \\n8.16.1 Absence at the End Term Examination solely due medical exigencies \\nspecifically hospitalization, trauma, including death of immediate family'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='members (Parents, Offspring, Siblings and Spouse) or contagious disease \\nonly, and gets replaced by an appropriate regular letter grade after the \\nstudent completes the performance evaluation for the  Course(s) concerned \\nin the “Make-Up Examinations” (refer to Section 13.0).  \\n8.16.2 Malpractice case (under investigation) reported against the student in the \\nEnd Term Examination of concerned Course. The placeholder grade “I” shall'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='be replaced with a regular grade based on recom mendations of the Unfair \\nMeans and Malpractices Committee (UMMC) (as constituted and provisioned \\nby the Examination Regulations of the University) and the subsequent \\napproval and decision of the Chairperson, BOE.  \\n8.16.3 The Course(s) in which a student has received “I” grade shall not be included \\nin the SGPA/CGPA calculations. (Refer Section 9.0).  \\n8.17 Grade Card:'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='8.17 Grade Card:  \\nGrade Card is a record of a student’s performance in the Courses for which the \\nstudent has registered for in a concerned Academic Term of the Program of study.  \\nThe Grade Card shall contain the following details pertaining to the student’s \\nacademic performance:  \\n8.17.1 The List of Courses (which includes Course Name, Course Code and \\nassociated Credits) registered by the student in the concerned Academic \\nTerm.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Term.  \\n8.17.2 The Grade obtained in each of the concerned Courses.  \\n8.17.3 The SGPA and CGPA obtained by the student.  \\n8.17.4 Total credits registered and completed  in the ongoing Program of study \\nincluding the concerned Academic Term.  \\n9.0 ACADEMIC PERFORMANCE INDICES: SGPA AND CGPA  \\n9.1 The overall academic performance of a student shall be measured by two indices: \\nSGPA which is the “ Semester Grade Point Average” and CGPA which is the \\n“Cumulative Grade Point Average”.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='9.2 The performance of a student in a Semester is indicated by a number, Semester \\nGrade Point Average . The SGPA is the weighted average of the grade points \\nsecured in all the concerned Courses registered by the student during that Semester. \\nSGPA for a particular Semester is computed as follows:'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              20 \\n  \\nwhere:  \\nn is the number of all Courses (with Letter Grade s and Grade Points, including the \\nLetter Grades F and NP, which have zero grade points) registered by the student \\nin the Semester concerned;  \\nCk is the Credits assigned to Course k and  \\nGk is the Grade Point received by the student for the Course k.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='9.3 The Cumulative Grade Point Average indicates overall academic performance of \\na student in all the Courses registered up to and including the latest completed \\nsemester. CGPA is computed as follows:  \\n  \\nwhere:  \\nn is the number of all the Courses (with Letter Grades and Grade Points, including \\nthe Letter Grades F  and NP, which have zero grade points) registered by the \\nstudent up to, and including the latest completed Academic Term;'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Ci is the Credits assigned to Course i and Gi is the Grade Point received by the student \\nfor the Course i.  \\n9.4 The SGPA and CGPA are calculated to TWO decimal places.  \\n10.0  DISPLAY OF PERFORMANCE IN CONTINUOUS ASSESSMENTS  \\n10.1 The performance of all students in the components of Continuous Assessments for \\nall Courses registered in the concerned Academic Term, shall be communicated to \\nthe students and displayed in the concerned Department/School by the respective \\nHOD/Dean.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='HOD/Dean.  \\n10.2 The concerned HOD/Dean shall attest and submit to the COE, a consolidated marks \\nsheet of the continuous assessment marks, where applicable,  obtained by all \\nstudents of a Program of study, in all the respective Courses registered in the \\nconcerned Academic Term, before the commencement of the End Term Examination.  \\n10.3 Answer scripts of Mid Term Examination , where applicable,  of the Course shall be'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='shown to the students for discussion, verification and corrections (if any) on pre -\\nnotified date(s) in class. \\n10.3.1 Answer books shall be shown to the students by the Faculty/Course \\nInstructor of the Department as per the schedule announced by the \\nDepartment/ School;  \\n10.3.2 Students shall be entitled to check whether all answers have been \\nevaluated and marked, and that all the marks have been correctly totalled.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              21 \\n10.3.3 In case of Digital valuation, the portal shall be opened on specified date(s) \\nand information about the date shall be sent to students’ university email \\naddress.  \\n10.3.4 If the student finds any discrepancy, he/she shall bri ng the same into the \\nnotice of the Faculty/Course Instructor/ HOD concerned for corrections and \\nupdates \\n11.0  DETAILED SCHEDULE OF EXAMINATIONS'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='11.1 The detailed schedule of the Mid Term and End Term Examinations , as per dates \\nindicated in the Academic Calendar, shall be prepared by the COE in consultation \\nwith the HODs/Deans of Schools and shall be announced with due approval of the \\nVice Chancellor, at least two (02) weeks before the commencement of the \\nExaminations.  \\n11.2 The regulations and guidelines pertaining to the conduct of various University'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Examinations are prescribed in the Examination Regulations of the University.  \\n12.0  APPEAL FOR REVIEW OF GRADES \\n12.1 The University is committed to keep the entire process of  evaluation beyond \\nreproach. A mechanism for review of grades is incorporated in the evaluation system.  \\n12.2 In case of a grievance regarding the grade(s) awarded, a student shall submit an \\napplication along with the prescribed fee to the Office of the Controller of'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Examinations for obtaining the photocopy of End Term Examination answer script(s) \\nof the Course (or Courses), within Five (05) University working days from the date \\nof the declaration of the results of the End Term Examination. No requests shall be \\nadmissible after five (05) University working days from the date of the declaration \\nof the results of the End Term Examination.  \\n12.3 A copy of the answer script(s) of the End Term Examination with marks obtained for'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='each question and evaluation scheme shall be shared to the concerned student within \\nthree (03) days from the last date of application for photocopy of answer script . If \\nthe student is not satisfied with the marks awarded, he/she shall approach Course \\nInstructor/faculty assigned by the HOD/ Dean to get the recommendation in the \\nprescribed format, and submit the application for review of grade with prescribed \\nfees, within three (03) days from receipt of photocopy of the answer script.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='12.4 The COE shall forward the student’s request to  the concerned HoD / Dean to take \\nthe necessary steps to review the appeal. Copy of the answer script(s) with marks \\nobtained for each question and evaluation scheme shall be shared to the concerned \\nHoD / Dean, within two (2) days from the last date for app lication for review . The \\nconcerned HoD / Dean shall convene a panel consisting of the respective Course'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Instructor / Course In-Charge and two more faculty members who are familiar with \\nthe Course concerned to review the appeal.  \\n12.5 The panel shall review the appeal and submit a report regarding the revision / \\nretention of the Grade to the CoE, within five (05) days from the date of receipt of'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              22 \\nanswer script from CoE . The CoE shall declare the result based on the approval of \\nthe Vice Chancellor.  \\n13.0  MAKE-UP EXAMINATIONS  \\n13.1 Make-Up Examination is a provision for a student to complete a Course (or Courses) \\nin which she/he received an “F” grade (refer Section 8.0), or, was given the place'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='holder grade “I” (refer to Section 8.0) to reappear for the End Term Examination \\ncomponent of a Course (or Courses), subject to the conditions mentioned below in \\nClauses 13.2 to 13.5. Under no other circumstances, Make-Up Examinations shall be \\navailable to the student. Make-Up Examination is conducted o nly for those Courses \\nregistered in the concerned Academic Term (latest completed Semester).  \\n13.2 A student who fails to appear in the End Term Examinations, in some or all Courses,'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='due to medical exigencies, specifically hospitalization, trauma, including death of \\nimmediate family members (Parents, Offspring, Siblings and Spouse) or a contagious \\ndisease only, and, the said student informs the HOD/Dean concerned timely (i.e., on \\nor before the last date of the said End Term Examinations), may submit a request \\nto the concerned HOD/Dean for the provision of the Make -Up Examinations in the \\nCourse(s) for which he/she could not attend the scheduled End Term Examinations.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='13.2.1 Provided further, the student must submit, along with the registration form \\nfor the Make -Up Examinations, medical certificates, medical prescriptions, \\nhospital di scharge summary, medical fitness report and all such relevant \\ndocuments, duly attested by the concerned registered medical officer of the \\nhospital where the concerned student was hospitalized or medically treated.  \\n13.2.2 The HOD/Dean concerned shall submit a specific report to the Chairperson,'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Board of Examinations (BOE) in this regard, who shall convene a special \\nmeeting of the BOE to review the student’s application. The BOE may grant \\npermission based on the veracity of the case to permit the concerned student \\nto avail the provision of Make-Up Examinations. On approval of the BOE, the \\nstudent shall submit the application form for the Make -Up Examinations to \\nthe Examination Department of the University within the duly notified dates,'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='along with the prescribed fee for the Make -Up Examinations fixed by the \\nUniversity from time to time.  \\n13.2.3 On the basis of the student’s performance in the Make-Up Examinations and \\nconsidering the marks obtained by the student in all other Continuo us \\nAssessments as prescribed by the concerned Program Regulations and \\nCurriculum, the final letter grade awarded will replace the placeholder grade \\n“I”.  \\n13.2.4 In case the BOE rejects the application of the student for Make -Up'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Examinations, the student shall be declared “Failed” in the concerned \\nCourse(s) and the placeholder grade “I” shall be replaced with “F” (Fail) \\ngrade in the concerned Course(s). Further, the student shall have to \\ncomplete the Course(s) as per the provisions and conditions prescribed in \\nClause 13.3.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              23 \\n13.2.5 If the concerned student does not avail the Make -Up Examinations, or is \\nabsent for the Make-Up Examinations, the student shall be declared “Failed” \\nin the concerned Course(s) and the placeholder grade “I” shall be replaced \\nwith an “F” grade. Further, the student shall have to complete the Course(s) \\nas per the provisions and conditions prescribed in Clause 13.3.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='13.3 A student with “F” Grade in one or more Courses, declared under the conditions \\nstated in Section 8.0 and/or who secured “D” Grade in one or more Courses, may \\navail the benefit of the Make -Up Examinations to pass the failed Course(s) and/or \\nimprove her/his CGPA. The student shall submit the registration form for the Make -\\nUp Examinations to the Office of the Controller of Examinations of the University \\nwithin the duly notified date, along with the prescribed fee for the Make -Up'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Examinations fixed by the University from time to time.  \\n13.3.1 Further, if the student fails in the Course(s) attempted in the Make -Up \\nExaminations, including the Course(s) where the student had earlier secured \\n“D” Grade, the student will be awarded “F” grade in the Course(s) and will \\nhave to re-appear for the Examination.  \\n13.3.2 Students appearing for Make -Up Examinations can improve only by two \\ngrade level. This means that an \"F\" grade can be improved to a \"C\" grade at \\nmost.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='most. \\n13.4 The provision of Make-Up Examinations shall not be available for practice/laboratory/ \\nskill-based Courses as described in Clause 5.2. If a student has secured an “F” Grade \\nin such a Course, the student shall complete the concerned Courses only by \\nrepeating the Courses in the Semester when they become available for registration. \\nFurther, the student is cautioned that she/he shall have to register for the concerned'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Course(s) only in the concerned Semester of the next Academic Year when the \\nconcerned Course(s) shall be offered, which may result in the loss of an Academ ic \\nYear for the student. It is the sole responsibility of the student to ensure that she/he \\ncompletes the Course(s) and/or earns the required credits as prescribed by the \\nconcerned Program Regulations and Curriculum.  \\n13.5 Make-Up Examinations may be scheduled at the end of each Semester. The COE'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='shall announce the schedule of the Make-Up Examinations at least two (02) calendar \\nweeks before the commencement of the Make-Up Examinations.  \\n14.0  ACADEMIC PROMOTION  \\nYearly promotion criteria of a student who is reg istered for a given Academic year to the \\nnext Year of the Program of study after the end of an Academic Year is as described below \\nin Clauses 14.1 and 14.2. The Academic Promotion is applicable only for the Undergraduate \\nPrograms.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Programs. \\n14.1 A student is eligible to be promoted to the next academic year if he/ she has secured \\na CGPA of 4.00 or more at the end of the current academic year (after completion \\nof the Summer Term and/or Make-Up Examinations, as applicable).'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              24 \\n14.2 If the student has secured a CGPA of less than 4.00, they shall not be promoted to \\nthe next academic year. \\n14.3 The students who are not promoted to the next Academic year but have app ealed \\nfor review of grades  (Section 12 .0) may take provisional registration and be \\npermitted to attend classes till the review results are published. After the publication'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='of the review result, the promotion criteria stated above in Clauses 14.1 and 14.2 \\nshall be applicable. \\n14.4 A student, who is not promoted as per Clause 14.2, has the provision of improving \\nthe CGPA in the subsequent academic year by either appearing for Make-Up \\nexaminations or by re-registering in either Odd and / or Even semesters, or Summer \\nTerm of the next academic year , subject to the conditions stated in Sections 13.0 \\nand 15.0 respectively.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='14.5 Further, upon rejoining (Registration in the applicable Semester) , the student shall \\nadhere to the Academic Regulations and Program Regulations and Curriculum , \\napplicable to the batch in which the student is rejoining the Program of study.  \\n15.0  SUMMER TERM  \\n15.1 The Summer Term is an additional Academic Term that may be offered during the \\nsummer break, typically for about eight (08) weeks during June-July. The minimum'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='number of instruction days in the Summer Term shall be thirty (30) days.  \\n15.2 The Course(s) offered in the Summer Term are delivered in a shorter term of about \\n8 weeks (with a minimum of thirty instruction days). However, the total number of \\ncontact hours for these Courses are scheduled as per the Course Credit Structure. \\nThe Course Contents/Syllabus and the continuous assessments and evaluation \\npatterns for these Course(s) also remain the same as that prescribed by the'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='concerned Course Plan.  \\n15.3 The Departments/Schools desirous of offering Courses shall announce the details of \\nthe Courses on offer for registration in the Summer Term on the dates scheduled in \\nthe Academic Calendar or dates announced through University notifications.  \\n15.4 Some Departments/Schools may offer a limited number of Courses in the Summer \\nTerm with the following special provisions, subject  to all the conditions stated in \\nClause 15.5:'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Clause 15.5:  \\n15.4.1 Refer Clause 7.6: A student may re -register for the concerned Course(s), \\nif offered, in which the student had received the placeholder grade “NP”, to \\ncomplete the concerned Course(s) and earn the concerned credits;  \\n15.4.2 Refer Clause 8.13: A student may re-register for the concerned Course(s), \\nif offered, in which the student had received the “F” grade (Fail) in the \\nearlier Semesters if he/she wishes to do so.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='15.5 A student may register for the Summer Term Course(s), subject to all the conditions \\nstated below:'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              25 \\n15.5.1 A student who wishes to register for the Summer Term must complete the \\nregistration process on or before the last date  for Registration as specified \\nin the Academic Calendar or the University Notification to this effect. No late \\nregistration shall be permitted.  \\n15.5.2 A student can register for a maximum of 12 Credits.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='15.5.3 Attendance requirements as prescribed in Section 7.0 shall be applicable to \\nall the students registering for Course(s) in the Summer Term.  \\n15.5.4 A student cannot request or demand for a specific Course to be offered.  \\n15.5.5 A student, who is registering for Summer Term Course(s), must submit a \\ncompleted Summer Term Registration Form, checked and verified by the \\nDean/HOD concerned, to the Office of the Controller of Examinations of the'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='University. Further, where applicable, th e Summer Term Registration Form \\nwill contain the list of failed and/or lower graded Course(s) for which the \\nstudent is registering.  \\n15.5.6 The student shall remit the registration fee per Course, as prescribed by the \\nUniversity from time to time, within the date specified for payment.  \\n15.5.7 A Course that is offered in summer term may be withdrawn if the number of \\nRegistrations for the concerned Course(s) is less than TEN (10). Further, if'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='the Course is withdrawn due to lack of the minimum number of Registrations \\nrequired (i.e., 10), the Registration Fee for the concerned Course shall be \\nrefunded to the students who had registered for the concerned Course. \\n15.5.8 Further, the student,  \\na) must have paid all the required fees and other charges including hostel \\ncharges, where applicable, for the Summer Term;  \\nb) must have cleared all University fees and Hostel dues of previous \\nSemester(s)/year(s); and,'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='c) has not been debarred from registering on disciplinary or other grounds.  \\n15.5.9 A student can apply for the Summer Term in any of the Courses in which he/ \\nshe was declared “NP” grade in any semester preceding the Summer Term, \\nincluding the immediately preceding semester , provided that the Course is \\nbeing offered by the School. However, the student cannot demand for a \\nparticular Course which the School is not offering or for which the number of'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='applicants is below 10 as stated in Sub-Clause 15.5.7.  \\n15.5.10 A student who did not register for a regular semester (Odd or Even) shall \\nnot be permitted to register for any  Courses from that semester (for which \\nthe student did not register)  during the Summer Term. Registration in the \\nSummer Term is only applicable fo r Courses previously registered but not \\ncompleted (i.e. Course(s) in which grade given was \"NP\", “F”, or “NC”).'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              26 \\n16.0  WITHDRAWAL FROM THE PROGRAM  \\n16.1 Temporary Withdrawal:  \\nA student who has been admitted to a Degree Program of the University may be \\npermitted to withdraw temporarily, for a period of one Academic Year, on medical \\ngrounds provided:  \\n16.1.1 The student submits an application to the University, stating the reasons'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='for withdrawal together with supporting documents and endorsement from \\nher/his parent or legal guardian;  \\n16.1.2 The University is satisfied that the student is likely to complete the \\nrequirements for the award of the Degree of the concerned Program within \\nthe specified maximum duration to complete the Program (refer Section \\n20.0).  \\n16.1.3 A student seeking temporary withdrawal shall not be entitled to a refund of \\nthe Annual Fee paid to the University for the concerned Academic Year.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='16.1.4 There are no outstanding dues with the De partment/School/Hostels/ \\nLibrary etc.  \\n16.1.5 Scholarship holders are bound by the appropriate rules applicable to them.  \\n16.1.6 Normally, a student will be permitted only one such temporary withdrawal \\nduring her/his tenure as a student.  \\n16.2 Rejoining the Program:  \\nA student who temporarily withdraws from the Program (Clause 16.1) and rejoins \\nthe Program in the following Academic Year, shall be governed by all the Regulations,'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='including the PRC, of the University and the University Fee Structure in force at the \\ntime of his/her rejoining the program.  \\n16.3 Permanent Withdrawal:  \\nThe rules pertaining to withdrawal of admission at the time of joining the University \\nare as stipulated by the Admission Rules and Fee Policy of the University.  \\nIn case of a student seeking withdrawal from the Program of study after completion \\nof one/more Academic Year(s), the rules and terms of withdrawal are as stipulated'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='in the Withdrawal from Program and Fee Refund Policy of the University.  \\nThe decision of the Vice Chancellor regarding all aspects of withdrawal of a student \\nfrom the Program of study shall be final and binding.  \\n17.0  TRANSFER OF CREDITS  \\nThe University allows students to acquire credits from other Indian or foreign institutions \\nand/or Massive Open Online Course (MOOC) platforms, subject to prior approval. These'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='credits may be transferred and counted toward fulfilling the minimum credit requirements \\nfor the award of a degree. The process of transfer of credits is governed by the following \\nrules and guidelines:'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              27 \\n17.1 The transfer of credits shall be examined and recommended by the Equivalence \\nCommittee (Refer ANNEXURE B) and approved by the Dean - Academics. \\n17.2 Students may earn credits from other Indian or foreign Universities/Institutions with \\nwhich the University has an MOU, and that MOU shall have specific provisions, rules'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='and guidelines for transfer of credits. These transf erred credits shall be counted \\ntowards the minimum credit requirements for the award of the degree.  \\n17.3 Students may earn credits by registering for Online Courses offered by Study Web \\nof Active Learning by Young and Aspiring Minds (SWAYAM) and National Program on \\nTechnology Enhanced Learning (NPTEL), or other such recognized Bodies/ \\nUniversities/Institutions as approved by the concerned BOS and A cademic Council'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='from time to time. The concerned School/Parent Department shall publish/include \\nthe approved list of Courses and the rules and guidelines governing such transfer of \\ncredits of the concerned Program from time to time. The Rules and Guidelines for \\nthe transfer of credits specifically from the Online Courses conducted by SWAYAM / \\nNPTEL/ other approved MOOCs  are as stated in the following Sub-Clauses:  \\n17.3.1 A student may complete SWAYAM /NPTEL/other approved MOOC s as'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='mentioned in Clause 17.3 and transfer equivalent credits to partially or fully \\ncomplete the mandatory credit requirements of Discipline Elective Courses \\nand/or the mandatory credit requirements of Open Elective Courses  as \\nprescribed in the concerned Curriculum Structure. However, it is the sole \\nresponsibility of the  student to complete the mandatory credit \\nrequirements of the Discipline Elective Courses and the Open Elective'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Courses as prescribed by the Curriculum Struc ture of the concerned \\nProgram.  \\n17.3.2 SWAYAM/NPTEL/ other approved MOOCs as mentioned in Clause 17.3 shall \\nbe approved by the concerned Board of Studies and placed (as Annexures) \\nin the concerned PRC.  \\n17.3.3 Parent Departments may release a list of SWAYAM /NPTEL/other approved \\nMOOCs for Pre -Registration as per schedule in the Academic Calendar or \\nthrough University Notification to this effect.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='17.3.4 Students may Pre-Register for the SWAYAM/NPTEL/other approved MOOCs \\nin the respective Departments and register for the same Courses as per the \\nschedule announced by respective Online Course Offering body/institute/ \\nuniversity.  \\n17.3.5 A student shall request for transfer of credits only from such approved  \\nCourses as mentioned in Sub-Clause 17.3.2 above.  \\n17.3.6 SWAYAM/NPTEL/other approved MOOC s Courses are considered for'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='transfer of credits only if the concerned student has successfully completed \\nthe SWAYAM/NPTEL/other approved MOOC s and obtained a certificate of \\nsuccessful/satisfactory completion.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              28 \\n17.3.7 A student who has successfully completed the approved SWAYAM /NPTEL/ \\nother approved MOOCs and wants to avail the provision of transfer of \\nequivalent credits, must submit the original Certificate of Completion, or \\nsuch similar authorized documents to the HOD concerned, with a written \\nrequest for the transfer of the equivalent credits. On verification of the'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Certificates/Documents and approval by the HOD concerned, the Course(s) \\nand equivalent Credits shall forwarded to the COE for processing of results \\nof the concerned Academic Term.  \\n17.3.8 The credit equivalence of the SWAYAM /NPTEL/other approved MOOCs are \\nbased on Course durations and/or as recommended by the Course offering \\nbody/institute/university. The Credit Equivalence mapped to SWAYAM / \\nNPTEL approved Courses based on Course durations for transfer of credits'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='is summarised in Table shown below. The Grade will be calculated from the \\nmarks received by the Absolute Grading Table 8.11.  \\n \\nTable 17.3.8 Durations and Credit Equivalence for Transfer of \\nCredits from SWAYAM-NPTEL/ other approved MOOC Courses \\nSl. \\nNo. Course Duration Credit Equivalence \\n1 4 Weeks 1 Credit \\n2 8 Weeks 2 Credits \\n3 12 Weeks 3 Credits \\n \\n17.3.9 The maximum permissible number of credits that a student may request'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='for credit transfer from MOO Cs shall not exceed 20% of the mandatory \\nminimum credit requirements specified by the concerned Program \\nRegulations and Curriculum for the award of the concerned Degree. \\n17.3.10 The University shall not reimburse any fees/expense; a student may incur \\nfor the SWAYAM/NPTEL/other approved MOOCs.  \\n17.4 The maximum number of credits that can be transferred by a student shall be limited to'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='forty percent (40%) of the mandatory minimum credit requirements specified by the \\nconcerned Program Regulations and Curriculum for the award of  the concerned  \\nDegree. However, the grades obtained in the  Courses transferred from other \\nInstitutions/MOOCs, as mentioned in this Section (17.0), shall not be included in the \\ncalculation of the CGPA. \\n18.0 MAXIMUM DURATION FOR THE COMPLETION OF A PROGRAM  \\n18.1 A student who for whatever reason is not able to complete the Program within the'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='normal period or the minimum duration  (number of years)  prescribed for the \\nProgram, may be allowed a period of two years beyond the normal period to \\ncomplete the mandatory minimum credits requirement as prescribed by the \\nconcerned Program Regulations and Curriculum. In general , the permissible'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              29 \\nmaximum duration (number of years) for completion of Program is ‘N’ + 2 years, \\nwhere ‘N’ stands for the normal or minimum duration  (number of years)  for \\ncompletion of the concerned Program as prescribed by the concerned Program \\nRegulations and Curriculum. \\n18.2 The time taken by the student to improve Grades/CGPA, and in case of temporary'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='withdrawal/re-joining (Refer to Clause 16.1), shall be counted in the permissible \\nmaximum duration for completion of a Program. \\n18.3 In exceptional circumstances, such as temporary withdrawal for medical exigencies \\nwhere there is a prolonged hospitalization and/or treatment, as certified through \\nhospital/medical records, women students requiring extended maternity break  \\n(certified by registered medical practitioner) ,   and, outstanding sportspersons'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='representing the University/State/India  requiring extended time to participate in \\nNational/International sports events, a further extension of one  (01) year may be \\ngranted on the approval of the Academic Council.  \\n18.4 The enrolment of the student who fails to complete the mandatory requirements for \\nthe award of the concerned Degree (refer Section 19.0) in the prescribed maximum \\nduration (Sub-Clauses 18.1 and 18.2) , shall stand terminated and no Degree shall \\nbe awarded.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='be awarded.  \\n19.0 REQUIREMENTS FOR THE AWARD OF DEGREE  \\n19.1 The award of the Degree shall be recommended by the Board of Examinations and \\napproved by the Academic Council and Board of Management of the University.  \\n19.2 A student shall be declared to be eligible for the award of the concerned Degree if \\nshe/he:  \\n19.2.1 Fulfilled the Minimum Credit Requirements and all other mandatory \\nrequirements as prescribed by the concerned Program Regulation s and'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Curriculum (PRC) for the award of the concerned Degree;  \\n19.2.2 For Undergraduate Programs : Secured a minimum CGPA of 4.50 in the \\nconcerned Program at the end of the Semester/Academic Term in which \\nshe/he completes all the requirements for  the award of the Degree as \\nspecified in Sub-Clause 19.2.1;  \\n19.2.3 For Postgraduate Programs : Secured a minimum CGPA of 5.00 in the \\nconcerned Program at the end of the Semester/Academic Term in which'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='she/he completes all the requirements for the award of t he Degree as \\nspecified in Sub-Clause 19.2.1;  \\n19.2.4 No dues to the University, Departments, Hostels, Library, and any other such \\nCenters/ Departments of the University; and  \\n19.2.5 No disciplinary action is pending against her/him.  \\n19.3 Award of Class:  \\nThe award of Class in a Degree shall be based on the CGPA in the concerned Program \\nat the end of the Semester/Academic Term in which the student completes all the'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              30 \\nrequirements for the award of the Degree. In case a student has earned more credits \\nthan the required minimum as prescribed by the concerned Curriculum Struct ures, \\nthe higher CGPA, as applicable, considering the Credits and Grades corresponding to \\nthe mandatory minimum credit requirements as prescribed by the concerned'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Curriculum Structure, for the award of the concerned Degree shall be considered for \\nthe award of Class.  \\nClasses shall be awarded as per the following scale:  \\n19.3.1 First Class with Distinction: CGPA of 8.00 and above  \\n19.3.2 First Class: CGPA from 6.50 to 7.99  \\n19.3.3 Second Class (for Postgraduate Programs): CGPA of 5.00 to 6.49  \\n19.3.4 Second Class (for Undergraduate Programs): CGPA of 4.50 to 6.49  \\n20.0  PROVISIONAL DEGREE CERTIFICATE'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='On completion of the requirements for the award of the Degree as prescribed in Section \\n19.0, the student may apply for a Provisional Degree Certificate  in the prescribed \\napplication form, along with the prescribed Fee notified by the University from time to \\ntime, to the Controller of Examinations of the University.  \\nOn verification of the eligibility criteria prescribed in Clause 19.2, the Controller of'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Examinations shall issue the Provisional Degree Certificate to the concerned student, to \\nthe effect that the concerned student has fulfilled all the requirements for the award of \\nthe Degree in the concerned Program, and that, the Degree shall be conferred on the \\nconcerned student at the next Convocation of the University.  \\n21.0  CONVOCATION  \\nThe Convocation of the University shall be held annually as per the Convocation'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulations of the University. The University shall announce the date for the Convocation \\nand call for applications from eligible students to register for the Convocation. The duly \\ncompleted application form along with the prescribed Convocation Fee must be submitted \\nby the student to the University within the specified date announced by the University.  \\nDegrees shall be awarded in person at the Convocation for the students who have'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='graduated during the preceding Academic Year. Degrees shall be awarded in absentia to \\nsuch students who are unable to attend the Convocation.  \\n22.0  ISSUE OF DEGREE CERTIFICATE BEFORE THE CONVOCATION  \\nIn exceptional circumstances where a student requires the Degree Certificate before the \\ndate of the Convocation, for purposes of higher education or employment where the \\nconcerned University/Organization where the concerned student has secured/seeking'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='admission/employment requires that the concerned stude nt must produce the Degree \\nCertificate, the concerned student may submit an application to the University, along \\nwith the prescribed Fee and all the supporting documents.  \\nThe Vice Chancellor shall consider the merit of the application and submit her/his \\nrecommendation to the Chancellor for the issue of the Degree Certificate, or otherwise.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              31 \\nThe decision of the Chancellor shall be final and binding. On the approval of the \\nChancellor, the Degree Certificate shall be issued to the concerned student.  \\nThe minimum time taken to process and issue the Degree Certificate shall be two (02) \\ncalendar months from the date of receipt of the request for the issue of the Degree \\nCertificate.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Certificate.  \\n23.0 POWER TO REVISE, MODIFY AND AMEND  \\nNotwithstanding anything contained in the above Regulations:  \\n23.1 The Academic Council has the right to revise, amend or modify any of the above \\nRegulations from time to time, and shall be binding on all stakeholders concerned, \\nincluding the Students, Faculty, Staff, Departments, Schools and University \\nAuthorities.  \\n23.2 In case of a dispute, the decision of the Academic Council shall be final and binding.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='23.3 In case of difficulty in application of any of the Clauses of the Regulations specified \\nabove, the Chancellor shall have the powers to amend/modify/remove the difficulty \\nin the relevant Regulation.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              32 \\nANNEXURE A \\nDEPARTMENTAL ACADEMIC COMMITTEE (DAC) \\na) “Department” refers to the School/Department offering Degree Programs  \\nb) There shall be at least one DAC for every School/Department that is involved in teaching \\nDegree Programs.  \\nc) However, each program can also have a separate DAC.  The HoD/Dean is authorized to ta ke \\ndecisions to this effect.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='d) The Respective School Dean  shall notify the concerned DAC as per the following \\nconstitution:  \\nMembers Designation Remarks \\nChairperson \\nDean/Associate Dean/Assistant Dean of \\nconcerned School/Head of the Department/ \\nHOD In Charge of the Program \\nEx Officio \\nMembers (Five) \\nfrom within the \\nSchool/Department \\nThree (03) Faculty Members representation \\nfrom Senior Professors/Senior Faculty and  \\nTwo (02) Assistant Professors \\nAppointed by \\nChairman, DAC'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Chairman, DAC \\nMember (One) Senior Faculty member from another \\nSchool/Department of the University \\nNominated by \\nDean \\n(Academics) \\nMember Secretary Faculty member from the School/ \\nDepartment \\nAppointed by the \\nChairman, DAC \\nTenure of the DAC is for one academic year \\n \\ne) The Chairperson may co-opt and/or invite more members, if necessary.  \\nf) Functions:  \\ni. To monitor the conduct of the respective Programs of study of the Department/School.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='ii. To ensure academic standard and excellence of the respective Programs offered by the \\nDepartment/School.  \\niii. To consolidate the Registration List of the students and communicate to Course \\nInstructor, the Academic Office and Examination Department of the University.  \\niv. To review and approve the Course Plan (with Session Plan) submitted by the Faculty/ \\nCourse Instructor/Instructor In-Charge for each Course and forward the collated Course'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Plan of each Program to the Dean - Academics.  \\nv. To ensure that at least two Class Committee (Refer Annexure D) meetings are conducted \\nduring the Semester and act upon the Resolutions passed by Class Committee(s).  \\nvi. To arrange to obtain the Student Feedback for every Course, once during the middle of \\nthe Semester and one at the end of each Semester, and to submit the consolidated report \\nof such feedback to the Dean - Academics.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='vii. To conduct at least two DAC meetings each Semester and a copy of the Resolutions of \\nthe DAC Meeting shall be communicated to the Dean - Academics, and a record of the \\nsame to be maintained in the Department/School.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              33 \\nviii. To Plan the curriculum and syllabus changes based on various stakeholders (Faculty, \\nStudents, Alumni and Industry) feedback and suggestions. The complied suggestions \\nfrom DAC will be presented before the BOS for further discussions and follow up actions. \\nix. To implement the resolutions of the BOS for the upcoming batches and semesters.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='x. Any other responsibility or function assigned by the Dean (Academics).'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              34 \\nANNEXURE B \\nEQUIVALENCE COMMITTEE \\nEquivalence refers to the process of evaluating and recognizing academic credits earned by \\nstudents from other institutions. The purpose of equivalence is to facilitate academic mobility \\nwhile maintaining the integrity and quality of the degree programs. It ensures that the Courses,'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='credits, and learning outcomes align with the academic standards and program requirements of \\nthe University. This process applies to both credit transfers from other recognized institutions \\nand the acceptance of students transferring into the University. \\nEquivalence Committee shall have the following constitution: \\n1. Chairperson – Dean/Director of the Concerned School \\n2. Members – Two Professor(s)/Associate Professor (s) from the Concerned Program \\n3. Convenor – Head of the Department'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Responsibilities: \\n\\uf0b7 Equivalence Committee shall examine the case for Transfer/Lateral Entry admissions and \\nsubmit its report and recommendation for the approval of the Vice Chancellor for \\nenrolment to the concerned program. \\n\\uf0b7 Equivalence  \\n\\uf0b7 Committee shall examine the Credit Transfer from other Indian/Foreign Institutions and \\nsubmit its report and recommendation for the approval of the Dean – Academics.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              35 \\nANNEXURE C \\nCourse Instructor/Course In-Charge \\n \\nA Course Instructor for each Course on offer in a given Academic Term shall be assigned by \\nHoD/Dean/Director of School and approved by the Departmental Academic Committee. \\nIf a Course needs to be assigned to more than one class of students (due to a large number'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='registered for the concerned Course) and if more than one Course Instructor needs to be \\nassigned to teach this Course, the HoD shall assign a Course In -Charge (who must be a \\nCourse Instructor for at least one class taking this Course) to coordinate with other Course \\nInstructors to facilitate the delivery of Course Plan in a consistent manner and also to ensure the \\nevaluation scheme and grading is conducted in a proper and consistent manner. \\nFunctions/Responsibilities (Highlights)'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='The Course Instructor shall: \\na. follow all the Regulations related to teaching of a Course and evaluation of students; \\nb. be responsible for all the records (i.e., Course registration, assessment/answer \\nbooks, attendance, etc.) of the students registered for the Course; \\nc. shall conduct classes as prescribed in the Academic Calendar and as per the \\nteaching assignment time-table; \\nd. shall arrange to distribute a Course Plan and the evaluation plan together with the'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Course Outcomes, background materials to all the students within the first week of \\neach Semester; \\ne. prepare an evaluation plan showing details of how the student’s performance will \\nbe evaluated in the Course; \\nf. document the students’ performance and announce/declare such details as stipulated; \\ng. report to the HoD on a periodic (monthly) basis, the potential cases of poor \\nacademic performance (Slow Learners)  as well as those of low attendance, that'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='would possibly result in a ‘F’ or ‘NP’ grade at the end of the Semester. \\nThe Course In-Charge shall co-ordinate the above functions/responsibilities with the other \\nassigned Course Instructors regularly as decided by their concerned HoD.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Regulation No.: PU/AC-26/6/07_2025                                                                              36 \\n \\nANNEXURE D \\nCLASS COMMITTEE \\na) Every Class of the Degree Program (for example, 1st Year of a Program, Section A, etc., as \\napplicable) shall have a Class Committee, consisting of Faculty members and Students.  \\nb) The HOD/Program Head of the School/Department concerned shall notify the concerned Class \\nCommittee as per the following constitution:  \\nMembers Designation Remarks'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='Chairperson Senior Faculty \\nMember of the Parent/ \\nTeaching Department, \\nassociated with the Class \\nMembers (Faculty) All Course Instructors of that \\nClass  \\nMembers \\n(Students: at least \\nSix) \\nStudents representing the Class \\nChosen by the students \\namongst themselves, but \\nonly those whose \\nMember Secretary Class Coordinator of the Class Appointed by the Dean of \\nthe School concerned \\nTenure of the Class Committee is for the Semester concerned.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='All members must attend the Class Committee Meeting. \\nc) Functions:  \\ni. The basic responsibility of the Class Committee is to review the progress of the \\nclasses/Courses, to discuss problems concerning the conduct of the classes and \\ncontinuous assessments as per the Course Plan and recommend remedial measures, \\nwhere necessary.  \\nii. Each Class Committee will communicate its recommendations to the Chairperson, DAC \\nof the Parent/Teaching Department/School.'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='iii. There shall be at least two Class Committee meetings every Semester, the first one \\nbefore midterm Examinations and the second one at least two weeks before the last \\ninstruction day of the semester  \\niv. However, additional Class Committee meetings may be convened as decided by the \\nChairperson, DAC.  \\nv. The Resolutions of each Class Committee meeting shall be recorded and submitted to the \\nHOD/Dean of the Parent Department/School, and, a copy shall be submitted to the Dean'),\n",
       " Document(metadata={'source': 'data\\\\College-Rule.pdf'}, page_content='(Academics).  \\nvi. Any appropriate responsibility or function assigned by the Chairman of the DAC.'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='PU\\nUU \\nINSTITUTIONAL  INFORMATION  \\n \\n \\n \\n \\n \\n \\n \\n  \\nEnhance your degree with \\nExchange and Study Abroad \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\n \\n \\n \\nName of the Institution Presidency University (PU) \\nPostal Address \\nThe Office of International Affairs \\nPresidency University, Itgalpur Rajanakunte, \\nYelahanka, Bengaluru, Karnataka 560064 \\nWebpage www.presidencyuniversity.in  \\nTelephone Number +91 80 2309 3500 \\n \\nInternational Office Contact \\nDr Sivaperumal S \\nDirector of International Affairs \\ndirector-'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='director-\\ninternational.relations@presidencyuniversity.in  \\nStudent Exchange Website Presidency_InternationalAffairs-Student_Exchange \\nFact sheet \\nInbound Mobility Students \\n2025-26'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='Bangalore is a cosmopolitan city in India, known for its thriving IT industry and \\ninnovation hub. It is often referred to as the Silicon Valley of India. Bangalore city is \\nhome to many multinational companies, startups, research institutes, NGOs, etc. \\nthat provide internships and placements to students. Bengaluru will soothe you with \\nits pleasant weather throughout the year.  \\nBangalore is home to several prestigious universities and colleges that offer'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='undergraduate and postgraduate courses in a wide range of fields, including arts, \\nscience, commerce, law, management, and engineering.  \\nBangalore has a vibrant campus life that provides students with opportunities for \\nlearning, networking, cultural exchange, and extracurricular activities. The city is \\nalso known for its rich cultural heritage and attractions such as garde ns, parks, \\ntemples, and museums.  \\nCompared to other metro cities in India, Bangalore has a low cost of living and a'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='pleasant climate throughout the year. It is well -connected by road, rail, and air to \\nother parts of the country and the world.  \\nBangalore is listed as the top 10 fastest growing cities in the world, the economy of \\nthis city is an important part of the economy of India.'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='BENGALURU \\nBENGALUR  U, KARNA  TAKA,  INDIA  \\nSTUDE  NT MI GRATION  TREND  \\n46 . 55 % \\nSAME CITY \\n \\n6. 90% \\nSAME STATE \\n46 . 55 % \\nNATIONAL \\n \\nWHY  BENGALURU?  ( RANKED  ORDER)  \\n Good  We ath  \\n Sa fe t y \\n \\n  Soc  ial  Life  \\n \\n I n f r a s t r u c t u r e \\n Employability  \\n \\n  University Life \\n  Reputation  Public     \\n Transport \\n \\nNight Life \\nBest Student Cities, Bengaluru \\nwas ranked as India’s best \\nstudent city, while ranking 114 \\nglobally'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='Welcome Mid of August \\nSemester begins End of August \\nClasses end Mid of January \\nIncluding exams \\n \\nWelcome Mid of January \\nSemester begins Beginning of February \\nClasses end End of June \\nIncluding exams \\n \\nACADEMIC  CALENDAR  2025 -26 \\nSemester one* (Odd/Fall semester) Semester two* (Even/Spring semester) \\n \\n \\n* Confirmed dates will be indicated on the individual acceptance/visa letter. \\nSTUDY  ABROAD/EXCHANGE  APPLICATION  AND ADMISSION  \\nApplication documents (in English):'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='▪ Completed application form \\n▪ Academic transcripts of record (official, stamped and signed by home institution) \\n▪ Passport copy (valid for a minimum of six months beyond the date of intended \\ndeparture from India)  \\n▪ All non-native English speaking applicants must provide proof of English language \\nability or a letter from the home university certifying applicant proficiency \\n▪ Proof of international health insurance \\n \\nINSTRUCTION OF NOMINATION'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='Students must be nominated by their home institution’s Advisor/Coordinator. Once \\napproved by the home institution, students’ nomination should be sent via email by \\nthe Advisor/Coordinator to the respective region in charge officers stated below \\nwith the following information. \\n• First Name \\n• Last Name \\n• Class Level \\n• Date of Birth \\n• Email ID \\n• Program of Study \\n \\n \\nAfter home institution nomination the prospective exchange students are requested to'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='send the completed application form with required documents to:  \\nMs. Sai Prasanna \\noia4@presidencyuniversity.in \\n+91 97317 42211'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='Nomination deadlines Application deadlines* Semester \\n \\n20 March 2025 \\n \\n30 March 2025 \\nOne semester (odd/Fall \\nsemester) for August 2025 \\nentry \\nTwo semester (odd and even \\nsemester) for August 2025 \\nentry \\n20 September 2025 30 September 2025 One semester (even/Spring \\nsemester) for February 2026 \\nentry \\n \\n*We cannot guarantee consideration of applications submitted after the above \\ndeadlines, although we will try to consider every application where possible. \\nFEES'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='FEES  \\nAs an Incoming exchange student,  you will pay tuition fees to your  home institution \\nbased on their fee  requirements. However, exchange students shall pay for things \\nsuch as books and equipment, health insurance, local excursion , accommodation, \\nflight, and a student visa. \\n \\nACCOMMODATION  \\nAs soon as you have been accepted a course (s) offered from us, you can request \\nfor off -campus accommodation and Presidency University will facilitate incoming'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='students in finding accommodation  close to the campus , approximately 7 -10 kms. \\nStudents are advised to apply for accommodation as soon as possible after  \\naccepting an offer letter; so, you have accommodation arranged before your arrival \\nin Bangalore, India.  \\nNote: The university will provide a bus service for all incoming exchange students \\nfrom partner universities so that they can commute to and from campus. \\n \\nResidence Facilities: \\n▪ Twin sharing bedroom (Euro 300 approx. per month)'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='▪ Furnished with beds, wardrobes, study tables chairs, bookshelves \\n▪ Fan \\n▪ Common bathroom toilet \\n▪ Wi-Fi'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='AVAILABLE  PROGRAMMES  \\nInternational students are required to take a full-time study load from below schools: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\nComputer Science & Engineering \\n \\n▪ B.Tech. - Computer Science and Engineering \\n▪ B.Tech. - Computer Science and Engineering \\n(Artificial Intelligence & Machine Learning) \\n▪ B.Tech. - Computer Science and Engineering \\n(Data Science) \\n▪ B.Tech. - Computer Science and Engineering \\n(Cyber Security)'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='(Cyber Security) \\n▪ B.Tech. - Computer Science and Engineering \\n(Block chain) \\n▪ B.Tech. - Computer Science and Engineering \\n(Internet of Things) \\n▪ B.Tech. - Computer Science and Technology \\n(Big Data) \\n▪ B.Tech. - Computer Science and Technology \\n(DevOps) \\n▪ B.Tech. - Computer Science and Technology \\n[Spl. in Artificial Intelligence & Machine \\nLearning] \\n▪ B.Tech. - Computer Engineering [Spl. in \\nArtificial Intelligence & Machine Learning] \\n▪ B.Tech. - Computer Science and Information'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='Technology \\n▪ B.Tech. - Computer Science and Engineering \\n(Networks) \\n▪ B.Tech. - Information Science and Engineering \\n[Spl. in Artificial Intelligence & Robotics] \\n▪ B.Tech. - Information Science and Technology \\n[Spl. in Artificial Intelligence & Data Science] \\n▪ M.Tech. - Artificial Intelligence \\n▪ M.Tech. - Data Science \\nEngineering \\n \\n▪ B.Tech. - Civil Engineering \\n▪ B.Tech. - Electrical & Electronics Engineering \\n▪ B.Tech. - Electronics and Communication \\nEngineering'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='Engineering \\n▪ B.Tech. - Mechanical Engineering \\n▪ B.Tech. - Mechanical Engineering [Spl in \\nMechatronics] \\n▪ B.Tech. - Petroleum Engineering \\n▪ B.Tech. – VLSI \\n▪ M.Tech. - Embedded Systems & VLSI \\n▪ M.Tech. - Building & Construction Technology \\n▪ M.Tech. - Product Design and Development \\nCommerce, Economics & Management \\n \\n▪ Bachelor of Business Administration (BBA) \\n▪ BBA (Digital Marketing) \\n▪ BBA (Business Analytics) \\n▪ BBA (Aviation Management)'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='▪ B. Com – (Professional) – (Spl. In Banking and \\nFinance) \\n▪ B.Com – (Professional) – (Spl. In Corporate \\nAccounting and Taxation) \\n▪ B.Com – (Hons.) – (Spl. In Business Analytics) \\n▪ B.Sc. – Economics  \\n▪ Master of Business Administration (MBA) \\n▪ MBA (Business Analytics) \\n▪ MBA (Digital Marketing) \\n▪ MBA (Banking & Finance Management) \\n▪ MBA (Marketing & Finance) \\n \\nMedia Studies \\n \\n▪ BA (Journalism and Mass Communication) \\n \\nInformation Science \\n \\n▪ Bachelor of Computer Application (BCA)'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='▪ BCA Data Science \\n▪ BCA Artificial Intelligence & Machine Learning \\n▪ Master’s in Computer Applications (MCA) \\nDesign \\n \\n▪ B. Des – Product Design \\n▪ B. Des – Communication Design \\n▪ B. Des – Space Design [Interior Design] \\n▪ B. Des – Fashion Design \\n▪ B. Des – Game Design \\n▪ B.Sc. Multimedia (VFX, SFX & Gaming) \\n \\n *All the programmes at Presidency University are completely taught in English'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='CHOOSING MODULES/COURSES  \\nYou may take courses across multiple faculties (subject to availability, no guarantees \\nmay be given) as long as your course choices are approved by your home university  \\nand meet your degree requirements.  Most courses are open to Incoming Exchange \\nstudents. However, some have prerequisites or require permission from the relevant \\nfaculty or school before you can enroll in them. Students to enroll prior to their arrival'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='at Presidency University. However, courses need t o be finalized within one week of \\nstart of   the class. All the programmes/courses are taught completely in English.  \\nACADEMIC WORKLOAD  \\nExchange students can take a workload of 12 to 20 credits. The minimum \\nworkload is 12 credits  and maximum would be 20 credits.  It may be considered on \\nthe request of the home university on reducing the workload. \\nPU 01 credit = U.S. 01 credit.'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='PU 01 credit is 15 teaching contact hours (study period, project, assignments, and \\nexamination period is excluded) \\nATTENDANCE REQUIREMENTS  \\nA student must have a minimum of 75%  attendance of the classes actually \\nconducted in that academic term, for which course(s) the student has registered for \\nin the academic term, will be permitted to write the final examination. \\nGRADING SYSTEM \\nGrade Grade Point Marks range  \\n(out of 100) Qualitative Description \\nO 10 >= 90 Outstanding'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='A+ 9 >= 85 but < 90 Excellent \\nA 8 >= 80 but < 85 Very Good \\nB+ 7 >= 75 but < 80 Good \\nB 6 >= 70 but < 75 Above Average \\nC 5 >= 60 but < 70 Average \\nD 4 >= 50 but < 60 Pass \\nF 0 < 50 Fail'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='TRANSCRIPTS  \\nAll credit-bearing exchange students will be issued with a transcript detailing their  \\nmodules and final grades at the end of the semester, once the exam results have  \\nbeen finalized. Transcript’s will be mailed directly to the home university. \\n \\nWHEN SHOULD YOU ARRIVE  \\nYou should arrive at least 7  days prior to the commencement of the term. Late \\narrival may be accepted under certain conditions such as health or travel/diplomatic \\nrestrictions.'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='restrictions.  \\nVISA  AND IMMIGRATION  REQUIREMENTS  \\nAll international students applying to study in India must have a valid student visa \\n(before travelling to India) unless they have an alternative visa that enables them \\nto study  in India . If you are granted a student visa, you must comply with all \\nstudent visa conditions. For all visa enquiries and applications, please contact your \\nlocal Indian Embassy/High Commission/Consulate General of India . The visa must'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='be valid for the orientation days before the start of the semester. Find more details \\nby visiting https://www.mea.gov.in/    \\nINSURANCE  \\nAll international students  are required to acquire a  health insurance from their  \\nhome country before their  departure. The insurance  should cover for medical  and \\nevacuation expenses abroad due to accident or  sickness for the entire  duration of \\nexchange at the host country. \\nFOREIGN REGIONAL REGISTRATION OFFICES  (FRRO)'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='Foreigner visiting India on Student Visa(S) is required to get himself / herself \\nregistered with concerned FRRO, within 14 days of his/her first arrival, irrespective \\nof the duration of his / her stay. FORM –S (Foreign Students Information System) is \\nused to capture information about foreign nationals admitted in Indian educational \\ninstitutions. Follow the FRRO link for more details.'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='CURRENT  ESTIMATED  COST  OF LIVING * \\nAccording to the study in India, the average cost of living in India (Bangalore) for  \\nstudents is € 140 (A student can experience a comfortable stay for a month). \\nLiving costs will vary depending on lifestyle but it is generally inexpensive to live in  \\nBangalore than other Indian cities, such as Mumbai or Delhi. Here is a breakdown of \\nsome general expenses for you to consider when preparing your finances (click for  \\nmore details):'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='more details): \\n \\nGeneral Expenses Approximate cost \\nAccommodation (off campus) \\nPlease check with the office of International Affairs whether certain items are  \\nincluded e.g. bedding, kitchen utensils, etc., and whether you would be required \\nto pay a deposit as well as made an advance payment. \\n \\n€ 250 (per month) \\nGroceries € 65 (per month) \\nMeal (affordable restaurant) € 2-5 \\nTransport € 30 (per week) \\nWi-Fi € 4-12 (per month) \\nMobile telephone (depends on usage) € 8 (per month)'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='Water € 0.60 per liter \\nCourse related costs: books/stationery/photocopying/binding € 10 (per month) \\n*Please note: The above costs are estimated and subject to each student’s \\nindividual lifestyle - personal expenses and spending habits. \\nSERVICES and SUPPORT \\nStudying overseas is a rewarding opportunity to broaden your experience and \\noutlook, but it can also be challenging. PU provides the support you need to'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='develop academic and professional skills, feel confident in your study and maintain \\nyour wellbeing. \\nPU INTERNATIONAL OFFICE \\nThe PU International team offers you advice and support during the application \\nprocess and throughout your studies at PU. Our student advisers/Mentors can assist \\nwith general enquiries, and will keep you up to - date with important news and \\nevents around PU via emails.'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='SAFETY AND SECURITY \\nPU fosters a safe and secure environment for students, staff and visitors, with 24 -\\nhour security assistance on and around campus. This includes accessible security \\nofficers, regular patrols, and closed-circuit television cameras. \\nARRIVAL TIPS \\nStudents to arrive in Bangalore 7 days prior to start of the formal classes so as to \\nfinalize the courses and to settle in their accommodation. \\nPU International Office offers a complimentary airport shuttle service from'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='Bengaluru International Airport to PU for exchange students who arrive 7 days \\nbefore Orientation begins.  Exchange students need to provide their flights details \\nand visa for arrange the pick service from the Bengaluru Airport. \\nGENERAL SUPPORT SERVICES \\nPU provides a wide range of on-campus services for students, including: \\n• Medical services \\n• Counselling services \\n• Accessibility services for students with a disability or ongoing medical \\ncondition \\n• Wi-Fi facility throughout campus'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='• Library services \\n• Sports facilities \\n• Student welfare services \\n• Canteen facilities \\n• PU Buddy \\n• ATM'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='HOW TO APPLY \\n \\n1. Choose  your  \\nprogramme  \\nAre  you  applying  as a Student  Exchange/  Study  Abroad  \\n \\n2. Check  your  eligibility  Check that you meet the entry requirements for your \\nprogram.  \\n \\n3. Discuss  your  study  \\noptions with your home \\nuniversity  \\nConsult  with  your  home  university  to understand  the \\napplication  and  credit  requirements  of studying  abroad.  \\nIf you are from PU exchange partner university, you’  ll also'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='need home university approval to participate in the \\nexchange.  \\n4. Choose your courses \\n- 12 or 18 credit points  \\nReview the information in this guide and select the \\nappropriate study plan for  your  program in PU.  \\n \\n \\n \\n5. Apply  at PU \\nExchange  Programme  \\n\\uf0a8 Ensure your home university confirms your \\nnomination to PU first.  \\n\\uf0a8 Submit the f i l led  application form  with academic \\ntranscripts along with essential supporting  \\ndocuments  as requested  on the  application  form .'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='6. Apply for PU off -campus \\naccommodation  \\n \\nYou will receive an acknowledgement of your application  \\n \\n \\n7. Offer letter and study \\nplan  \\nPU will  assess  your  application.  I f you  are  successful,  \\nPU will  email  your  offer  Letter  after  receiving  the \\nconfirmation for accommodation and administrative \\ncharges.  \\nYou  can  start  to prepare  your  study  plan.  The  average  \\ntimeframe  to process  applications  is two  to three  weeks.  \\n8. Acceptance  and \\nconfirmation  of'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='confirmation  of \\nenrolment  \\nYou must formally accept your offer and, PU will also  \\npre - enroll  you  in your  preferred, approved subjects.  \\n \\n \\n9. Apply  for a student  \\nvisa  \\nApply for a student visa. Once your student visa has  \\nbeen approved, you should  finalize your travel  \\narrangements and insurance. You must obtain an Indian \\nstudent  visa  before  you  can  commence study in India.  \\n \\n10. Pre - arrival  \\nPU will send you pre - arrival information regarding'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='accommodation, airport reception and  orientation \\nactivities.  \\n \\n \\n \\n11. Arrival  and  \\nOrientation  \\nArrive in Bangalore, India and attend PU Orientation, \\nwhich  is compulsory for  all  exchange students.  Our  \\ncomprehensive Orientation programs include information \\nsessions  and  social  activities,  to help  you  get  to know  \\nPU and meet other new and experienced students. You \\nwill also be able to finalize your enrolment and receive \\nyour student ID card.'),\n",
       " Document(metadata={'source': 'data\\\\courses.pdf'}, page_content='Phone: +91 80 2309 3500  \\nEmail: ir_office@presidencyuniversity.in \\nWeb: https://presidencyuniversity.in  \\n \\nPlease note that this factsheet is subject to change \\nLast update: January 2025'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='“Cutting through the clutter, Martin Musiol explains generative AI with \\ngreat insight and clarity. The reader is left with a clear understanding of the \\ntechnology, without the need to master complex mathematics or code. A must \\nread for those who want to understand the future.”\\n—  Rens ter Weijde, Chairman & CEO of KIMO.AI\\n“ An illuminating guide through the evolving landscape of generative AI and \\nAGI, this book masterfully demystifies complex concepts, making them acces-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='sible to all and ignites the imagination about the boundless possibilities of \\nthe future.”\\n—  David Foster, author of Generative Deep Learning, Partner at \\nApplied Data Science Partners\\n“This book is a must-read for anyone wanting to improve their understand-\\ning of where AI has come from, where it stands today, and, importantly, \\nwhere it is heading. The advent of AGI and ASI is too important not to \\nunderstand, and Martin meticulously explains many potential outcomes'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='with a factual and unbiased perspective.”\\n—  Roy Bhasin (Zeneca), author, entrepreneur,  \\nangel investor\\n“Highly recommended. Musiol deeply and expertly demonstrates how to \\nnavigate the complex, exhilarating, and essential landscape of generative AI.”\\n—  Katie King, published author,  \\nCEO of AI in Business\\n“Generative AI by Martin Musiol offers a comprehensive overview of the \\nGenAI technology and skillfully demystifies complex concepts of this trans-\\nformative AI.”'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='formative AI.”\\n—  Sheamus McGovern, entrepreneur, investor, Founder & CEO Open \\nData Science\\nPraise for Generative AI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='“Martin, my esteemed former colleague and an AI expert, has authored this \\ncrucial book designed for anyone seeking to enhance their knowledge of gen-\\nerative AI, autonomous AI agents, and AGI. From complex subjects to com-\\npelling and easily comprehensible, this book is invaluable for business \\napplications and everyday life.”\\n—  Martin Weis, Country Head Switzerland & Global Co-Lead AI, \\nAnalytics & Automation at Infosys Consulting'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='“Martin’s book masterfully encapsulates the transformative power of AI and \\nprovides great foundational knowledge for innovators and builders to explore \\nthe industry further.”\\n—  Anton Volovyk, Co-CEO Reface  \\n(GenAI app, 250m downloads, backed by a16z)\\n“This book is akin to a comprehensive playbook, detailing strategies and \\nrules for navigating the complex field of AI, much like a coach laying out a \\nwinning game plan. It masterfully presents the evolutionary stages, key'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='players beyond ChatGPT, foundational technologies, and practical guidance, \\nequipping readers to effectively ’play’ and excel in the dynamic and competi-\\ntive arena of AI.”\\n—  Dr. Harald Gunia, Leader for Applied Artificial  \\nIntelligence Europe at Infosys Consulting\\n“Martin Musiol’s book on generative AI provides a compelling narrative \\nthat unveils the meticulous evolution of this groundbreaking technology. \\nFrom the quiet simmering of its inception, to the carefully curated recipe of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='technological advancements that propelled it to unprecedented heights, \\nMusiol carefully peels back the layers, revealing the pivotal factors that \\nshaped the rise of generative AI.”\\n—  Matteo Penzo, Co-Founder & CEO of zicklearn.com\\n“Martin’s book offers deep insights and a comprehensive overview that \\nmakes this complex subject accessible to all readers.”\\n—  Prof. Dr. Patrick Glauner\\n“This book is a must-read for anyone like me captivated by artificial intel-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ligence’s present and future implications.”\\n—  Catherine Adenle, Senior Director, Global Employer Brand,  \\nElsevier, top\\xa022 AI and tech influencer'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI\\nNavigating the Course to the Artificial \\nGeneral Intelligence Future\\nMartin Musiol'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Copyright © 2024 by John Wiley & Sons, Inc. All rights reserved.\\nPublished by John Wiley & Sons, Inc., Hoboken, New Jersey.\\nPublished simultaneously in Canada and the United Kingdom.\\nISBNs: 9781394205912 (Hardback), 9781394205950 (ePDF), 9781394205943 (ePub)\\nNo part of this publication may be reproduced, stored in a retrieval system, or transmitted in any form \\nor by any means, electronic, mechanical, photocopying, recording, scanning, or otherwise, except as'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='permitted under Section\\xa0107 or 108 of the 1976 United States Copyright Act, without either the prior \\nwritten permission of the Publisher, or authorization through payment of the appropriate per-copy \\nfee to the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-\\n8400, fax (978) 750-4470, or on the web at www.copyright.com. Requests to the Publisher for \\npermission should be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Street, Hoboken, NJ 07030, (201) 748-6011, fax (201) 748-6008, or online at www.wiley.com/go/\\npermission.\\nTrademarks: WILEY and the Wiley logo are trademarks or registered trademarks of John Wiley & \\nSons, Inc. and/or its affiliates, in the United States and other countries, and may not be used without \\nwritten permission. All other trademarks are the property of their respective owners. John Wiley & \\nSons, Inc. is not associated with any product or vendor mentioned in this book.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best \\nefforts in preparing this book, they make no representations or warranties with respect to the accuracy \\nor completeness of the contents of this book and specifically disclaim any implied warranties of mer-\\nchantability or fitness for a particular purpose. No warranty may be created or extended by sales rep-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='resentatives or written sales materials. The advice and strategies contained herein may not be suitable \\nfor your situation. Y ou should consult with a professional where appropriate. Further, readers should \\nbe aware that websites listed in this work may have changed or disappeared between when this work \\nwas written and when it is read. Neither the publisher nor author shall be liable for any loss of profit'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='or any other commercial damages, including but not limited to special, incidental, consequential, or \\nother damages. Generative AI tools were used by the author to research ideas for this book; however, \\nthe writing and finished text of the book are completely the work of the author and the Wiley editorial \\nstaff.\\nFor general information on our other products and services or for technical support, please contact'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='our Customer Care Department within the United States at (800) 762-2974, outside the United States \\nat (317) 572-3993 or fax (317) 572-4002.\\nWiley also publishes its books in a variety of electronic formats. Some content that appears in print \\nmay not be available in electronic formats. For more information about Wiley products, visit our web \\nsite at www.wiley.com.\\nLibrary of Congress Control Number: 2023951020\\nCover image: © undefined/Getty Images\\nCover design: Wiley'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='T o my parents, who have always supported me, and to my grandma \\nHelena, whose wise words continue to echo in my ears, guiding me \\nthrough life. I will be forever grateful for the deep love I have received \\nfrom you, and rest assured, I feel the same for you. A truth perhaps \\nnot spoken enough, yet profoundly felt.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Introduction ix\\nChapter 1 AI in a Nutshell 1\\nChapter 2 Innovative Approaches for\\xa0High-Quality  \\nData Generation 23\\nChapter 3 Generative AI’s Broad  Spectrum of  \\nApplications 119\\nChapter 4 Generative AI’s Exponential Growth 219\\nChapter 5 Ethical Concerns and Social Implications  \\nof Generative AI 285\\nChapter 6 Artificial General  Intelligence in\\xa0Sight 337\\nAcknowledgments 405\\nAbout the\\xa0Author 407\\nIndex  409\\xa0\\nContents\\nvii'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ix\\nI\\nn the realm of technology, epochs of transformation are often \\nignited by the spark of human imagination, fused with the \\nfinesse of engineering artistry. We stand at the precipice of such \\nan epoch, where the realms of generative AI unfurl into the once \\nuncharted territories of artificial general intelligence (AGI). I am \\nboth thrilled and humbled to be your guide on this thrilling \\nexpedition into the future, a journey that begins with the pages \\nof this book.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='of this book.\\nThe technological zeitgeist of our times is one of exponential \\nprogress. A mere glimpse into the recent past reveals the embry-\\nonic stages of generative AI, yet, within a fleeting span, advance-\\nments like ChatGPT have marked a point of no return. This \\ncrescendo of innovation is not confined to textual realms alone \\nbut spans across images, videos, 3D objects, datasets, virtual real-\\nities, code, music, and sound generation, each stride accelerating'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='our pace toward the enigmatic horizon of AGI. The rapid matu-\\nration and adoption of generative AI outshine the evolutionary \\narcs of many preceding technologies.\\nIt was during the cusp of this book’s creation that the concept \\nof autonomous AI agents morphed into a tangible reality, cour -\\ntesy of emerging open source frameworks. Now, a subscription \\naway, the first AI agents are at our beck and call. This swift pro-\\ngression, magnifying the efficiency of AI model development, \\nIntroduction'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='x IntroductIon\\nunderscores the urgency and the timeliness of delving into the \\ndiscourse this book intends to foster. As you traverse through its \\nchapters, you’ll realize we are merely at the dawn of an exhilarat-\\ning technological epoch with a vast expanse yet to be unveiled.\\nWho should venture into this exploration? Whether you’re a \\ntechnology aficionado, a student with a zest for the unknown,  \\na policymaker, or someone who’s merely curious, this book beck-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ons. No prior acquaintance with AI or machine learning is \\nrequired; your curiosity is the sole ticket to this expedition. As we \\ncommence, we’ll demystify the essence of AI, its lexicon, and its \\nmetamorphosis over time. With each page, we’ll delve deeper, yet \\nthe narrative is crafted to foster an understanding, irrespective of \\nyour prior knowledge. By the narrative’s end, your imagination \\nwill be aflame with the boundless possibilities that the future holds.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='The narrative arc of this book has been meticulously crafted \\nto offer an understanding yet a profound insight into generative \\nAI and its trajectory toward AGI. Our expedition begins with the \\nrudiments of AI, tracing its evolution and the brilliant minds that \\npropelled it forward. As we delve into the heart of generative AI, \\nwe’ll explore its broad spectrum of applications, unraveling \\npotential startup ideas and pathways to venture into this domain.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='The discussion will then transcend into the convergence of \\ndiverse technological realms, each advancing exponentially \\ntoward a shared zenith. Ethical and social considerations, indis-\\npensable to this discourse, will be deliberated upon before we \\nventure into the realms of AGI, humanoid and semi- humanoid \\nrobotics, and beyond. Through the annals of my experience, \\nincluding my tenure as the generative AI lead for EMEA at Info-\\nsys Consulting, we’ll traverse through real- world scenarios,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='albeit veiled for confidentiality, offering a pragmatic lens to envi-\\nsion the theoretical discourse.\\nWhat sets this narrative apart is not merely the content, but \\nthe vantage point from which it is observed. My journey, from'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Introduction xi\\nadvocating generative AI since 2016, founding GenerativeAI.net \\nin 2018, to now sharing a platform with luminaries at the AI \\nSpeaker Agency, has been nothing short of exhilarating. It’s \\nthrough the crucible of real- world implementations and contin-\\nuous discourse with global thought leaders that the insights \\nwithin this book have been honed. Our conversations, a conflu-\\nence of diverse perspectives, have enriched the narrative, making \\nit a crucible of collective wisdom.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='A treasure trove of knowledge awaits to equip you to navi-\\ngate the complex yet exhilarating landscape of generative AI and \\nAGI. The ethos of this narrative is to empower you to become a \\n10X more effective human, to harness the tools that propel you \\nforward, and should a spark of an idea ignite within, to pursue it \\nwith vigor. Things can be figured out along the way, especially in \\nthis era equipped with generative AI tools. Remember, AI in itself'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='won’t replace us, but those wielding AI effectively certainly will \\nhave an edge.\\nIn the words of British physicist David Deutsch, our civiliza-\\ntion thrives on technological growth, and it’s our prerogative to \\nstrive for a better future. This book is a stepping stone toward \\nthat endeavor, and I invite you to step into the future, one page \\nat a time.\\nHow to\\xa0Contact the\\xa0Publisher\\nIf you believe you’ve found a mistake in this book, please bring it'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='to our attention. At John Wiley & Sons, we understand how \\nimportant it is to provide our customers with accurate content, \\nbut even with our best efforts an error may occur.\\nIn order to submit your possible errata, please email it to our \\nCustomer Service T eam at wileysupport@wiley.com with the \\nsubject line “Possible Book Errata Submission.”'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='xii IntroductIon\\nHow to\\xa0Contact the\\xa0Author\\nI appreciate your input and questions about this book! Feel free \\nto contact me at the following:\\nMartin Musiol’s email: generativeai.net@gmail.com\\nMartin’s LinkedIn profile: www.linkedin.com/in/martinmusiol1\\nGenerativeAI.net’s web page: https://generativeai.net'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='1\\nN\\no other field of technology has such inconsistent jargon as \\nartificial intelligence (AI). From mainstream media to tech \\ninfluencers to research scientists, each layer of media has con-\\ntributed to that confusion. In order of their degree of contribu-\\ntion and frequency, I observed mainstream media simplifying \\nand misusing terms consistently, tech influencers misunderstand-\\ning the tech in- depth, and even some research scientists over-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='complicating their model findings with fancy terms. By no means \\ndo I intend to criticize research scientists. They are the backbone \\nof everything discussed in this book. Their work offers solutions \\nto a plethora of problems, making AI the umbrella term for \\nalmost every intelligent problem. However, its interdisciplinary \\nnature, the rapid advancements in this space, and AI’s general \\ncomplexity make it already difficult to gain a clear understanding'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='of this field. I am convinced that consistent and clear language \\nwould help to understand this topic area.\\n1\\nCHAPTER\\nAI in a Nutshell'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='2 GENERATIVE AI\\nWe can see two broad classes in AI: generative AI, the subject \\nof this book, and discriminative AI. The latter is the traditional \\nand better- known part of AI. Before delving into both AI classes, \\nlet’s take a moment to understand the broader picture of AI, \\nmachine learning (ML), deep learning (DL), and the process of \\ntraining models, to avoid getting ahead of ourselves.\\nWhat Is AI?\\nEven though AI includes a broad spectrum of intelligent code,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='the term is often incorrectly used. Figure\\xa01.1 shows how AI, ML, \\nand DL are related. ML, a part of AI, learns from data. DL, a \\ndeeper part of ML, uses layered setups to solve tougher prob-\\nlems. Non- self- learning programs like expert systems don’t learn \\nfrom data, unlike ML and DL. We’ll explore these more next.\\nHow AI Trains Complex Tasks\\nAI can perform tasks ranging from predefined expert answers, \\nalso known as expert systems, to tasks that require human- level'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='intelligence. Think about recognizing speech and images, \\nAI\\nNon-Self-\\nLearning\\nAlgorithms\\nSelf-Learning\\nAlgorithms\\nML\\nDL\\nFIGURE\\xa01.1 The relationship between AI, ML, and DL'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 3\\nunderstanding natural language processing (NLP), making \\nsophisticated decisions, and solving complex problems. For tasks \\nlike this, the AI has to train on a respective dataset until it is able \\nto perform the desired activity as well as possible. This self- \\nlearning part of AI is referred to as machine learning (ML). \\nBecause most of the interesting applications are happening \\nthrough machine learning in one way or another, and to keep it'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='simple, we use AI and ML interchangeably.\\nT o make it tangible, we are designing an AI system that rates \\nthe cuteness of cats from 5 (absolutely adorable) to 1 (repulsively \\ninelegant). The ideal dataset would consist of pictures of cute \\nkittens, normal cats, and those half- naked grumpy cats from the \\nInternet. Further, for classifying pictures in a case like this, we \\nwould need labeled data, meaning a realistic rating of the cats.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='The model comes to life through three essential steps: training, \\nvalidation, and evaluation.\\nIn training, the model looks at each picture, rates it, com-\\npares it with the actually labeled cuteness of the cat, and adjusts \\nthe model’s trainable parameters for a more accurate rating next \\ntime— much like a human learns by strengthening the connec-\\ntions between neurons in the brain. Figure\\xa01.2 and Figure\\xa01.3 \\nillustrate training and prediction, respectively.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Throughout the training process, the model needs to make \\nsure training goes in the right direction— the validation step. In \\nvalidation, the model checks the progress of the training against \\nseparate validation data. As an analogy, when we acquire a skill \\nlike solving mathematical problems, it makes sense to test it in \\ndedicated math exams.\\nAfter training has been successfully completed and respective \\naccuracy goals have been reached, the model enters the predic-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tion or evaluation mode. The trainable parameters are not being \\nadjusted anymore, and the model is ready to rate all the cats in \\nthe world.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='4 GENERATIVE AI\\nIt is typical for a model in production mode that the accuracy \\ngets worse over time. The reason for this could be that the real- \\nworld data changed. Maybe we are only looking at kittens and \\nthey are all cute compared to our training data. Retraining the \\nmodel, whenever accuracy decreases or by scheduling retraining \\nperiodically, tackles the problem of a discrepancy between the \\ndata distribution of training data and evaluation data.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Perhaps you have a sense already that training AI models \\nrequires much more computing power than they need in  \\nprediction mode. T o adjust its trainable parameters, often referred \\nto as weights, we need to calculate the grade of adjustment care-\\nfully. This happens through a famous model function called \\nAI Model in Prediction\\nAI Model\\nImage Cute = 5\\nFIGURE\\xa01.3 Prediction mode in a supervised ML model.\\nImage1\\nAI Model in Training (2 Steps)\\nAI Model - Training prediction, get error\\nLabel'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Label\\nAI Model - Use error to update weights (Bach propagation)\\nError\\nCute = 5 Cute = 5\\nCute = 4\\nError\\n2\\nFIGURE\\xa01.2 In supervised training of a ML model, two main steps are \\ninvolved: predict the training data point, then update the trainable \\nparameters meaningfully based on the prediction’s accuracy.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 5\\nbackpropagation. It entails the backward propagation of prediction \\nerrors— the learning from making mistakes in the training pro-\\ncess. The errors are turned back to respective weights for improve-\\nment. This means that we go forward to predict a data point and \\nbackward to adjust the weights. In prediction mode, however, we \\ndon’t adjust the weights anymore, but just go forward and predict. \\nThe function that has been trained through the training data is'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='being applied, which is comparatively cheap.\\nUnsupervised Learning\\nWhen ML models reach a certain complexity by having many \\ncomputing stages, called layers, we enter the realm of deep learn-\\ning (DL). Most of the cutting- edge applications are at least  \\npartially drawing their algorithms from DL. Algorithms are step- \\nby- step instructions for solving problems or performing tasks.\\nThe preceding example of rating the cuteness of a cat was'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='simplified drastically and didn’t tell the whole story. A relevant \\naddition to this is that as we train on labeled cat pictures, with \\nthe label being the cuteness of the cats, we call this supervised \\nmachine learning. With labels, we provide guidance or feedback \\nto the learning process in a supervised fashion.\\nThe counterpart for supervised ML is called unsupervised \\nmachine learning. The main difference between them is that in'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='unsupervised ML the training data is not labeled. The algorithms \\nought to find patterns in the data by themselves.\\nFor example, imagine you have a dataset of customer pur -\\nchases at a grocery store, with information about the type of \\nproduct, the price, and the time of day. In AI these attributes are \\ncalled features. Y ou could use an unsupervised clustering algo-\\nrithm to group similar purchases together based on these fea-\\ntures. This could help the store better understand customer'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='buying habits and preferences. The algorithm might identify'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='6 GENERATIVE AI\\nthat some customers tend to buy a lot of fresh produce and dairy \\nproducts together, whereas others tend to purchase more pro-\\ncessed foods and snacks. This information could be used to cre-\\nate targeted marketing campaigns or to optimize store layout \\nand product placement.\\nComparing the performance of unsupervised learning appli-\\ncations to that of supervised learning applications is akin to con-\\ntrasting boats with cars— they represent distinct methodologies'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='for addressing fundamentally diverse problems. Nevertheless, \\nthere are several reasons why we reached success years faster \\nwith supervised than with unsupervised learning methods.\\nIn supervised learning, the model is given a training dataset \\nthat already includes correct answers through labels. Under -\\nstandably, this helpful information supports model learning. It \\nalso accurately outlines the AI model’s intended objective. The'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='model knows precisely what it is trying to achieve. Evaluating \\nthe model’s performance is simpler than it is in unsupervised \\nmachine learning, as accuracy and other metrics can be easily \\ncalculated. These metrics help in understanding how well the \\nmodel is performing.\\nWith this information, a variety of actions can be taken to \\nenhance the model’s learning process and ultimately improve its \\nperformance in achieving the desired outcomes.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Unsupervised models face the challenge of identifying data \\npatterns autonomously, which is often due to the absence of \\napparent patterns or a multitude of ways to group available data.\\nGenerative AI a Decade Later\\nGenerative AI predominantly employs unsupervised learning. \\nCrafting complex images, sounds, or texts that resemble reason-\\nable outputs, like an adorable cat, is a challenging task compared \\nto evaluating existing options. This is primarily due to the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='absence of explicit labels or instructions.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 7\\nT wo main reasons explain why generative AI is taking off \\nroughly a decade after discriminative AI. First, generative AI is \\nmostly based on unsupervised learning, which is inherently more \\nchallenging. Second, generating intricate outputs in a coherent \\nmanner is much more complex than simply choosing between \\nalternatives. As a result, generative AI’s development has been \\nslower, but its potential applications are now visible.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Between supervised and unsupervised learning, there are \\nplenty of hybrid approaches. We could go arbitrarily deep into \\nthe knick- knacks of these ML approaches, but because we want \\nto focus on generative AI, it is better to leave it at that. If you \\nwant to dive deeper into the technicalities, I recommend the \\nbook Deep Learning (Adaptive Computation and Machine Learn-\\ning series), by Ian Goodfellow, Y oshua Bengio, and Aaron Cour-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ville (MIT Press, 2016), which covers ML and DL in great detail, \\nlaying the theoretical generative AI foundation. It is regarded as \\nthe best book in the space, which isn’t surprising, given the \\nauthors. I will come back to those gentlemen later.\\nThe AI landscape is vast and ever- expanding. In this book, I \\nstrike a balance between simplifying concepts for clarity and \\nproviding sufficient detail to capture the essence of recent AI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='advancements. T o understand what generative AI is and its value \\nproposition, we first have to understand the traditional part of \\nAI, called discriminative AI.\\nWhat Is Discriminative AI?\\nDiscriminative AI models made headlines long before large lan-\\nguage models (LLMs) like ChatGPT by OpenAI and image gen-\\neration models like stable diffusion by Stability AI entered the \\nstage. Since the term “artificial intelligence” was coined by John'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='McCarthy in 1955, discriminative models have yielded great \\nresults, especially in the past 15 years.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='8 GENERATIVE AI\\nDiscriminative AI focuses on algorithms that learn to tell \\napart different data classes. They recognize patterns and features \\nunique to each class, aiming to link input features with labels for \\nthe output. This way, they can effectively classify instances into \\npredefined groups, making it easier to distinguish one class from \\nanother. Discriminative AI has found numerous applications in \\nvarious domains, including NLP , recommendations, and com-\\nputer vision.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='puter vision.\\nIn the field of NLP , discriminative AI is used to classify text \\ndata into different categories, such as sentiment analysis or topic \\nclassification. In the domain of recommendations, discriminative \\nAI is used to predict user preferences and make personalized \\nproduct recommendations. In computer vision, discriminative \\nAI is used to recognize objects and classify images based on their \\ncontent. The applications of discriminative AI are vast and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='diverse, and its impact on various industries is immense.\\nLooking at existing applications, discriminative AI generally \\nhas five main tasks: classification, regression, clustering, dimen-\\nsionality reduction, and reinforcement learning. They are not \\ncrucial to be able to follow the book’s thread, but it helps to \\nunderstand them conceptually because then the term “discrimi-\\nnative” and what it means in the context of AI becomes apparent.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Put simply, in one way or another, this part of AI is deciding, \\nselecting, distinguishing, or differentiating on data or a prob-\\nlem at hand.\\nClassification\\nThe objective of classification is to accurately predict the class of \\nnew inputs based on prior training with labeled examples  \\n(Figure\\xa0 1.4). This supervised learning process uses training \\nexamples accompanied by their respective class labels.\\nFor instance, consider unlocking your phone with facial rec-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ognition. Y ou initially show your face from various angles,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 9\\nallowing the classifier model to learn your appearance. Advanced \\nface recognition systems, like the iPhone’s FaceID, quickly iden-\\ntify you due to their extensive pretraining and incorporation of \\nbiometric information to deterministically classify users. In \\nessence, the model or system of models assesses your face and \\ndiscriminates whether you belong to the “person with access \\nrights” or “person without access rights” class.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Classification has driven breakthroughs in diverse applica-\\ntions, including image classification, sentiment analysis, disease \\ndiagnosis, and spam filtering. These applications typically involve \\nmultiple processing steps and rely on deep learning techniques.\\nRegression\\nA regression model in AI is designed to predict numerical values \\nfor new inputs based on data it has learned from a given problem. \\nIn this case, the output is not a class label but a continuous value.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='For example, imagine you want to buy a 100- square- meter apart-\\nment with a balcony in Munich, Germany. A real estate agent pre-\\nsents three similar apartments, priced at 2\\xa0million, 2.5\\xa0million, and \\n2.7\\xa0million euros.\\nY ou have three options: the naive approach, where you \\nassume these three properties represent the market; the informed \\napproach, where you estimate market prices by researching mul-\\ntiple offers; or the data science approach, which involves build-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ing a machine learning model to determine a fair price by \\nAI Model\\nImage\\nAccess\\nNo access\\nFIGURE\\xa01.4 In ML, the concept of classification involves assigning data \\nto one of a finite set of categories.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='10 GENERATIVE AI\\nanalyzing all available properties in the market with their \\nprice tags.\\nA well- trained regression model will give you a market- based \\nand rational price, as it takes into account all the characteristics \\nof apartments in the market (Figure\\xa0 1.5), helping you make a \\nmore informed decision. By recommending a price, the model \\ninherently has a discriminative nature.\\nClustering\\nAs the name suggests, this application field in AI clusters data'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='points. Be they people, groceries, or songs, based on a similarity \\nmeasure, these items are grouped. By the way, you are being clus-\\ntered all the time. For example, Internet ads are targeted to your \\ndigital persona, including your sex, age, IP address (which repre-\\nsents your location), and all other data ad- providing companies \\nhave collected about you. T o cement it, if you use a web page that \\nrecommends songs like Spotify, movies like Netflix, and prod-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ucts like Amazon to you, then you have been clustered. In the \\nsuccess of big tech companies like those mentioned previously, \\nclustering algorithms have played a crucial role, as they are the \\nbackbone of every recommendation engine.\\nHouse\\nBalcony\\n67 m2\\n...\\nPrice\\nAI Model\\nHouse Instances\\n2 Million\\nLearnt Regression\\nm2\\nBalcony yes/no\\n67\\n1 Million\\nFIGURE\\xa01.5 In regression, data like house details go into the ML model, \\nwhich then predicts its price based on these features.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 11\\nIn clustering tasks, the data comes without labels. For \\ninstance, there are no labels on our heads indicating “prefers Ben \\n& Jerry’s Chubby Hubby.” Clustering models must identify pat-\\nterns and groups autonomously, making it an unsupervised learn-\\ning task. Moreover, the process of assigning items or personas to \\nclusters is a decision- making aspect of discriminative AI.  \\nFigure\\xa0 1.6 illustrates the conceptual operation of a clustering'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='model. By analyzing other people’s behavior, it infers that indi-\\nviduals who purchase butter and milk might also prefer cereals. \\nAdding soda to the mix increases the likelihood of a preference \\nfor Ben & Jerry’s Chubby Hubby.\\nDimensionality Reduction\\nDimensionality reduction is not an application field of AI that is \\ndiscussed much in mainstream media. It is rather research- heavy \\nand often a means to achieve something greater, more efficiently.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Its primary purpose is to reduce low-information data, mainly \\nmaking machine learning applications as effective as possible. By \\n“low- information data,” I mean data that contains little to no \\nmeaningful insights to solve a problem. See Figure\\xa0 1.7 for a  \\nvisual representation.\\nShopping List:\\n- Milk\\n- Butter\\n- Flour\\nButter\\nAI Model\\nRecommend\\nB & J Chubby\\nHubby\\nMilk\\nOther groceries\\nLikes pizza\\nLikes cereals\\nLikes Ben & Jerry’s\\nChubby Hubby'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Chubby Hubby\\nFIGURE\\xa01.6 Clustering model identifying buying patterns'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='12 GENERATIVE AI\\nImagine that you have an extensive recipe book with hun-\\ndreds of recipes. Each recipe has several ingredients, and some of \\nthem are similar. For example, many recipes might call for salt, \\npepper, and olive oil. If you were to list all the ingredients used \\nin the book, it would be a long list with many similar items.\\nNow imagine that you want to make a simpler version of the \\nrecipe book that is easy to use on a daily basis. One way to do this'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='is to group similar ingredients. For example, you could create a \\ncategory called “seasonings” that includes salt, pepper, and other \\nspices used in the recipes. Y ou could also create a category called \\n“cooking oils” that contains olive oil, vegetable oil, and so forth.\\nIn the world of data science, the same thing happens. We \\nmight have a large dataset with many different features, and we \\nwant to simplify it to make it easier to work with. Dimensionality'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='reduction techniques help us to do this by finding a way to rep-\\nresent the data with fewer features while still preserving essential \\ninformation. They make it easier to analyze data, build models, \\nor visualize data more understandably.\\nNaturally, the data is not labeled, and we don’t know up \\nfront which features carry relevant information. In an unsuper -\\nvised manner, the models must learn to distinguish what low-  \\ninformation data can be modified or truncated and how. The'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='models must decide or discriminate, indicating that we are in \\ndiscriminative AI.\\nDataset\\nMany features\\nAI Model\\nDataset\\nFew features\\nX\\nY\\nZ\\nY\\nY\\nX\\nZ\\nFIGURE\\xa01.7 Dimensionality reduction'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 13\\nReinforcement Learning\\nReinforcement learning (RL) models, typically called agents, \\nlearn from positive or negative consequences that their actions \\nyield in real- world or virtual environments. A positive conse-\\nquence is a reward, and a negative consequence is a punishment. \\nIn Figure\\xa01.8, the agent executes an action in a virtual/physical \\nenvironment, altering the environment (even if minimally), and \\nreceives a reward or penalty based on its stated goal. During the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='training phase of the RL model, initial emphasis is on explora-\\ntion to identify available paths (e.g., for warehouse navigation), \\ngradually shifting to an exploitation phase for efficient goal \\nachievement (or technically, maximizing rewards), as indicated in \\nFigure\\xa01.9.\\nVirtual environments encompass a wide range of applica-\\ntions, from simulations for practicing real- world maneuvers to \\ngaming experiences, and even stock market environments for'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='trading agents. In gaming, AI has demonstrated remarkable \\nsuper- human abilities, excelling in games such as Super Mario. \\nWhen an RL agent acts in a real- world environment, it is prob-\\nably a robot in a warehouse or Boston Dynamics’s Atlas perform-\\ning ninja moves. The agents acquire the ability to determine the \\noptimal action in a given situation, positioning them as a compo-\\nnent of discriminative AI.\\nAgent\\nAction\\nNew state of environment\\nReward/\\npunishment\\nVirtual/\\nphysical\\nenvironment'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='environment\\nFIGURE\\xa01.8 Technical workings of reinforcement learning models'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='14 GENERATIVE AI\\nReinforcement learning has many exciting aspects, one of \\nwhich is forming great synergies with generative AI. It was of lit-\\ntle public interest for decades until its turning point in 2016, \\nwhen AlphaGo by Google’s DeepMind won a series of Go \\nmatches against the former world champion Lee Sedol. Go is a \\ncomplex Chinese board game with a 19×19 grid, and thus it has \\n10^172 possible moves. For comparison, there are 10^82 atoms'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='in the universe. RL not only plays complex games exceptionally \\nwell but also delivers on a variety of tasks, ranging from autono-\\nmous vehicles to energy management in buildings. More on the \\npowerful collaboration between RL and generative AI later.\\nAdditionally, RL is helping to advance our understanding of \\nthe learning process itself, leading to new insights into how intel-\\nligence works and how it can be developed and applied.\\nWhat Is Generative AI?'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='So far we have talked about discriminative AI, which can decide, \\ndistinguish, or discriminate between different options or con-\\ntinuous values.\\nGenerative AI, however, is fundamentally different. It has the \\nability to generate all kinds of data and content. By learning the \\npatterns and characteristics of given datasets, generative AI \\nLearn First\\nData Collection/Sample Learning\\nExplore/Learn Exploit/Earn\\nTime\\nFIGURE\\xa01.9 Exploration versus exploitation in RL training over time'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 15\\nmodels can create new data samples that are similar to the \\noriginal data.\\nRecent advancements, such as the mind- blowing creations of \\nMidjourney’s image generation, the steps of video generation \\nlike Meta’s Make- A- Video, and the conversational abilities of \\nChatGPT , have completely altered the way we view AI. It is a \\nfascinating field that revolutionizes the way we create products \\nand interact with data.\\nGenerally speaking, generative AI models can perform three'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tasks, each with a unique and exciting set of applications.\\nData Generation\\nFirst, and it is the most obvious one, that they can generate all \\nkinds of data, including images, videos, 3D objects, music, voice, \\nother types of audio, and also text—like book summaries, poems, \\nand movie scripts. By learning the patterns and characteristics of \\ngiven data, generative AI models can create new data samples \\nthat are similar in style and content to the original.\\nData Transformation'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Data Transformation\\nThe second task of generative AI is to perform data transforma-\\ntions. This means transforming existing data samples to create \\nnew variations of them. T ransformations can reveal new insights \\nand create appealing outputs for various applications. For exam-\\nple, you can transform winter pictures into summer pictures or \\nday pictures into night pictures. T ranslating an image from one \\ndomain (for example, summer) into another (winter) is called a'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='domain transfer. Image style transformation involves taking an \\nimage, such as a photograph of your garden, and maintaining the \\ncontent (i.e., the garden) while altering its appearance to resem-\\nble the artistic style of, say, Monet’s paintings. This process,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='16 GENERATIVE AI\\nknown as style transfer, is not limited to visual content like photos \\nand videos but can also be applied to other data types like music, \\ntext, speech, and more. The essence of style transfer lies in pre-\\nserving the original content while imbuing it with a distinct and \\nrecognizable, often artistic, flair.\\nStyle transfer is more than just a delightful tool; it possesses \\nthe potential to significantly improve datasets for broader appli-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='cations. For example, researchers from Korea and Switzerland \\nhave independently investigated the use of style transfer tech-\\nniques to augment the segmentation of cancer cells in medical \\nimages using machine learning. This method, dubbed contextual \\nstyle transfer, relies on the seamless integration of style- transferred \\ninstances within the overall image, ensuring a smooth and cohe-\\nsive appearance— something that generative adversarial net-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='works (GANs) are able to perform. In a fascinating study, Nvidia \\nshowcased a remarkable improvement in segmentation perfor -\\nmance by incorporating synthetic data into the training set. This \\nintegration led to a leap from 64 percent to 82 percent in accu-\\nracy simply by augmenting the dataset, without modifying the \\nmachine learning pipeline in any way.\\nData Enrichment\\nAs already indicated with style transfer, the third task of genera-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tive AI is to enrich datasets to improve machine learning models \\nultimately. This involves generating new data samples similar to \\nthe original dataset to increase its size and diversity. By doing so, \\ngenerative AI can help to improve the accuracy and robustness of \\nmachine learning models.\\nImagine we want to build a computer vision model that uses \\nML techniques to classify whether rare cancer cells are benign or \\nmalignant. As we are looking at a rare cancer type, it will be a'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='small dataset to train on. In real- world scenarios, privacy issues \\nare another data- diminishing factor. However, our neural net is'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 17\\ndata- hungry and we can’t get the most out of its power, landing \\nat 64 percent classification accuracy. Through generative AI, rare \\ncancer images can be generated to create a larger and more \\ndiverse training dataset for improved detection performance.\\nOverall, the capabilities of generative AI are truly remarka-\\nble, and the potential applications are vast and varied. AI limits \\nare being pushed every day, not only by research but also by for-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='profit companies. This is especially true of generative AI.\\nIf we zoom out further, we see that the overall concept of \\ngenerative AI is even simpler. Models generate data based on \\nsome input. The complexity of the input can vary a lot. It could \\nrange from simple tasks, such as transforming a single digit like \\n6\\xa0into a handwritten image, to complex endeavors like applying \\ndomain transformations to a video.\\nUnder the\\xa0Radar No More: Picking Up\\xa0Speed'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='What we often observe, especially in AI, is that a new tech \\napproach has early roots, but has been in stealth mode for a cou-\\nple of decades. Once sufficient advancements transpire in a \\nrelated tech domain, the dormant technology awakens, deliver -\\ning substantial value in real- world applications. This is recog-\\nnized as technological convergence.\\nDeep Learning Tech Convergence with GPUs The advent \\nof deep learning, the underlying technology propelling fields'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='such as computer vision and robotics, traces its roots back to \\n1967, when the first neural network, the multilayer perceptron, \\nwas conceived and introduced by two prominent Soviet scien-\\ntists, Ivakhnenko and Lapa.1 For numerous decades deep learn-\\ning struggled to yield tangible business value and real- world \\n1A. G. Ivakhnenko and Valentin Grigor’evich Lapa,\\xa0 Cybernetics and Forecasting T echniques, American Elsevier \\nPublishing Company, 1967.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='18 GENERATIVE AI\\napplications. However, a transformative moment arrived with \\nthe emergence of graphics processing units (GPUs) at the onset \\nof the 21st century.\\nGPUs first became popular in the gaming industry. In the \\nlate 1990s and early 2000s, video games became increasingly \\ncomplex and required more processing power to render high- \\nquality graphics and animations.\\nIn the 1990s, GPUs were initially developed with the pri-\\nmary aim of providing specialized processing for intricate 3D'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='graphics and rendering in video games and other computer \\napplications. Firms such as 3DFX, ATI, and Nvidia spearheaded \\nthese advancements. The early 2000s witnessed another signifi-\\ncant development for GPUs: the introduction of parallel pro-\\ncessing, enabling multiple calculations to be executed \\nsimultaneously.\\nThis ability to compute large amounts of data breathed new \\nlife into deep learning, allowing it to gain traction and experi-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ence a surge in research popularity. Leveraging GPUs’ enhanced \\ncapabilities, researchers and practitioners accelerated deep learn-\\ning’s potential, sparking a multitude of practical applications. \\nT oday, it’s unimaginable to train a robust machine learning or \\ndeep learning model without the assistance of GPUs.\\nDeep learning has reaped the benefits of other advancements \\nas well. The Internet’s growth and technological innovations \\nprovided abundant data for training models, while committed'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='researchers and research, in general, led to numerous break-\\nthroughs in deep neural networks. This progress extends from \\nconvolutional neural networks achieving remarkable feats in \\nimage recognition to recurrent neural networks demonstrating \\nadvanced NLP capabilities. It’s not just the researchers who are \\npassionate about the subject; capital allocators and profit- driven \\ncompanies have also invested heavily in the field.\\nIncidentally, it’s worth mentioning that we are now seeing,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='and will likely keep seeing, a similar rise in interest in generative'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 19\\nAI. The growth of other areas, especially discriminative AI and \\ncomputational power, along with the increasing amount of data, \\nwere crucial for generative models to evolve in the background.\\nT oday, we see billions being invested in generative AI pro-\\njects aimed at tackling a wide range of business and non- business \\napplications, as long as people can imagine it. This growing focus \\non generative AI promises to bring even more transformative'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='advancements in the near future, building on the foundation \\nestablished by previous AI breakthroughs.\\nIn today’s attention economy, capturing the focus of individ-\\nuals has become increasingly challenging, as attention itself is a \\nscarce and valuable resource. The widespread adoption of the \\nInternet, social media, and other digital technologies has led to \\nan overwhelming influx of information and stimuli, all compet-\\ning for our limited attention. Consequently, only groundbreak-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ing technologies can truly stand out and capture the spotlight. \\nFor a long time, generative AI remained relatively obscure in this \\ncompetitive landscape. However, recent advances and remarka-\\nble achievements have now propelled generative AI into promi-\\nnence, showcasing its immense potential and securing its place at \\nthe forefront of technological innovation.\\nGenerative AI’s Early Impact Generative AI is still quite new, \\nbut its future effects are expected to be amazing, going beyond'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='what we’ve seen so far. Its influence can be noticed in many areas, \\nbut it has mainly made a difference in three sectors: creative \\nindustries, gaming, and natural language processing.\\nCreative Industries Generative AI has made a lasting impact on \\ncreative fields like art. This technology enables artists to create \\nunique and inventive digital artworks. By studying patterns and \\nstyles in existing art, music, and fashion, AI algorithms can pro-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='duce new content that matches market trends and engages'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='20 GENERATIVE AI\\naudiences. In the world of music, these algorithms can generate \\noriginal tracks or remix current ones, opening up fresh possibili-\\nties for both producers and artists.\\nThe integration of generative AI has led to new business \\nmodels in the creative industry, such as selling exclusive digital \\nart or creating customized products using AI- generated designs. \\nThis growth has occurred alongside a technological convergence'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='between AI and the rapidly expanding cryptocurrency landscape.\\nIn the last eight years, the cryptocurrency world has seen \\nincredible progress, with numerous coins quickly making some \\npeople wealthy and leaving others financially devastated. Decen-\\ntralized finance and institutional adoption have drawn significant \\ninterest. However, the most far- reaching impact may come from \\nnon- fungible tokens (NFT s).\\nNFT s allow artists and creators to produce unique, verifiable'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='digital assets, leading to a growing demand for imaginative, high- \\nquality AI- generated art. While not the sole driving force behind \\nadvancements in image generation, the NFT market has undeni-\\nably accelerated progress in this area.\\nGaming Industry The gaming industry has experienced a sig-\\nnificant transformation due to generative AI, which has opened \\nup possibilities for a variety of new game content, such as levels, \\ncharacters, 3D objects, scenarios, and even entire quests. A nota-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ble example is Microsoft’s Flight Simulator, which partnered \\nwith Blackshark.ai to generate a photorealistic, three- dimensional \\nworld from two- dimensional satellite images, covering the \\nwhole Earth.\\nThe popularity of open- world concepts in gaming has \\nencouraged many companies to adopt AI- generated content. \\nImagine AI algorithms that study player behavior and dynami-\\ncally modify game difficulty or generate new content on the spot,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI in a Nutshell 21\\nleading to personalized and engaging gaming experiences. Con-\\nsider the potential of giving non- player characters (NPCs) AI- \\ndriven language models for more captivating and immersive \\ninteractions. These advancements could make returning to the \\nreal world a challenge.\\nBy using generative AI to create in- game items and environ-\\nments more efficiently, gaming companies can allocate more \\ntime and resources to concentrate on core aspects, ensuring the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='production of intriguing and original content. The future of \\ngaming, fueled by generative AI, is set to be an exciting and \\nimmersive adventure for players.\\nNatural Language Processing The third impact vertical is not a \\nsingle industry per se but rather many industries.\\nGenerative AI can be used to generate new content such as \\ntext, summaries, or translations. Large language models are at \\nthe forefront of generative AI applications, with widespread'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='impacts across various industries. LLMs can improve operational \\nefficiencies by automating repetitive internal processes and \\naccelerating innovation through customer feedback analysis, \\ninsights, and market research. These models can also improve \\ncustomer experiences with concise answers and summaries avail-\\nable 24/7. The potential for managing knowledge is perhaps one \\nof the most significant aspects of AI systems; organizations with'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='specialized knowledge can offer their expertise in a tailored and \\nconcise manner to end users. T ake the Mayo Clinic, for instance. \\nSpecializing in patient care, research, and education, the Mayo \\nClinic has amassed a wealth of data on medical conditions and \\ntreatments, such as patient records, research studies, and medical \\nimaging data. They could create chatbots and virtual assistants \\nthat harness this data to provide expert guidance and advice to'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='patients. By integrating these AI- driven tools into the Mayo'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='22 GENERATIVE AI\\nClinic’s website or mobile app, patients could access expert med-\\nical advice from anywhere around the globe.\\nLanguage models don’t just generate language, but also code, \\nmusic, poetry, stories, jokes, captions, summaries, translations, \\nrecommendations, and much more. The fields will further \\nbroaden, with LLMs providing innovative solutions for busi-\\nnesses and society.\\nGenerative AI is immensely exciting as it will undoubtedly'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='revolutionize how we create, consume, and process content \\nacross all aspects of our lives. As the technology develops, we can \\nexpect further paradigm shifts, leading to groundbreaking \\nadvancements in industries worldwide.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='23\\nT\\nhe present and future of generative AI are significantly more \\nexhilarating than the developments of previous decades. As \\nwe consider the key milestones in AI’s evolution, we’ll highlight \\nthe features that have informed modern advancements in the \\nfield. Pioneering approaches have been crucial for the high-quality  \\ndata generation we witness today, leading to a paradigm shift in \\nartificial intelligence. This shift has transformed the way we pro-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='duce and consume content and, consequently, the way humanity \\nprogresses.\\n2\\nCHAPTER\\nInnovative Approaches \\nfor\\xa0High-Quality Data \\nGeneration'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='24 GENERATIVE AI\\nWhy Generative Models?\\nWhat makes generative models so special? How do they differ \\nfrom others? T o fairly answer these questions, we must ultimately \\ndelve into the innovative thought processes behind their crea-\\ntion. While avoiding overly technical details, we’ll examine how \\ndevelopers thought outside the box to devise sophisticated, intel-\\nligent, and novel methods for generating data from scratch.\\nExplaining generative model concepts can quickly become'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='too scientific and perplexing. However, their fundamental idea is \\nrelatively simple to grasp. Consider an example of handwritten \\ndigits from the renowned MNIST (Modified National Institute \\nof Standards and T echnology) dataset. A discriminative model’s \\ntask might be to discern if an image of a handwritten digit is 0, 1, \\n2, 3, 4, 5, 6, 7, 8, or 9. For simplicity, let’s focus only on 0s and 1s. \\nConceptually, a discriminative model seeks to differentiate digits'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='by constructing a boundary in the data space. (Imagine the data \\nspace as a canvas where each data point represents a digit, and \\nthe boundary is like an invisible line that divides the different \\ncategories.) This boundary, representing the decision-making \\nprocess of the discriminative AI model, separates the 0s and 1s.\\nIf the model accurately establishes this boundary, it can dis-\\ntinguish the digits without explicitly identifying the exact loca-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tions of instances in the data space. In this context, achieving a \\nreasonably accurate separation between categories might be suf-\\nficient for the model to perform its classification task effectively.\\nDiscriminative models look at where 0s and 1s are located  \\nin the data space and use this information to find the best way  \\nto separate them. The term conditional probability refers to the \\nlikelihood of an instance being a 0 or 1 based on its features. By'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='understanding these probabilities, the models can tell apart  \\nnew instances, distinguishing between 0s and 1s, as shown in \\nFigure\\xa02.1.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 25\\nIn contrast, generative models study the training data. As \\nthey train on the data, they see what the data looks like and how \\nits features are distributed. They then try to generate data— 1s \\nand 0s, in this case as shown in Figure\\xa02.2— that fall close to the \\nreal counterparts in the data space. Concrete, a generator model, \\nwould generate 1s that look similar to other 1s in the training'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='data, and 0s that look similar to the 0s in the training data. This \\nis what in the literature is meant by “modeling the distribution \\nthroughout the data space.”\\nAgain, from this point of view it is not sufficient to roughly \\nunderstand the data to replicate it; it must be understood precisely. \\n• Discriminative Model\\nx p(y|x)\\n1\\n/\\n0\\n0 y = 0\\ny = 1\\nFIGURE\\xa02.1 Representation of a discriminative model, showing how it \\ndistinguishes between two classes (y = 0 and y = 1) given input exam-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ples, choosing between the two options based on what model (the \\ndotted line) has been trained on.\\n• Generative Model\\nx p(x, y)\\ny = 0\\ny = 1\\n1\\n/\\n0\\n0\\nFIGURE\\xa0 2.2 Representation of a generative model, highlighting the \\njoint probabilities p(x, y). Data samples are drawn based on input fea-\\ntures: 1s are sourced from the joint probability distribution, whereas \\n0s stem from their specific probability within this specific model.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='26 GENERATIVE AI\\nGiven the training data distribution, the models have to learn how \\nto connect the output data distribution to it— jointly. They cap-\\nture the joint probability, which makes them probabilistic. Their \\noutput is typically happening based on the probability of the pos-\\nsible outputs. And this is how you generate new data.\\nThe underlying concept is basically that simple idea, and it is \\nremarkable how good the different models have become. The'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='output quality has jumped significantly because they are succes-\\nsively getting better at mapping both distributions correctly. A \\nmuch-underestimated benefit of generative models is their abil-\\nity to cope with unlabeled data. They not only identify the under-\\nlying structure of the unlabeled data but can represent it. The \\nfirst step is already nontrivial, and conventional artificial intelli-\\ngence struggles with it.\\nThe potential of generative AI is incredibly exciting and is'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='based on this simple technical idea of mapping input and output \\ndistributions. However, as simple as the idea is, the execution is \\nmuch harder. Research scientists, data scientists, and other very \\nsmart folks had to be creative in the process of developing these \\nalgorithms. From neural networks trying to fool each other, to \\niteratively adding noise and denoising images, to extended atten-\\ntion mechanisms, achieving breakthroughs goes hand in hand'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='with breaking out from normal AI architectures. This is what has \\nenabled truly special AI models.\\nFrom Birth to\\xa0Maturity: Tracing the\\xa0 \\nDevelopment of\\xa0Generative Models\\nCurrently, we are at a point where a lot of the tech hasn’t been \\ndefined yet. However, some tech approaches have made a perma-\\nnent mark in the evolution of generative AI and AI as a whole. \\nThis section considers some of those approaches.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 27\\nELIZA\\nIt is 1966. The Vietnam War intensified as the United States \\nlaunched Operation Rolling Thunder, a sustained bombing cam-\\npaign against North Vietnam, and the Chinese Cultural Revolu-\\ntion began, marking the start of a decade of political upheaval \\nand social unrest in China.\\nA small group of computer scientists is standing in the IT lab \\n2.3.5 at MIT in Boston, Massachusetts, where Associate Profes-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='sor Dr. Joseph Weizenbaum is about to reveal something ground-\\nbreaking: a chatbot named ELIZA, designed to imitate a \\npsychotherapist’s conversational style (Figure\\xa02.3). The audience \\nis stunned. ELIZA analyzes human input and generates responses \\nthat seem like they’re coming from a real person. Weizenbaum \\nexplains how ELIZA ’s algorithm works: First it identifies pat-\\nterns, then generates a response using predefined templates and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='rules. For example, if the input includes the word “mother,” \\nELIZA might respond with “T ell me more about your family.” \\nThe responses are usually in the form of a question or statement \\ndesigned to encourage further conversation.\\nAfter initial reservations, something extraordinary is happen-\\ning, as the scientists are opening up to this machine, sharing their \\ndeepest thoughts and emotions. ELIZA ’s ability to connect with \\npeople on a human level is simply astonishing. The demo ends'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='and ELIZA has opened the door to a new world of possibilities, \\nwhere machines and humans can communicate in ways never \\nthought possible.\\nCould machines one day communicate with humans in a nat-\\nural, conversational way? What kind of impact would this have \\non society?\\nIt is officially agreed that ELIZA is the first chatbot that prop-\\nerly imitates conversations. ELIZA wasn’t the first bot that \\nexisted, but the first with the ripple effect in research. The first'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='28 GENERATIVE AI\\ntrials of bots date back to 1950. The field was too primitive to use \\nthe term chatbot, as there was no chat happening. 1950 was also \\nthe year Alan T uring proposed a test for describing machine intel-\\nligence. He titled his work “Computing Machinery and Intelli-\\ngence.” He wrote that if a machine can trick humans into thinking \\nit is human, then it has intelligence— the so-called Turing test. \\nT oday we have a much more refined idea of the T uring test, as we'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='are experiencing the performance of large language models \\n(LLMs) like ChatGPT . We see in detail what language models \\nare good at and where they lack skills, making it easy for us to \\nreveal them as nonhuman. Even though Alan T uring was decades \\nahead of his time, he wouldn’t have a way to imagine this. How-\\never, ELIZA was not good enough to pass the T uring test.\\nBy no means is Alan T uring an insignificant figure. Widely \\nregarded as the father of modern computing, T uring is best'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='known for his work during World War II at Bletchley Park, the \\nFIGURE\\xa02.3 A conversation with the ELIZA chatbot.\\nSource: Wikimedia Commons / Public Domain'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 29\\ncodebreaking center established to decipher German messages. \\nThere, he led a team of codebreakers who cracked the Nazi \\nEnigma code, an accomplishment believed to have shortened the \\nwar by several years. Indeed, his name graces the T uring Award, \\noften referred to as the Nobel Prize for computing.\\nThe year 1955\\xa0 marked another pivotal moment in the  \\nevolution of AI, as the term “artificial intelligence” was coined'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='by another heavyweight computer scientist, John McCarthy.  \\nAn American computer scientist, McCarthy co-authored the \\ngroundbreaking document that introduced the term artificial \\nintelligence (AI) alongside Marvin Minsky, Nathaniel Rochester, \\nand Claude E. Shannon on August 31, 1955. McCarthy described \\na field of study centered on creating machines capable of execut-\\ning tasks typically requiring human intelligence, such as reason-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ing, learning, and problem-solving. As a testament to his immense \\ncontributions to the theory and practice of AI and the develop-\\nment of the programming language Lisp, McCarthy was hon-\\nored with the T uring Award in 1971. Indeed, Lisp holds a special \\nplace in AI history as it was specifically designed to support sym-\\nbolic processing— a cornerstone concept in artificial intelligence.\\nSymbolic processing is when a program uses words, num-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='bers, and other symbols to do things that generally require \\nhuman thinking. Just like how we use letters and numbers to \\nwrite words and sentences, computers use symbols to represent \\ninformation and then use special rules to do things with that \\ninformation.\\nLisp was widely used in the development of expert systems \\nand other AI applications, not only because of its symbolic pro-\\ncessing but also because it is a high-level programming language.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='This means it uses syntax that is closer to natural language, and \\noften includes features like variables, functions, and control \\nstructures that allow programmers to write complex programs \\nmore easily. For example, Python, Java, C++, and Ruby are'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='30 GENERATIVE AI\\nhigh-level programming languages, whereas machine code and \\nassembly code are low-level. T rying to read it the first time is a \\nsure way into headache land.\\nIn the field of AI, there was a lot happening in the 1940s and \\n’50s. Another result of the momentum in AI research is the mul-\\ntilayer perceptron first implemented in 1957 by Frank Rosen-\\nblatt. Inspired by the human brain and built on top of McCulloch \\nand Pitts’s theoretical invention of the perceptron in 1943, the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='multilayer perceptron (MLP) paved the way for neural networks. \\nIt has one input layer, a few in layers, and an output layer of \\ninterconnected nodes called neurons. Each layer is a step that \\nprocesses the output of the previous layer to gradually build up a \\nmore complex representation of the input data. The MLP is \\ntrained in an iterative fashion via, for example, backpropagation, \\nwhich adjusts the weights and biases of the neurons to minimize'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='the difference between the network’s output and the desired out-\\nput, as described in Chapter\\xa01, “AI in a Nutshell.”\\nSo far, all set for AI takeoff. However, winter was coming. An \\nAI winter to be precise. T o be even more precise, an AI ice age, as \\nit spanned the late 1970s and early 1980s. It was triggered by a \\ncombination of factors, including unrealistic expectations about \\nthe capabilities of AI systems, a lack of progress in the develop-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ment of AI technologies, and a reduction in government funding \\nfor AI research. In addition, some AI researchers were skeptical \\nof the dominant approaches to AI at the time, resulting in no \\nconfidence, no developments, and no money.\\nAnd, as if this were not enough, there was a second AI winter \\nfollowing in the late 1980s and early 1990s, with no ground-\\nbreaking achievements in between the winters. Both AI winters \\nwere caused by a similar combination of factors; plus, there was'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='a shift in research funding toward other areas, such as the Inter-\\nnet and biotechnology. In addition, there was a growing percep-\\ntion among some researchers that AI was overhyped and that'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 31\\nprogress in AI was unlikely without significant breakthroughs in \\nareas such as natural language processing (NLP) and knowledge \\nrepresentation.\\nDuring this low point of AI, a then nameless research scien-\\ntist proposed a very interesting idea that carried a lot of weight \\nin the development of AI. The convolutional neural network \\n(CNN) was first proposed by Yann LeCun and his team in 1989.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Their convolutional layers are conceptually scanning images and \\nmaking sense of them. Over multiple layers, they abstract detailed \\nimages. For example, the first convolution identifies straight \\nlines. In the second convolution, these lines can become curves. \\nIn the third convolution layer, curves become eyes, whereas other \\nlayers represent ears and a nose. In the final layer, based on all \\nthe facial features, the decision is clear. It’s a Chihuahua! LeCun'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='and his colleagues developed the first practical implementation \\nof CNNs, which was used for handwritten digit recognition and \\nachieved state-of-the-art performance on benchmark datasets. \\nAmong all deep learning architecture, CNNs has had probably \\nthe most industry impact since then. The vast majority of com-\\nputer vision (CV) applications are based on CNNs. Like the per-\\nceptron, CNNs  proved to be a crucial step in the evolution of AI \\nand generative AI later on.\\nBoltzmann\\xa0Machines'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Boltzmann\\xa0Machines\\nBack to generative AI. The first significant machine learning \\narchitecture, which is an important precursor to later models, \\nwas the Boltzmann machine, which was introduced in the 1980s \\nas a neural network that could learn and generate data from a \\nprobability distribution. For this, the data distribution needs to \\nbe stable, which means that there is a low degree of variability. \\nThis helps the Boltzmann machines to learn and represent'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='32 GENERATIVE AI\\ncomplex patterns. If the data is unstable, the generated samples \\ngenerated by the Boltzmann machine are inaccurate or incon-\\nsistent, and the training is generally inefficient. The way a Boltz-\\nmann machine generates data is close to modern generative \\nAI models.\\nIn Boltzmann machines there are hidden, invisible neurons \\nthat take binary states, either at 1 or 0, “on” or “off   ” (Figure\\xa02.4). \\nT o generate a new data sample, the network is initialized with'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='random values for the visible units, and then a series of alternat-\\ning Gibbs sampling steps are performed. In Gibbs sampling, the \\nnodes in the Boltzmann machine are updated one at a time, while \\nkeeping the other nodes fixed. The probability of a node being \\n“on” or “off   ” is determined by the current state of the other \\nnodes in the network. This process is repeated many times, \\nresulting in a sample from the probability distribution of the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Boltzmann machine. By generating many such samples, the \\nmodel can learn the underlying distribution of the input data. \\nGibbs sampling is an iterative process that gradually improves \\nthe quality of the samples, allowing the model to converge on a \\nstable distribution. The final state of the visible units represents \\na new data sample that has been generated by the Boltzmann \\nmachine. This process can be repeated to generate multiple new'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='samples from the learned probability distribution. Even though \\nBoltzmann machines have the capabilities to generate data, in \\nthe early days of these machines they were primarily used as a \\ntool for exploring the properties of complex systems, rather than \\nfor generating data.\\nThe standard Boltzmann machine was a blueprint for other \\nneural network architectures that have contributed to the evolu-\\ntion of modern generative AI. But before we shed light on that,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='another headline has dominated the news about AI for quite \\nsome time.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 33\\nDeep Blue\\nIn 1997, the world watched in awe as a chess-playing computer \\nnamed Deep Blue (Figure\\xa02.5), created by IBM, faced off against \\nthe reigning world chess champion, Garry Kasparov (Figure\\xa02.6). \\nThis was the first time in history that a machine had challenged \\na human being at the game of chess on such a grand stage.\\nThere was much speculation as to whether a machine could'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ever defeat a human being in a game as complex and strategic as \\nchess. Many believed that Kasparov, widely regarded as one of \\nthe greatest chess players of all time, would easily defeat Deep \\nBlue and prove once and for all that machines could never truly \\nrival human intelligence.\\nHowever, as the match progressed, it became clear that Deep \\nBlue was a formidable opponent. The computer, which had been \\nspecially programmed to play chess using advanced algorithms'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='and machine learning techniques, was able to analyze millions of \\nHidden Nodes\\nVisible Nodes\\nFIGURE\\xa02.4 Boltzmann machine concept'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='34 GENERATIVE AI\\npossible moves per second and make decisions based on complex \\npatterns and strategies.\\nDespite his best efforts, Kasparov was unable to outmaneu-\\nver the machine, and in the end, Deep Blue emerged victorious. \\nThe result was a stunning upset, and it sent shockwaves through-\\nout the world of chess, artificial intelligence, and the world.\\nThe match between Deep Blue and Kasparov marked a turn-\\ning point in the history of AI, capturing the imagination of the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='FIGURE\\xa02.5 Deep Blue, a computer similar to this one, defeated chess \\nworld champion\\xa0Garry Kasparov in May 1997.\\nSource: James the photographer / Wikimedia Commons / CC BY 2.0.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 35\\nworld and sparking a new era of innovation and discovery. It was \\na moment that would be remembered for years to come, and it \\nlaid the foundation for a future in which machines and humans \\nwould continue to push the limits of what is possible.\\nEven though Deep Blue’s victory over Kasparov was per -\\nceived as an excellent case for AI that unlocked interest and fund-\\ning, I see it more as a case for computational power. The'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='underlying machine learning algorithms of Deep Blue were not \\nrevolutionary; rather, it was Deep Blue’s power to process all \\npossible moves and choose the best. However, sometimes it’s not \\nabout technical truth, but perception.\\nRestricted Boltzmann Machines\\nIn 2006 Geoffrey Hinton and his team developed a variant of \\nBoltzmann machines as a solution to the problem of inefficient \\nFIGURE\\xa02.6 Garry Kasparov.\\nSource: S.M.S.I., Inc / Wikimedia Commons / CC BY-SA 3.0.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='36 GENERATIVE AI\\ntraining— restricted Boltzmann machines (RBMs). RBMs restrict \\nthe connections between neurons to only occur between visible \\nneurons and hidden neurons (Figure\\xa02.7). Visible neurons repre-\\nsent the input data, whereas hidden neurons represent the fea-\\ntures that RBMs learn to represent the input data. This restriction \\nmakes RBMs computationally more efficient and easier to train. \\nOn a conceptual level, the Boltzmann machine and the restricted'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Boltzmann machine aren’t significantly different. Nevertheless, \\nthere’s a gap of 24 years between their development. Back then, \\ndevising the restricted Boltzmann machine algorithm might not \\nhave been straightforward, and in reality, its intricacies run \\ndeeper than one might initially realize.\\nOnce the RBM is trained, it can be used for a variety of tasks \\nin discriminative AI and generative AI, such as classification, \\nregression, or generating new data samples.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='So, media attention has been captured, but on the algorithm \\nsite, there was still a lot to be done. While in the conventional \\npart of AI a lot of progress has happened, especially with neural \\nnetworks, generative AI hasn’t enjoy much attention.\\nThey were only a few research scientists who were popular -\\nizing and promoting generative models like Boltzmann machines \\nVisible units\\nHidden units\\nFIGURE\\xa02.7 Concept of restricted Boltzmann machines.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 37\\nand others. Yann LeCun was one of them and Geoffrey Hinton \\nwas another.\\nLike LeCun, Hinton is regarded as one of the AI superstars. \\nIn 1978 he was awarded a PhD in AI. T oday he is a professor at \\nthe University of T oronto and a researcher at Google Brain. He \\nis considered to be one of the fathers of deep learning, as he \\ntogether with other colleagues developed the backpropagation'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='algorithm for training neural networks. He won numerous \\nawards for his work before he also received the prestigious T uring \\nAward in 2018. On Yann LeCun’s fun stuff page, he shares some \\nGeoffrey Hinton facts. One of them: “Geoff Hinton goes directly \\nto third Bayes”— a nerdy joke that refers to Bayes’ theorem, a \\nmathematical formula that calculates the probability of an event \\nbased on prior knowledge or information. It took me three nights \\nuntil I laughed.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='until I laughed.\\nHinton had a huge interest in Boltzmann machines. How-\\never, Boltzmann machines have a problem known as the sign \\nproblem, which makes it difficult to perform efficient learning due \\nto the sign of the weights in the neural network that the machine \\nis made of. Updating the weights, which is the learning, includes \\nthe product of the weights of the neurons. This product can be \\npositive or negative, leading to cancellation effects that make the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='learning process slow and inefficient.\\nDeep Belief Networks\\nIn 2006, Geoffrey Hinton and his colleagues, building on the \\nadvancements of RBMs, introduced the concept of deep belief \\nnetworks (DBNs). They stacked multiple RBMs or other unsu-\\npervised learning models to create a more powerful and efficient \\narchitecture.\\nThe deep in DBNs comes from stacking multiple layers of \\nRBMs, with each layer learning a more abstract representation'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='38 GENERATIVE AI\\nof the input data (Figure\\xa0 2.8). The training process of DBNs \\ntypically involves unsupervised pretraining using layer-wise \\ntraining, followed by supervised fine-tuning using backpropaga-\\ntion. This made DBNs effective in unsupervised feature extrac-\\ntion, as the layers learned to capture increasingly abstract features \\nfrom the input data. For example, when applied to image recog-\\nnition, DBNs could identify edges and textures in the lower lay-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ers and more complex shapes and objects in the higher layers.\\nDBNs found applications in various fields such as image  \\nrecognition, NLP , and speech recognition. They marked a signifi-\\ncant difference from RBMs in that they learned hierarchical rep-\\nresentations with higher layers, capturing more abstract features, \\nwhereas RBMs only learned a single layer of features. Additionally, \\nDBNs employed backpropagation during the fine-tuning phase,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='whereas RBMs were solely unsupervised learning models.\\nInput\\nlayer\\nHidden\\nlayer 1\\nHidden\\nlayer 2\\nHidden\\nlayer 3\\nOutput\\nlayer\\nRBM 3\\nRBM 2\\nSource: Peltarion.com\\nRBM 1\\nFIGURE\\xa02.8 A deep belief network.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 39\\nInterestingly, DBNs played a crucial role in the resurgence of \\ndeep learning research in the mid-2000s. They were among the \\nfirst models to demonstrate the effectiveness of unsupervised \\npretraining for deep architectures. The introduction of DBNs \\nsparked renewed interest in the field of deep learning, leading to \\na wave of innovation and groundbreaking discoveries. Speaking \\nto fellow data scientists, this seems to be forgotten.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Deep Boltzmann Machines\\nThe journey of generative AI took yet another significant turn in \\n2009\\xa0 when Ruslan Salakhutdinov and Geoffrey Hinton intro-\\nduced deep Boltzmann machines (DBMs). DBMs were another \\nleap forward in generative AI, as they further enhanced the capa-\\nbilities of generative models.\\nDBMs, similar to DBNs, are hierarchical generative models \\nmade up of multiple layers of unsupervised networks, allowing \\nthem to model complex, high-dimensional data. They’re created'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='by stacking multiple RBMs, with each layer learning an increas-\\ningly abstract representation of the input data.\\nT raining DBMs is done using a two-step process: layer-wise \\npretraining, which involves training each layer of RBMs indepen-\\ndently, followed by fine-tuning using methods like contrastive \\ndivergence or persistent contrastive divergence. Contrastive diver-\\ngence is an optimization algorithm that minimizes the difference'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='between the input data distribution and the distribution learned \\nby the model, while persistent contrastive divergence maintains a \\nset of persistent samples that are updated throughout the training \\nprocess, making it more efficient.\\nDBMs have found applications across various fields, such as \\nimage recognition, NLP , and speech recognition, thanks to their \\nability to model complex data structures and learn abstract  \\nfeatures.\\nIn terms of architecture, both DBMs and DBNs stack multi-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ple RBMs, but DBMs have undirected connections between all'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='40 GENERATIVE AI\\nlayers, whereas DBNs have directed connections between layers, \\nexcept for the top two layers, which have undirected connections.\\nThe generative process in DBMs and DBNs also differs. In \\nDBNs, the process is top-down, starting from the highest layer \\nand moving downward. For example, in image recognition, a \\nDBN might start with the high-level concept of an object and \\nwork its way down to the details. In contrast, DBMs sample from'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='the joint probability distribution between visible and hidden \\nunits, allowing them to generate new data samples by taking into \\naccount the complex relationships between different features.\\nThe introduction of DBMs contributed to the growing inter-\\nest in the unsupervised learning and generative models that have \\ncontinued to shape the field of AI. This further highlights the \\nextraordinary impact of Hinton’s work and dedication to the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='field of AI, which has propelled generative models and deep \\nlearning to new heights.\\nAutoencoders\\nAs the field of AI continued to evolve, researchers explored new \\nand innovative ways to leverage the power of neural networks. \\nOne such development was the emergence of autoencoders \\n(AEs), a unique type of artificial neural network designed for \\nunsupervised learning tasks. Autoencoders caught the attention \\nof the AI community for their ability to learn efficient represen-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tations of data, as well as their potential to transform the land-\\nscape of generative AI.\\nThe structure of autoencoders consists of two main parts: an \\nencoder, which compresses input data into a lower-dimensional \\nlatent representation, and a decoder, which reconstructs the \\noriginal data from the latent representation (Figure\\xa0 2.9). For \\nexample, imagine an autoencoder trained to process images of \\nhandwritten digits. The encoder could compress the input image'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 41\\ninto a compact numeric representation, while the decoder would \\nattempt to generate an image resembling the original input based \\non this compressed representation.\\nAutoencoders aim to minimize the difference between the \\ninput data and the reconstructed output, usually by optimizing a \\nloss function like mean squared error or cross-entropy. In our \\nhandwritten digit example, the autoencoder would seek to mini-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='mize the differences between the original input image and the \\nreconstructed image produced by the decoder, thereby learning \\nthe most efficient way to represent and reconstruct the data.\\nAutoencoders have found a variety of practical applications, \\nsuch as denoising, anomaly detection, and data compression. In \\ndenoising, an autoencoder can be trained to remove noise from \\nimages, effectively “cleaning” them up. For anomaly detection,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='autoencoders can be employed to identify unusual patterns  \\nin data, such as detecting fraudulent credit card transactions. In \\ndata compression, autoencoders can be used to reduce the size  \\nof data files while still maintaining their essential information.\\nCode\\nInput Output\\nredoceDredocnE\\nFIGURE\\xa02.9 The autoencoder architecture.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='42 GENERATIVE AI\\nWith the advent of deep learning, more complex, multilay-\\nered autoencoders have emerged, enabling the learning of intri-\\ncate data representations. These deep autoencoders are capable \\nof capturing hierarchical relationships within the data, leading to \\neven more powerful applications.\\nOne notable use of autoencoders is in visualizing high-\\ndimensional data in lower-dimensional spaces, allowing for eas-\\nier interpretation and analysis of complex datasets. For instance,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='a deep autoencoder could be utilized to reduce the dimensions of \\na dataset containing gene expression data, making it possible for \\nresearchers to visualize and understand the relationships between \\ndifferent genes more easily.\\nThe history of autoencoders spans several decades, with their \\napplication in generative AI truly taking off in the 2010s, primar-\\nily due to advancements in deep learning. Autoencoders have \\ninspired other powerful generative models, such as variational'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='autoencoders (VAEs), which have been applied to generate new \\nimages, text, and other data types by sampling from the learned \\nlatent space. This development marked a significant leap in the \\nevolution of AI, opening up new possibilities for the future of \\nmachine learning and artificial intelligence.\\nVariational Autoencoders\\nIn 2013, the world of generative AI saw a significant advance-\\nment by the introduction of VAEs by Kingma and Welling in'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='their paper “Auto-Encoding Variational Bayes.”1 VAEs are built \\non the foundation laid by autoencoders, which are neural net-\\nworks that learn to encode input data into a lower-dimensional \\nrepresentation and then decode it back to the original input. \\n1Diederik Kingma and Max Welling, “Auto-Encoding Variational Bytes,” arXiv, December 10, 2022, https://\\narxiv.org/pdf/1312.6114.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 43\\nAutoencoders played a key role in the development of VAEs by \\nproviding a foundation for unsupervised learning and dimen-\\nsionality reduction.\\nUnlike traditional autoencoders, VAEs introduced a proba-\\nbilistic framework, modeling the input data using a continuous \\nprobability distribution. This enabled more diverse and realistic \\nsample generation, a significant milestone in the evolution of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='generative AI. VAEs consist of two main components: an encoder, \\nwhich maps input data to a latent space, and a decoder, which \\nreconstructs the input data from the latent space (Figure\\xa02.10).\\nVariational inference played a crucial role in the success of \\nVAEs, as it was used to approximate the true posterior distribu-\\ntion of the latent variables, enabling efficient learning and sam-\\npling. For the first time, true generative capabilities were'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='unlocked, allowing AI models to generate new images by inter -\\npolating between existing data points in the latent space, such as \\ncreating entirely new faces by blending features of existing faces.\\nVAEs found applications across various fields, such as image \\ngeneration, text generation, drug discovery, and anomaly detec-\\ntion. For instance, VAEs have been used to generate realistic 3D \\nInput Output\\nEncoder Decoder\\nCode\\n/uni03BC\\n/uni03C3\\n/uni03F5'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='/uni03C3\\n/uni03F5\\nFIGURE\\xa02.10 The variational autoencoder architecture.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='44 GENERATIVE AI\\nmodels of molecules for drug discovery, accelerating the process \\nof finding new treatments for diseases.\\nWomen in Generative AI History\\nBorn in various eras, numerous exceptional women have left \\ntheir mark on the broader field of AI. Ada Lovelace, Grace  \\nHopper, Elaine Rich, and Daphne Koller are just a few who have \\nmade substantial contributions. However, pinpointing outstand-\\ning women who specifically impacted early generative AI is chal-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='lenging due to the historical gender imbalance in the field. \\nNevertheless, several women have made remarkable contribu-\\ntions to AI areas indirectly connected to generative AI or laid the \\ngroundwork for the development of generative AI techniques.\\nFor instance, Pamela McCorduck, an author and AI histo-\\nrian, chronicled the history of AI in her influential book Machines \\nWho Think, published in 1979. She provided valuable insights'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='into the evolution of generative AI over the years. Cognitive psy-\\nchologist Eleanor Rosch, active in the 1970s, developed proto-\\ntype theory, which asserts that human categorization is based on \\nprototypical examples rather than strict rules. Rosch’s work indi-\\nrectly impacted the development of generative AI, as her insights \\non human cognition informed AI model structure and data gen-\\neration methods.\\nCynthia Breazeal’s research, primarily focused on social'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='robotics during the late 1990s and early 2000s, laid the ground-\\nwork for AI systems generating human-like responses and behav-\\niors. By creating robots capable of interacting and communicating \\nwith humans, such as Kismet, Breazeal made an indirect yet sig-\\nnificant contribution to the generative AI domain.\\nIn 2009, Fei-Fei Li co-developed ImageNet, a large-scale \\nimage database crucial for advancing deep learning. Although \\nthe modern generative AI era, marked by advancements like'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 45\\ngenerative adversarial networks (GANs), began around 2014, \\nLi’s work on ImageNet facilitated these advancements by sup-\\nplying the necessary data and infrastructure for training deep \\nlearning models.\\nIt is essential to acknowledge the historical gender imbalance \\nin the field of AI and promote increased diversity and inclusion \\nin AI research moving forward. While there are many official'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='female contributors, numerous unofficial ones have gone unmen-\\ntioned for their contributions in the past. By recognizing and \\ncelebrating these women, we can work toward a more equitable \\nfuture in AI research, ultimately leading to more diverse perspec-\\ntives and innovative solutions in the realm of generative AI.\\nGANs: The Era of Modern Generative AI Begins\\nIn 2014, just a year after the variational autoencoder caught the \\nattention of the AI community, a 27-year-old research scientist'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='named Ian Goodfellow revolutionized the AI landscape. Along \\nwith his team, Goodfellow developed a groundbreaking approach \\ncalled generative adversarial networks (GANs), ushering in a \\nnew era of modern generative AI. This innovative technique took \\nthe AI world by storm, but it didn’t come without its challenges.\\nGoodfellow’s exceptional mind and relentless determination \\npropelled him to the forefront of AI research. Beginning his aca-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='demic journey at Stanford University, he earned his bachelor’s \\nand master’s degrees in computer science under the guidance of \\nAndrew Ng, a renowned AI expert and cofounder of Coursera. \\nGoodfellow later pursued his PhD in machine learning at the \\nUniversité de Montréal, supervised by Y oshua Bengio, a pioneer \\nin deep learning, and Aaron Courville, an esteemed AI researcher.\\nGoodfellow was surrounded by top-tier mentors, and his'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='career trajectory was nothing short of extraordinary. Alongside \\nBengio and Courville, he co-authored the MIT textbook Deep'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='46 GENERATIVE AI\\nLearning, which quickly became a staple resource in the field. His \\nnumerous accolades include being named one of MIT T echnology \\nReview’s 35\\xa0Innovators Under 35.\\nGoodfellow’s career took him to prestigious institutions like \\nGoogle Brain, OpenAI, Google Research, and Apple, where he \\nserved as a director of machine learning in the Special Projects \\nGroup. However, he never shied away from standing up for his \\nprinciples. In April 2022, Goodfellow resigned from his lucrative'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='position at Apple to protest the company’s in-person work \\nrequirements for employees. His next step took him to Google \\nDeepMind as a research scientist, demonstrating his unwavering \\npassion for AI research.\\nHow GANs Work\\nSo, how do GANs work? In a two-step process involving training \\nand production, the crux of the magic unfolds during  \\nthe training phase. The brilliance of GANs lies in their dual- \\ncomponent structure, comprising a generator that meticulously'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='crafts new data samples and a discriminator that determines the \\nauthenticity of said samples. T o create images, for instance, the \\ngenerator employs a deconvolutional neural network, transform-\\ning noise into data samples, whereas the discriminator relies on a \\nconvolutional neural network to classify images as genuine or \\ngenerated (Figure\\xa02.11).\\nThe essence of adversarial training involves the generator \\nattempting to deceive the discriminator with lifelike creations,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='while the discriminator strives to differentiate between the \\nauthentic and the artificial. Should the generated data be detected \\nas such, the generator must update its trainable parameters; like-\\nwise, if the generated data is not detected, the same process occurs \\nfor the discriminator. This dynamic propels both components'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 47\\nto improve until they reach the Nash equilibrium— a point  \\nwhere neither can gain an advantage by changing their strategy. \\nReaching Nash equilibrium is a necessary condition for good \\nperformance.\\nAfter training, the generator, now at its peak performance, is \\nfrozen and subsequently employed for generating the respective \\ndata. With the ability to produce highly realistic and intricate'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='data samples, such as images, text, and audio, GANs have sparked \\na revolution in numerous fields, ranging from art and design to \\nscientific research and beyond. The true potential of generative \\nmodels and their capacity to transform our interactions with \\ntechnology has been unveiled.\\nThe applications of GANs are astoundingly diverse, with \\nuses such as\\n• Generating strikingly realistic images of faces, animals, and  \\nobjects\\n• Image-to-image translation, morphing simple sketches into'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='vibrant masterpieces\\n• Super-resolution, rejuvenating low-quality images by enhanc-\\ning their resolution\\nReal\\nFake\\nReal-world\\nImages\\nLatent\\nVariable\\nLOSSDiscriminator\\nGenerator\\nSample\\nSample\\nFIGURE\\xa02.11 The generative adversarial network architecture.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='48 GENERATIVE AI\\n• Data augmentation, producing additional training samples \\nfor machine learning models\\n• Style transfer, which imbues one image with the artistic \\nessence of another image\\nWith GANs, the landscape of AI, and even other fields, like \\nphysics, are continually evolving, opening up a world of endless \\npossibilities.\\nGAN Challenges\\nThe inception of GANs was no small feat. The groundbreaking \\nconcept of pitting two networks against each other not only rev-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='olutionized deep learning but also introduced a host of new chal-\\nlenges. The delicate balance of power between these networks \\nhinges on factors such as hyperparameters, architecture, and \\ntraining methods. If any one of these elements is off kilter, one \\nnetwork may overpower the other, resulting in training stagna-\\ntion due to insufficiently differentiated feedback.\\nNavigating the complexities of GANs also involves address-\\ning issues like mode collapse, vanishing gradients, and internal'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='covariate shifts. In simple terms, mode collapse occurs when the \\ngenerator becomes fixated on producing a limited variety of out-\\nputs, hindering its ability to generate diverse samples. Vanishing \\ngradients, on the other hand, refer to the dwindling gradients \\nthat arise during backpropagation, making it difficult for the net-\\nworks to learn effectively. Lastly, internal covariate shifts pertain \\nto the inconsistencies in the distribution of layer inputs during'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='training, which can hamper the overall learning process.\\nSince 2014, the landscape of GAN variations has expanded \\nexponentially, now approaching nearly 9,300\\xa0iterations, each tai-\\nlored to tackle a specific challenge. Although newer GAN models'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 49\\nhave grown more sophisticated, the initial breakthrough was made \\npossible by the efforts of Ian Goodfellow and his colleagues.\\nGoodfellow’s dedication and expertise laid the foundation \\nfor a transformative technology that has since become a corner-\\nstone of AI. As GANs continue to influence the future of artifi-\\ncial intelligence, Goodfellow’s remarkable career serves as a \\npowerful reminder of the potential unleashed through determi-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='nation, collaboration, and innovation.\\nFrom Pixels to Perfection: The Evolution of AI \\nImage Generation\\nAs a visually compelling field, it’s no wonder that AI image gen-\\neration has garnered widespread attention. The rapid progress, \\ncombined with the ease of grasping its potential, makes the gen-\\nerative AI story captivating to tell.\\nT o achieve what was once deemed unattainable, generative AI \\nimage generation demanded remarkable algorithms and innova-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tive technical ideas. The secret sauce that AI needed to generate \\nexceptional images emerged from the evolution of autoencoders, \\nGANs, and diffusion models.\\nInitially, autoencoders demonstrated prowess in reconstruct-\\ning images. However, as deterministic models, they lacked true \\nimage generation capabilities. Deterministic, in this context, \\nmeans that given the same input data, an autoencoder will con-\\nsistently produce the same output.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='The introduction of the variational component in the form \\nof variational autoencoders marked a turning point for these \\nmodels, granting them genuine generative potential. With vari-\\national autoencoders, AI began to yield promising results in gen-\\nerating images and faces. Y et, it was the arrival of GANs that \\npropelled image generation quality to new heights.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='50 GENERATIVE AI\\nGANs for Image Generation\\nGANs have emerged as a formidable force in the realm of image \\ngeneration. As they learn the distribution of a given dataset, their \\nflexibility allows them to generate a wide array of images, from \\nrealistic photographs and abstract art to depictions of nonexist-\\nent objects or creatures. However, their architecture, which sug-\\ngests parallel data generation, is not traditionally suited for \\nsequential data generation, such as text.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='T o bridge this gap, images and their captions can be com-\\nbined in their respective vector embeddings. Vector embeddings \\nare representations of images or pieces of text as a vector of num-\\nbers, capturing the semantic meaning of the input in a compact \\nand useful form for downstream machine learning tasks. By inte-\\ngrating text and image representations through vector embed-\\ndings during GAN training, the image generation process \\nbecomes steerable via text. This groundbreaking functionality'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='enables the seamless fusion of images and styles.\\nOne of the remarkable attributes of GANs is their ability to \\ngenerate images without labeled training data, as they inherently \\nunderstand the original data distribution. Additionally, GANs \\ncan be trained progressively, commencing with low-resolution \\nimages and gradually enhancing resolution over time. This \\napproach ensures that the generator learns to create increasingly \\ndetailed and realistic images as training advances.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='The surge of research interest in GANs has sparked numer-\\nous innovations. Here are some notable examples:\\n• In 2016 and 2017, Wasserstein GAN (WGAN) and progres-\\nsive growing of GANs (ProGAN) enhanced GAN training \\nstability, allowing for the generation of higher-resolution \\nimages with improved quality.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 51\\n• In 2018, BigGAN pushed the boundaries of GAN-generated  \\nimage quality and resolution, creating high-fidelity images \\nup to 512×512 pixels in size, boasting more realistic and \\ndiverse content.\\n• Between 2019 and 2021, StyleGAN emerged as a state-of-\\nthe-art image generator, providing fine-grained control over \\nstyle and content. This enabled impressive results in face \\ngeneration and other domains.\\nCLIP'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='CLIP\\nWhile GANs have made substantial progress in generating \\nimages based on textual descriptions, they occasionally yield \\nresults that lack consistency with the text or the desired level of \\ncontrol. In January 2021, OpenAI introduced an innovative neu-\\nral network model called CLIP (Contrastive Language-Image \\nPre-T raining) to bridge this gap.\\nCLIP , bridging the gap between NLP and CV , is pretrained \\non a vast dataset of over 400\\xa0million image-text pairs. With an'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='objective to create a joint representation of images and text, it \\nuses contrastive pretraining to distinguish between similar and \\ndissimilar pairs. This approach helps CLIP relate relevant text to \\nimages, even when the text doesn’t directly describe the visual \\ncontent. In a subsequent step, the model encodes images and text \\ninto a shared space through an image encoder and a text trans-\\nformer. The goal is to amplify the similarity of genuine image-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='text pairs and reduce it for mismatched pairs, thereby boosting \\nits efficiency. Figure\\xa02.12 shows the three main steps of its train-\\ning process. The ability of CLIP to comprehend the meaning of \\na text in relation to images has unlocked new possibilities for \\nfusing NLP and CV .'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='52 GENERATIVE AI\\nAs a powerful tool for tasks requiring an understanding of \\nthe relationship between text and images, CLIP surpasses GANs \\nfor several reasons:\\n• CLIP allows for more fine-grained control over image gen-\\neration, enabling users to specify desired attributes such as \\ncolor or orientation.\\n• CLIP can work with multiple modalities, including images, \\ntext, and audio, paving the way for more intricate and \\nnuanced generation tasks.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='• CLIP has demonstrated excellent generalization to unseen \\ndata, meaning it can generate high-quality images consistent \\nwith textual descriptions, even when the images are not seen \\nduring training.\\nThe impact of CLIP on the AI community has been immense. \\nInfluencing other models like DALL-E and Stable Diffusion, \\nCLIP has spurred research in text-to-image models and popu-\\nlarized the contrastive pretraining method.\\nImage 1 Image\\nCLIP\\nText\\nEmbed image\\nand text\\nCompare the\\nembeddings'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='embeddings\\nPrediction Label\\n1\\n(Similar)\\n1\\n(Similar)\\n0\\n(Not similar)\\n0\\n(Not similar)\\nCaption 1\\nUpdate the\\nmodels321\\nImage\\nembedding\\nText\\nembedding\\nFIGURE\\xa02.12 Training of CLIP.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 53\\nDALL-E 2\\nBolstered by the success of CLIP and the advancements it has \\nspurred in the field of AI, research scientists have continued to \\npush the boundaries of what’s possible in a text-to-image genera-\\ntion. One such breakthrough, which has captured the world’s \\nattention, is OpenAI’s DALL-E 2.\\nOpenAI’s DALL-E 2\\xa0 was the talk of the town in summer \\n2022, setting the tech world abuzz with its jaw-dropping image'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='generation capabilities. A nearly solved problem, DALL-E 2 \\ngenerates astoundingly realistic images at higher resolutions, \\nadeptly blending concepts, attributes, and styles. It can manipu-\\nlate and rearrange objects within images, and is a maestro at \\nplacing design elements in innovative compositions.\\nDALL-E 2’s finesse lies in its ability to inpaint and outpaint \\nimages, generate variations, and transform aspects of images \\nusing text. Inpainting involves filling in missing or corrupted'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='parts of an image using surrounding information, whereas out-\\npainting, also known as image extrapolation, extends the content of \\nan image beyond its original boundaries.\\nOnce a nonprofit organization, OpenAI was established in \\n2015\\xa0with the noble objective of developing AI for the benefit of \\nhumanity. However, in 2018, the company made a controversial \\nshift to a for-profit model, raising concerns about conflicts of \\ninterest and the potential undermining of its original mission.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Nowadays, OpenAI isn’t as open as it used to be. No longer \\nopen sourcing their models, the organization discloses only \\nselect information, which means we can discuss the models only \\nfrom a secondhand perspective.\\nT o understand DALL-E 2, picture a skilled artist who listens \\nto your description, captures the concept, and then produces a \\ndetailed, realistic image based on your vision. This wondrous'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='54 GENERATIVE AI\\ntechnology is built on two key innovations: CLIP , which we’ve \\ntouched upon before, and diffusion, which we’ll delve into shortly.\\nIn a nutshell, DALL-E 2 uses CLIP encoders to map inputs \\nto an embedding within a shared concept space, where matching \\npairs are mapped to nearby points and mismatching pairs are \\nmapped to distant ones. The diffusion model, which they call \\nGLIDE by the way, is trained to undo the steps of a fixed corrup-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tion or noising process, reversing the corruption or denoising \\nand regenerating erased information. More on this in a moment.\\nDALL-E 2’s prowess is showcased through a two-stage pro-\\ncess: First, the prior model generates a CLIP image embedding \\nfrom the given caption, capturing the gist of the image. Next, the \\ndiffusion model (unCLIP) generates the actual image from the \\nembedding, filling in the details.\\nThe advantages of this two-stage sampling process are evi-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='dent: it prioritizes high-level semantics, making images more \\nmeaningful to humans, and allows for text-based transformations \\nusing CLIP’s multimodal embedding space. In the summer of \\n2022\\xa0DALL-E 2\\xa0was, without a doubt, a testament to the poten-\\ntial of generative AI and a harbinger of even greater advancements.\\nDiffusion Models\\nAs all of this evolves at a rapid pace, the open source ethos pro-\\npelling its growth has enabled both researchers and hobbyists'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='alike to explore and develop the capabilities of diffusion models.\\nJune 2021\\xa0marked a pivotal moment for image generation, as \\na publication emerged, revealing that diffusion models had sur -\\npassed GANs in their capabilities. This revelation piqued my \\ninterest and brought the potential of diffusion models into focus \\nfor the first time. Fast-forward 10\\xa0months, and OpenAI’s DALL-2,  \\nan image generation model based on the diffusion principle, has'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 55\\ntaken the world by storm, producing premium images that have \\nleft many astounded.\\nIn August 2022, another significant development in the field \\nof AI made headlines: Stability AI released Stable Diffusion, a \\nmodel capable of achieving outputs on par with DALL-E 2.  \\nT aking a different approach from its counterparts, Stability AI \\nastonished the tech community by open sourcing the model'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='almost immediately. This model has been made accessible to all, \\nrunnable within a Python Notebook and on the Hugging Face \\nplatform. Hugging Face, a hub for sharing pretrained models, \\ndatasets, and demos of machine learning projects, promotes open \\nsource contributions and fosters a collaborative environment for \\nAI enthusiasts.\\nStability AI, under the leadership of CEO and founder Emad \\nMostaque, distinguishes itself by open sourcing AI technology— a'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='rarity among the few companies equipped with the resources and \\ntalent to develop it. Their mission is to democratize access to AI \\ntechnology and prevent its monopolization by major tech players.  \\nBeyond Stable Diffusion, they are working on projects such as \\nHarmonai, which focuses on open source generative audio tools, \\nand OpenBioML, a venture into the intersection of machine \\nlearning and biology. A vast and dedicated community has rallied \\nbehind Stability AI’s vision.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Mostaque and his team are steadfast in their commitment to \\ncreating tools that empower individuals and grant them agency, \\na pursuit they believe can lead to a happier world and drive posi-\\ntive change. Stability AI, a well-capitalized startup, has garnered \\nfunding from Mostaque’s personal fortune, a $100\\xa0million invest-\\nment led by Coatue, and has plans to monetize by concentrating \\non specific domains, such as Bollywood.\\nDespite the general trend of keeping AI technology closed'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='source— exemplified by OpenAI, ironically enough— it is both \\nrefreshing and challenging to see a company like Stability AI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='56 GENERATIVE AI\\nopen source its models. This strategy comes at the cost of relin-\\nquishing much of their competitive advantage, as anyone can \\ndownload a stable diffusion model, run it on some GPUs on-\\npremises or in the cloud, fine-tune it, and obtain a remarkable \\nimage generation model without paying Stability AI a single penny.\\nStable Diffusion Tech\\nDiffusion models stand at the forefront of innovation. What sets \\nthem apart is their unique methodology: introducing noise to'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='learn the art of denoising, thereby unraveling the secrets of gen-\\nerating images. The results are nothing short of enchanting!\\nAs previously mentioned, the crux of the diffusion model lies \\nin its ability to add and remove noise from images. Picture this: \\nDuring the forward diffusion phase, noise is added to the image, \\nakin to static interference on a television screen. In the reverse \\ndiffusion stage the noise is eliminated, gradually revealing the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='image beneath the static. However, the pure diffusion model is \\nhampered by its sluggishness, especially when dealing with a \\nlarge number of diffusion steps or sizable images, as there are \\nsimply too many pixels to process.\\nEnter stable diffusion, a swifter alternative. This technique \\noperates within the latent space, which is essentially a compressed \\nversion of the image, much like a smaller, condensed file. This fam-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ily of models is known as latent diffusion models. T o create the latent \\nspace, an autoencoder is employed, acting as a simplified version of \\nthe variational autoencoder mentioned earlier. The autoencoder’s \\nencoder compresses the image into lower-dimensional data, similar \\nto zipping a file, whereas the decoder decompresses the latent data \\nback into an image, akin to unzipping a file.\\nOne of the most remarkable features of stable diffusion is its'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ability to generate images from text prompts in a highly impressive'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 57\\nmanner. The diffusion model is adapted to accept conditioning \\ninputs, comparable to modifying a recipe based on a special request. \\nT ext inputs are transformed into embeddings (vectors) using a lan-\\nguage model, reminiscent of the process employed by CLIP .\\nFor inquisitive minds yearning to delve into stable diffusion, \\nlook no further than GitHub, where the code is easily accessible.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Additionally, a web application has been thoughtfully designed \\nto offer a hands-on experience with this revolutionary model.\\nMidjourney\\nMidjourney is an AI image-generation company that has taken \\nthe world by storm. Its latest creation, Version 5, is renowned for \\ngenerating images of unparalleled quality, spanning from  \\nphotorealistic to a wide array of artistic and nonartistic styles. \\nHailed as the epitome of AI-generated artistry, Midjourney’s'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='images are so remarkably lifelike that they have earned the title \\nof being “indistinguishable” from real photographs.\\nHowever, this near-perfect level of realism has raised eye-\\nbrows among AI art enthusiasts. Some have dubbed Midjour -\\nney’s creations as “creepy” and “too perfect.” The groundbreaking \\nimprovements in Version 5\\xa0include incredibly realistic skin tex-\\ntures, impeccably detailed facial features, cinematic lighting'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='effects, and striking reflections, glares, and shadows. The model \\nalso boasts more expressive angles or overviews of a scene, and— \\nperhaps most importantly— human hands now consistently dis-\\nplay the correct number of fingers.\\nAccessible through a Discord bot command, Midjourney’s \\nplatform was still in open beta as of December 2023. The com-\\npany’s trailblazing team, led by founder David Holz, has a track \\nrecord of releasing new and improved model versions every few'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='months. With a keen eye for innovation and a commitment to'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='58 GENERATIVE AI\\nconsistent progress, Midjourney has already achieved profitabil-\\nity. Artists worldwide employ the platform for rapid prototyping \\nof artistic concepts, while the advertising industry reaps the ben-\\nefits of quickly creating original content.\\nNevertheless, Midjourney remains vigilant about the images \\ngenerated by its platform. In a fascinating turn of events, the \\ncompany made headlines in March 2023\\xa0when it preemptively'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='blocked the generation of images depicting Xi Jinping. This \\nmove was taken to prevent potential censorship by the Chinese \\ngovernment. Holz said that “the ability for people in China to \\nuse this tech is more important than your ability to gener -\\nate satire.”2\\nThe enigmatic team behind Midjourney has kept their train-\\ning techniques under wraps. However, it’s very likely that they \\nmight use methods similar to stable diffusion, as its approach is'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='known in detail. As AI-generated artistry evolves, the interplay of \\nideas and techniques among pioneers like Midjourney fuels pro-\\ngress and sparks anticipation for future revelations.\\nThe Importance of\\xa0Training Data\\nT raining data reigns supreme as the vital cornerstone of AI image \\ngeneration model performance. T ext-to-image models necessi-\\ntate sizable datasets, often procured by scouring the web for \\nimage-text pairs. However, this method bears inherent limita-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tions and biases, including toxic language, nudity, violence, and \\nharmful social stereotypes.\\nFor those desiring elite model performance and possessing \\nample budgets, the LAION-400M dataset is the gold standard. \\nSourced from Common Crawl web data, it amasses an impressive \\n2Christopher McFadden, “Midjourney will no longer let you generate images of Xi Jinping,” Interesting Engi-\\nneering, April 3, 2023, https://interestingengineering.com/culture/midjourney- bans- xi- jinping- images'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 59\\n413\\xa0million image-text pairs tailored for top-tier models. T o ensure \\nsafety, filters can be applied to regulate output, and models can be \\nretrained on custom datasets to minimize biases for specific use \\ncases. The operations are fueled by donations and public research \\ngrants. The team comprises 15\\xa0 members, although it remains \\nuncertain if all are engaged full-time.\\nMeanwhile, smaller AI image generation models like Craiyon—'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='also known as DALL-E mini— trained on a mere 30\\xa0million images, \\nproduce fewer photorealistic images compared to their larger \\ncounterparts like stable diffusion. Here, strategic partnerships play \\na pivotal role, providing invaluable training data inaccessible to \\nothers. For instance, OpenAI’s strategic partnership with Shutter-\\nstock was instrumental in DALL-E’s development. Shutterstock is \\na marketplace for high-quality, royalty-free photographs, vectors,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='illustrations, videos, motion graphics, and music.\\nAnother interesting dataset that merits attention is ImageNet.  \\nThis extensive image database is organized following the Word-\\nNet hierarchy, which, as of now, is confined to nouns. Each node \\nwithin this hierarchy is illustrated by hundreds, even thousands, \\nof images. The data is available at no cost to researchers for non-\\ncommercial purposes and comprises an impressive 14,197,122'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='images along with 21,841 synsets indexed. “Synsets” is short for \\n“synonym sets,” which are groups of words that mean the same \\nthing. In ImageNet, each synset is linked to a bunch of images \\nthat show the same thing. Conceived as a large-scale visual data-\\nbase, the ImageNet project is designed for use in the field of \\nvisual object recognition software research.\\nThough Midjourney remains tight-lipped about the datasets \\nutilized in training its model, whispers within the insider com-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='munity suggest that copyrighted artists’ work may have been \\nincluded. Despite the lack of official confirmation, Midjourney’s'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='60 GENERATIVE AI\\nperformance speaks volumes. Key speculations that stand out \\ninclude the following:\\n• Midjourney enhances prompts pregeneration and applies post-\\nprocessing to the image, resulting in its distinctive aesthetic.\\n• A carefully trained classifier model may evaluate and filter \\ngenerated content.\\n• Midjourney’s output is somewhat limited in terms of style, as \\nthey understand what works and what doesn’t.\\n• Most crucially, they meticulously curate their data, retaining'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='only the most exquisite images— a testament to their unwa-\\nvering commitment to quality.\\nAs the tale of Midjourney continues to unfold, the world \\neagerly anticipates the next chapter in the company’s enigmatic \\njourney, as well as the innovations and revelations that are yet \\nto emerge.\\nAutoregression\\nGoogle is another significant player in the realm of generative \\nAI. Among their most notable models are the image generation \\nmodels Imagen and Parti. Imagen, a latent diffusion model,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='showcases Google’s expertise in diffusion models. Parti offers an \\nimpressive performance through a different approach to image \\ngeneration— autoregression. Although this method is sequential \\nrather than parallel, it is worth delving into autoregressive mod-\\nels for image generation. As you shall see, they play a crucial role \\nin this field.\\nEnter Parti, Google’s answer to DALL-E 2, which began  \\nwith the publication of “Scaling Autoregressive Models for'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 61\\nContent-Rich T ext-to-Image Generation.”3 Parti addresses text-\\nto-image generation as a sequence-to-sequence modeling prob-\\nlem, taking advantage of advances in LLMs. Employing  \\nthe Vision-T ransformer-based VQGAN (ViT-VQGAN) image \\ntokenizer, Parti encodes images as sequences of discrete tokens, \\nenabling the reconstruction of high-quality, visually diverse images. \\nThe result is state-of-the-art zero-shot and fine-tuned FID'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='(Fréchet inception distance) scores on MS-COCO\\xa0 (Microsoft \\nCommon Objects in Context), with the model proving effective \\nacross a broad range of categories and difficulty aspects, as demon-\\nstrated in the Localized Narratives and PartiPrompts bench-\\nmark analysis.\\nIn essence, zero-shot refers to a model’s ability to perform a \\ntask without prior training or examples specific to that task. It \\nhighlights a model’s capacity to generalize and apply learned'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='knowledge from one context to another without the need for \\nadditional fine-tuning.\\nFID is a commonly used metric for evaluating the quality of \\ngenerated images. Picture it as a ruler measuring the distance \\nbetween two distributions of features extracted from real and \\ngenerated images. Lower FID scores signify that the generated \\nimages more closely resemble the real ones, thus indicating \\nhigher quality.\\nMS COCO is an extensive image recognition, segmenta-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tion, and captioning dataset, boasting over 330,000 images and \\nmore than 2.5\\xa0million object instances labeled with object cat-\\negories, instance segmentation, and dense captioning. Its \\nimportance in image generation research cannot be overstated, \\nas it provides a widely used benchmark dataset for assessing \\nthe quality and diversity of generated images. Numerous state-\\nof-the-art image generation models are evaluated using'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='3Jiahui Yu et\\xa0al. “Scaling Autoregressive Models for Content-Rich T ext-to-Image Generation,” arXiv, June 22, \\n2022, https://arxiv.org/pdf/2206.10789.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='62 GENERATIVE AI\\nthe MS COCO dataset, and high scores on this benchmark \\nstrongly indicate the performance and generalization ability of \\nthe model.\\nAutoregressive models are undoubtedly innovative, achiev-\\ning remarkable results in both parallel and sequential data gen-\\neration. While they may have been underestimated in the past, \\nthey have brought about significant advancements in AI and \\ncould lead to further breakthroughs in the field. Perhaps their'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='true potential lies in supporting video generation and other  \\nyet-to-be-discovered applications in the realm of generative AI.\\nThe Future of AI Image Generation\\nAs the modern generative AI era unfolds, a plethora of models \\nhave emerged, including stable diffusion, Midjourney, DALL-E \\n2, Craiyon, Parti, Imagen, and others such as Night Café,  \\nArtbreeder, DeepAI, StarryAI, WOMBO Dream, and Bria \\n(which is targeted for business-to-business [B2B])— and even'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='earlier models like Google’s Deep Dream Generator. This pro-\\nliferation heralds a future teeming with mind-blowing technol-\\nogy. Improvements, innovations, trends, new paradigms, issues, \\nadoption, and applications of generative AI will persist and evolve \\nin the years to come, with AI image generators creating 2D, 3D, \\nand even 4D images based on text.\\nSimply put, 4D images represent changes over time— a \\nsequence of three-dimensional images depicting a transforming'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='object or scene. Achievable through video capture, 3D modeling, \\nanimation, and machine learning, 4D images hold immense \\npotential. For instance, generative AI could revolutionize medi-\\ncal diagnostics by transforming X-rays and CT scans into realis-\\ntic, interactive images, allowing doctors, for example, to examine \\na broken rib from various angles.\\nAs generative AI platforms become increasingly prevalent, \\nimage generation as a standard functionality seems inevitable.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 63\\nEmad Mostaque’s theory posits that most image generation \\ncompanies will eventually converge in terms of AI capabilities. \\nHowever, this may not necessarily be true, as consistently excep-\\ntional personnel are required to push these hard tech boundaries, \\nand the diverse landscape of generative AI allows for countless \\nturns on the highway of innovation. Consider use case–specific'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI image generation: one focusing on training data for self-driving  \\ncars, another on medical imaging. Ultimately, this diversity \\nhinges on the training data each company obtains and potentially  \\ngenerates.\\nAssuming AI image generation models do eventually reach \\nsimilar capabilities and qualities in a profitable manner, compa-\\nnies must explore what’s next. In this innovative, competitive \\nspace with high expectations set by capital allocators, models will'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='likely evolve into more capable, multimodal systems, eventually \\nculminating in artificial general intelligence. More on this fasci-\\nnating prospect will be explored later in the book.\\nLastly, generative AI companies must be nimble in pivoting \\ntheir strategies, even after expending significant energy on a par-\\nticular tech approach. As witnessed in AI image generation, many \\ncompanies initially doubled down on GANs, tweaking and refin-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ing them to fit narrow use cases. However, the open source release \\nof stable diffusion— with its superior performance— prompted an \\nimmediate shift in strategy. In this ever-evolving landscape, adapt-\\nability and resilience are the hallmarks of success, as generative AI \\ncontinues to forge new frontiers in the world of technology.\\nA Crucial Tech Disruption: Text Generation\\nIn the realm of AI data generation, two primary streams have'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='emerged, each with its own unique capabilities: image generation, \\nwhich exemplifies parallel data generation, and text generation, \\nrepresentative of sequential data generation. These two distinct'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='64 GENERATIVE AI\\nstreams complement one another, paving the way for AI’s versatile \\napplications in various domains.\\nT ext generation models, being intrinsically adept at handling \\nsequential data, excel in generating not only written text but also \\nother forms of sequential data, such as code, music, voice, and \\nother auditory elements. Furthermore, they can generate time-\\nseries data, encompassing synthetic sensor data to enhance data-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='sets, stock market data, and much more. A few examples include \\ncomposing original music pieces, simulating stock market trends, \\nand even generating realistic human speech, all thanks to the \\ninherent sequential nature of these models.\\nAs you delve further into this chapter, you will witness the \\ninnovative spirit of research scientists who achieved groundbreak-\\ning results. This creative triumph is best exemplified by the launch \\nof ChatGPT on November 22, 2022. Since then, LLMs have'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='transcended mere hype, offering tangible value for businesses and \\nindividuals alike. My experience with GenerativeAI.net is a testa-\\nment to this, as I consult companies on leveraging language mod-\\nels for tailored applications, and as a leader at Infosys Consulting, \\nI guide teams in implementing this revolutionary technology, \\naccumulating an impressive array of client success stories and cre-\\ndentials. Our work with these organizations extends beyond sim-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ple implementation; we help them harness the power of generative \\nAI to transform into AI-first companies.\\nAutoregression Models\\nIn the fascinating realm of text generation models, an overarch-\\ning player emerges: the autoregressive model. Whenever a model \\nuses a sequence of words or other sequences to predict the  \\nensuing words, we are witnessing the prowess of autoregression. \\nWhile this mechanism is not exclusive to text generation, it'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='dominates the field. As we traverse through the landscape of text'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 65\\ngeneration, note that all models presented, except for rule-based \\nsystems and GANs, are autoregressive. However, we shall main-\\ntain our chronological approach.\\nOur journey takes us back to the early 20th century, when the \\nBritish statistician Yule first introduced autoregression models, \\nalso known as autoregressive models. These statistical marvels \\nutilize past values of a time series to forecast future values. When'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='applied to text generation, autoregression models astutely pre-\\ndict the next word or token, basing their deductions on the con-\\ntext of the preceding words in the sequence.\\nAutoregression models come in various orders, ranging from \\nthe elementary first-order model, AR(1), to more intricate vari-\\nants. AR(1) predicts the value of the time series at time ‘t’ by \\nrelying on its value at time ‘t-1’. Meanwhile, the more sophisti-\\ncated AR(p) models predict the time-series value at time ‘t’ by'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='considering values at times ‘t-1’, ‘t-2’, and so forth, up to ‘t-p’.\\nWhile these models are traditionally grounded in statistical \\nmethods, they have evolved to adapt to neural network architec-\\ntures such as recurrent neural networks (RNNs) and transform-\\ners. This adaptation has enabled them to capture more complex \\ndependencies, thus generating text that is not only coherent but \\nalso imbued with semantic meaning. The autoregressive model’s'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='journey from its inception to its modern adaptations reflects the \\never-evolving nature of AI, a testament to human ingenuity and \\nour drive to understand the intricacies of language.\\nMarkov Chains\\nBorn in Russia, Andrey Markov was a prodigious mathemati-\\ncian who, in 1906, introduced the world to Markov chains. His \\ngroundbreaking paper laid the foundation for the study of sto-\\nchastic processes, particularly those now called Markov chains.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Although they were far removed from text generation at the \\ntime, their potential in this area would soon be recognized.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='66 GENERATIVE AI\\nFast-forward to 1948\\xa0when Claude Shannon, an illustrious \\nmathematician and electrical engineer who later helped to coin \\nthe term artificial intelligence, presented a paper demonstrating \\nthe use of Markov chains in text generation. Shannon’s innova-\\ntive Markov chain model generated English text that echoed the \\nstyle and structure of natural English sentences. The model was \\ntrained on a corpus of text data, and it crafted new sentences by'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='predicting the next word based on the previous word.\\nMarkov chains, a type of statistical model, depict sequences \\nof events in which each event’s probability depends solely on the \\nstate of the system during the previous time step, not on earlier \\nevents. T o generate new text, Markov chains predict the next \\nword in a sequence based on the probability of each word, given \\nthe previous word. By training the model on a corpus of text'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='data, the probabilities of each word given the previous word are \\nestimated. With an initial seed word or phrase, the model gener-\\nates new text by predicting the next word using the probability \\ndistribution and incorporating it into the sequence. Figure\\xa02.13 \\nshows an example.\\nChristmas Wish\\nClique\\n0.10\\n1.00\\n1.00\\n1.00 1.00\\n1.00 1.00\\n0.33\\n0.33\\n0.33\\n1.00\\n0.25\\n0.75\\n0.10\\n0.10\\n0.10\\n0.10\\n0.20\\n0.30\\nCold\\nColonyThe\\nCom\\nClient\\nColor\\nHeart\\nList\\nPurple\\nof\\na\\nCourage\\nLove:\\nKiller\\nStoryJacey’s'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Killer\\nStoryJacey’s\\nFIGURE\\xa02.13 A probability diagram of a Markov chain for text genera-\\ntion. Each node represents a state (word or sequence of words), and \\neach edge represents the transition probability from one state to \\nanother, as determined from the training text.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 67\\nAlthough Markov chains offer simplicity and computational \\nefficiency in text generation, their limitations lie in capturing long-\\nterm dependencies and generating coherent, semantically mean-\\ningful text. As such, Markov chains often serve as a baseline model \\nfor text generation tasks, whereas more advanced applications rely \\non sophisticated models like recurrent neural networks and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='transformer-based models. Thus, Markov chains, while founda-\\ntional, represent just one stepping stone in the ever-evolving jour-\\nney of AI, as we strive to decode the complexities of language.\\nRule-Based Text Generation\\nPioneered in the 1980s, rule-based systems for text generation \\nmarked another significant milestone in text generation. These \\nsystems harnessed the collective knowledge of researchers and \\ndevelopers from various disciplines, including computer science'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='and linguistics. By employing sets of rules and handcrafted \\nknowledge, rule-based systems generated text with structure, \\ncontent, and style that adhered to linguistic principles.\\nIn essence, rule-based systems generate text by following \\nhandcrafted rules based on linguistic knowledge, such as gram-\\nmar rules and semantic relationships between words. For \\ninstance, the rules might dictate that a weather report should \\nbegin with a general statement about the overall weather condi-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tions, followed by specific details about temperature, precipita-\\ntion, and wind.\\nThese rule-based systems have been used for various applica-\\ntions, including weather reports, financial reports, and medical \\nreports. They remain relevant even today in specific domains \\nthat require standardized text output. For example, rule-based \\nsystems have been employed to generate personalized medical \\nreports for patients, summarizing their symptoms, diagnoses,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='and treatment plans in a clear, concise manner. The quality of the \\ngenerated text is contingent on the quality and accuracy of the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='68 GENERATIVE AI\\nrules, which demand considerable domain expertise and manual \\neffort to develop.\\nAlthough rule-based systems have their merits, they are \\ninherently limited in generating novel or creative text. Their \\nstrength lies in producing standardized or formulaic text,  \\nwhere adherence to linguistic rules and conventions is of para-\\nmount importance. Consequently, rule-based systems, much like \\nMarkov chains, form an essential part of the ever-evolving AI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='journey, as we endeavor to unravel the complexities of language \\nand craft increasingly sophisticated text generation models.\\nRecurrent Neural Networks\\nBuilding upon the foundations laid by rule-based systems and \\nMarkov chains, recurrent neural networks (RNNs) emerged in \\nthe early 1980s, thanks to the pioneering work of John Hopfield \\nand David Rumelhart. Both Hopfield and Rumelhart were lead-\\ning figures in the realm of AI, with Hopfield renowned for his'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='contributions to neural networks and Rumelhart for his work on \\nparallel distributed processing— a great team fit.\\nRNNs are a type of neural network designed to process \\nsequential data by maintaining an internal state that captures the \\ncontext of previous inputs. In text generation tasks, RNNs com-\\nmonly predict the next word or token based on the context of \\npreceding words in the sequence. By processing the input \\nsequence one token at a time and updating its internal state at'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='each step based on the input token and the previous state, RNNs \\neffectively encapsulate a summary of prior inputs. This internal \\nstate is instrumental in predicting the next output. Figure\\xa02.14 \\nillustrates an unrolled RNN, and Figure\\xa0 2.15 showcases the \\ndeceptively simple mechanics of a standard RNN unit. A layer is \\nquite straightforward.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 69\\nRNNs have found widespread applications in natural lan-\\nguage processing, including language translation, dialogue gen-\\neration, and sentiment analysis.\\nHowever, RNNs are not without their limitations. They \\noften grapple with the vanishing gradient problem, which hin-\\nders their ability to capture long-term dependencies, akin to \\nlong-term memory. This issue can lead to degraded performance,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='rendering RNNs impractical for large-scale applications. T o \\naddress this challenge, researchers have developed variants of \\nRNNs, such as long short-term memory (LSTM) networks and \\ngated recurrent units (GRUs). Both LSTMs and GRUs excel at \\ncapturing long-term dependencies, enabling the generation of \\nmore coherent and semantically meaningful text.\\nA\\nX2X1X0Xt Input\\nOutput\\nXt...\\n=A AAA\\n0t 00 01 02 0t\\nFIGURE\\xa02.14 A recurrent neural network unrolled.\\nXt-1 Xt+1Xt\\nAA\\nOutput\\nInput\\nOt-1 Ot+1Ot\\ntanh'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Ot-1 Ot+1Ot\\ntanh\\nFIGURE\\xa02.15 A standard RNN unit.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='70 GENERATIVE AI\\nLSTMs typically outperform GRUs, making them the pre-\\nferred choice for many applications. As a result, we will bypass \\nGRUs and delve directly into LSTMs, looking at their capabili-\\nties and potential.\\nLong Short-Term Memory Networks\\nLong short-term memory (LSTM) networks first appeared on \\nthe AI scene in 1997, thanks to the innovative work of Sepp \\nHochreiter and Jürgen Schmidhuber, two researchers known for \\ntheir expertise in neural networks and deep learning. T oday, they'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='continue to be influential in the AI research community; Schmid-\\nhuber is the scientific director of the Dalle Molle Institute for \\nArtificial Intelligence Research in Switzerland.\\nAs previously mentioned, LSTMs are a specialized type of \\nRNN designed to tackle the vanishing gradient problem, which \\nplagues traditional RNNs in capturing long-term dependencies \\nwithin sequential data. While they outshine earlier models, \\nLSTMs are overshadowed by the more recent transformer archi-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tecture, which boasts unparalleled attention mechanisms.\\nLSTMs manage to maintain a cell state that selectively adds \\nor removes information, allowing the network to remember or \\nforget details over extended input sequences. This feat is accom-\\nplished through a system of gates that regulate the flow of infor-\\nmation into and out of the cell state. Figure\\xa0 2.16 depicts the \\ndetailed workings of an LSTM unit.\\nSince their inception, LSTMs have been employed in a vast'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='array of applications, such as machine translation, text classifica-\\ntion, and sentiment analysis. In text generation tasks, LSTMs \\nhave proven especially effective, generating coherent and seman-\\ntically meaningful text with fewer errors than earlier models.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 71\\nLSTMs have been broadly adopted within the tech industry, \\nwith numerous companies utilizing them for natural language \\nprocessing applications. Google, for instance, has used LSTMs \\nin products like Google T ranslate and Google Assistant for lan-\\nguage translation and speech recognition. However, it is worth \\nnoting that more recently, LSTMs have been largely superseded \\nby more advanced systems, such as neural machine translation'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='(NMT). NMT specializes in language translation, with the neu-\\nral network being trained on vast corpora of parallel sentences to \\nlearn the relationships between words and phrases in source and \\ntarget languages.\\nOther areas where LSTMs have been the go-to AI model \\ninclude chatbot development, language modeling for speech rec-\\nognition, and speech synthesis. All in all, LSTMs have been an \\ninstrumental tool in natural language processing and have left a'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='lasting impact on the field since their introduction.\\nOutput\\ncurrent\\nOt\\nOt\\nOutput\\ncurrent\\nCurrent\\ncell state;\\nupdated\\n“memory”\\nCt\\nit\\n/uni03C3/uni03C3\\n×\\n×\\n+\\nft\\nOt\\nCtˆ\\nCt–1\\nXt\\nPrevious\\ncell state\\n“memory”\\nCandidate for\\ncell update\\nUpdated cell state\\nto help determine\\nnew hidden state\\nInput gate:\\nHow much emphasis do\\nwe give the new input info?\\nForget gate [0–1]: How much info\\nfrom previous output do we forget?\\nOutput gate: What info\\nshould the hidden\\nstate carry to the next state?\\nPrevious'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Previous\\noutput Input\\n×\\ntanh\\ntanh\\n/uni03C3Ot-1\\nFIGURE\\xa02.16 An LSTM unit'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='72 GENERATIVE AI\\nN-Gram Models\\nDelving into the annals of computer science and language mod-\\neling, one might find that the specific origins of n-gram models \\nremain shrouded in mystery. Nevertheless, it is widely acknowl-\\nedged that these models experienced a resurgence in popularity \\nduring the mid-2000s. Exhibiting a simplicity that is both elegant \\nand efficient, n-gram models operate by counting the frequency \\nof word sequences in a corpus of text and estimating their prob-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='abilities. The models’ computational efficiency renders them an \\nattractive option for implementation in large-scale applications.\\nY et, like all things, n-gram models do have shortcomings. \\nChief among these are their inability to capture long-term \\ndependencies in text and their susceptibility to data sparsity and \\noverfitting. Despite these limitations, the models have been \\nemployed in an array of applications, ranging from voice assis-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tants like Siri, Alexa, and Cortana to keyword extraction, topic \\nmodeling, and sentiment analysis.\\nHowever, as the sands of time have shifted and more advanced \\nmodels have emerged, the once-prevalent n-gram models have \\ngradually receded into the background. Nonetheless, their \\nimpact on the development of natural language processing \\nshould not be understated, and they will forever remain an \\nimportant milestone in the rich tapestry of AI history.\\nSeq2Seq'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Seq2Seq\\nVenturing deeper into the labyrinth of AI text generation, we \\narrive at the ingenious development of sequence-to-sequence \\n(Seq2Seq) models. Much like an architect who carefully con-\\nstructs a sturdy frame around the building’s core, Seq2Seq mod-\\nels ingeniously harness the power of other AI text generation \\nmodels, elevating them to a new level of sophistication and \\nefficiency.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 73\\nThe foundations of the Seq2Seq model were laid in 2014\\xa0in \\na paper titled “Sequence to Sequence Learning with Neural \\nNetworks” by a group of trailblazing researchers from Google, \\nincluding Ilya Sutskever, Oriol Vinyals, and Quoc V . Le.4 As an \\nintriguing aside, Ilya Sutskever cofounded OpenAI and serves as \\nits chief scientist.\\nSeq2Seq models consist of two recurrent neural networks'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='(RNNs)— LSTMs and GRUs— working in tandem as an encoder \\nnetwork and a decoder network. With applications ranging from \\nmachine translation and text summarization to speech recogni-\\ntion, Seq2Seq models operate by using the encoder to transform \\nan input sequence into a fixed-size vector representation, aptly \\ndubbed the context vector. This vector serves as a concise sum-\\nmary of the input sequence, providing the foundation on which'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='the decoder generates an output sequence (the text generation \\ncomponent). The training process hinges on minimizing a loss \\nfunction that quantifies the disparity between the predicted out-\\nput sequence and the ground truth.\\nAs with any great invention, there is always room for improve-\\nment. Enter the attention mechanism, introduced by Dzmitry \\nBahdanau, KyungHyun Cho, and Y oshua Bengio in 2015, which \\nbestowed upon the decoder the ability to focus on different seg-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ments of the input sequence at varying time steps. This break-\\nthrough significantly enhanced the model’s context awareness. \\nT o distill this concept into its simplest form, imagine the decod-\\ner’s initial limitation: A single hidden state vector at the end of \\nthe encoder proved insufficient. The attention mechanism’s \\nsolution was elegant and effective; it provided as many hidden \\nstate vectors as there were instances in the input sequence, ena-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='bling the decoder to process information with greater finesse and \\nprecision.\\n4Ilya Sutskever, Oriol Vinyals, and Quoc V . Le, “Sequence to Sequence Learning with Neural Networks,” Neu-\\nrIPS Proceedings, accessed November 27, 2023, https://proceedings.neurips.cc/paper/2014/file/a14ac55a4f \\n27472c5d894ec1c3c743d2- Paper.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='74 GENERATIVE AI\\nIt becomes apparent that Seq2Seq models’ applications are \\nvast and varied. One such prominent application, which I touched \\nupon earlier, is Google T ranslate. Seq2Seq models are not limited \\nto LSTMs but can incorporate them, enabling the translation of \\none sequence or sentence in one language to another sequence \\nor sentence in a different language. Refer to Figure\\xa02.17 for a \\nzoomed-out view of the architecture of Seq2Seq models.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Google’s innovative streak does not end with translation. \\nThe tech giant has also harnessed the power of Seq2Seq models \\nto enhance the accuracy of speech recognition in Google Assis-\\ntant, among other applications. Meanwhile, chatbots and con-\\nversational agents have benefited greatly from Seq2Seq models, \\nwhich, when trained on a vast corpus of conversational data, gen-\\nerate responses that are more contextually appropriate and \\nnatural-sounding.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='natural-sounding.\\nGoogle is not alone in recognizing the potential of Seq2Seq \\nmodels. Other tech behemoths, including Facebook, Microsoft, \\nand Amazon, have incorporated these models into their products \\nand services. However, Google has undoubtedly been a key driv-\\ning force in the development and popularization of Seq2Seq \\nmodels, with Google Brain hosting numerous leading research-\\ners in the field.\\nHe\\nEncoder\\nEmbed\\nloved to eat .\\nNULL\\nSoftmax\\nDecoderS\\nEr liebte zu essen'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Er liebte zu essen\\nEr liebtez u essen .\\nFIGURE\\xa02.17 The big picture perspective of a Seq2Seq model.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 75\\nComparing Seq2Seq models with their AI counterparts, \\nLSTMs excel at capturing long-term dependencies, while n-gram \\nmodels are faster to train but lack the ability to capture context as \\neffectively. Seq2Seq models, as a kind of meta-model, are specifi-\\ncally designed for sequence-to-sequence mapping tasks and can \\ngenerate more natural-sounding output. However, they require \\nmore data and fine-tuning.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='The Amazon AlexaTM 20B, a moderate-sized (20 billion \\nparameter) Seq2Seq language model, is likely the most powerful \\nSeq2Seq model to date. It outperforms the much larger GPT-3\\xa0in \\nlanguage translation and summarization, achieving state-of-the-\\nart performance in few-shot-learning tasks across all Flores- \\n101\\xa0language pairs. Despite its impressive capabilities, its release \\nin August 2022 did not cause the same stir in the AI community'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='as OpenAI’s ChatGPT did three months later. The reason behind \\nthis disparity in impact lies in the output quality: AlexaTM 20B’s \\noutput was not as impressive as ChatGPT’s. The intriguing  \\nreasons behind this discrepancy shall be unveiled later.\\nGANs for Text Generation\\nBefore delving into transformers, the cornerstone of state-of-\\nthe-art language generation models like GPT , let’s pause to take \\na look at GANs in text generation.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='T o recapitulate, GANs for text generation operate in a fasci-\\nnating dance of deception and detection. The generator model \\nconcocts realistic text samples, aiming to dupe the discriminator \\nmodel into believing the text is genuine. Simultaneously, the dis-\\ncriminator model hones its ability to discern between authentic \\nand fabricated text samples. Through this iterative process, both \\nmodels evolve, refining their skills based on feedback from one  \\nanother.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='76 GENERATIVE AI\\nSeveral GAN architectures have emerged specifically for text \\ngeneration, such as SeqGAN, MaliGAN, and T extGAN. Examin-\\ning T extGAN as a representative example offers valuable insights \\ninto the process of generating sequential data using GANs. T o \\nbetter grasp its inner workings, we must first address the unique \\nchallenges posed by the text’s discrete nature, which hinders the \\ndirect application of gradients from the discriminator to the gen-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='erator. T extGAN adapts to these challenges in several ways:\\n• It converts both real and fake sentences into high-dimensional  \\nlatent feature distributions, transforming the discrete text \\nproblem into a continuous space. In layman’s terms, it maps \\nthe text onto a spectrum, smoothing out the rough edges \\nand making it more amenable to analysis.\\n• T extGAN employs a kernelized discrepancy metric called \\nreproducing kernel Hilbert space (RKHS) to gauge the dis-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='parity between real and fake text samples. Simply put, it \\nmeasures the “distance” between the two, enabling the gen-\\nerator to better understand how to produce realistic text.\\nT o render the generator differentiable, T extGAN utilizes a \\nsoft-argmax operator and additional techniques like initializa-\\ntion strategies and discretization approximations. In essence, \\nT extGAN modifies the traditional GAN framework, overcoming \\nthe hurdles of text generation and producing more plausible and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='coherent text samples.\\nHowever, GANs’ potential for text generation is not without \\nlimitations. They can suffer from mode collapse, reducing the \\ngenerator model’s output range and stifling sentence variety. \\nFurthermore, GANs may generate nonsensical or irrelevant text \\nand can be difficult to train and optimize due to an unstable \\ntraining process.\\nIn the grand scheme of text generation, GANs are unlikely to \\nplay a pivotal role in the future.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 77\\nAttention\\xa0– Transformer\\xa0– Self-Attention\\nThe intriguing tale of attention mechanisms in deep learning \\nunfurled with the publication of a seminal paper in 2016 titled \\n“Neural Machine T ranslation by Jointly Learning to Align and \\nT ranslate,”5 by Dzmitry Bahdanau, KyungHyun Cho, and Y oshua \\nBengio. Within the dense text of their paper, they introduced the \\nworld to the concept of the attention mechanism— an innovative'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='solution to the problem of long-range dependencies in Seq2Seq \\nmodels. Imagine reading a lengthy novel with countless charac-\\nters and plotlines. The attention mechanism is akin to a well-\\nplaced bookmark, enabling you to keep track of important details \\nand navigate the narrative more efficiently. In the context of \\nSeq2Seq models, Bahdanau, Cho, and Bengio’s attention mecha-\\nnism operates like this literary bookmark, allowing the model to'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='focus on different parts of the input sequence while generating \\nthe output, thereby attenuating the issue of long-range depend-\\nencies. This novel approach drastically enhanced the perfor -\\nmance of neural machine translation systems, setting a new path \\nfor future exploration in the field.\\nFast-forward to 2017, a year marked by another monumental \\nstride in AI research— a groundbreaking paper titled “Attention \\nIs All Y ou Need,” by Ashish Vaswani and his fellow researchers at'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Google Brain and Google Research. 6 The paper proposed the \\ninnovative transformer architecture, making attention mecha-\\nnism its central pillar. In a way, it’s like shifting from a traditional \\nbook to an e-reader that allows you to highlight and annotate  \\nthe most crucial parts of the text. The attention mechanism in \\nthese models enables focusing on specific parts of the input to \\nmake accurate predictions, much like highlighting pivotal points \\nin a text.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='in a text.\\n5Dzmitry Bahdanau, KyungHyun Cho, and Y oshua Bengio, “Neural Machine T ranslation by Jointly Learning \\nto Align and T ranslate,” arXiv, May 19, 2016, https://arxiv.org/pdf/1409.0473.pdf\\n6Ashish Vaswani et\\xa0al. “Attention Is All Y ou Need,” NeurIPS Proceedings, accessed November 27, 2023, https://\\nproceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa- Paper.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='78 GENERATIVE AI\\nSelf-attention, a specific variant of attention mechanism \\nemployed in the transformer architecture, functions somewhat \\nlike a photographic memory— it captures relationships between \\ndifferent parts of the input sequence, irrespective of their dis-\\ntance. This mechanism allows the model to “remember” infor -\\nmation from far-flung parts of the sequence and use that \\ninformation to create a better output.\\nA key advantage of the transformer architecture was its'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ability to process input sequences in parallel, rather than sequen-\\ntially. It’s a bit like reading multiple chapters of a book simultane-\\nously without losing the narrative thread. This meant improved \\nefficiency and scalability, which in turn led to a rise in the popu-\\nlarity and application of transformer models.\\nSubsequently, transformers took the AI world by storm, rap-\\nidly emerging as the state-of-the-art architecture for an array of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='NLP tasks, including machine translation, text summarization, \\nand language modeling. They outclassed existing RNN-based \\nmodels, as they effectively address the issues of long-range \\ndependencies, a problem that LSTM and RNN models grappled \\nwith. It’s like upgrading from an old typewriter to a modern \\ncomputer— the core concept remains the same, but the capabili-\\nties are vastly expanded.\\nTech Triumphs in\\xa0Text Generation\\nSince the advent of the self-attention mechanism, we have wit-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='nessed an effusion of diverse LLMs, each bringing unique fea-\\ntures to the table. Among the most notable are OpenAI’s GPT \\nseries, Google’s BERT , T ransformer-XL from Google Brain, \\nFacebook’s BART , and T5 from Google Research. Subsequent \\nchapters will delve deeper into the intricacies of these different \\nmodels. However, for now, let’s focus on some key technical'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 79\\naspects like tokenization, models being probabilistic, training, \\nfine-tuning, prompting, scaling laws, reinforcement learning \\nfrom human feedback (RLHF), emergent abilities, and more. \\nThese, in essence, form the backbone of these models, acting as \\nthe nuts and bolts that piece together the entire machinery of AI.\\nTokenization for LLMs\\nT okenization, in the context of language models, is akin to the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='process of linguistic dissection. It involves the fragmentation of \\ninput and output texts into smaller, manageable units known as \\ntokens. These tokens could be as minute as characters, as standard \\nas words, or as nuanced as subwords and symbols. This process is \\nnot merely an act of division, but a means to a greater end. \\nT okenization is instrumental in enabling AI models to grapple \\nwith the diversity and complexity of human language, encom-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='passing different vocabularies, languages, and formats. Moreo-\\nver, it allows for a significant reduction in computational and \\nmemory costs, thus boosting the efficiency of these models.\\nThe act of tokenization, however, is not a one-size-fits-all \\napproach. There are different methods of tokenization, such as \\nrule-based, statistical, or neural. The choice of method is deter -\\nmined by the complexity and variability of the texts being han-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='dled. Rule-based methods, for instance, rely on predetermined \\nrules to tokenize text, whereas statistical methods look for com-\\nmon patterns and frequencies in the text. Neural methods, on \\nthe other hand, leverage the power of neural networks to under-\\nstand and segment text.\\nAmong these methods, OpenAI, the creator of this very \\nmodel you’re interacting with, has opted for a subword tokeniza-\\ntion method known as byte-pair encoding (BPE) for its GPT-based'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='models. BPE operates akin to a keen-eyed linguist, identifying \\nand merging the most frequently occurring pairs of characters or'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='80 GENERATIVE AI\\nbytes into a single token. It’s important to note that the number \\nof tokens or the size of the vocabulary is not a constant across all \\nmodels; it varies, much like the models themselves.\\nT okenization inevitably impacts the amount of data and the \\nnumber of calculations a model is required to process. It’s a sim-\\nple equation: The more tokens a model has to juggle, the greater \\nthe demand on memory and computational resources. Conse-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='quently, the cost of running a model is intrinsically linked to the \\ntokenization method employed, the size of the vocabulary, as \\nwell as the length and complexity of the input and output texts.\\nAs of February 2023, OpenAI’s Davinci model cost $0.06 per \\n1,000 tokens. T o illustrate, generating a summary for a 2,500-\\nword article, roughly 3,125 tokens, costs about $0.19. For a \\nbook-length text, the price rises to approximately $7.50. Scaling'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='up to an industrial operation, such as producing 100 books a day, \\ndaily costs hit $750, monthly around $22,500, and annually about \\n$270,000— only for tokenization, prediction excluded, and train-\\ning is a totally different topic. These estimates vary with factors \\nlike text length, complexity, and potential volume usage agree-\\nments. As impressive as AI models are, it’s important to under -\\nstand the underlying costs associated with their operation.\\nOutput Probability'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Output Probability\\nLanguage models such as GPT , short for Generative Pre-trained \\nT ransformer, fundamentally operate as probabilistic models. A \\nprobabilistic model is a distinctive design that assigns probabili-\\nties to myriad possible outcomes.\\nT o delve deeper, we must turn our attention to the trans-\\nformer architecture, the underlying framework on which  \\nGPT and other LLMs are built. Herein lies the significance of \\nprobability.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 81\\nAt its core, the principal duty of transformer-based language \\nmodels like GPT is to forecast the subsequent word or token in \\na sequence. Given a certain input, the model computes a proba-\\nbility distribution spanning the entire vocabulary for the follow-\\ning word. T ypically, the word boasting the highest probability is \\nchosen as the predicted outcome. Imagine feeding the model a'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='sequence such as “The cat is on the”; it then calculates the prob-\\nabilities for all conceivable succeeding words and may conclude \\nthat “roof   ” bears the highest probability. This process can be sig-\\nnificantly adjusted through the art of prompt engineering, an \\nintriguing topic that I’ll cover in more detail later in this chapter.\\nThis fundamental principle extends to entire sequences as \\nwell. The model is capable of computing the joint probability of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='a series of words by breaking it down into conditional probabili-\\nties. This clever mathematical maneuver is carried out using the \\nchain rule of probability, enabling the model to churn out sen-\\ntences that are not only coherent but also contextually appropriate.\\nDuring the training phase, the model tweaks its parameters \\nin a bid to maximize the likelihood of the training data. This \\nprocess, known as maximum likelihood estimation (MLE), entails'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='adjusting the model’s internal learnable parameters— weights \\nand biases— to ensure that the probabilities assigned to the actual \\nsucceeding words in the training data are as high as possible.\\nFinally, during the generation of new text, sampling methods \\nsuch as beam search, nucleus sampling, or top-k sampling lever-\\nage the probability distribution over the subsequent word to \\nproduce diverse and captivating outputs. While beam search'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='considers multiple possible sequences simultaneously and keeps \\nthe top few, nucleus sampling selects from a core group of most \\nlikely words, and top-k sampling chooses from the top ‘k’ prob-\\nable words. With that we make sure that instead of always opting \\nfor the word with the highest probability— a strategy that can'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='82 GENERATIVE AI\\nlead to monotonous and deterministic text— the model might \\nsample from the distribution, resulting in more varied and crea-\\ntive outputs.\\nThus, while the cost of running such models may seem steep \\nat first glance, understanding the intricate play of probabilities in \\ngenerating coherent, creative, and contextually appropriate text \\nreveals the true value of these advanced AI systems.\\nPretraining LLMs\\nAs we journey through the world of LLMs, we find ourselves'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='encountering various stages of their training process. The initial \\ntraining phase— often referred to as pre-training— is where our \\nfocus now lies (Figure\\xa02.18).\\nWhen considering pre-training in the context of LLMs, two \\nbroad strategies stand out. The first approach, known as autore-\\ngressive training, is akin to predicting the next word in a sentence. \\nPre-training LLMs\\nPrompt Engineering\\nFine-tuning\\nRLHF\\n1\\n2\\n3\\nMust\\noptional\\nSpecific and quality\\ndataset needed\\nCarefully constructed'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='prompts needed\\nUsed to further\\nimprove the weights\\nGeneralSpecific\\nFIGURE\\xa02.18 The different stages of receiving a desired LLM output.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 83\\nFor instance, given the phrase “I like to eat,” the model’s task is \\nto predict what comes next— perhaps “ice cream.”\\nThe second pre-training approach is called masked training. \\nHere, parts of the sentence are obscured or “masked,” and the \\nmodel must predict the missing elements. For instance, given  \\n“I like to [MASK] [MASK] cream,” the model would need to fill \\nin the gaps, possibly with “eat ice.”'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='In addition to these primary pre-training tasks, there are aux-\\niliary ones that further refine the model. For instance, the next \\nsentence prediction (NSP) task requires the model to predict \\nwhether pairs of sentences appear consecutively in the training \\ncorpus. This aids in honing the model’s understanding of narra-\\ntive flow and coherence.\\nThe objective of all this training is to minimize a specific loss \\nfunction, often the average negative log-likelihood per token,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='otherwise known as cross-entropy loss. Think of it as a scoring sys-\\ntem: It measures how well the model’s predictions align with the \\nactual outcomes. If the model predicts “cake” when the sentence \\nis “I like to eat ice cream,” the cross-entropy loss will be high, \\nsignaling the model to adjust its internal parameters.\\nAnother concept that comes into play during training is regu-\\nlarization loss. It’s akin to a guiding hand that prevents the model'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='from overfitting or memorizing the training data. However, this \\nis typically applied during training and not considered during \\ntesting and evaluation.\\nThe scale of training datasets for LLMs is astoundingly large. \\nEarly LLMs, like GPT-1, cut their teeth on datasets such as Book-\\nCorpus, boasting a hefty 985\\xa0million words. BERT , another early \\nmodel, trained on a combination of BookCorpus and English \\nWikipedia, amassing a total of 3.3 billion words. With time, the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='size of these training corpora ballooned, reaching up to a stagger-\\ning trillions of tokens.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='84 GENERATIVE AI\\nThere’s no denying that the computational cost of training \\nLLMs is high. But there is a silver lining. Over the years, thanks \\nto technology advancements and economies of scale, these costs \\nhave been steadily decreasing. Moore’s Law, despite being dec-\\nades old, still holds relevance in this context. It postulates that \\nthe number of transistors on a microchip doubles approximately \\nevery two years, which in turn drives down computing costs.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Consider this: The cost of training a 1.5 billion parameter \\nLLM in 2019\\xa0 was around $1.6\\xa0 million. Fast-forward to 2023, \\nand you could train a model with four times as many parame-\\nters— 6 billion— for the same price.\\nShifting our focus to larger models, GPT-3, which carries \\n175 billion trainable parameters, created a noteworthy shift in \\nthe cost landscape. The actual figure remains undisclosed by its \\nprogenitor, OpenAI, but estimates range between $5\\xa0million and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='$12\\xa0million. As we leap forward to GPT-4, the details of its size \\nare still under wraps, yet the speculated costs of training such a \\nmodel oscillate between a hefty $100\\xa0million and $200\\xa0million. \\nThe path forward in AI is a costly one indeed, but given the vast \\npotential, it remains a worthy exploration.\\nFinally, it’s worth noting the cost difference between training \\nand inference (or using the model to make predictions) in'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='transformer-based LLMs. T raining costs about six floating point \\noperations (FLOPs) per parameter for each token, whereas infer-\\nence costs significantly less— just one or two FLOPs per param-\\neter per token. This roughly equates to a 4.5 to 1 ratio, making \\ninference more economical, whereas pre-training is the necessary  \\ninitial investment.\\nFine-tuning LLMs\\nT urning our attention to the next pivotal element of our AI jour-\\nney, we encounter the concept of fine-tuning language models.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='This process is akin to chiseling a masterful statue out of a crude'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 85\\nslab of marble. Initially, pre-trained language models are exposed \\nto large, diverse corpora, absorbing language patterns and a \\nsomewhat profound understanding of the world and learning to \\nconstruct coherent text. This, however, is just the beginning.\\nWhen we engage in the fine-tuning process, the preexisting \\nparameters of our pre-trained model serve as our foundation. \\nSubsequent training is carried out on task-specific data, which'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='might be annotated to illustrate the desired behavior or output \\nfor a specific task. Like a versatile tool, fine-tuning can be applied \\nto the entire neural network or just a subset of layers. Imagine \\nlocking some layers in place, their learning stalled, while others \\nadapt and evolve.\\nThis finely honed focus allows the language model to imbibe \\ntask-specific characteristics, vocabulary, and subtleties integral to \\nthe target application. The outcome? More precise, contextually'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='relevant responses and heightened performance on niche NLP \\ntasks such as textual question answering within a corpus of com-\\nplex jargon, such as contracts and other legal documents.\\nA recurring theme in my myriad interactions at conferences \\nand dialogues with other thought leaders suggests a veering \\ntoward smaller, task-specific AI models. Echoing this sentiment \\nis Sam Altman, the CEO of OpenAI. Altman foresees an immi-\\nnent halt to the expansion of LLMs. His focus rests on augment-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ing capability rather than simply inflating parameter count. If \\nsubstantial improvements can be attained via lesser parameters \\nor through an amalgamation of smaller models, so be it. There \\nare, after all, finite datacenters that companies like OpenAI can \\nconstruct— a limit to their pace of construction as well as financial  \\nrestrictions.\\nWhile full fine-tuning offers improved results, it’s not as \\nmuch as pre-training, a resource-intensive endeavor that’s sus-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ceptible to overfitting. A fascinating piece of ongoing research \\nthat caught my attention was published in Nature under the title \\n“Parameter-Efficient Fine-T uning of Large-Scale Pre-T rained'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='86 GENERATIVE AI\\nLanguage Models” by Ning Ding et\\xa0al.7, who propose a strategic \\nbalance between performance and efficiency when fine-tuning \\nlarge-scale pre-trained language models.\\nThey present an innovative method christened delta tuning, \\nwhich adjusts the pre-trained model by adding or tweaking a \\nsmall number of parameters. The striking results: delta-tuning \\nmethods have exhibited similar or even superior performance to \\nconventional fine-tuning methods while employing a mere'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='10–20 percent of the original parameters. The inherent prowess \\nof fine-tuning large-scale models, coupled with the resourceful-\\nness of delta tuning, paints an exhilarating picture of the poten-\\ntial locked within AI.\\nPrompt Engineering\\nNavigating the maze of AI innovations, one cannot help but \\nnotice the understated role of prompt engineering. This meth-\\nodology involves meticulously crafting or sculpting the prompts \\nor directions given to a generative model. The idea is to manipu-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='late the model’s output by molding the input information and \\ncontext. Certain keywords, phrases, or even the layout can be \\nwielded strategically to steer the model’s responses. The over -\\narching objective is to trigger a desired behavioral outcome, \\nheighten precision, or command the output style. It is no sur -\\nprise then that prompt engineering has come to be a trusted ally \\nin optimizing the performance of generative AI models for speci-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='fied tasks. It also serves as a robust tool to counter biases and \\nfoster fairness in the produced output.\\nThe importance of prompt engineering is hard to overstate. \\nIt holds the potential to completely redefine the manner in which \\nwe interact with AI. By incorporating the best practices of \\n7Ning Ding et\\xa0al., “ Parameter-Efficient Fine-T uning of Large-Scale Pre-T rained Language Models,” Natural \\nMachine Intelligence, 5, 220–235 (2023), www.nature.com/articles/s42256- 023- 00626- 4'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 87\\ncommunication between humans and machines, prompt engi-\\nneering allows machines to accurately interpret human instruc-\\ntions and provide valuable responses. Not only does it underscore \\na science in its own right, but it also has significant implications \\nfor the future job market.\\nWhile most of the scientific exploration of prompting is cen-\\ntered around language models, owing to their versatility in han-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='dling text, it is important to note that image generation prompting \\nalso offers a wealth of techniques and guidelines.\\nChain-of-Thought (CoT) Prompting One of the more nota-\\nble advancements in the world of prompting is chain-of-thought \\n(CoT) prompting. Coined by researchers at Google in 2022, \\nCoT prompting enhances the reasoning ability of LLMs by \\nmaking them generate intermediate steps that lead to the final \\nanswer of a multistep problem. This methodology shows'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='marked improvements with larger and more powerful language \\nmodels and can be fine-tuned on CoT reasoning datasets.\\nFew-Shot and Zero-Shot Prompting CoT reasoning can be \\ntriggered using two primary methods: few-shot prompting \\nand zero-shot prompting. Few-shot prompting (Figure\\xa02.19) \\nemploys at least one example of a question paired with  \\nappropriate human-written CoT reasoning, whereas zero-\\nshot prompting (Figure\\xa0 2.20) could be as uncomplicated as'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='appending “Let’s think step by step” to the prompt.\\nSelf-Consistency Prompting In our pursuit of improved \\nCoT reasoning for more complex problems, we come across \\nthe technique of self-consistency prompting. This method \\nentails supplying the AI model with multiple reasoning paths \\nor diverse perspectives, after which the most consistent and \\ncoherent answer among the generated responses is selected \\n(Figure\\xa02.21). Not only does self-consistency prompting help'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='88 GENERATIVE AI\\ndiminish biases in the AI’s responses, but it also propels  \\nthe model to consider various viewpoints before reaching a \\nconclusion.\\nFIGURE\\xa02.19 Few-shot prompting.\\nSource: OpenAI\\nFIGURE\\xa02.20 Zero-shot prompting.\\nSource: OpenAI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 89\\nKnowledge Prompting Another significant tool in our prompt-\\ning toolkit is knowledge prompting. This technique involves \\nfeeding the AI model with extra information or knowledge to \\nenhance its performance on specific tasks. Such information, \\nwhich might provide context or background, can be embedded \\ninto the input prompt to assist the model in better understand-\\ning the task at hand. Knowledge prompting proves particularly'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='useful for complex tasks requiring a deeper comprehension of \\nthe subject matter. However, it is of utmost importance to \\nmeticulously design and optimize prompts for specific use cases \\nto ensure optimal performance.\\nFIGURE\\xa02.21 Self-consistency prompting: same question asked multi-\\nple times, resulting in same answer.\\nSource: OpenAI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='90 GENERATIVE AI\\nKnowledge prompting isn’t haphazard; it follows a defined \\nprocess (Figure\\xa02.22). This begins with identifying the task or \\nproblem and understanding the AI model’s existing knowledge \\nto spot any gaps. Next, external knowledge sources are identified \\nand integrated, enhancing the model’s understanding. The \\nresultant knowledge-rich prompts are then refined to optimize \\ntask-specific performance. Following this, the AI’s output is eval-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='uated, assessing the effectiveness of the prompts. The evaluation \\nprovides invaluable insights for further iterative improvements, \\nbeginning again from the first step, if required. This process \\nensures knowledge prompting serves as a robust tool to elevate \\nAI performance on complex tasks, each iteration bringing us \\ncloser to creating optimized knowledge prompts.\\nDirectional Stimulus Prompting In 2023, Li and his team \\nintroduced a novel prompting technique, directional stimulus'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='prompting, aiming to enhance the guidance provided to LLMs \\nin generating desired summaries. The process involves train-\\ning a manageable policy language model (LM) to generate a \\nstimulus or hint, marking an increasing trend in the use of \\nreinforcement learning (RL) to optimize LLMs. Figure\\xa02.23 \\noffers a comparative view of directional stimulus prompting \\nagainst conventional prompting. Notably, the policy LM, kept \\ncompact for convenience, is fine-tuned to generate hints that'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='efficiently navigate a black-box, frozen LLM toward the \\ndesired output.\\nKnowledge 1\\nKnowledge 2\\n...\\nKnowledge\\nGeneration AnswerKnowledge\\nIntegrationQuestion\\nFIGURE\\xa02.22 Generated knowledge prompting structure.\\nSource: https://arxiv.org/pdf/2110.08387.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 91\\nReAct (Reason + Act) Prompting T aking things a notch \\nhigher, ReAct prompting merges reasoning and action tasks to \\namplify the capabilities of LLMs. The ReAct method inter -\\nleaves reasoning traces and task-specific actions to enhance the \\ndecision-making and comprehension abilities of LLMs. This \\napproach refines the model’s capacity to formulate action plans, \\nhandle exceptions, and source more information from external'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='avenues. The prompts featured in ReAct are comprehensive \\nand multifaceted. They encompass few-shot task-solving trajec-\\ntories, which involve solutions that emerge after only seeing a \\nfew examples of a problem. Additionally, they also contain \\nhuman-written reasoning traces, providing insight into the \\nthought processes that led to certain conclusions or decisions. \\nFurthermore, the prompts detail specific actions taken and the \\nsubsequent environmental responses that arise due to these'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='actions, offering a clear picture of cause-and-effect relationships \\nin various scenarios. Outperforming the existing baselines in \\ndiverse tasks, ReAct demonstrates improved performance, \\nhuman interpretability, and trustworthiness. This will be espe-\\ncially important for robots.\\nFIGURE\\xa02.23 Directional stimulus prompting.\\nSource: https://arxiv.org/pdf/2302.11520.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='92 GENERATIVE AI\\nFigure\\xa02.24 depicts the “ReAct” (Reason + Act) method. In \\nthis approach, “Act” signifies the decisions or actions undertaken \\nby the agent, while “Obs” stands for observations, highlighting \\nthe consequences or results of the said actions.\\nIt is important to acknowledge that prompting does have pit-\\nfalls. For instance, it opens the door to vulnerabilities and poten-\\ntially malicious use. An AI model can be exploited through'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='prompt injection— a technique that coerces a language model, \\nwhich is usually trained to follow human-given instructions, to \\ncomply with the instructions of a malicious user. The prompt \\ninjection can happen when instructions and data are mashed \\ntogether, rendering it challenging for the underlying system to \\ndifferentiate between the two.\\nAs we journey further into the world of AI, it is essential to \\napproach these innovations with an understanding of their'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='potential, but also their associated risks.\\nFIGURE\\xa02.24 ReAct prompting.\\nSource:\\xa02022 https://arxiv.org/pdf/2210.03629.pdf'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 93\\nLLMs Until ChatGPT\\nThe release of GPT-2\\xa0in 2019 still stands out in my mind. OpenAI \\nmade an unprecedented move by initially withholding the full \\nmodel due to concerns about its potential misuse. Their decision \\nsparked extensive discussions about the responsible development \\nof AI and the delicate balance between harnessing benefits and \\nmitigating risks. OpenAI’s stance left me pondering— was this'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='simply a marketing ploy, or did GPT-2 truly possess capabilities \\nthat warranted such caution?\\nGPT-2\\xa0 was more than a mere upgrade to its predecessor, \\nGPT . It was a quantum leap in terms of scale, boasting over 10 \\ntimes the parameters— with a mind-boggling count of 1.5 billion \\ntrainable parameters. T rained on an extensive dataset of 8\\xa0mil-\\nlion web pages, GPT-2 flexed its muscles by demonstrating a \\nbroad array of capabilities, including the generation of synthetic'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='text samples of unprecedented quality.\\nSince the advent of GPT-2, countless LLMs have been \\ndeveloped, each with its own unique strengths. However, a few \\nLLMs have distinguished themselves from the crowd, demand-\\ning special mention.\\nJust over a year after the release of GPT-2, OpenAI unveiled \\nGPT-3\\xa0 in June 2020. This new iteration made GPT-2\\xa0 look \\nalmost modest in comparison, sporting not 10 times, but over \\n100 times the trainable parameters, amounting to a staggering'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='175 billion. Such a scale was unrivaled at the time of its release. \\nThis beast of a model was trained on roughly 570\\xa0GB of Internet \\ntext, and the results spoke for themselves. GPT-3\\xa0marked a sig-\\nnificant leap in language generation quality and has been \\nemployed in a variety of applications, including the generation of \\ncode snippets, regular expressions, and even Microsoft Excel \\nfunctions from simple text descriptions. Owing to its advanced'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='capabilities, OpenAI opted to keep GPT-3 under wraps, grant-\\ning access only to a select few, and never open sourcing it.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='94 GENERATIVE AI\\nReflecting on the landscape of LLMs in late 2020, the scene \\nwas not entirely monopolized by OpenAI. Google was also mak-\\ning waves with its research contributions. They introduced  \\nmodels such as the T ext-to-T ext T ransfer T ransformer (T5) and  \\nT ransformer-XL, which both had substantial impacts on the field. \\nThe T5 stood out with its unified, text-to-text framework, revolu-\\ntionizing how various NLP tasks were approached, whereas the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='T ransformer-XL excelled in handling longer sequences of text, \\nproving its mettle in language modeling and text generation tasks. \\nDespite OpenAI’s dominance, it’s clear that other players, like \\nGoogle, have also played a significant part in shaping the pro-\\ngress of LLMs.\\nIn June 2021, Google introduced a model known as LaMDA. \\nThis LLM had 137 billion trainable parameters and was trained \\non an extensive dataset comprising 1.56 trillion words. LaMDA'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='was not open source, but it was designed with a unique goal in \\nmind: to facilitate free-flowing conversations on a broad range of \\ntopics. This capability made LaMDA intriguing, as it suggested a \\nmove toward more naturalistic, dynamic human-computer \\ninteractions.\\nNot necessarily to facilitate natural conversations but rather \\ncode generation, OpenAI released Codex later in the same year. \\nThis model had fewer trainable parameters than LaMDA— 12'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='billion in total— but it was fine-tuned for a very specific task: \\nprogramming applications. Codex was trained on a vast array of \\nprogramming languages sourced from 54\\xa0million GitHub repos-\\nitories, making it a significant development in the realm of cod-\\ning automation. Like LaMDA, Codex was not made open source, \\nfurther illustrating the growing trend of proprietary LLMs.\\nGoogle made further strides in 2022\\xa0 with the release of \\nLaMDA 2. Unfortunately, not much is known about this model’s'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='specifications due to Google’s decision to keep the details under'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 95\\nwraps. This secrecy might seem unusual, but it is likely a strate-\\ngic move designed to maintain a competitive edge in the rapidly \\nevolving field of AI.\\nThe close of 2022 saw the arrival of Galactica, an LLM by \\nMeta. With 120 billion trainable parameters, Galactica was \\ntrained on 48\\xa0million examples taken from an assortment of sci-\\nentific articles, websites, textbooks, lecture notes, and encyclope-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='dias. This model was not only open source but also specifically \\ndesigned to aid scientists in simplifying their research and accel-\\nerating the writing of scientific literature. Despite these ambi-\\ntious goals, Galactica received substantial criticism for generating \\nnonsensical and inaccurate information, as it was very good at \\nconfidently hallucinating facts and results. In response to this \\nbacklash, Meta removed the public demo after just three days'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='and temporarily halted the project. While the model remains \\naccessible to researchers interested in working with it or repli-\\ncating its results, this incident underscored the challenges that \\neven the most advanced AI can face.\\nDespite these exciting developments, we saw that even by the \\nend of 2023, LLMs had yet to make a truly transformational \\nimpact. The promise of these technologies is immense, but their \\npractical applications continue to evolve, often in unexpected'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ways. It’s clear that the journey of LLMs is far from over and \\ntheir potential to reshape our world remains largely untapped.\\nLLM Scaling Laws\\nThe advent of LLMs has brought forth a profound shift, akin to \\nthe tectonic movements shaping the landscape of a planet, subtly \\nyet inexorably altering the contours of the field. Among the \\nforces driving these changes, none are perhaps as influential as \\nthe phenomenon known as scaling laws.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='96 GENERATIVE AI\\nScaling laws, in essence, delineate the relationship between \\nthe size of a model— its number of parameters— and the amount \\nof data it requires for optimal performance. Among these laws, a \\nset of findings known as the Chinchilla scaling laws, unearthed by \\nDeepMind in 2022, has proven especially instrumental in guid-\\ning the development of language models.\\nThe Chinchilla scaling laws assert that an optimal LLM \\nrequires approximately 20 text tokens per parameter. Compared to'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='the earlier Kaplan scaling laws, which served as the guiding star for \\nOpenAI’s GPT-3 and suggested a requirement of 1.7 text tokens \\nper parameter, the Chinchilla laws signal a massive leap in data \\ndemands. For instance, to align GPT-3\\xa0with the Chinchilla laws, \\nthe model would either need to be pared down to 15 billion param-\\neters, using its original 300 billion tokens, or inflate its dataset to a \\nwhopping 3.5 trillion tokens, maintaining its original 175 billion'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='parameters. This implies an 11-fold surge in data requirements.\\nThe reach of the Chinchilla scaling laws extends to models of \\ngargantuan proportions, those measured in trillions of parame-\\nters and trained on petabytes of text data— a quantity equivalent \\nto quadrillions of text tokens. However, the quest to feed such \\ntitanic models presents a herculean challenge. As the number of \\nparameters begins to outstrip the number of unique published'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='books, sourcing sufficient data becomes an increasingly complex \\nendeavor. Privacy concerns, issues related to sensitive data, and \\nthe emerging trend of companies charging for data scraping \\nfrom platforms rich in user-generated content, such as Reddit \\nand Quora, all contribute to the complexity of this landscape.\\nPredictions for the year 2023 and beyond suggest a contin-\\nued adherence to the Chinchilla scaling laws among LLMs.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Nevertheless, the area of data optimization and efficient data use \\nduring training remains a hotbed of research, with new discover-\\nies anticipated on the horizon.\\nFigure\\xa02.25 illustrates the dataset sizes necessary to conform \\nto the principles of Chinchilla data optimization across a range'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 97\\nof model sizes. Alongside, it provides a concise summary of the \\nexisting models, capturing their tokens-to-parameters ratios.\\nT wo central conclusions can be drawn from this. First, \\nmerely ballooning the size of models in the coming years will \\nnot suffice. The need for a significantly larger pool of data and \\nthe development of smaller, more specialized models that excel \\nin specific tasks will become paramount. Prompt designing and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='specific datasets will play a critical role in enhancing perfor -\\nmance. Second, it is projected that the generation of data will \\nsee an exponential increase. According to IDC, the compound \\nannual growth rate of new data creation from 2020 to 2025 is \\nforecast at 23 percent, resulting in approximately 175 zetta-\\nbytes of new data. Coupled with increasingly affordable com-\\nputing resources, this will permit the expansion of model sizes \\nin a balanced manner.\\nChatGPT'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ChatGPT\\nDrawing upon the successful launch of ChatGPT on November \\n30, 2022, built atop the impressive framework of GPT-3.5, the \\nAI world experienced a monumental event. This was not merely \\nFIGURE\\xa02.25 Chinchilla scaling in table.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='98 GENERATIVE AI\\nthe introduction of yet another AI model, but a revolution that \\nswept across the globe. With over 1\\xa0million users within its first \\nfive days, and a staggering 100\\xa0 million just two months post-\\nlaunch, the application became an unparalleled success. By Janu-\\nary 2023, the count of visits had skyrocketed to about 590\\xa0million.\\nThis global embracement wasn’t happenstance but rather a \\nmeticulously curated triumph. The brilliance of ChatGPT lies in'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='its sheer versatility, transforming words into a vast array of out-\\nputs, from articles, essays, and jokes, to job applications and \\npoetry. Its utility expanded across various sectors, aiding in draft-\\ning emails, writing code, creating written content, tutoring, \\ntranslating languages, and even simulating characters for video \\ngames. Its ability to generate human-like responses, coupled with \\nits versatility and precision, set it apart in the AI industry, making \\nit a vanguard of its time.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Propelled by the resounding success of ChatGPT , OpenAI \\nheld an enviable position in the AI industry, a first-mover advan-\\ntage that was not to be taken lightly. The substantial usage pro-\\nvided invaluable insights and feedback, instrumental in refining \\nand honing the chatbot’s responses.\\nHowever, the journey of ChatGPT was not without its share \\nof criticism. The potential for malicious use loomed large, with \\nconcerns over malware creation and phishing. The AI, in its'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='enormous capacity, also grappled with issues of potential copy-\\nright infringement, generating content that could be similar or \\nidentical to existing copyrighted material. Ethical concerns like \\nracism, sexism, and other biases also formed part of the discourse. \\nMoreover, the AI’s occasional inaccuracy, or “hallucinating,” led \\nto erroneous answers, including failures in basic math and logic \\nquestions.\\nY et, OpenAI’s resolve remained unshaken, grounded in its'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='mission to ensure that artificial general intelligence serves all of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 99\\nhumanity. It was a vision that acted as a beacon, illuminating the \\npath toward the development of more refined, responsible, and \\nbeneficial AI applications.\\nThis was clearly evident with the initial launch of ChatGPT . \\nWhile it wasn’t fully at the AGI level, the AI showcased  \\nan unprecedented level of complexity and understanding. It  \\nwas far from a simple mimic, merely echoing back predetermined \\nresponses.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='responses.\\nT ransitioning toward the more practical aspects of its design, \\nChatGPT demonstrated a conscientious approach. It was hard-\\nwired to abstain from generating inappropriate content, showcasing \\nOpenAI’s commitment to ethical AI development. Further more, \\nthe model was designed with a knowledge cutoff in September \\n2021, creating a well-defined boundary to its awareness of world \\nevents beyond this date.\\nThe power of ChatGPT was continually enhanced through'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='an iterative system of upgrades and improvements, fueled by user \\nfeedback. This is known as reinforcement learning from human \\nfeedback (RLHF).\\nReinforcement Learning from\\xa0Human Feedback\\nThe concept of RLHF unfolded as a significant milestone in the \\nsphere of AI development. This technique, which marries rein-\\nforcement learning with human feedback, is essentially used to \\ntrain a “reward model.” Launched by OpenAI in the early days of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='2020, it pioneered the use of human feedback to directly shape \\nthe reward function to optimize an agent’s policy using rein-\\nforcement learning. The approach involves a dynamic update of \\nthe model’s parameters based on the feedback received from \\nhumans, thus introducing a unique interactive element into the \\nlearning process.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='100 GENERATIVE AI\\nThis innovative approach found its applications in various \\ndomains of natural language processing, such as conversational \\nagents, text summarization, and natural language understanding, \\nmaking the process of AI communication more refined and effec-\\ntive. ChatGPT , an exemplar of this advanced technique, was fine-\\ntuned using a combination of supervised learning and RLHF . A \\ncohort of human trainers was actively involved, providing crucial'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='feedback on the model’s performance and ranking different model-\\ngenerated outputs based on their quality or correctness.\\nThis feedback was then transformed into a reward signal for \\nreinforcement learning, following which the model was fine-\\ntuned using proximal policy optimization (PPO) or similar algo-\\nrithms. PPO is an optimization technique used in reinforcement \\nlearning that helps to improve the policy (or decision-making \\nprocess) of an AI model while ensuring that the changes made'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='don’t deviate too much from the previous policy. This ensures a \\nbalance between exploration and exploitation, allowing the \\nmodel to learn effectively without taking undue risks.\\nThis unique feedback collection and refinement process, \\nwhich is repeated iteratively, stimulates continuous improvement \\nin ChatGPT’s performance. RLHF offers several advantages in \\nthe development of AI systems, including improved performance, \\nadaptability, reduced biases, continuous improvement, and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='enhanced safety. However, like any other process, it comes with its \\nown set of challenges, such as scalability, ambiguity and subjectiv-\\nity in human feedback, and long-term value alignment. There is a \\npotential for models to output harmful or factually inaccurate text \\nwithout any uncertainty. This puts into perspective the need for \\ncontinuous monitoring and refinement of such models to prevent \\nthe dissemination of misleading or harmful information. There is'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='a pressing need for further research to gain a better understanding \\nof RLHF , improve its performance, and address these hurdles.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 101\\nThis transformative approach is not limited to language mod-\\nels alone. It has also found applications in other areas, such as the \\ndevelopment of video game bots. Noteworthy examples of RLHF-\\ntrained language models include OpenAI’s ChatGPT and its pre-\\ndecessor InstructGPT , as well as DeepMind’s Sparrow. Sparrow, a \\nchatbot equipped with 70 billion trainable parameters, adheres to'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='the Chinchilla scaling laws and is trained accordingly. However, its \\napplication appears to be largely confined to the realm of videos, \\ngiven its closed source nature.\\nIn the grand scheme of things, RLHF has emerged as an out-\\nof-the-box approach in AI training that has proven pivotal in the \\ndevelopment of advanced LLMs. It is a testament to the impor -\\ntance of investing in further research and development of tech-\\nniques like RLHF to ensure the creation of AI systems that are'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='not only powerful but also aligned with human values and \\nexpectations.\\nEvaluation of\\xa0Large Language Models\\nThe evaluation of LLMs is a critical aspect of AI development. It \\nprovides a measure of the model’s performance, accuracy, and \\nreliability, which are essential for ensuring the quality of the AI’s \\noutput and its suitability for various applications.\\nLLMs can be assessed using benchmark datasets, which pro-\\nvide scores that serve as numerical indicators for comparison'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='across different models. However, it’s important to note that the \\nperformance of these models is often influenced by minor imple-\\nmentation details. Consequently, it can be challenging to expect \\nresults from one codebase to transfer directly to another.\\nT o address these issues, several approaches have been pro-\\nposed. EleutherAI, a nonprofit AI research lab known for its \\nwork on models like GPT-Neo and GPT-J, has introduced the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='102 GENERATIVE AI\\nLM Evaluation Harness. This unifying framework allows any \\ncausal language model to be tested on the same exact inputs and \\ncodebase. This not only provides a ground-truth location for \\nevaluating new LLMs but also saves practitioners time imple-\\nmenting few-shot evaluations repeatedly, ensuring that their \\nresults can be compared against.\\nAnother intriguing approach is the evaluation of LLMs with \\nLLMs. This method involves comparing and ranking the results'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='against a baseline or other LLMs, providing valuable insights \\ninto the relative strengths and weaknesses of each model.\\nPerplexity, a commonly used measure of a language model’s \\nperformance, is another approach. It gauges how well a model \\npredicts the contents of a dataset. In simple terms, a model with \\nlower perplexity has a higher likelihood of accurately predicting \\nthe dataset’s content, making it a valuable tool for evaluating  \\nLLMs.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='LLMs.\\nT ask-specific datasets and benchmarks have also been devel-\\noped to evaluate the capabilities of language models on more \\nspecific downstream tasks. These tests may evaluate a variety of \\ncapabilities, including general knowledge, common sense rea-\\nsoning, and mathematical problem-solving.\\nQuestion-answering datasets, which consist of pairs of  \\nquestions and correct answers, are another version of this. A \\nquestion-answering task is considered “open book” if the model’s'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='prompt includes text from which the expected answer can be \\nderived; otherwise, the task is considered “closed book,” and the \\nmodel must draw on knowledge retained during training.\\nT ext completion is another form of evaluation, where the \\nmodel selects the most likely word or sentence to complete a \\nprompt. Composite benchmarks, such as GLUE, SuperGLUE, \\nMMLU, BIG-bench, and HELM, combine a diversity of differ-\\nent evaluation datasets and tasks.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 103\\nThere are also adversarially constructed evaluations, which \\nfocus on particular problems on which extant language models \\nseem to have unusually poor performance compared to humans. \\nExamples include the T ruthfulQA dataset and the Swag and its \\nsuccessor, HellaSwag.\\nHowever, the rapid pace of improvement of LLMs presents \\nchallenges in evaluation. Due to the swift saturation of existing'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='benchmarks by state-of-the-art models, which often exceed the \\nperformance of human annotators, there is a continuous need to \\nreplace or augment the benchmark with more challenging tasks. \\nThis highlights the dynamic nature of AI development and the \\nneed for ongoing refinement in evaluation methods.\\nIt’s undeniable that the development of large AI models has \\nseeped into the strategic consciousness of numerous companies. \\nEntities such as Stanford, OpenAI, DeepMind, and Hugging Face'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='come to mind when contemplating organizations that are stead-\\nfast in their pursuit to comprehend, enhance, and detoxify LLMs. \\nThese strides are more than mere indications of the prowess of \\nthese entities; they signify promising leaps toward the responsible \\nusage of these potent tools. Some selected observations:\\n• Stanford University has reported that LLMs can generate \\nhigh-quality legal content and predict court decisions with \\nreasonable accuracy. They are committed to studying these'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='issues and developing guidelines for the responsible \\nuse of LLMs.\\n• OpenAI is actively working on techniques to make LLMs \\nrefuse inappropriate requests. They are also investing in \\nresearch aimed at reducing harmful and untruthful outputs \\nfrom these models.\\n• DeepMind has pointed out the limitations of current detoxi-\\nfication methods, such as the risk of overgeneralization and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='104 GENERATIVE AI\\nthe difficulty in defining what constitutes harmful content. \\nThey are committed to further research in this area to \\nimprove the safety and fairness of LLMs.\\n• Hugging Face employs a combination of crowd-sourcing \\nand expert review to assess the fairness and inclusivity of \\ntheir models. They are also in the process of developing \\ntools that would allow users to customize the behavior of \\ntheir models.\\n• The increasing capabilities of LLMs in various fields, includ-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ing science and law, suggest a future where these models \\ncould significantly accelerate research and development in \\nthese areas.\\n• The focus on benchmarking and evaluation methods indi-\\ncates a future where the performance and behavior of LLMs \\nare more transparent and accountable.\\nGPT-4\\nGPT-4, stepping up from the legacy of GPT-3.5, is a robust, \\nmultimodal model that surpasses previous versions in nearly \\nevery aspect. Its superior performance is undeniably impressive,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='but what truly sets it apart are the additional functionalities it \\nintroduces.\\nOne of the most striking features of GPT-4 is its creativity. \\nIt’s more creative and collaborative than ever before. Whether \\nit’s composing songs, writing screenplays, or learning a user’s \\nwriting style, GPT-4 can generate, edit, and iterate on creative \\nand technical writing tasks with a level of finesse that is truly \\nremarkable.\\nAnother significant advancement is in the area of extended'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='outputs and context inputs. GPT-4 is capable of accepting long \\ncontextual input information. It can handle up to 32,000 tokens, \\nwhich is roughly equivalent to 43,000\\xa0words, or about half of a'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 105\\n270-page book. This capability opens up a world of possibilities \\nfor more complex and nuanced interactions with the model.\\nMultimodality in AI and GPT-4’s Multimodal Advancement\\nIn the realm of AI, the term multimodal refers to models that can \\nprocess more than one type of input, such as text, images, audio, \\nand video. GPT-4 takes a significant leap in this direction by \\naccepting images as input and generating captions, classifica-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tions, and analyses with meticulous detail. See, for example,  \\nFigure\\xa02.26. The implications of this are profound, as it opens \\nup a new frontier for AI applications, from content moderation \\nand targeted advertising to more nuanced interactions with \\nAI models.\\nFIGURE\\xa02.26 The multimodal capabilities of GPT-4 allow it to compre-\\nhend the content of an image. Moreover, it possesses a sufficient \\nunderstanding of the world to recognize when the events depicted in'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='the image are out of the ordinary.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='106 GENERATIVE AI\\nThe idea of multimodality extends beyond text and images. \\nIt encompasses audio and video streams, and even data from \\ndevices measuring physiological parameters such as heart rate or \\nblood sugar levels. In essence, any mode of data could be relevant \\nto an AI model, depending on the use case. This multimodal \\ncapability can significantly enhance the capabilities and applica-\\ntions of AI models.\\nConsider a social media post, for instance. A multimodal AI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='could analyze both the text and images in the post to understand its \\ncontent more fully. This could be used in content moderation, sen-\\ntiment analysis, or targeted advertising. Similarly, in e-commerce, a \\nmultimodal AI could analyze both product descriptions and cus-\\ntomer reviews to make more accurate product recommendations.\\nThe potential applications are not limited to these examples. \\nIn healthcare, a multimodal AI could analyze both medical imag-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ing data and patient records to assist in diagnosis or treatment \\nplanning. In the realm of autonomous vehicles, a multimodal AI \\ncould process data from various sensors, such as cameras, radar, \\nand lidar, to navigate safely. The possibilities are vast, and the \\nopportunities for startups and companies are immense. The sky is \\nindeed the limit!\\nWhile the concept of multimodality is not new, OpenAI has \\nmanaged to make it work well, though there is still room for'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='improvement. Other notable contributions in this field include \\nthe Multimodal-CoT model with 738\\xa0million trainable parame-\\nters, released by Amazon Science in February 2023. This open \\nsource model garnered attention for its strong performance on \\nvarious multimodal tasks, incorporating both language (text) and \\nvision (images), for now, into a two-stage framework.\\nAmazon Science, a division of Amazon, is at the forefront of \\nresearch and innovation in various fields, including machine'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='learning, robotics, operations research, and cloud computing. \\nTheir goal is to apply cutting-edge scientific research to create'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 107\\nnew technologies, improve services, and enhance the customer \\nexperience. They have made significant strides in multimodal \\nresearch, as evidenced by their contributions.\\nIn one paper, Amazon Science trained a model that used vis-\\nual information to ground speech recognition in videos. The \\nmodel improved word error rate (WER) performance by up to \\n18 percent over subword prediction models, and incorporating'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='visual information further improved performance.8\\nIn another paper, they addressed the problem of learning \\nproduct similarity for real-world data from the Amazon catalog. \\nThe model used the image as the primary source of information, \\nwith the title helping the model focus on relevant regions in the \\nimage. The model achieved up to a 10 percent improvement in \\nprecision compared to state-of-the-art multimodal benchmarks \\nand effectively scaled across multiple product categories.9'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='The release of GPT-4, with its multimodal capabilities, is a \\nsignificant milestone. Although not the first to implement these \\nfeatures, OpenAI, much like Apple, has a knack for delivering \\noutstanding capabilities when they do. The demo of GPT-4\\xa0was \\nunparalleled, leveraging its unmatched text generation capabili-\\nties to set a new standard in the field of AI. This is just the begin-\\nning, and the future holds even more exciting possibilities.\\nEmergent Capabilities of GPT-4'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='The grand reveal of GPT-4\\xa0was more than a spectacle; it was a \\ntestament to a significant leap in AI capabilities. These capabili-\\nties, known as emergent abilities, were not explicitly programmed \\nbut surfaced during the training process. As we delve into the \\n8Georgios Paraskevopoulus et\\xa0al. “Multiresolution and Multimodal Speech Recognition with T ransformers,” \\nAmazon Science, 2020, www.amazon.science/publications/multiresolution- and- multimodal- speech- recognition-  \\nwith- transformers'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='with- transformers\\n9Nilotpal Das et\\xa0 al. “MAPS: Multimodal Attention for Product Similarity,” Amazon Science, 2022, www \\n.amazon.science/publications/maps- multimodal- attention- for- product- similarity'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='108 GENERATIVE AI\\nremarkable capabilities of GPT-4, let’s first explore the concept \\nof emergent abilities, a pivotal element in our journey toward \\nartificial general intelligence (AGI).\\nEmergent abilities in AI are like unexpected gifts. They are \\nskills or capabilities that aren’t directly coded into the system but \\nemerge, almost magically, as the system learns and processes \\ninformation. These abilities surface as the large language models'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='(LLMs) are scaled up, without any specific training or architec-\\ntural modifications for these tasks. They appear in rapid and \\nunpredictable ways, demonstrating the power of LLMs to learn \\nand adapt simply by observing natural language, and visual input \\nin some cases.\\nThese abilities are the result of the system’s capacity to com-\\nbine and extrapolate from simpler learned behaviors or rules, \\nwhich it has gleaned from the data it was trained on. Essentially,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='emergent abilities are unexpected skills that the system develops \\norganically through its learning process.\\nExamples of these abilities are diverse and impressive. They \\ninclude answering questions, summarizing passages, guessing a \\nmovie from an emoji sequence, and performing multistep rea-\\nsoning. LLMs can also understand the sentiment or emotion \\nconveyed in a piece of text, generate original stories, screenplays, \\nor even poetry, and check the veracity of a statement by cross-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='referencing it with the information they were trained on. Other \\nnotable abilities include advanced empathy modeling, real-time \\ntranslation, cultural understanding, ethical decision-making \\nguidance, historical analysis, and performing arithmetic.\\nOpenAI tested GPT-4’s capabilities using simulated real-\\nworld exams. The model’s performance on various benchmarks, \\nincluding exams designed for humans, was nothing short of \\nastounding. It’s important to note that GPT-4\\xa0wasn’t specifically'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='trained for these exams. It had only seen a minority of the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 109\\nproblems during training. Y et, the results were representative, \\nand they were impressive.\\nFor instance, GPT-4 didn’t just pass the notoriously complex \\nUniform\\xa0Bar Exam; it scored in the top\\xa010 percent of test takers. \\nSimilarly, it exceeded the passing score on the United States \\nMedical Licensing Examination (USMLE) by over 20 points, \\noutperforming not only earlier general-purpose models but also'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='models specifically fine-tuned on medical knowledge. In the \\nrealm of mathematics, GPT-4 scored a 4 out of 5 on the Advanced \\nPlacement Calculus BC exam, a significant improvement over \\nChatGPT’s (GPT-3.5) score of 1 (see Figure\\xa02.27).\\nHowever, GPT-4’s performance was not flawless. It strug-\\ngled with the advanced LeetCode exam, a test that prepares \\ndevelopers for technical interviews, especially for those aiming \\nFIGURE\\xa02.27 GPT-4 of simulated exams. Additional visual information'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='helps the model to perform better on the exams.\\nSource: OpenAI / https://openai.com/research/gpt-4.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='110 GENERATIVE AI\\nto join the ranks of the MAANG (Meta, Amazon, Apple, Netflix, \\nGoogle). This serves as a reminder that while AI has come a long \\nway, there are still areas where it struggles.\\nInterestingly, one such area is abstract creativity. Despite its \\nremarkable capabilities, GPT-4\\xa0has been noted to be “incapable \\nof abstract creativity.” This suggests that there are still facets of \\nhuman intelligence where we outshine our AI counterparts. It’s a'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='humbling reminder that while we continue to push the bounda-\\nries of AI, there’s still much to learn and explore.\\nGPT-4 also exhibits steerability, the ability to change its per-\\nsonality and behavior based on user prompts (Figure\\xa02.28). This \\nallows for a more personalized and engaging interaction. Rather \\nthan the classic ChatGPT personality with a fixed verbosity, \\ntone, and style, you can now prescribe their AI’s style and task by \\ndescribing those directions in the “system” message.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='These system messages, along with contextual information \\nand other parameters like a goal, tone, and so forth, are opening \\nup new marketplaces where people can buy and sell effective \\nprompts, prompt patterns, and meta prompts. This is an exciting \\ndevelopment, as it opens up a whole new world of possibilities \\nfor customization and personalization of AI systems. It’s like hav-\\ning your own personal AI assistant that can be tailored to your'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='specific needs and preferences. The future of AI is not just about \\nmore powerful models, but also about more personalized and \\nuser-friendly experiences.\\nOther Large Models and Specific Models\\nThe year 2023\\xa0marked a significant surge in the number of capable \\nAI models. Companies such as Berkeley, Stability AI, EleutherAI, \\nT ogether, Microsoft, and NVIDIA, to name a few, unveiled their \\nmodels. Each of these models was designed with a specific objective'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='in mind, from providing medical reasoning to supporting coding.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 111\\nThese models, both small and large, have demonstrated their value \\nin various ways. T o illustrate this, consider Stanford’s Alpaca and \\nBloombergGPT .\\nStanford’s Alpaca is a fascinating example of an instruction-\\nfollowing language model. It was fine-tuned from Meta’s LLaMA \\n7B model, which itself was trained on 52,000 instruction-  \\nfollowing demonstrations generated using OpenAI’s GPT-3.5.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='This process of one model fine-tuning another exemplifies the \\npotential of diverse data sources in AI development.\\nFIGURE\\xa02.28 Steerability example of GPT-4 as a Socratic tutor.\\nSource: OpenAI / https://openai.com/research/gpt-4.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='112 GENERATIVE AI\\nThe instruction-following demonstrations were generated \\nusing the self-instruct method. This involved using 175 human-\\nwritten instruction-output pairs from the self-instruct seed set. \\nIn simpler terms, this means that the model was trained using a \\nset of instructions and their corresponding outputs, which were \\nprovided by humans. This method allowed the model to learn \\nhow to follow instructions and generate appropriate outputs.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='One of the most striking aspects of Alpaca is its cost- \\neffectiveness. The generation pipeline was simplified, and the \\ncost was significantly reduced. This resulted in 52,000 unique \\ninstructions and corresponding outputs, costing less than $500 \\nusing the OpenAI API. Fine-tuning a LLaMA 7B model took \\nonly threes hours on eight 80\\xa0GB A100s, costing less than $100 \\non most cloud compute providers. Figure\\xa02.29 shows the Alpaca \\nmodel development process.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Despite its size, Alpaca exhibits many behaviors similar to \\nthose of OpenAI’s GPT-3.5, making it surprisingly powerful and \\nLLaMA 7BText-davinci-003\\n175 Self-\\nInstruct\\nseed tasks\\nModified Self-instruct\\nInstruction Generation\\nSupervised\\nFinetuning \\nInstruction: Brainstorm a list of\\npossible NewYear’s resolutions.\\nOutput:\\n- Lose weight\\n- Exercise more\\n- Eat healthier \\nAlpaca 7B 52K\\nInstruction-following\\nexamples \\nExample seed task\\nInstruction: Brainstorm creative\\nideas for designing a conference'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='room.\\nOutput:\\ncomponents, such as moveable\\n... incorporating flexible\\nwalls and furniture ...\\nExample Generated task\\nFIGURE\\xa02.29 The Alpaca model development process: starting with a \\nseed set of human-written instructions, expanding it using text-\\ndavinci-003, and fine-tuning the LLaMA models using Hugging Face’s \\ntraining framework.\\nSource: https://crfm.stanford.edu/2023/03/13/alpaca.html. (a) OpenAI and (b) Meta.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 113\\neasy to reproduce. However, it still exhibits some of the classic \\nlimitations of instruction-following models, such as toxicity, hal-\\nlucinations, or stereotypes.\\nThe researchers behind Alpaca believe that releasing the train-\\ning recipe, data, model weights, and training code incurs minimal \\nfurther risk, given the simplicity of the recipe. They see this as a \\nsignificant step toward reproducible science. However, it’s impor-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tant to note that Alpaca is intended only for academic research, \\nand any commercial use is prohibited.\\nMoving on to BloombergGPT , this model was developed by \\nBloomberg and has been specifically trained on a wide range of \\nfinancial data. It is a 50 billion-parameter LLM that is purpose-\\nbuilt from scratch for finance. BloombergGPT can evaluate \\nfinancial data in real time, including market data, breaking news, \\nfinancial research, and advanced analytics. It can perform tasks'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='such as sentiment analysis, news classification, and question-\\nanswering, among others.\\nBloombergGPT is designed to enhance Bloomberg’s current \\nfinancial NLP capabilities and open up fresh possibilities for \\norganizing the enormous amounts of data available on the \\nBloomberg T erminal. For those unfamiliar, the Bloomberg T er-\\nminal is a computer software system provided by Bloomberg L.P . \\nthat enables professionals in finance and other industries to'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='access Bloomberg’s professional services, including real-time \\nfinancial data, news feeds, and messages, and also to place trades.\\nThe model is trained on Bloomberg’s extensive archive of \\nfinancial data, which has been meticulously collected and curated \\nover 40 years. This makes BloombergGPT unique as it is trained \\non highly specific financial data, which is expected to make it \\nmore effective for financial NLP tasks. However, Bloomberg-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='GPT is only accessible within Bloomberg and will be used to \\nprocess large amounts of data on Bloomberg T erminal.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='114 GENERATIVE AI\\nThe release of BloombergGPT is part of a trend of companies \\ndeveloping their own LLMs, tailored to their specific needs and \\ndata. This trend is not just a passing fad, but a significant shift in \\nthe AI landscape. Many companies have already announced their \\ninterest in following suit, indicating that the future of AI is not just \\nabout more powerful models, but also about more personalized \\nand user-friendly experiences.\\nApplications of\\xa0Specific Language Models'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Let’s consider a few more sectors where these models could be \\nand in fact are leveraged to great effect.\\nIn the realm of healthcare, hospitals and healthcare providers \\ncould develop a language model trained on medical literature \\nand patient data (while respecting privacy laws) to assist doctors \\nin diagnosing diseases or suggesting treatments. Imagine a  \\n“MayoClinicGPT” that could interpret patient symptoms and \\nmedical history, suggest potential diagnoses, and even generate'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='patient-friendly explanations of complex medical conditions. \\nThis is not a far-fetched idea. K Health, for instance, has devel-\\noped an AI-driven platform that uses anonymized health data to \\nprovide personalized medical information.\\nIn the legal sector, law firms might create a language model \\ntrained on legal texts and case law to assist in legal research or \\ndrafting legal documents. A “LegalGPT” could help lawyers to \\nquickly find relevant case law, draft legal documents, and even'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='predict the outcome of legal cases based on historical data. Har-\\nvey AI, a UK-based company, has developed an AI model for the \\nlegal sector that uses AI to automate legal processes, making it \\neasier for lawyers to manage their workloads and focus on more \\ncomplex tasks, utilizing their core competencies.\\nEducation is another sector ripe for AI intervention. Educa-\\ntional institutions or e-learning platforms could create a language \\nmodel trained on educational content to provide personalized'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 115\\nlearning experiences. Khan Academy, for instance, has partnered \\nwith OpenAI to create an AI model for education. This model, \\n“Khanmigo,” is designed to provide personalized learning experi-\\nences, making education more accessible and effective.\\nIn the retail sector, e-commerce companies might develop a \\nlanguage model trained on product descriptions and customer \\nreviews to improve product recommendations or customer ser -'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='vice. An “AmazonGPT” could be used to generate accurate prod-\\nuct recommendations, answer customer queries, and even predict \\nfuture shopping trends.\\nInsurance companies could develop a language model trained \\non insurance claims and policy data to streamline the claims pro-\\ncess and provide personalized policy recommendations. For exam-\\nple, a “StateFarmGPT” could be used to interpret insurance \\nclaims, suggest policy adjustments, and even generate customer-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='friendly explanations of complex insurance terms. MetLife, for \\ninstance, is using AI to streamline the claims process and provide \\npersonalized policy recommendations.\\nIn the real estate sector, firms might create a language model \\ntrained on property listings and market data to assist in property \\nvaluation or predicting market trends. A “ZillowGPT” could \\nhelp real estate agents to quickly find comparable properties, \\nestimate property values, and even predict future real estate mar-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ket trends. Skyline AI, a real estate investment technology com-\\npany, uses AI to enhance the property investment process.\\nT ravel agencies and hospitality companies could develop a \\nlanguage model trained on travel guides and customer reviews to \\nprovide personalized travel recommendations. Allora, a travel \\ntechnology company, has developed an AI-driven platform for \\nthe hospitality industry that uses customer reviews and travel \\nguides to provide personalized travel recommendations.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='In the media and entertainment sector, companies could cre-\\nate a language model trained on scripts, reviews, and audience \\ndata to assist in content creation and audience targeting. A'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='116 GENERATIVE AI\\n“NetflixGPT” could be used to suggest plot ideas, predict audi-\\nence preferences, and even generate promotional content.\\nConsider the telecommunications sector. Here, AI models \\ncould be a game changer. Imagine a “VerizonGPT ,” trained on \\nnetwork data and customer feedback, working tirelessly to \\nenhance network performance and customer service. It could \\npredict network issues before they occur, suggest improvements,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='and even demystify complex telecom terms for customers. This \\nisn’t just speculation— McKinsey reports that AI is already trans-\\nforming telco service operations, with models predicting net-\\nwork issues, recommending improvements, and simplifying \\ncomplex telecom jargon.\\nIn the energy sector, companies might develop a language \\nmodel trained on energy usage data and research to improve \\nenergy efficiency and develop new energy solutions. An “Exxon-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='MobilGPT” could be used to analyze energy usage trends, sug-\\ngest energy-saving measures, and even predict future energy  \\ntrends.\\nThink food and beverages, and imagine the transformative \\npower of AI. Envision a “CocaColaGPT ,” an AI model trained \\non a rich blend of recipe data and customer reviews. It’s stirring \\nup new beverage ideas, responding to customer queries with \\nease, and even forecasting the next big trends in food and bever-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ages. This isn’t a futuristic dream— it’s already happening. For \\nexample, McCormick & Company is using AI to create an excit-\\ning array of new flavors and food products.\\nPharmaceutical companies could develop a language model \\ntrained on medical research and clinical trial data to assist in drug \\ndiscovery and development. A “PfizerGPT” could be used to \\ninterpret research findings, suggest potential drug candidates, \\nand even generate patient-friendly explanations of complex'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='medical research.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Innovative Approaches for\\xa0High-Quality Data Generation 117\\nPicture the aerospace industry, where AI could take flight in \\na big way. Companies could harness a language model like, for \\nexample, “SpaceXGPT ,” trained on aerospace engineering data \\nand research, to turbocharge the design and development of air-\\ncraft and spacecraft. This AI co-pilot could assist engineers in \\nswiftly locating pertinent research, sparking innovative design'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ideas, and even forecasting the trajectory of aerospace projects \\nbased on historical data.\\nThe potential for AI model applications across industries is \\ninfinite. Y et, it’s worth noting that some of the strategies I’ve dis-\\ncussed are already being implemented by ChatGPT plug-ins. \\nWe can anticipate not just a tenfold increase in productivity, but \\nalso a tenfold enhancement in experience. The horizon of AI \\nholds promise for even more thrilling advancements in the \\nyears to come.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='119\\nT\\nhis chapter offers a concise exploration of generative AI’s \\ndiverse applications, highlighting how the technology is \\nreshaping industries from music to 3D object generation. The \\nconcept of “finding the untapped” is an observed strategy for \\nuncovering and leveraging gen AI’s vast potential.\\nFoundational and Specialized AI Models, and \\nthe Question of Open Source vs. Closed Source\\nJust as the Internet has become a fundamental part of the opera-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tions of most companies, we are witnessing a similar transition \\nwith AI. We are still in the early stages of this transition, and \\nthere is a vast landscape of opportunities for those venturing into \\n3\\nCHAPTER\\nGenerative AI’s Broad \\n Spectrum of Applications'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='120 GENERATIVE AI\\nthis field and making progress in it. Established companies like \\nIBM and Microsoft have shifted their focus to AI over time, and \\nnew companies and startups are emerging with AI at the core of \\ntheir products. For instance, Rain Neuromorphics is building \\nartificial brains to make AI radically cheaper, aiming to enable \\nubiquitous advanced AI and power fully autonomous artificial \\ngeneral intelligence (AGI). Allganize, on the other hand, is revo-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='lutionizing enterprise productivity with its AI document under -\\nstanding platform, Alli. Adept is building an ML model that can \\ninteract with everything on your computer, aiming to build an AI \\nteammate for everyone.\\nThe direction is clear: an AI-driven future, not only in indus-\\ntry but also in society. There is, however, another important \\nobservation to make. We can roughly separate AI adoption into \\ntwo waves, or shock waves, looking at the pace of it. The first'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='wave consists of model-maker companies, and the second wave \\nconsists of startups and companies with innovative approaches \\nthat use the models of the model-makers to build niche products. \\nThese companies, perhaps already niche somewhere, are paving \\nthe way for society to experience the power of AI.\\nFirst Wave of the Generative AI Adoption: Model-Makers\\nThe first wave of AI adoption is characterized by the rise of \\nmodel-maker companies. These are exceptional companies with'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='exceptional talent. They require substantial funding, as training \\nAI models can cost millions, and they need the knowledge to \\nbuild these models. Interestingly, these model-maker companies \\noften don’t have large teams of thousands of engineers and com-\\nputer scientists. Instead, they tend to operate with smaller, more \\nfocused, and highly talented teams. This approach seems to fos-\\nter innovation and efficiency, allowing these companies to make'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='significant strides in AI development with a lean team structure.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 121\\nOpenAI, for instance, has raised more than $11 billion in \\nfunding over four rounds. Most of this funding is used for train-\\ning their models. Despite having a relatively small team of \\nroughly 375 employees, they have achieved significantly more \\nthan companies with thousands of research scientists. This still is \\na mystery to me. Y es, they have a few hundred contractors, but \\nthe core team and capabilities are within OpenAI. They have'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='been pioneering research on the path to AGI and transforming \\nwork and creativity with AI. They have introduced products like \\nthe ChatGPT app for iOS or plug-ins for ChatGPT and are \\ncontinuously making strides in AI research and safety.\\nAnthropic AI In the midst of the COVID pandemic in 2021, a \\nnew player emerged on the AI scene. Anthropic, founded by for-\\nmer senior members of OpenAI, including siblings Daniela \\nAmodei and Dario Amodei (who served as OpenAI’s vice presi-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='dent of research), burst onto the scene with a clear and compel-\\nling mission. They aimed to build large-scale AI systems that are \\nsteerable, interpretable, and robust.\\nAnthropic, a company that started from scratch, has raised \\na staggering $1.5 billion in funding, catapulting it to a valuation \\nof almost $5 billion. This meteoric rise is a testament to the \\ntransformative potential of AI and the faith investors have in \\nAnthropic’s vision and capabilities. As you might expect, they'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='are now in a phase of rapid expansion, hiring talent to join their \\n“small but growing” team.\\nAnthropic’s focus is on AI safety and alignment with human \\nvalues, a crucial aspect of AI development that cannot be over -\\nstated. They envision a future where AI’s impact could be on par \\nwith the industrial and scientific revolutions, a future where rapid \\nAI progress leads to transformative AI systems. T o prepare for \\nthis future, they are pursuing a variety of research directions,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='122 GENERATIVE AI\\nall aimed at better understanding, evaluating, and aligning \\nAI systems.\\nTheir approach is empirical, heavily relying on evidence and \\nreal-world observations. This grounded approach allows them to \\nnavigate the complex landscape of AI development with a clear \\nvision and a firm grasp on reality. What sets them apart is their \\nunique approach to AI safety research. They take a “portfolio \\napproach,” preparing for a wide range of scenarios, from the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='most optimistic to the most pessimistic, regarding the safety and \\ncontrol of advanced AI systems.\\nAnthropic’s unique approach to ensuring AI safety is a topic \\nwe’ll revisit in a later chapter, specifically when we explore the \\nethical side of generative AI. Their story is representative of the \\nexciting and dynamic nature of the AI field, where new players \\ncan emerge and make significant strides in a short span of time.\\nGoogle DeepMind In the dynamic landscape of AI, Google'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='DeepMind stands as a beacon of innovation. Acquired by Google \\nin 2014 for a staggering $500\\xa0 million dollars, DeepMind has \\ngrown into a powerhouse of AI development. The acquisition, \\nfor which Facebook had initially been in negotiations, has proven \\nto be a lucrative deal for Google, as DeepMind has been at the \\nforefront of numerous groundbreaking advancements in the \\nfield of AI.\\nDeepMind’s prowess lies in its innovative approach to AI, par-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ticularly in the areas of deep learning and reinforcement learning. \\nThe company has developed AI systems capable of learning and \\nmastering complex tasks autonomously, demonstrating its com-\\nmitment to creating systems that can adapt and evolve.\\nHowever, the achievement that truly shook the world of AI \\nwas Google’s AlphaGo’s historic victory over Go champion Lee'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 123\\nSedol. This victory was significant because Go had previously \\nbeen regarded as a hard problem in machine learning that was \\nexpected to be out of reach for the technology of the time. Alpha-\\nGo’s victory not only demonstrated the capabilities of AI but also \\nmarked a turning point in the perception of AI’s potential.\\nDeepMind’s mission is to “solve intelligence” and create AGI, \\na type of AI that can understand, learn, and apply its knowledge'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='to a wide variety of tasks, much like a human brain. Their \\napproach is unique in that it focuses on creating systems that can \\nlearn and adapt autonomously. They combine two promising \\nareas of research— deep neural networks and reinforcement \\nlearning algorithms— to create AI systems that can apply their \\nlearning from one domain to a new domain.\\nOne of DeepMind’s most significant achievements is Alpha-\\nFold, an AI system that has been recognized as a solution to the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='50-year-old grand challenge in biology known as the protein- \\nfolding problem. This breakthrough demonstrates the impact AI \\ncan have on scientific discovery and its potential to dramatically \\naccelerate progress in some of the most fundamental fields that \\nexplain and shape our world.\\nSecond Wave of AI Adoption: AI Model Wrapper Companies\\nAs we delve deeper into the realm of AI, we encounter a diverse \\narray of entities known as model-makers. These are the master -'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='minds behind large-scale machine learning models trained on a \\nbroad spectrum of Internet data. These models serve as a base— a \\nfoundation, if you will— for myriad downstream tasks. Their \\nsize and the vastness of their training data endow them with a \\ngeneral understanding of human language, making them incred-\\nibly versatile and useful across a multitude of applications.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='124 GENERATIVE AI\\nModel-making powerhouses include Facebook AI Research \\n(FAIR), Baidu Research, NVIDIA AI Research, and Stability AI, \\nin addition to the previously mentioned OpenAI, Anthropic, and \\nGoogle DeepMind. Each organization has made significant \\nstrides in the development and application of foundation models. \\nAdept AI, a company with a keen focus on crafting useful general \\nintelligence, also stands out in this field. Even conglomerates like'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='LG from Korea have dedicated research departments working \\non these models. The list is extensive and continues to grow, \\nreflecting the increasing importance and influence of foundation \\nmodels in the field of AI.\\nThe second wave of the generative AI impact has given rise \\nto a multitude of startups and a handful of established compa-\\nnies. They harness the power of foundation models to tailor \\nsolutions to specific needs, as indicated in Figure\\xa03.1. The ripple'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='effects of this wave are far-reaching and diverse. Advancements \\nin text generation have revolutionized copywriting, customer \\nrelations, knowledge, and research. In the realm of audio, we’ve \\nseen innovations in music generation, speech generation, and \\nother sounds. Image generation has seen significant strides in \\ninfluencing design and marketing. Code generation and devel-\\nopment applications have also seen advancements. Video genera-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tion, synthetic data generation, and even the gaming and design \\nindustry have been revolutionized with the creation of 3D assets \\nand worlds, characters, and NPCs. Legal, tax advisory, and health \\nsolutions have also been influenced. AI model management has \\nseen advancements in fine-tuning, prompt management, and \\ndesigning, optimization, monitoring, and storage.\\nBetween March and May 2023, thousands of companies were \\nfounded. The first wave of generative AI was fundamentally'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='important, and the second wave is equally crucial in capturing \\nthat value. Goldman Sachs suggests that generative AI could \\ndrive a 7 percent (or almost $7 trillion) increase in global GDP'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 125\\nover 10 years. Other research estimates that the global artificial \\nintelligence market, which includes generative AI, is expected to \\nreach $1,811.75 billion by 2030, expanding at a compound annual \\ngrowth rate (CAGR)— a measure of the average yearly growth \\nrate over a specified period— of 37.3 percent from 2023 to 2030. \\nThe generative AI market\\xa0alone is expected to reach $38.8 bil-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='lion by 2026. While different sources suggest different figures,  \\nI am much more optimistic, as I anticipate a tenfold increase  \\nin productivity, after some adoption, and hopefully a diminished \\nreluctance to use it.\\nMicrosoft’s AI Dominance\\nWhile the primary aim of this chapter is to explore the expansive \\npanorama of generative AI and its far-reaching implications, \\nwe’ll momentarily pause our examination of the application \\nData\\nText\\nImages\\nSpeech\\nStructured\\nData\\n3D Signals'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Data\\n3D Signals\\nTraining Foundation\\nModel\\nAdaptation\\nTasks\\nQuestion\\n Answering\\nSentiment\\n   Analysis\\nInformation\\nExtraction\\nImage\\nCaptioning\\nObject\\nRecognition\\nInstruction\\nFollowing\\nFIGURE\\xa03.1 From foundation models to serving specific tasks.\\nSource: “On the Opportunities and Risks of Foundation Models,” Stanford University'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='126 GENERATIVE AI\\nfields and their innovative approaches. There’s an undercurrent, \\na less apparent yet significant power struggle, that merits our \\nattention. It’s the clash of titans: Microsoft versus Google. This \\nconfrontation is worth noting as we stand at a pivotal juncture, a \\nmoment that will determine who will seize the reins of global AI \\ndominance.\\nMicrosoft has been making strategic moves to assert its lead-\\nership in the global AI landscape. One of their notable initiatives'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='is that they have ramped up their efforts in the development and \\ndeployment of specialized supercomputing systems. These sys-\\ntems are designed to accelerate OpenAI’s groundbreaking inde-\\npendent AI research, and they also continue to enhance Azure’s \\nleading AI infrastructure to aid customers in building and deploy-\\ning their AI applications on a global scale.\\nAnother significant step taken by Microsoft is their partner -\\nship with OpenAI. Initially investing in OpenAI, Microsoft has'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='extended its partnership through a multiyear, multibillion-dollar \\ninvestment. This partnership aims to accelerate AI breakthroughs \\nand ensure these benefits are broadly shared with the world. The \\nagreement extends their ongoing collaboration across AI super -\\ncomputing and research and enables both parties to indepen-\\ndently commercialize the resulting advanced AI technologies.\\nMicrosoft has also been deploying OpenAI’s models across'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='its consumer and enterprise products and introduced new cate-\\ngories of digital experiences built on OpenAI’s technology. This \\nincludes Microsoft’s Azure OpenAI Service, which empowers \\ndevelopers to build cutting-edge AI applications through direct \\naccess to OpenAI models backed by Azure’s trusted, enterprise-\\ngrade capabilities and AI-optimized infrastructure and tools.\\nAs OpenAI’s exclusive cloud provider, Azure powers all  \\nOpenAI workloads across research, products, and API services.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='This exclusive partnership has been a strategic move for'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 127\\nMicrosoft, reinforcing its commitment to AI and its position as a \\nglobal leader in the field.\\nIn a significant development, OpenAI’s GPT-4 technology, \\nwhich was designed to be the underlying engine that powers \\nchatbots and all sorts of other systems, has been integrated into \\nMicrosoft’s Bing search engine. This integration showcases the \\npractical application of advanced AI technologies in everyday \\ndigital experiences.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Google’s AI Dominance\\nGoogle, from its inception, has been a beacon of AI innovation. \\nHowever, Microsoft’s strides with OpenAI have started to chal-\\nlenge this position significantly. In response, Google has been \\nfocusing on building an answer to ChatGPT . Let’s examine the \\nsteps Google has taken to maintain its position in this competi-\\ntive landscape.\\nGoogle Cloud offers a suite of AI and machine learning (ML) \\nservices that businesses can use to build, deploy, and scale AI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='models. These services include Atoll, AI Platform, and AI Build-\\ning Blocks. Google Cloud also provides industry-specific AI \\nsolutions, such as Contact Center AI and Document AI.\\nGoogle’s 2014 acquisition of DeepMind, a leading AI research \\nlab, has led to significant advancements in AI research and devel-\\nopment. More recently, Google acquired Anthropic AI, a startup \\nfocused on building large-scale models that are understandable'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='and interpretable. This acquisition further strengthens Google’s \\nAI capabilities.\\nIn an effort to consolidate its AI research and development \\nefforts, Google merged its two main AI research groups, Google \\nBrain and DeepMind. This strategic move has streamlined \\nGoogle’s AI research, allowing for more focused and efficient \\ndevelopment.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='128 GENERATIVE AI\\nGoogle announced an ambitious project to develop a single \\nAI language model that supports the world’s “1,000\\xa0most spoken \\nlanguages.” This initiative aims to bring various AI functionali-\\nties to languages that are poorly represented in online spaces and \\nAI training datasets, thereby promoting inclusivity and diver -\\nsity in AI.\\nGoogle has also developed Bard, a conversational generative \\nAI chatbot, as a direct response to the rise of OpenAI’s Chat-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='GPT . Bard, initially based on the LaMDA family of large lan-\\nguage models (LLMs) and later on PaLM, an LLM also developed \\nby Google, was released in a limited capacity in March 2023.\\nGoogle’s Bard In the wake of OpenAI’s ChatGPT , Google \\nintroduced Bard, a conversational AI chatbot. Bard was initially \\nbuilt on the LaMDA family of LLMs but was later upgraded to \\nthe more powerful PaLM LLM. The development of Bard was \\na reaction to the success of ChatGPT , which had gained world-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='wide attention and was seen as a potential threat to Google \\nSearch. This led to emergency meetings involving Google  \\nco-founders Larry Page and Sergey Brin, where they discussed \\nGoogle’s response to ChatGPT .\\nBefore Bard, Google had already developed LaMDA, a pro-\\ntotype LLM. However, it had not been released to the public due \\nto concerns about reputational risk. In January 2023, Google \\nemployees were instructed to accelerate progress on a ChatGPT'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='competitor, intensively testing “Apprentice Bard” and other \\nchatbots. Bard was announced on February 6, 2023, and was first \\nrolled out to a select group of 10,000 “trusted testers,” who rig-\\norously tested its capabilities.\\nThe technology was developed under the codename “Atlas,” \\nwith the name “Bard” chosen to reflect the creative nature of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 129\\nthe algorithm. The announcement of Bard was seen as a \\nresponse to Microsoft’s planned event to unveil its partnership \\nwith OpenAI to integrate ChatGPT into its Bing search engine. \\nHowever, after a poorly received livestream showcasing Bard, \\nGoogle’s stock fell 8 percent, equivalent to a $100 billion loss in \\nmarket value.\\nDespite criticism from Google employees and concerns \\nabout safety and ethics, Google executives decided to proceed'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='with the launch of Bard. Bard was launched as a stand-alone web \\napplication, with users prompted to submit feedback on the use-\\nfulness of each answer. However, the launch was not without \\ncontroversy. Google researcher Jacob Devlin resigned from the \\ncompany after claiming that Bard had surreptitiously leveraged \\ndata from ChatGPT , an allegation that Google denied.\\nBard was later upgraded to be based on PaLM, a newer and \\nmore powerful LLM from Google, and gained the ability to assist'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='in coding. The Pathways Language Model (PaLM), a 540 billion–\\nparameter, densely activated T ransformer language model, was \\ntrained on 6144 TPU v4 chips using Pathways, a new ML system \\nthat enables highly efficient training across multiple TPU Pods. \\nGoogle custom-developed its own tensor processing units \\n(TPUs), which are application-specific integrated circuits (ASICs) \\nused to accelerate ML workloads. TPUs are designed to handle'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='massive matrix operations used in neural networks at fast speeds.\\nPaLM surpassed average human performance on the BIG-\\nbench benchmark, a collaborative benchmark openly developed \\nby GitHub that was intended to probe LLMs and extrapolate \\ntheir future capabilities. BIG-bench includes more than 200 \\ntasks summarized by keyword and task name. PaLM showed \\nstrong results on tasks such as logical inference.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='130 GENERATIVE AI\\nPaLM is part of Google’s vision to enable a single AI system \\nto generalize across thousands or millions of tasks, to understand \\ndifferent types of data, and to do so with remarkable efficiency. It \\nhas set new state-of-the-art records on English-only natural lan-\\nguage processing (NLP) tasks and competitive performance on \\nmultilingual tasks. The team behind PaLM has noted areas for \\nimprovement, such as the model being too large for its compute'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='budget and the fact that encoder-decoder models fine-tune better.\\nGoogle is working to integrate Bard into its ChromeOS \\noperating system and Pixel devices. Bard received mixed reviews \\nupon its initial release, with some critics finding it faster than \\nChatGPT and Bing, but others criticizing its uninteresting and \\nsometimes inaccurate responses. Despite these criticisms, Google \\ncontinues to improve Bard, with recent updates adding improved \\nmath and logic capabilities.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='The journey of Bard has been a rollercoaster ride, with its \\nshare of highs and lows. From its inception as a response to \\nChatGPT to the controversies surrounding its launch and the \\nsubsequent improvements and upgrades, Bard has been a testa-\\nment to Google’s commitment to advancing AI technology. \\nDespite the initial setbacks, Google has continued to refine and \\nenhance Bard, demonstrating its dedication to creating a chatbot \\nthat can effectively interact with and assist users.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='The development of Bard and PaLM also highlights Google’s \\nefforts to promote inclusivity and diversity in AI. Despite the exist-\\nence of over 7,000\\xa0languages worldwide, the Internet represents \\nonly a fraction of these. Google Search supports 348\\xa0languages, \\nFacebook recognizes 120, and LinkedIn only 24. This disparity \\ncreates a barrier to information access for many people, not only \\ndue to a lack of technology but also because their language is'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='underrepresented online. Google’s Bard and PaLM, part of a'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 131\\nproject to support the world’s “1,000\\xa0most spoken languages,” aim \\nto address this issue, promoting inclusivity and diversity in AI. \\nThis endeavor could significantly contribute to making the Inter-\\nnet a more inclusive space.\\nChatGPT vs. Bard Performance\\nThe intense competition between Google’s Bard and OpenAI’s \\nChatGPT has sparked much debate. Each chatbot possesses dis-\\ntinct strengths and weaknesses, and their performance fluctuates'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='depending on the task at hand.\\nWhen it comes to summarizing long-form content, Chat-\\nGPT has an edge over Bard. It provides a more detailed sum-\\nmary, whereas Bard’s summary tends to be terse and conveys less \\ninformation. In the realm of coding, both models have their \\nshortcomings. However, ChatGPT has shown a quicker ability \\nto iterate to a correct version of a Python function. As for craft-\\ning a customized tweet, both models perform adequately, but'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ChatGPT’s response tends to exceed the character limit, neces-\\nsitating edits.\\nIn terms of mimicking natural language and facilitating open-\\nended conversations, Bard outshines ChatGPT . Bard’s responses \\nare designed to be ultra-authentic, mimicking human speech. \\nHowever, some responses have been found to be less than authen-\\ntic, indicating room for improvement. One of Bard’s significant \\nadvantages is its capability to draw responses from the Internet in'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='real time, while ChatGPT relies on a dataset that only goes up \\nuntil late 2021. This changes if one is enabled to use plug-ins or \\nthe ChatGPT Browser, which is gradually being released to \\nthe public.\\nWhen it comes to user-friendliness and interface, Bard takes \\nthe lead with a more visually appealing interface and formatted'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='132 GENERATIVE AI\\ntext that’s easier to scan. It also allows users to edit their ques-\\ntions after they ask them, enhancing the user experience. How-\\never, in the area of text processing, such as summarization and \\nparagraph writing, ChatGPT outperforms Bard, making it ideal \\nfor applications that require these capabilities.\\nIn terms of cost, access to ChatGPT is limited and comes at \\na price, whereas Bard is free for all.\\nChatGPT leads in text generation, with Microsoft/OpenAI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='and Google’s models rapidly evolving, reshaping conversational \\nAI. Amidst this, Elon Musk’s xAI’s Grok, with unique data access \\nto X/T witter, challenges their dominance, indicating a dynamic  \\nfuture.\\nGenerative AI Platforms\\nAs we traverse the landscape of generative AI applications, a \\nmore fundamental question arises: What new generative  \\nAI platforms are emerging, and who will be their proprietors? A \\nmultitude of platforms are sprouting up, each with unique offer-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ings. For instance, Selas AI provides plug-and-play services to \\nleverage state-of-the-art text-to-anything features for businesses, \\noffering a full-stack solution to build products. Another platform, \\nAspen AI, offers a no-code platform for building AI-powered \\nweb apps, allowing users to configure AI models and deploy their \\napplications in minutes.\\nIn the midst of this technological evolution, we are witness-\\ning a shift from a software-centric world to an AI-centric one.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI platforms are becoming the new infrastructure for \\ndigital products and services, replacing traditional software. This \\ntransformation is not merely a change in the tools we use but a \\nfundamental shift in how we approach the creation and delivery \\nof digital services.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 133\\nHowever, this shift does present challenges. Some, like the \\ninvestment firm Andreesen Horowitz, argue that the control of \\ngenerative AI platforms, including the respective data therein, by \\na few large tech companies could lead to a concentration of \\npower and a lack of competition. While the point of dominance \\nis valid, I believe that there have never been so many opportuni-\\nties for everyone in a tech revolution like this one. There'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='are so many angles and ideas to deploy that this dominant posi-\\ntion, while influential, does not necessarily stifle competition or \\ninnovation.\\nIn fact, we are also witnessing a completely new open and \\ncollaborative approach to AI development, arguing that this \\nwould lead to more innovation and better outcomes for society. \\n(Chapter\\xa04, “Generative AI’s Exponential Growth,” explores the \\nopen source activities happening on this front.)'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Now, let’s turn our attention to the existing layers of the tech \\nlandscape (Figure\\xa03.2). The first layer is hardware, which includes \\nGPUs, TPUs, servers, and accelerator chips optimized for model \\ntraining and inference workloads. These components form the \\nphysical infrastructure that powers AI technologies. The second \\nlayer is the cloud platforms, such as Google Cloud, AWS from \\nAmazon, and Azure. These platforms build a virtual layer on top'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='of the hardware, providing scalable computing resources and a \\nrange of services for developing, deploying, and managing AI \\napplications.\\nIn the tech chain, we have large foundation models that are \\nexpensively trained on vast data. These foundation models are \\nthen customized, fine-tuned, or prompt-designed for specific use \\ncases. This process leads to the development of end-to-end apps, \\nwhich are end user–facing applications with proprietary models.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='A good example of an end-to-end app is ActiveChat.AI, a  \\nplatform that uses AI to automate customer service and sales \\nprocesses.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='134 GENERATIVE AI\\nOn the other hand, we observe the separation of foundation \\nmodels and downstream customization. Here, we distinguish \\nbetween closed and open source. Closed source foundation mod-\\nels, like OpenAI’s GPT-4, are large-scale, pretrained models \\nexposed to downstream apps via APIs, which are paid. The open \\nsource variant uses openly available foundation models like Sta-\\nble Diffusion or StableLM from Stability AI. These models are'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='often released as trained weights and hosted on model hubs, like \\nHugging Face and Replicate, which share and host models.\\nApps\\nApps\\nEnd-to-End Apps\\nClosed Source\\nFoundation Models\\nModel Hubs\\nCloud Platforms\\nCompute Hardware\\nOpen Source\\nFoundation Models\\nUsers Models\\nInfrastructure\\nExamples: Jasper, Github Copilot\\nExamples: Hugging Face, Replicate\\nExamples: Stable Diffusion (Stability)\\nExamples: AWS, GCP, Azure, Coreweave\\nExamples: GPUs (NVIDIA), TPUs (Google)\\nExamples: GPT-3\\n(OpenAI)'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='(OpenAI)\\nExamples: Midjourney,\\nRunway\\nEnd user–facing B2B and B2C applications\\nwithout proprietary models\\nPlatforms to share and host models\\nModels released as trained weights\\nCompute hardware exposed to developers in a cloud deployment model\\nAccelerator chips optimized for model training and inference workloads\\nLarge-scale, pre-\\ntrained models\\nexposed via APIs\\nEnd user–facing\\napplications with\\nproprietary models\\nFIGURE\\xa03.2 Preliminary generative AI tech stack.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 135\\nThe closed source and open source foundation models ena-\\nble downstream applications via APIs. The apps are end user–\\nfacing B2B and B2C applications without proprietary models. \\nExamples here include Jasper, an AI-powered assistant that  \\nhelps manage and automate digital marketing tasks, and GitHub  \\nCopilot, a tool that suggests code snippets as developers type, \\neffectively acting as an AI pair programmer.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='This platform landscape, as I see it, will consolidate even fur-\\nther. One emerging element in this big-picture perspective is \\nautonomous agents. These are systems capable of autonomous, \\npurposeful action in the real world. They sense and act autono-\\nmously in their environment, realizing a set of goals or tasks for \\nwhich they are designed. We will discuss autonomous agents in \\nmore detail later, and time will tell how they will shape the AI \\nlandscape.\\nOpen Source Models'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Open Source Models\\nOpen source models, such as StableLM and GPT-NeoX-20B, \\nare a cornerstone of the AI landscape. They are software or AI \\nmodels whose source code is made available to the public, allow-\\ning anyone to view, use, modify, and distribute the project’s \\nsource code. This openness fosters a collaborative environment \\nwhere developers from around the globe can contribute to the \\ncode, leading to a diverse range of perspectives and expertise that'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='can enhance the quality and functionality of the model.\\nFor instance, GPT-NeoX-20B, developed by EleutherAI, is a \\n20 billion–parameter autoregressive language model trained on the \\nPile using the GPT-NeoX library. Its architecture closely resembles \\nthat of GPT-3. The model was trained on a multitude of English-\\nlanguage texts, reflecting its general-purpose nature. The model’s \\nsource code is available on Hugging Face, the platform that hosts'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='and shares models, allowing anyone to study and modify it.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='136 GENERATIVE AI\\nOpen source models like these promote transparency and \\naccountability, as anyone can inspect the code for bugs, errors, or \\nbiases. They also serve as a great learning resource for individu-\\nals and organizations looking to understand or get started with \\nAI, as they can study and modify existing models. The open \\nnature of these models encourages innovation, as developers can \\nbuild upon existing models to create new solutions.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='However, it’s important to note that training large AI models \\ncan be expensive, and this cost can be prohibitive for some devel-\\nopers or organizations. Moreover, because open source models \\nare publicly available, they can be misused by malicious actors. \\nDespite these challenges, the benefits of open source models in \\npromoting transparency, fostering innovation, and serving as a \\nlearning resource make them a vital part of the AI landscape.\\nClosed Source Models'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Closed source models, unlike their open source counterparts, are \\nproprietary software or AI models whose source code is not dis-\\nclosed to the public. The code is owned, controlled, and main-\\ntained by a specific individual, team, or organization.\\nA prime example of a closed source model is GPT-4, devel-\\noped by OpenAI. GPT-4, the successor to GPT-3, is OpenAI’s \\nmost advanced system, producing safer and more useful responses. \\nIt can solve complex problems with greater accuracy, thanks to'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='its broader general knowledge and problem-solving abilities. \\nGPT-4 is more creative and collaborative than ever before, capa-\\nble of generating, editing, and iterating with users on creative \\nand technical writing tasks. However, the source code of GPT-4 \\nis not publicly available, making it a closed source model.\\nThese models are typically commercial products developed \\nby businesses for profit. They can provide a competitive advan-\\ntage to the company that developed them. For instance, GPT-4'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 137\\ndeepens the conversation on Duolingo, transforms visual acces-\\nsibility on Be My Eyes, and streamlines the user experience and \\ncombats fraud on Stripe.\\nOne of the benefits of closed source models is that they \\noften come with customer support and regular updates. This \\ncan be a boon for users who are not tech-savvy or do not have \\nthe resources to maintain and update the software themselves.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='However, the lack of transparency can lead to concerns about \\nbias, fairness, and privacy. Users have to trust the provider that \\nthe software is performing as it should, without any hid-\\nden issues.\\nA significant concern with closed source models is that they \\ncan lead to a concentration of power, as only a few entities have \\ncontrol over the most advanced AI models. For instance, OpenAI \\nhas exclusive control over its source code and usage.\\nOpenAI’s Founding Story'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='The story of OpenAI’s inception is a captivating narrative, \\nmarked by unexpected twists and high-stakes decisions. It all \\nbegan amidst the acquisition talks between DeepMind and \\nGoogle. Elon Musk implored DeepMind’s leaders, including \\nDemis Hassabis, not to sell. Musk’s concern was rooted in the \\npotential dominance of a commercial entity like Google in the \\nAI landscape.\\nAfter DeepMind’s eventual sale to Google, Musk, along  \\nwith a group of influential figures such as Sam Altman, Greg'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Brockman, Reid Hoffman, Jessica Livingston, and Peter Thiel, \\nand organizations including Amazon Web Services (AWS), Info-\\nsys, and YC Research, announced the formation of OpenAI in \\nDecember 2015. They pledged over a billion dollars to the ven-\\nture, promising to freely collaborate with other institutions and \\nresearchers by making their research open to the public.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='138 GENERATIVE AI\\nHowever, by early 2018 Musk felt that OpenAI had fallen \\nsignificantly behind Google. He proposed taking control of \\nOpenAI and running it himself, a proposal that was rejected by \\nthe other founders. Following this, Musk distanced himself from \\nOpenAI and withdrew a substantial planned donation. His depar-\\nture was publicly attributed to a conflict of interest, as T esla was \\ndeveloping its own AI for autonomous driving, which would be \\ncompeting for talent with OpenAI.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='In the same year, Sam Altman, who also ran the influential \\nstartup accelerator Y Combinator, stepped in and added the title \\nof president to his role at OpenAI. Musk stepped down from \\nOpenAI’s board of directors. In the fall of 2018, OpenAI made a \\nsignificant decision to pivot toward T ransformer models, which \\nrequired feeding vast amounts of data to train the AI, a \\ncostly endeavor.\\nOn March 11, 2019, OpenAI announced it was transitioning'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='into a for-profit entity to raise enough capital to fund the com-\\nputing power necessary to pursue the most ambitious AI models. \\nThis marked a significant shift from OpenAI’s original mission, \\nleading some to refer to the organization as “ClosedAI,” a term \\ncoined by Jason Calacanis. In 2019, OpenAI secured $1 billion \\nfrom Microsoft, which provided not just funding but also infra-\\nstructure know-how. T ogether, they built a supercomputer to'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='train massive models that eventually led to the creation of Chat-\\nGPT and DALL-E.\\nBy November 2022, when ChatGPT launched, OpenAI \\ninstantly became the hottest new tech startup, forcing Google to \\nscramble to keep up. However, in December 2022, Musk pulled \\nOpenAI’s access to the T witter “fire hose” of data— a contract \\nthat was signed before Musk acquired T witter.\\nIn 2023, Musk expressed his confusion and frustration over \\nOpenAI’s transformation from a nonprofit to a for-profit entity'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='(Figure\\xa03.3). In a surprising turn of events, Musk has founded  \\na new AI company called X.AI, which aims to compete with'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 139\\nOpenAI in the artificial intelligence industry. X.AI is reportedly \\nplanning to adopt an open source approach, a stark contrast to \\nOpenAI’s recent shift. Musk is the sole listed director of the com-\\npany, which was incorporated in Nevada. X.AI has authorized \\nthe sale of 100\\xa0million shares for its privately held business. Musk \\nhas been actively recruiting researchers to establish a rival effort'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='to OpenAI, marking yet another intriguing chapter in the evolv-\\ning narrative of the AI industry.\\nNo Moat Leakage Letter at Google\\nIn 2019, OpenAI underwent a significant transformation, shift-\\ning from a nonprofit to a for-profit entity. The leaders of  \\nOpenAI justified this move as a necessary measure to secure the \\nfunding needed for the creation of advanced AI models. How-\\never, after extensive research and numerous conversations with'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='thought leaders at conferences and interviews, it becomes \\nincreasingly clear that this transition may not have been as cru-\\ncial as it was portrayed.\\nOpenAI’s shift toward a for-profit model has sparked a debate \\nabout the future of AI model development and research. The \\nopen source approach, in my opinion, holds immense potential. \\nIt could secure a top-notch, if not pole position, in the AI land-\\nscape. The future of open source AI models could be as vibrant,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='collaborative, and impactful as the React community is today. \\nReact, an open source, frontend JavaScript library for building \\nFIGURE\\xa03.3 Tweet from Elon Musk about OpenAI turning from a non-\\nprofit to a for-profit company.\\nSource: X Corp.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='140 GENERATIVE AI\\nuser interfaces or UI components, is maintained by Meta (for -\\nmerly Facebook) and a community of individual developers and \\ncompanies.\\nEven within Google, this topic is a subject of ongoing discus-\\nsion. A leaked document from a Google researcher recently sur-\\nfaced, shared by an anonymous individual on a public Discord \\nserver. The document, titled “We Have No Moat, and Neither \\nDoes OpenAI,” provides an insightful analysis of the competitive'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='landscape of AI, with a particular focus on Google and OpenAI.\\nThe document suggests that open source AI will outperform \\nboth Google and OpenAI. It highlights several advancements in \\nopen source AI, such as running foundation models on a Pixel 6, \\nscalable personal AI, and unrestricted release of art models. \\nWhile closed source models still hold a slight edge in terms of \\nquality, the gap is closing quickly. Open source models are faster,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='more customizable, more private, and more capable. The docu-\\nment asserts that Google has no secret sauce and should learn \\nfrom and collaborate with others outside Google. It also suggests \\nthat people will not pay for a restricted model when free, unre-\\nstricted alternatives are comparable in quality. I find myself in \\nagreement with this sentiment. A few months of difference in \\ndevelopment doesn’t make a significant difference.\\nThe document further highlights the rapid innovation in the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='open source community, particularly after the leak of Meta’s \\nLLaMA model. The community quickly developed variants with \\ninstruction tuning, quantization, quality improvements, human \\nevaluations, multimodality, and so forth. The document discusses \\nthe recent successes of open source AI, particularly in image gen-\\neration and language model fine-tuning. It suggests that Google \\ncould benefit from paying more attention to these innovations.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Interestingly, the document also suggests that OpenAI is \\nmaking the same mistakes as Google in their posture relative to \\nopen source, and their ability to maintain an edge is necessarily'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 141\\nin question. It proposes that Google should establish itself as a \\nleader in the open source community, even if it means taking \\nsome uncomfortable steps, like publishing the model weights.\\nThe future of AI model development and research seems to \\nbe leaning toward the open source approach. The rapid advance-\\nments in open source AI, coupled with the closing gap in quality \\nbetween proprietary and open source models, suggest that the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='open source approach could be the key to unlocking the full \\npotential of AI.\\nGenerating Revenue with\\xa0Open Source Models\\nThe question of how a for-profit company can differentiate itself \\nwhile open sourcing its expensively trained AI models is indeed a \\npertinent one. How can such a company generate revenue? The \\nanswer may seem counterintuitive at first, but open sourcing an \\nAI model can be a strategic decision that opens up several ave-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='nues for revenue generation and maintaining a competitive edge.\\nOne such avenue is through consulting and customization \\nservices. While the model may be open source, many businesses \\nlack the expertise to effectively implement and customize it. \\nOffering consulting services to assist these businesses in inte-\\ngrating the model into their systems can be beneficial. This could \\nalso involve providing custom solutions tailored to specific use \\ncases or industries.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='T raining and support is another potential revenue stream. \\nProviding training programs and support services can help users \\nunderstand how to use the model effectively. This could take the \\nform of workshops, online courses, or personalized train-\\ning sessions.\\nDeveloping premium features or services that complement \\nthe open source model is another option. These could be offered \\non a subscription basis or as one-time purchases. For instance,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='142 GENERATIVE AI\\na cloud-based API for easy access to the model, advanced analytics, \\nor additional tools for fine-tuning the model could be provided.\\nOpen sourcing the model can also attract potential partner -\\nships and collaborations. Companies interested in collaborating \\non further development or application of the model may be \\ndrawn to the project. Such partnerships can lead to new reve-\\nnue streams.\\nIf users interact with the model via a platform or API,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='anonymized usage data and analytics can be collected (with user \\nconsent and in compliance with privacy laws). This data can be \\nvaluable for improving services, and of course AI models. Fur -\\nther, the data can also be used to provide businesses with insights \\nand analytics.\\nOpen source projects often attract sponsorships and grants \\nfrom businesses that find value in the project. Additionally, \\nnumerous grants are available for open source development.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='The differentiator in these scenarios is the expertise and the \\nvalue-added services provided. The offering is not just a model, \\nbut a complete solution that includes the model, support, cus-\\ntomization, and potentially other services. This can make the \\noffering more attractive to businesses compared to just using the \\nopen source model independently.\\nCertainly, licensing is another crucial aspect to consider. In a \\ndual licensing model, the software is released under two types of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='licenses: an open source license and a commercial license. The \\nopen source license permits free use, but it often comes with cer-\\ntain conditions. For instance, any modifications or derivative \\nworks must also be open source. On the other hand, the com-\\nmercial license, which can be purchased, allows for use under \\nmore permissive conditions and may include additional services \\nor features. This model can be particularly attractive to busi-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='nesses that wish to use the software in ways not permitted by the \\nopen source license, or those who desire additional services \\nor support.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 143\\nThere are also other licensing models to consider. One such \\nmodel is the open-core model. In this model, the basic version of \\nthe software is open source, but a more feature-rich version or \\nadditional modules are available under a commercial license. \\nThis model provides users with the flexibility to choose the ver-\\nsion that best suits their needs.\\nAnother model is the service provider license agreement'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='(SPLA). Under this model, companies can license your software on \\na monthly basis to provide services to their customers. This model \\ncan provide a steady stream of income and can be particularly ben-\\neficial for software that requires regular updates or maintenance.\\nT rademark licensing is another option, especially if the soft-\\nware has a strong brand. In this model, you can license the use of \\nthe trademark to companies that want to market their own ser -'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='vices or products as compatible with or based on your software. \\nThis can help to increase the visibility of your software and can \\nprovide additional revenue streams.\\nWhile open sourcing AI models may initially appear to be a \\nchallenge for generating revenue, they can, in fact, open up a \\nmultitude of opportunities for a company to differentiate itself \\nand create sustainable revenue streams.\\nDemocratizing AI: Hugging Face’s Success Story'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Known as the hub for open source models, Hugging Face has \\nmanaged to create a thriving ecosystem around its offerings.\\nHugging Face presents a master class on leveraging the open \\nsource model to build a brand and drive growth. Founded in \\n2016, the company initially targeted teenagers with a chatbot \\napp. However, after open sourcing the model behind the chat-\\nbot, the company pivoted to focus on being a platform for \\nmachine learning. This strategic shift marked the beginning of a'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='journey that would see the company catapult to a staggering'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='144 GENERATIVE AI\\n$2 billion valuation in roughly seven years, with a team of around \\n150 employees.\\nThe company’s growth trajectory has been marked by signifi-\\ncant milestones. In March 2021, Hugging Face raised $40\\xa0million \\nin a Series B funding round. Later, in December 2021, the com-\\npany announced its acquisition of Gradio, a software library used \\nto create interactive browser demos of machine learning models. \\nThis acquisition expanded the company’s capabilities and further'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='solidified its position in the AI industry.\\nThe year 2022\\xa0was particularly eventful for Hugging Face. \\nIn collaboration with several other research groups, the BigSci-\\nence Research Workshop concluded with the announcement of \\nBLOOM, a multilingual large language model with 176 billion \\nparameters. This marked a significant advancement in the field \\nof AI and demonstrated the company’s commitment to pushing \\nthe boundaries of what is possible with machine learning.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='In the same year, the company announced its Series C fund-\\ning round led by Coatue and Sequoia, which valued the company \\nat $2 billion. This was a testament to the company’s success and \\nthe faith investors had in its potential for future growth. In a bid \\nto fulfill its mission to teach machine learning to 5\\xa0million peo-\\nple within the first 18\\xa0months, the company also introduced its \\nStudent Ambassador Program in May 2022.\\nHugging Face’s commitment to innovation was further dem-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='onstrated by its partnership with Graphcore to optimize its \\nT ransformers library for the Graphcore IPU. An intelligence \\nprocessing unit (IPU) is a type of processor specifically designed \\nfor AI workloads. This partnership aimed to enhance the perfor-\\nmance of Hugging Face’s offerings and provide better tools for \\nAI developers.\\nIn August 2022, the company announced the Private Hub, \\nan enterprise version of its public Hugging Face Hub that sup-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ports software-as-a-service (SaaS) or on-premises deployment.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 145\\nThis move was aimed at providing more flexible and tailored \\nsolutions for businesses, further expanding the company’s reach \\nand influence.\\nThe company’s growth continued into 2023, with a partner-\\nship with Amazon Web Services (AWS) announced in February. \\nThis partnership would allow Hugging Face’s products to be \\navailable to AWS customers, providing them with powerful tools \\nfor building custom applications. The company also announced'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='that the next generation of BLOOM would be run on T rainium, \\na proprietary machine learning chip created by AWS.\\nThe story of Hugging Face exemplifies the power of open \\nsource. Not a single element of their success can be attributed to \\na closed source solution. Quite the contrary, their entire ecosys-\\ntem thrives on openness and collaboration. This ethos has led to \\na staggering collection of more than 200,000\\xa0models, 34,000\\xa0data-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='sets, and more than 25\\xa0machine learning libraries. These resources \\nare utilized by over 10,000 organizations and half a million daily \\nusers. The scale of their operation is truly awe-inspiring.\\nHugging Face’s capabilities are not just vast but also incred-\\nibly accessible. They have democratized AI to such an extent that \\nyou can build an AI minimum viable product starting from just \\nan idea. If you lack an idea, they even provide inspiration by map-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ping models against different tasks that can be solved. The spec-\\ntrum of applications is broad, ranging from text-to-speech and \\naudio-to-audio to zero-shot text classification and image-to-3D \\nobject translation.\\nChoosing the right model for your application is made easy \\nwith Hugging Face. They support decision making with com-\\nprehensive information about the models, including details about \\nthe licenses, which is crucial if you intend to use the model com-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='mercially. Once you’ve selected a pre-trained model, it can be \\nintegrated into an existing or new application via Hugging Face’s \\naccelerated inference API.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='146 GENERATIVE AI\\nIf you’re starting from scratch, Hugging Face’s acquisition of \\nGradio comes in handy. Y ou can build a machine learning app, \\nhost it, and deploy it via Hugging Face Spaces, powered by  \\nGradio. The result? A working application that can be up and \\nrunning in under an hour. There are numerous Y ouT ube videos \\ndemonstrating this process.\\nFurther, the Leadership board is a valuable tool provided by \\nHugging Face (Figure\\xa03.4). It presents the performance of the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='respective models, a task that was previously challenging as it \\nrequired either trying out the models or reading surveys and \\npapers, which often lacked comparability.\\nHugging Face has made it possible to build pretty much any-\\nthing. With their tools and resources, the possibilities are end-\\nless. This brings us to the next topic of our discussion: the \\napplications that are at the forefront of generative AI.\\nFIGURE\\xa03.4 Hugging Face’s LLM-Leaderboard, mapping performances'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='for various tasks against AI models.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 147\\nApplication Fields\\nThe advent of generative AI has sparked a productivity revolu-\\ntion. We are witnessing a tenfold increase in productivity, a phe-\\nnomenon that is currently being embraced by early adopters and \\nwill soon permeate the majority of society and the economy. This \\nsurge in productivity is accompanied by a hundredfold increase \\nin the number of startups being founded and a thousandfold'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='increase in the number of products, ideas, and projects being  \\nlaunched.\\nThe applications of generative AI are as diverse as they are \\nfascinating. Voice generation, for instance, involves the use of AI \\nto synthesize human-like speech, enabling more natural interac-\\ntions between humans and machines. Video generation, on the \\nother hand, leverages AI to create realistic as well as stylistic vid-\\neos, transforming the way we create and consume visual content.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='T ext generation and language translation are other promi-\\nnent applications of generative AI. Here, AI is used to generate \\ncoherent and contextually relevant text or to translate text from \\none language to another, thereby breaking down linguistic barri-\\ners and fostering global communication. Music generation, \\nanother intriguing application, involves the use of AI to compose \\nmusic, pushing the boundaries of creativity.\\nGenerative AI plays a pivotal role in image generation and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='manipulation, enabling the creation of realistic images or the \\nmodification of existing ones. In the realm of 3D object genera-\\ntion, AI is used to create detailed and accurate 3D models, a \\ncapability that is transforming industries such as architecture, \\ngaming, and entertainment.\\nGenerative design, another application of generative AI, \\ninvolves the use of AI to generate a wide range of design alterna-\\ntives for a given problem, thereby enhancing creativity and effi-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ciency in the design process. In the scientific domain, generative'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='148 GENERATIVE AI\\nAI is being used for protein folding and other science-specific \\nuse cases. For instance, DeepMind’s AlphaFold uses AI to predict \\nthe 3D structure of a protein based solely on its genetic sequence, \\na breakthrough that could accelerate scientific discoveries and \\npotentially lead to new methods of therapy.\\nThe landscape of generative AI is highly dynamic, with noth-\\ning set in stone. The boundaries that were once clear are now'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='blurred, as AI continues to evolve and redefine the limits of what \\nis possible. Let’s explore how it is shaping our present and \\nnear future.\\nVoice and Speech Generation\\nNow, let’s turn our attention to voice and speech generation. \\nThis technology, which converts text into spoken language, is \\nused in a variety of applications. Think of voice assistants like Siri \\nor Alexa, audiobooks, and accessibility tools. T oday, we have \\nadvanced speech synthesis models that can generate human-like'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='voices. These models are trained on large datasets and can han-\\ndle different languages, accents, and speech patterns. They can \\nalso adjust the tone, pitch, and speed of the speech.\\nLet’s consider a real-world example of a company using \\nspeech synthesis technology combined with AI in their market-\\ning campaigns.\\xa0Respeecher collaborated with Mondelēz Interna-\\ntional, Ogilvy, and Wavemaker to create a revolutionary ad \\ncampaign for the Indian market. They used their voice-cloning'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='technology to generate personalized ads from Shah Rukh Khan, \\na popular Bollywood actor, for thousands of local retailers. This \\nwas a game-changing approach, as these retailers would not have \\notherwise been able to afford such a high-profile endorsement. \\nThis example illustrates the transformative potential of speech \\nsynthesis technology when combined with AI, particularly in the \\nrealm of marketing.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 149\\nThe process of speech synthesis is a fascinating one, typically \\ninvolving three stages. The first stage is text to words, also known \\nas preprocessing or normalization. This involves reducing ambi-\\nguity and turning elements like numbers, dates, times, abbrevia-\\ntions, acronyms, and special characters into words. This process \\nuses statistical probability techniques or neural networks to \\narrive at the most likely pronunciation.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='The second stage is words to phonemes. After figuring out \\nthe words, the speech synthesizer generates the speech sounds \\nthat make up these words. This involves breaking down the writ-\\nten words into their graphemes, the smallest units in a writing \\nsystem, and then generating phonemes, the distinct units of \\nsound, that correspond to them using a set of simple rules.\\nThe third stage is phonemes to sound. The computer converts'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='the text into a list of phonemes. There are three different approaches \\nto this: using recordings of humans saying the phonemes, the com-\\nputer generating the phonemes itself by generating basic sound \\nfrequencies, and imitating the technique of the human voice.\\nThere are different types of speech synthesizers: concatena-\\ntive, formant, and articulatory. Concatenative synthesizers use \\nrecorded human voices and rearrange them. They are based on'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='recorded human speech. Formant synthesizers generate speech \\noutput using additive synthesis and physical modeling synthesis. \\nThey can say anything, even words that don’t exist or foreign \\nwords they’ve never heard off. Articulatory synthesizers make \\ncomputers speak by modeling the intricate human vocal tract \\nand articulating the process occurring there. It is the least \\nexplored method due to its complexity.\\nSpeech synthesis systems usually try to maximize both natu-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ralness and comprehensibility. Naturalness refers to how closely \\nthe synthesized speech resembles human speech, while compre-\\nhensibility refers to how easily the synthesized speech can be \\nunderstood by listeners.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='150 GENERATIVE AI\\nSpeech synthesis has multiple applications. It helps the visu-\\nally impaired to read and communicate. It can be used for teach-\\ning spelling and pronunciation of different languages. It is used \\nin different kinds of telephone inquiry systems and multimedia \\napplications. There are several free and paid speech recognition \\nprograms available in the market, such as Google Now, Siri, \\nCortana, Simon, Kaldi, Dragon Anywhere, Amazon Lex, Dragon'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Professional, Voice Finger, and T azti.\\nOne company that stands out in this field is Murf.ai. They \\nprovide an AI voiceover platform that can generate human-like \\nspeech with high quality. Their platform allows users to choose \\nfrom a variety of voices and customize the tone, pitch, and speed \\nof the speech. Murf.ai offers high-quality natural-sounding AI \\nvoices for your projects. It provides a complete toolkit for mak-\\ning voice-over videos. Y ou can combine images, videos, music,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='adjust timing, and so on. It’s not just a text-to-speech tool— it’s a \\ncomplete solution for creating voiceovers.\\nAnother noteworthy player is Poly.ai. This company has \\ncarved out a niche for itself by creating a voice generation system \\nthat is so high-quality, it borders on the uncanny. The generated \\nvoice is so flawless that it almost seems too perfect, as it lacks the \\nhuman-like imperfections such as the occasional “uhms” and \\n“ahs” that we are accustomed to in natural speech.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='However, Poly.ai’s prowess extends beyond just the creation \\nof high-quality synthetic voices. Their solution is designed to \\nextract valuable information such as dates, places, and names, \\nand can handle tasks like table booking and other organizational \\nmatters automatically. This level of sophistication in handling \\ncomplex tasks rises from the company’s commitment to pushing \\nthe boundaries of what AI can achieve in the realm of speech \\nsynthesis and natural language processing.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Founded in 2017, according to Crunchbase, Poly.ai has \\nalready secured a substantial $66\\xa0million in funding and boasts'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 151\\na workforce of between 100 and 250 employees. This level of \\nfinancial backing and human capital speaks volumes about the \\npotential of this company and the faith that investors have in \\nits vision.\\nAs we look to the future, it’s exciting to imagine what else is \\non the horizon for Poly.ai. With their track record of innovation \\nand their commitment to pushing the boundaries of AI, there’s'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='no doubt that they will continue to make waves in the field of \\nspeech synthesis and beyond.\\nIn the next section of this book, we will continue our explora-\\ntion of the fascinating world of AI, turning our attention to \\nanother topic that has been making headlines in the world of \\nartificial intelligence.\\nWhere Is Voice Generation Going? Voice cloning technol-\\nogy, such as the voice imitation algorithm developed by Descript, \\nhas the power to replicate a person’s unique voice. This capabil-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ity opens up a world of possibilities, from creating personalized \\nvoice assistants that echo our own speech patterns to narrating \\naudiobooks in the author’s voice, thereby enhancing user engage-\\nment and accessibility.\\nIn the sphere of education, platforms like T utorAI are har -\\nnessing voice generation to produce interactive educational con-\\ntent. This transformative approach to learning is reshaping the \\nway we engage with information, making the learning process'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='more dynamic and immersive.\\nLanguage learning, too, stands to gain immensely from voice \\ngeneration technology. By creating realistic voices in a multitude \\nof languages, this technology can serve as a valuable tool in lan-\\nguage learning apps, aiding students in refining their pronuncia-\\ntion and listening skills.\\nThe entertainment and gaming industry is another sector \\nwhere voice generation is making a significant impact. It has the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='152 GENERATIVE AI\\npotential to breathe life into characters in video games, anima-\\ntions, and other forms of entertainment. Whether it’s creating \\nvoices for nonexistent characters or re-creating voices from clas-\\nsic games or shows, voice generation adds a new dimension to \\nthe user experience.\\nThe concept of personal branding for content creators is also \\nbeing redefined by voice cloning. Imagine content creators using \\ntheir unique voice clones to interact with their audiences across'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='different platforms, creating a consistent and recognizable per -\\nsonal brand. It’s not far-fetched to envision a future where pro-\\nfessionals have their own voice generators, akin to business cards \\nof yore, integrated into their personal web pages or LinkedIn \\nprofiles. This could be a game changer for social media compa-\\nnies, offering an additional service that enhances user engagement.\\nIn the telecommunications sector, voice generation can revo-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='lutionize user experience by creating realistic voices for automated \\nphone systems. This could automate redundant calls, making the \\nprocess more efficient and user-friendly.\\nHealthcare is another field where voice generation can make \\na significant difference. For speech therapy patients or individu-\\nals who have lost their ability to speak, the creation of realistic, \\npersonalized voices can be a lifeline, offering them a chance to \\ncommunicate effectively.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Lastly, let’s consider the role of voice generation in enhanc-\\ning accessibility. This technology can be used to read out text for \\npeople with visual impairments or to translate sign language into \\nspoken words. This integration of technology can make our digi-\\ntal world more inclusive, ensuring that everyone, regardless of \\ntheir abilities, can participate fully.\\nAs we continue our journey through the fascinating world of \\nAI, we will explore more such groundbreaking technologies and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='their potential impact on our lives. Stay tuned as we unravel the \\nintricacies of this rapidly evolving field.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 153\\nGenerative Design\\nIn the vast expanse of generative AI, generative design stands out \\nas the field most intimately connected to the physical world. This \\ninnovative approach takes a leaf from nature’s book, emulating \\nits evolutionary process. Here’s how it works: Designers or engi-\\nneers input their design goals into a generative design software, \\nalong with parameters such as the materials to be used, manufac-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='turing methods, and cost constraints. The software then embarks \\non an exploration of all possible permutations of a solution, gen-\\nerating a multitude of design alternatives. It tests each one, learn-\\ning from every iteration. This process enables the creation of \\ncomplex shapes and internal lattices that are optimized for effi-\\nciency. Some of these forms are so intricate that they would be \\nimpossible to produce using traditional manufacturing methods.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Instead, they come to life through the magic of new additive \\nmanufacturing methods.\\nIn 2016, during my tenure in the research department at  \\nAirbus, I witnessed the power of generative design firsthand. We \\nwere working on innovative predictive maintenance systems, \\nincluding generative models to balance out unbalanced datasets. \\nThat year, Airbus built a fully functioning motorcycle that was \\nnot only robust but also weighed just 35\\xa0kg (Figure\\xa03.5). Seeing'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='it in person was a revelation of what’s possible with generative \\ndesign, especially when coupled with 3D printing.\\nT oday, generative design finds applications in various sec-\\ntors. In the automotive industry, for instance, it’s used for light-\\nweighting components and consolidating parts. A notable \\nexample is General Motors, which used generative design to \\nreduce the mass of a seat bracket by 40 percent while improv-\\ning its performance.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='In aerospace, it contributes to weight reduction, environ-\\nmental impact mitigation, and safety improvements. Airbus, for'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='154 GENERATIVE AI\\ninstance, used generative design to optimize the partition wall of \\nan airplane cabin, reducing its weight by 45 percent.\\nGenerative design has found a compelling application in the \\nrealm of architecture, transforming the way structures are con-\\nceived and built. Consider the skyscrapers that punctuate city \\nskylines. These towering structures are designed to withstand \\ndiverse environmental challenges— for example, high winds in'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Chicago and earthquakes in Japan. Beyond ensuring safety, archi-\\ntects and clients often aspire to infuse their buildings with a \\nunique aesthetic appeal. Generative design enables this, allowing \\narchitects to set necessary parameters and explore a multitude of \\ndesign options.\\nA striking example comes from Brazilian architect Guto \\nRequena, who employed generative design to create stools for a \\nbar. The design of these stools mirrored the rhythm of local pop-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ular music. Once the design was finalized, the stools were brought \\nto life through 3D printing.\\nFIGURE\\xa03.5 Airbus APWorks launches the Light Rider, the world’s first \\n3D-printed motorcycle.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 155\\nBut generative design isn’t confined to specific parameters. It \\ncan also accommodate broader ones. It can be used to construct \\nthe most robust bridge with the most cost-effective materials, or \\nto design a school based on the natural movement patterns \\nof people.\\nThe creators of Autodesk took this concept even further \\nwhen building their new offices. They incorporated the prefer -'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ences of future occupants as design parameters. The result was a \\nworkspace tailored to the workflows of its users, a building that \\nwas customized to the needs of the people who would use it. This \\npreemptive approach minimizes the need for postconstruction \\nmodifications, creating a refined building that truly serves its \\ninhabitants.\\nGenerative design is revolutionizing the industrial machin-\\nery sector, pushing the boundaries of innovation in the creation'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='of specialty tools and equipment. A prime example of this is the \\nGen5X, a 5-axis 3D printer designed using generative principles.\\nThe Gen5X is not just any 3D printer; it’s an open source, \\nself-replicating marvel. It’s capable of designing and manufactur-\\ning its own components, and its design can be replicated on any \\nhobbyist-level machine. This 5-axis 3D printer is a product of \\nthe RepRap project, which explores the frontier of self-replicating  \\nmachines.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='machines.\\nThe design process of the Gen5X employs Fusion 360’s gen-\\nerative design tools, which use parametric inputs to generate \\ndesigns. This means the Gen5X can be customized based on the \\ncomponents you already have.\\nIn building products, generative design simplifies complex \\nassemblies. An example is the Elbo chair, designed by Autodesk’s \\ngenerative design lab (Figure\\xa03.6). The chair’s design was opti-\\nmized by algorithms, resulting in a structure that is 18 percent'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='lighter and shows fewer signs of stress in its joints.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='156 GENERATIVE AI\\nWhere Is Generative Design Going? The future holds the \\npromise of designs that are not only superior in quality but also \\nmore aligned with the designer’s intent, all achieved in less time. \\nGenerative design is poised to be a game changer, particularly in \\nthe fields of architectural, industrial, and product design. Its \\nstrength lies in its ability to optimize parameters directly linked \\nto geometric changes, making it a formidable tool for early \\ndesign and prototyping.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='T ake, for instance, the realm of mechanical, electrical, and \\nplumbing (MEP) services. Some companies have started to har -\\nness the power of generative design for design exploration and \\ndecision making. Addiform, a company specializing in additive \\nmanufacturing, leverages generative design to create complex \\noptimized parts for various industries. This is not merely a mat-\\nter of employing a new tool; it’s about harnessing our collective'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='imagination to unlock the full potential of this technology.\\nFIGURE\\xa0 3.6 The Elbo chair, an exemplar of generative design and \\nadditive manufacturing by Autodesk.\\nSource: Autodesk Inc.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 157\\nIn the realm of architecture, the potential applications of gen-\\nerative design are vast and compelling. Consider the case of the \\nlate architect Antoni Gaudí and his magnum opus, the Sagrada \\nFamilia in Barcelona. After Gaudí’s passing, the construction of \\nthe Sagrada Familia proceeded based on reconstructed versions of \\nhis plans, which had been partially destroyed in a fire. While gen-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='erative design was not employed in this instance, one can envision \\nhow it could have significantly contributed to this process, aiding \\nin the completion of the architectural designs in a way that hon-\\nored Gaudí’s original vision.\\nThe implications of this technology are far-reaching. As ele-\\nments become lighter and stronger, industries such as aerospace \\nand construction will be significantly boosted. For instance, gen-\\nerative design is already transforming the way aircraft are built.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='A BBC article reported how designers are using AI and genera-\\ntive design to create aircraft components that are lighter, stronger, \\nand more efficient. This not only reduces the weight of the air -\\ncraft but also enhances its overall performance.\\nImagine a future skyline, a vista of towering buildings pro-\\nduced by generative design (Figure\\xa03.7). We are not as far off \\nfrom this reality as one might think. People using Midjourney'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='build visual ideas that are at the forefront of this movement, cre-\\nating innovative solutions that not only meet functional require-\\nments but also inspire awe with their aesthetic appeal. However, \\nit’s important to note that this transformation will not occur \\novernight. It’s a mid- to long-term projection, as it will take time \\nfor us to fully realize the potential of generative design.\\nThe future of generative design is bright and full of poten-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tial. As we continue to explore and harness this technology, we \\ncan expect to see a revolution in the way we design and create \\nobjects, from the smallest components to the tallest skyscrapers. \\nThe key lies in our ability to imagine, to innovate, and to inte-\\ngrate this powerful tool into our design processes.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='158 GENERATIVE AI\\nSolving Problems in Science by Google DeepMind\\nLet’s now turn our attention to the work of Google DeepMind, \\nwhose groundbreaking applications have not only pushed the \\nboundaries of what we thought was possible but also laid a sig-\\nnificant foundation for the future of artificial general intelligence.\\nDeepMind’s Broad Range of Offerings In 2016, the world of \\nAI was abuzz with the news of DeepMind’s AlphaGo triumphing'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='over Lee Sedol, a player of the highest skill level, 9th dan, in the \\nintricate game of Go. A game of immense complexity, Go boasts \\nmore potential board configurations than the number of atoms in \\nthe universe. This extraordinary accomplishment underscored \\nthe formidable capabilities of AI and its potential to navigate and \\nsolve problems of great complexity.\\nFIGURE\\xa03.7 Midjourney prompt: “Architecture futuristic city designed'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='from parametric organic buildings, CGI render, beautiful, cinematic, \\nphotorealistic, highly detailed, vivid, unreal engine.”\\nSource: AI-generated image created in Midjourney, Inc.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 159\\nBuilding on the success of AlphaGo, DeepMind introduced \\nAlphaGo Zero in 2017. Unlike its predecessor, which learned \\nfrom thousands of human games, AlphaGo Zero learned solely \\nthrough self-play, a process known as reinforcement learning. \\nThis improved version of AlphaGo defeated the original \\nAlphaGo 100\\xa0games to 0, demonstrating the power of learning \\nfrom scratch.\\nLater that year, DeepMind unveiled AlphaZero, a modified'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='version of AlphaGo Zero that could handle any two-player game \\nof perfect information. AlphaZero gained superhuman abilities \\nat chess and shogi, again learning solely through self-play. This \\nwas a significant step forward, showing that an AI system could \\nlearn to master different games without any prior knowledge.\\nIn a similar vein, DeepMind researchers published a new \\nmodel named MuZero in 2019. MuZero mastered the domains \\nof Go, chess, shogi, and Atari 2600\\xa0games without human data,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='domain knowledge, or known rules. This was a significant leap \\nforward in the development of AGI, demonstrating that an AI \\nsystem could learn to understand and master different environ-\\nments from scratch.\\nIn October 2022, DeepMind unveiled AlphaT ensor, a new \\nversion of AlphaZero, in a paper published in Nature. AlphaT en-\\nsor discovered a faster way to perform matrix multiplication— \\none of the most fundamental tasks in computing— using'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='reinforcement learning. For example, AlphaT ensor figured out \\nhow to multiply two mod-2 4×4\\xa0matrices in only 47\\xa0multiplica-\\ntions, unexpectedly beating the 1969 Strassen algorithm record \\nof 49\\xa0multiplications. This discovery has significant implications \\nfor computational efficiency and could lead to substantial savings \\nin computing steps in the future. This is a monumental achieve-\\nment in the field of AI and evidence of the potential of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='160 GENERATIVE AI\\nreinforcement learning in discovering novel, efficient algorithms \\nfor fundamental computational tasks.\\nIn the realm of competitive gaming, DeepMind’s AlphaStar \\nmade significant strides. In July 2019, AlphaStar began playing \\nagainst random humans on the public 1v1 European multiplayer \\nladder. Unlike the first iteration of AlphaStar, which played only \\nProtoss v. Protoss, this one played as all of the game’s races and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='had earlier unfair advantages fixed. By October 2019, AlphaStar \\nreached Grandmaster level on the StarCraft II ladder on all three \\nStarCraft races, becoming the first AI to reach the top league of \\na widely popular electronic sport (esport) without any game \\nrestrictions.\\nThese achievements of Google DeepMind are not just impres-\\nsive feats in the world of AI; they also mark important milestones \\nin our journey towards AGI. Each of these AI solutions, powered'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='by conventional AI and reinforcement learning, serves as a corner-\\nstone for the future of AGI. As we continue to explore and harness \\nthe power of AI, we can expect to see even more groundbreaking \\nadvancements in the field.\\nAlphaFold One of DeepMind’s most notable contributions in \\ngenerative AI is AlphaFold, a program that predicts protein \\nstructure using deep learning techniques. This is not a general \\napplication field but rather a specific one, and it’s crucial for solv-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ing problems in biology. However, it’s worth noting that despite \\nthe heavyweight nature of this specific application field, where \\ndeep knowledge is required to achieve even slight results, there \\nare countless other niche application fields that one can still \\nexplore or even create. We are very much in the early stages of \\ngenerative AI and AI in general.\\nAlphaFold has had two major versions: AlphaFold 1 (2018) \\nand AlphaFold 2 (2020), both of which placed first in the Critical'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 161\\nAssessment of Structure Prediction (CASP) competitions of \\ntheir respective years. But why focus on protein folding? What’s \\nthe problem it’s trying to solve?\\nProteins consist of chains of amino acids that fold to form \\nthe 3D structures of the proteins, a process known as protein \\nfolding. Understanding how the amino acid sequence determines \\nthe 3D structure is highly challenging, and this is referred to as'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='the protein folding problem. Before AlphaFold, methods of deter -\\nmining protein structures were expensive and time-consuming, \\nand computational methods were not close to experimental tech-\\nniques in terms of accuracy.\\nAlphaFold was trained on over 170,000 proteins from a pub-\\nlic repository of protein sequences and structures. The program \\nuses a form of attention network, a deep learning technique that \\nfocuses on having the AI identify parts of a larger problem, as'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='mentioned earlier in the section “Democratizing AI: Hugging \\nFace’s Success Story,” then piecing them together to obtain the \\noverall solution (Figure\\xa03.8). Y ou can see that its predictive power \\nis a close approximation to the experimental result, which can be \\nseen as the ground truth.\\nAlphaFold 1, introduced in 2018, used advanced learning \\nmethods to estimate a probability distribution for how close the \\nresidues were likely to be, turning the contact map into a likely'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='distance map. AlphaFold 2, introduced in 2020, is significantly \\ndifferent from the original version. It replaced the software \\ndesign used in AlphaFold 1\\xa0with a system of subnetworks cou-\\npled together into a single differentiable end-to-end model, \\nbased entirely on pattern recognition. Local physics, in the form \\nof energy refinement based on the AMBER model, is applied \\nonly as a final refinement step once the neural network predic-\\ntion has converged. The AMBER model, in simple terms, is'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='162 GENERATIVE AI\\na tool used in computational chemistry and biology to simulate \\nand understand how molecules, like proteins, behave. It uses the \\nprinciples of physics to predict how atoms in a molecule move \\nand interact with each other.\\nThere are four main concepts to understand about Alpha-\\nFold. First, AlphaFold generally works by starting off with an \\neducated guess, then iteratively improving the 3D generation. \\nSecond, it uses an attention-based model, focusing on all impor-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tant information rather than the latest information. For example, \\nin protein folding, certain amino acids could be folded right next \\nto each other while being far away in the input sequence. Third, \\nexpert knowledge is integrated. Some proteins fold in a specific \\nway and some are exceptions. Much of this expertise is included \\nin the model. Fourth, around 95 percent of the AI pipeline is \\ntrainable, so the model is continuously refined where possible \\nT1037 / 6vr4 T1049 / 6y4f'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='90.7 GDT 93.3 GDT\\n(adhesin tip)(RNA polymerase domain)\\nExperimental result\\nComputational prediction\\nFIGURE\\xa03.8 AlphaFold’s predictive power.\\nSource: www.deepmind.com/blog/alphafold- a- solution- to- a- 50- year- old- grand-  \\nchallenge- in- biology'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 163\\nand where new data is available. The team at Google DeepMind \\ncontinues to develop AlphaFold, focusing their efforts on areas \\nwhere they know the model’s weaknesses lie, such as in the field \\nof human antibody interactions.\\nDeepMind’s Gift to Humanity The typical narrative of inno-\\nvation involves a company solving a complex problem and subse-\\nquently monetizing the solution. The more intricate the problem,'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='the higher the price tag, particularly when demand is high. How-\\never, Google DeepMind chose a different path. They not only \\nopen sourced the AlphaFold source code but also made its data-\\nbase, containing all resulting 3D protein structures, freely avail-\\nable. This database has grown exponentially over the past year, \\nfrom 1\\xa0 million to over 200\\xa0 million proteins, covering nearly \\nevery known protein on Earth. Figure\\xa0 3.9 illustrates a rough \\nscale of proteins starting from 1 amino.\\n1'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='1\\nAMINO ACID AMINO ACIDS\\nIN A STRING\\nAMINO ACIDS\\nIN A PROTEIN\\n20 100’s 20,000\\nPROTEINS IN\\nTHE HUMAN BODY\\nDISTINCTIVE PROTEINS\\nFOUND ON EARTH\\n200,000,000\\nFIGURE\\xa0 3.9 The exponential growth of the protein database, now \\nencompassing nearly every known protein on Earth.\\nSource: Adapted from www.deepmind.com/research/highlighted-research/alphafold.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='164 GENERATIVE AI\\nThis decision has had profound implications for the scien-\\ntific community. Researchers can now encounter a protein \\nsequence in their work and find its 3D folding already cataloged \\nin Google DeepMind’s database. This has significantly acceler -\\nated the pace of research. As John McGeehan, a professor of \\nstructural biology at the University of Portsmouth, puts it, “What \\ntook us months and years to do, AlphaFold was able to do in a'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='weekend.” This has effectively put research on steroids, enabling \\nscientists to make rapid advancements in their respective fields.\\nSeveral alternatives to AlphaFold have emerged. Meta AI’s \\nESMFold offers accurate atomic-level predictions and competes \\nwith RoseTTAFold, another significant player developed by aca-\\ndemic researchers. Both are open source and have demonstrated \\ntheir utility to the scientific community.\\nRaptorX and IntFOLD are other protein prediction models'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='that hold their own in this competitive field. OmegaFold, devel-\\noped by Chinese biotech firm Helixon, predicts high-resolution \\nprotein structure from a single primary sequence, even outper -\\nforming RoseTTAFold while achieving prediction accuracy sim-\\nilar to that of AlphaFold 2.\\nPhyre and Phyre2 offer remote template detection, alignment, \\nand 3D modeling tools for protein structure prediction. Lastly, \\nOpenFold is another notable option for protein folding predic-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tion, often mentioned as an alternative to AlphaFold 2. These \\ntools, each with their unique strengths, contribute to the rapid \\nadvancements in protein folding prediction.\\nWhere Is AlphaFold Going? AlphaFold’s (and other models’) \\nimpact is not just a ripple, but a tidal wave that is reshaping our \\nunderstanding of the world. Its implications are vast, and its \\npotential is only just beginning to be realized.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 165\\nThe potential of AlphaFold is not confined to the realm of \\nacademia; it has profound implications for the future of human-\\nity. As an example, Ray Kurzweil, the American inventor and \\nfuturist, in his book The Singularity Is Near, envisions a future \\nwhere diseases like cancer and heart disease could be cured, and \\nthe human body could be maintained indefinitely by 2030. This \\nis not just a lofty dream; with the advancements brought about'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='by AlphaFold, it is a tangible possibility.\\nOne of the most significant impacts of AlphaFold is its poten-\\ntial to enhance our understanding of the human body. For \\ninstance, the nuclear pore complex, a massive assembly of pro-\\nteins that controls the traffic in and out of the nuclei in cells, has \\nlong been a mystery to scientists. However, with the help of \\nAlphaFold, researchers have been able to decipher its structure, \\npaving the way for a deeper understanding of how cells function'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='and opening up new avenues for medical research.\\nIn the realm of medicine, AlphaFold holds the promise of \\ncreating more effective treatments. For example, it could aid in \\nthe development of drugs to combat malaria, a disease that con-\\ntinues to claim hundreds of thousands of lives each year. By pre-\\ndicting the structure of the proteins involved in the disease, \\nresearchers could design drugs that target these proteins more \\neffectively, potentially saving countless lives.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='The implications of AlphaFold extend to our food system as \\nwell. By understanding the structure of proteins involved in food \\nproduction, we could develop healthier and more nutritious \\nfood. This could revolutionize the food industry and contribute \\nto the global fight against malnutrition and obesity.\\nIn terms of disease prevention, AlphaFold could play a crucial \\nrole in the development of effective vaccines. By predicting the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='structure of viral proteins, it could aid in the design of vaccines'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='166 GENERATIVE AI\\nthat can effectively neutralize these viruses, potentially prevent-\\ning future pandemics.\\nAlphaFold could also contribute to our efforts to combat \\nglobal warming. By understanding the structure of proteins \\ninvolved in carbon capture, we could develop effective tools for \\ncapturing carbon dioxide. This could be a significant step in reduc-\\ning greenhouse gas emissions and mitigating the effects of cli-\\nmate change.\\nIn the realm of materials science, AlphaFold could aid in the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='production of sustainable biomaterials. By predicting the struc-\\nture of proteins involved in material production, we could design \\nand produce materials that are not only strong and durable but \\nalso environmentally friendly.\\nMoreover, AlphaFold could also aid in the creation of artifi-\\ncial enzymes to produce building materials like carbon nano-\\ntubes and graphene. These materials have unique properties that \\nmake them ideal for a variety of applications, from electronics to'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='energy storage. With the help of AlphaFold, we could design \\nenzymes that can produce these materials more efficiently and \\nsustainably.\\nCode Generation\\nMuch like text, sound, and other sequential data types, code is \\nwell suited for T ransformer models. The implications of this are \\nprofound, as it streamlines the coding process and enhances the \\nproductivity of developers.\\nGoogle DeepMind’s AlphaCode Google DeepMind has con-\\ntinued its AlphaSeries with the introduction of AlphaCode. This'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='AI code-generation system has reached a competitive level of per-\\nformance in programming competitions, a feat that marks a sig-\\nnificant milestone in the field. AlphaCode operates by leveraging'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 167\\na massive dataset of programming problems and solutions, as well \\nas unstructured code from GitHub.\\nAlphaCode’s approach to code generation is not just intelli-\\ngent but also efficient. It generates thousands of proposed solu-\\ntions to a given problem, filters out the invalid ones, and then \\nclusters the remaining solutions into groups. From each group, a \\nsingle example is selected for submission. The system has been'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='trained in various programming languages, including C++, C, \\nGo, Java, JavaScript, Lua, PHP , T ypeScript, Ruby, Scala, Rust, \\nand Python.\\nIn a Codeforces programming contest, AlphaCode ranked \\non average in the top\\xa054 percent against more than 5,000 partici-\\npants in 10 contests. This achievement, which took place in 2022, \\nmarked the first time an AI code generation system has reached \\na competitive level of performance in programming competitions.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='However, it’s important to note that AlphaCode still  \\nrelies heavily on specific examples provided with the problem \\ndescription. Without these examples, its success rate would \\ndrop significantly.\\nThe advent of AI-driven code generation is not just a techno-\\nlogical breakthrough; it’s a paradigm shift in how we approach \\ncoding. As we continue to explore and harness the power of AI in \\nthis field, we can look forward to a future where coding is not just'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='faster and more efficient, but also more accessible to a broader \\nrange of individuals.\\nGitHub Copilot As a data scientist, I find the advent of code \\ngeneration not just fascinating, but exhilarating. I am, by nature, \\nan optimist. The thought of AI taking over some aspects of my \\njob doesn’t fill me with dread; rather, it stirs in me a sense of \\nanticipation. The prospect of seeing my ideas come to life with \\nless manual effort is genuinely exciting.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='168 GENERATIVE AI\\nT oday’s coding landscape offers a rich array of tools, two of \\nwhich have become integral to my work. I not only use these \\ntools extensively but also strongly advocate for their use within \\nmy teams. GitHub Copilot is the first of these, serving as my reli-\\nable companion throughout the coding process. The second is \\nChatGPT , a tool I frequently engage with during non-coding \\nphases, such as the initial stages of a project.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='However, it’s important to note a crucial aspect of using \\nChatGPT . While it’s a powerful tool for generating human-like \\ntext and assisting with various tasks, it’s essential to remember \\nthat it’s not designed to handle confidential information. I always \\nensure that my teams are aware of this and exercise caution not \\nto send any sensitive data to ChatGPT . This way, we can lever-\\nage the benefits of these advanced AI tools while maintaining our \\ncommitment to data privacy and security.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Now, GitHub Copilot is an AI-powered pair programmer \\nthat provides autocomplete-style suggestions as you code. Devel-\\noped by GitHub and OpenAI, it’s a cloud-based tool that assists \\nusers of various integrated development environments (IDEs), \\nincluding Visual Studio Code, Visual Studio, Neovim, and Jet-\\nBrains. It’s powered by OpenAI Codex, a production version of \\nthe Generative Pre-trained T ransformer 3 (GPT-3). This lan-\\nguage model uses deep learning to produce human-like text. The'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Codex model is further trained on gigabytes of source code in \\nmultiple programming languages.\\nGitHub Copilot is trained on a selection of the English lan-\\nguage, public GitHub repositories, and other publicly available \\nsource code. This includes a filtered dataset of 159 gigabytes of \\nPython code sourced from 54\\xa0million public GitHub reposito-\\nries. Interestingly, OpenAI’s GPT-3 is licensed exclusively to \\nMicrosoft, GitHub’s parent company— a strategic move, indeed.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='GitHub Copilot is designed to help developers code faster, \\nfocus on solving bigger problems, and stay in the flow longer.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 169\\nIt aims to make work more fulfilling. However, it’s worth noting \\nthat it may also produce suggestions based on insecure coding \\npatterns, bugs, or references to outdated APIs or idioms. The \\ncoder has to remain responsible at all times and not go on auto-\\npilot. Despite these potential pitfalls, the tool is expected to com-\\nplement the work of developers, empowering them to write code \\nmore easily and focus more on their core competencies and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='creativity.\\nCoding with ChatGPT and Other LLMs Using ChatGPT or \\nsimilar LLMs, you can easily code entire programs. For example, \\nask it to create a Python agent that plans your day using the  \\nOpenAI API, integrating with your calendar. The model will \\nclarify details, suggest a program structure, and even write the \\ncode. While your oversight is necessary, the process significantly \\naccelerates product development. Figure\\xa03.10 shows an example'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='of ChatGPT output, guiding you to build an AI agent.  \\nRemember to responsibly manage sensitive information shared \\nwith ChatGPT .\\nTransforming Traditional Data Analyst Practices The \\ntransformative power of generative AI doesn’t stop at making \\ncoding 10 times faster and more efficient. It’s also reshaping the \\nlandscape of data analysis as we know it. In fact, it’s safe to say \\nthat traditional data analysis is, to a degree, becoming legacy.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='With applications like PandasAI and the Code Interpreter plug-\\nin for ChatGPT , or offerings from Notable, data analysis has \\nbecome accessible to anyone who can formulate their thoughts \\nlogically.\\nConsider the Code Interpreter plug-in for ChatGPT , for \\nexample. Imagine you have a dataset that needs to be clustered. \\nY ou simply upload the data and ask the plug-in to perform an'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='170 GENERATIVE AI\\nelbow chart for the data. Instead of manually choosing the range \\nof numbers of clusters, performing a k-means clustering for each \\ncluster number, calculating the sum of squared errors, plotting \\nthe sum of squared errors per number of clusters (the so-called \\nelbow plot), and identifying the elbow point (the optimal num-\\nber of clusters in a dataset), the Code Interpreter does all these \\nsteps for you. Y ou state what you want, and it infers what needs'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='to be done to get there, then codes the respective analysis code.\\nPandasAI works similarly, except it takes only library com-\\nmands from the Pandas library. This shift in the way we approach \\nFIGURE\\xa03.10 An overview of how to build an LLM agent, its structure, \\nclasses, and methods needed.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 171\\ndata analysis and coding has a profound impact on future app \\nand product development. It democratizes the field, turning eve-\\nryone into a developer. Figure\\xa03.11 illustrates PandasAI in action.\\nThe AI code generation space is bustling with other notable \\nprojects and startups. Magic AI, for instance, is building an AI \\nplatform that generates code by allowing software engineers to'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='describe what they want in natural language. Other players in the \\nfield include T abnine, CodePal, Builder.ai, Engineer.ai, T uring, \\nT onic.ai, and many more. Each of these entities is contributing \\nto the evolution of coding and data analysis, making these fields \\nmore accessible and efficient than ever before.\\nFIGURE\\xa03.11 Using a single command to generate a plot from the data \\ncontained within the df data frame.\\nSource: https://github.com/gventuri/pandas- ai'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='172 GENERATIVE AI\\nText Generation\\nT ext generation transforms ideas into written language, creating \\ncoherent, contextually relevant text. This technology, powering \\napplications like chatbots and content creation tools, is revolu-\\ntionizing current communication. While this book delves into \\nvarious LLMs like open source options, ChatGPT , and Bard, we \\nalso focus on strategically planning LLM applications such \\nas Cicero.\\nCicero As we continue to explore the vast potential of language'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='models in generative AI, it’s worth shifting our gaze to the \\ngroundbreaking work done by Meta AI with Cicero. Cicero is an \\nAI that has mastered the art of Diplomacy, a strategy game that \\ndemands not just strategic planning but also the ability to build \\ntrust, negotiate, and cooperate with multiple players.\\nFor those unfamiliar with Diplomacy, it’s a game that can be \\nlikened to a blend of Risk, poker, and the TV show Survivor. \\nUnlike many board games where the objective is to outmaneuver'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='your opponents on the board, Diplomacy requires a cooperative \\ncomponent. The only way to win is by working with other play-\\ners to capture as much territory as possible, with negotiation and \\nalliance-building being key to success.\\nCicero has the distinction of being the first AI to play Diplo-\\nmacy at a human level. It has demonstrated an uncanny ability to \\nform strong alliances, make moves that benefit its allies, and \\nengage in simultaneous planning and conversation with players.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='It uses honesty as a tactic, understanding that trustworthiness is \\na valuable trait in the game. However, it’s also capable of decep-\\ntion when necessary to secure a win for its team.\\nProfessional human players have reported an eerie sense \\nthat Cicero seems to anticipate their plans. This is likely due to \\nCicero’s integration of a language model with planning and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 173\\nreinforcement learning, allowing it to infer players’ beliefs and \\nintentions. There’s more to language models and strategic rea-\\nsoning than just scaling up models.\\nCicero’s performance in Diplomacy is nothing short of supe-\\nrior. It has achieved more than double the average score of human \\nplayers on webDiplomacy.net, an online version of the game, and \\nranked in the top\\xa010 percent of participants who played more'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='than one game. This achievement is a testament to the power of \\ncombining two different areas of AI: strategic reasoning and nat-\\nural language processing. The integration of these techniques \\ngives Cicero the ability to reason and strategize with regard to \\nplayers’ motivations, then use natural language to communicate, \\nreach agreements to achieve shared objectives, form alliances, \\nand coordinate plans.\\nThe success of Cicero illustrates the potential of AI in com-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='plex strategy games that require not just strategic thinking but \\nalso the ability to communicate and negotiate.\\nWhere Are Applications Like Cicero Going? The question \\nis not so much about where we are now, but rather, where we are \\nheaded. How can this be harnessed to benefit us in ways we have \\nyet to imagine?\\nThe potential applications and directions for AI models like \\nCicero are as vast as they are varied. One such avenue lies in the'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='realm of military strategy. The U.S. Army War College has \\nalready begun to explore this, developing an AI tool called the \\nEnemy Analysis T ool, which uses AI to analyze enemy actions \\nand predict their future movements. This tool has the potential \\nto revolutionize military strategy, providing a level of insight and \\nforesight previously unattainable.\\nIn the commercial arena, AI is already leaving an indelible \\nfootprint. Pactum, a pioneering startup, has engineered an AI'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='174 GENERATIVE AI\\ncapable of autonomously negotiating business agreements, \\nthereby eliminating the need for human involvement. This AI, \\narmed with machine learning and game theory, adeptly navigates \\nthe intricacies of contract negotiation.\\nThe sphere of political decision making is another area ripe for \\nAI transformation. SingularityNET , an AI-focused enterprise, is in \\nthe process of crafting an AI sociopolitical decision support system.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='This innovative system employs AI to dissect complex sociopoliti-\\ncal scenarios and offer insightful decision-making guidance.\\nEvent planning, too, could undergo a revolution with the \\nadvent of AI. Skift, a platform specializing in travel industry \\nintelligence, has explored the potential of AI to automate diverse \\nfacets of event planning, from scheduling intricacies to vendor \\nnegotiation.\\nThe gaming industry is another sector that stands to gain'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='significantly from AI. Artificial intelligence is being harnessed to \\nautomate various elements of game development, such as charac-\\nter dialogue generation and the creation of personalized racing \\ncommentary. This not only lightens the load for game develop-\\ners but also enriches the gaming experience for players.\\nFinally, AI models akin to Cicero could be employed to \\namplify social interactions. A study featured in the Journal of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Marketing delves into the concept of artificial empathy, where AI \\nis crafted to mirror human empathy in interactions. This innova-\\ntive approach holds the potential to elevate the customer experi-\\nence across various sectors, from customer service to marketing.\\nAI Agents: The Active Executors in Generative AI As we talk \\nabout the capabilities of LLMs and their systems, it becomes appar-\\nent that AI agents represent the next logical frontier in the realm of'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='generative AI. Far from being just another application field, AI \\nagents are a burgeoning domain that amplifies the potential of gen-\\nerative AI. They hold the promise of enhancing every application'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 175\\nfield we’ve discussed so far. The only constraint, it appears, is the \\nboundary of our imagination, and perhaps more development.\\nAI agents, while in their infancy, are already showing promis-\\ning results. However, defining them precisely at this moment in \\ntime is challenging due to the various versions and interpreta-\\ntions that exist. This is the very active part of generative AI. T wo'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='dominant types of AI agents have emerged, with everything in \\nbetween yet to be determined.\\nThe first type of AI agent is one that is given a simple task, \\nexecutes it, and returns with the result. This could be a stand-alone \\nagent or a language model like ChatGPT that uses a plug-in. It \\ndoesn’t matter if it’s a single agent that is launched and then exe-\\ncutes the requested task or if it’s a language model that performs \\nan action based on the ask.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ChatGPT plug-ins, for instance, are connected to the Inter-\\nnet, external data sources, or third-party services, enhancing the \\naccuracy of its responses and allowing for a more personalized \\nexperience. Developed by third-party developers or OpenAI \\nitself, these plug-ins enable ChatGPT to access up-to-date infor-\\nmation, run computations, and interact with APIs defined by \\ndevelopers (Figure\\xa03.12).\\nFIGURE\\xa03.12 The rapid expansion of ChatGPT plug-ins, with over 100'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='unique plug-ins developed in just 40\\xa0days.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='176 GENERATIVE AI\\nHere are a few notable ChatGPT plug-ins available in 2023:\\nWolfram This plug-in provides access to advanced computa-\\ntional, mathematical, and real-time data to answer various \\nquestions of quantifiable nature— a great complement to what \\nlanguage models appear to be lacking. Its technical nature \\nmight be off-putting for some users, but it’s one of the best due \\nto its advanced abilities.\\nZapier Designed for busy professionals and marketers, Zapier'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='streamlines repetitive tasks by facilitating seamless communi-\\ncation between more than 5,000 popular business programs, \\nsuch as Gmail, Microsoft Outlook, and Slack.\\nChatGPT Chess Plug-in This plug-in allows you to play \\nchess with the AI and get better at the game.\\nChatGPT KAYAK or Expedia Plug-in Another travel-\\nrelated plug-in, KAYAK assists with flight and hotel bookings.\\nArgil AI This plug-in assists with 3D modeling and design.\\nChatWithPDF This plug-in allows you to view, annotate, and'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='extract text from PDFs— making it an invaluable tool for aca-\\ndemic research or extensive reading.\\nSpeechki Ideal for podcasters, audiobook creators, and con-\\ntent producers, Speechki transforms text into high-quality  \\naudio.\\nThe potential for new plug-ins that could enhance the capa-\\nbilities of ChatGPT is vast. Let’s explore some of these potential \\nideas that might exist by the time you are reading this, keeping in \\nmind that data privacy is not our focus here.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Imagine a healthcare plug-in that seamlessly integrates with \\nelectronic health record systems. This would allow healthcare pro-\\nfessionals to pull up patient information, check drug interactions, or'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 177\\neven generate preliminary diagnoses based on symptoms described \\nby the patient.\\nIn the sphere of education, a plug-in that connects to educa-\\ntional resources and databases could be a game changer. It could \\nprovide students with explanations of complex concepts, solu-\\ntions to problems, or even personalized study plans based on \\ntheir learning style and progress.\\nIn the financial sector, a plug-in that integrates with financial'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='APIs could allow users to check stock prices, get investment \\nadvice, or even execute trades directly from the chat interface.\\nThe real estate industry could also benefit from a plug-in \\nthat integrates with real estate databases. This would allow users \\nto search for properties, compare prices, and get information \\nabout different neighborhoods.\\nFitness enthusiasts would appreciate a plug-in that integrates \\nwith fitness APIs, allowing users to track their workouts, get'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='exercise recommendations, or even create personalized workout  \\nplans.\\nLastly, a legal plug-in that connects to legal databases could \\nprovide users with basic legal advice and explanations of legal \\nterms, or even help them draft simple legal documents.\\nThese are just a few examples of the potential plug-ins that \\ncould be developed to enhance the capabilities of ChatGPT . The \\npossibilities are endless, and the future of AI-assisted conversa-\\ntions is exciting.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tions is exciting.\\nAutonomous Agents The second type of AI agent is autono-\\nmous agents. These are not the AI tools of yesteryear, but \\nadvanced systems capable of executing tasks independently, with \\nminimal human supervision. Y et, they are designed with a fail-\\nsafe, a provision for human intervention, should the need arise. \\nThis is not a distant future concept, but a reality that is taking \\nshape even as we speak.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='178 GENERATIVE AI\\nThe allure of autonomous agents lies in their efficiency and \\ncost-effectiveness. They are tireless, working around the clock \\nwithout the need for breaks or sleep. They perform tasks at a \\nfraction of the cost of human employees.\\nThe applications of these autonomous agents are as diverse \\nas they are numerous. Consider the realm of social media man-\\nagement, a task that requires constant vigilance and timely \\nresponses. An autonomous agent can monitor multiple platforms'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='simultaneously, respond to queries, and even manage promo-\\ntional campaigns, all without breaking a sweat.\\nBut the reach of autonomous agents extends beyond the realm \\nof social media. They are making inroads into the world of politi-\\ncal campaign management, a field that requires strategic planning, \\nmeticulous execution, and constant monitoring. Autonomous \\nagents can analyze vast amounts of data, identify trends, and make \\nstrategic recommendations, all while managing the day-to-day'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='tasks of a campaign.\\nThe future of work is also set to undergo a seismic shift with \\nthe advent of autonomous agents. In the not-too-distant future, \\nit is conceivable that most people will not report to a human \\nboss, but to an autonomous agent. This is not a dystopian vision, \\nbut a pragmatic projection based on the capabilities of these \\nadvanced AI systems.\\nThe trajectory of autonomous agents points toward main-\\nstream adoption, not just in niche sectors, but across the board.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Every category, every industry, every task that can be automated \\nwill likely see the integration of autonomous agents. This is not \\na prediction but an eventuality that we are moving toward. \\nAutonomous agents are not just tools, but partners, collabora-\\ntors, and perhaps even future colleagues.\\nUnderstanding Autonomous Agents: A\\xa0Practical Example  \\nImagine the task at hand is to construct a web page that fetches \\ndaily T witter news, presenting the top three categories and 10'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='Generative AI’s Broad  Spectrum of Applications 179\\nposts of the day. T o accomplish this, we first need to set up the \\nautonomous agent. In my experience, the open source project \\nAutoGPT is the most robust code repository for autonomous \\nagents currently available. We’ve cloned it, configured all neces-\\nsary APIs like OpenAI for GPT-4, and prepared for the heavy \\nlifting. We’ve also set up GPT-3.5 for quick, cost-effective \\nresponses.\\nA crucial component that requires setup is long-term mem-'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='ory. From my experiments, Pinecone seems to be the best option, \\nalthough open source solutions like Milvus also hold their own.\\nOnce set up, AutoGPT is capable of cloning GitHub reposi-\\ntories, running them, accessing X (formerly T witter), and per -\\nforming online search engine searches. We present our goal to \\nthe autonomous agent, which, in a touch of whimsy, gives itself a \\nname— in this case, WebdevGPT . It then dissects the goal into \\nmanageable tasks.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='manageable tasks.\\nThe tasks it identifies include performing an online search \\naround best practices for setting up such web pages, developing \\nthe frontend with HTML, CSS, and JavaScript, and creating \\nbackend functionalities such as setting up APIs, building  \\ncron jobs, data fetching scripts, and a database. There’s also a \\ndata processing part, and finally, we want to deploy and test the  \\nweb page.\\nIn a fascinating display of autonomy, for each of these tasks'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='the autonomous agent spawns its own team. It creates an AI \\nagent for performing prior online research, one for frontend \\ndevelopment, one for backend functionalities, and one for testing.\\nThe research agent dives into the Internet, swiftly scanning \\nthe top\\xa01,000 Google, Reddit, and Quora results. It distills its \\nfindings and reasons through them. The research agent then \\npasses its findings to the next agent, the frontend development'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='agent, which uses this information to build the web page accord-\\ningly. It sets up the structure with HTML, styles it with CSS, and \\nadds functionality with JavaScript.'),\n",
       " Document(metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='180 GENERATIVE AI\\nSimultaneously, the backend agent codes the X/T witter \\nfetching pipeline, sets up the necessary cron jobs, and establishes \\nthe database. Once all these agents have completed their tasks, \\nthe quality assurance agent deploys the code locally and performs \\na thorough testing. If the quality standards are met, the code gets \\npackaged and the agents shut down. In just 17\\xa0minutes, we have \\na rudimentary, fully functioning web page.'),\n",
       " ...]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ac2445d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: e8a36d3e-72b7-49f0-b948-25bb3d602a7b)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding = download_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "24392ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d52d6411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.034477200359106064,\n",
       " 0.031023219227790833,\n",
       " 0.0067349993623793125,\n",
       " 0.02610897459089756,\n",
       " -0.03936201333999634,\n",
       " -0.16030248999595642,\n",
       " 0.06692397594451904,\n",
       " -0.006441470701247454,\n",
       " -0.04745051637291908,\n",
       " 0.014758859761059284,\n",
       " 0.07087533175945282,\n",
       " 0.05552757531404495,\n",
       " 0.019193289801478386,\n",
       " -0.026251329109072685,\n",
       " -0.010109508410096169,\n",
       " -0.026940548792481422,\n",
       " 0.022307483479380608,\n",
       " -0.022226618602871895,\n",
       " -0.14969265460968018,\n",
       " -0.01749304309487343,\n",
       " 0.007676269859075546,\n",
       " 0.05435226485133171,\n",
       " 0.003254482988268137,\n",
       " 0.03172600269317627,\n",
       " -0.0846213772892952,\n",
       " -0.02940598875284195,\n",
       " 0.051595672965049744,\n",
       " 0.04812409356236458,\n",
       " -0.003314794274047017,\n",
       " -0.05827922374010086,\n",
       " 0.041969284415245056,\n",
       " 0.022210709750652313,\n",
       " 0.1281888633966446,\n",
       " -0.022338956594467163,\n",
       " -0.011656241491436958,\n",
       " 0.06292833387851715,\n",
       " -0.032876305282115936,\n",
       " -0.09122610837221146,\n",
       " -0.03117538057267666,\n",
       " 0.05269957706332207,\n",
       " 0.047034792602062225,\n",
       " -0.08420304954051971,\n",
       " -0.0300561785697937,\n",
       " -0.020744718611240387,\n",
       " 0.009517784230411053,\n",
       " -0.003721792483702302,\n",
       " 0.007343328557908535,\n",
       " 0.03932436183094978,\n",
       " 0.09327410906553268,\n",
       " -0.0037885827478021383,\n",
       " -0.052742086350917816,\n",
       " -0.05805819109082222,\n",
       " -0.0068643949925899506,\n",
       " 0.005283229053020477,\n",
       " 0.08289298415184021,\n",
       " 0.019362755119800568,\n",
       " 0.0062844837084412575,\n",
       " -0.010330805554986,\n",
       " 0.009032356552779675,\n",
       " -0.037683770060539246,\n",
       " -0.04520607367157936,\n",
       " 0.02401638962328434,\n",
       " -0.0069442023523151875,\n",
       " 0.013491633348166943,\n",
       " 0.10005491971969604,\n",
       " -0.071683868765831,\n",
       " -0.02169504575431347,\n",
       " 0.03161846846342087,\n",
       " -0.05163463577628136,\n",
       " -0.08224768191576004,\n",
       " -0.06569331139326096,\n",
       " -0.00989536102861166,\n",
       " 0.0058163986541330814,\n",
       " 0.07355453819036484,\n",
       " -0.03405030816793442,\n",
       " 0.02488601580262184,\n",
       " 0.01448806282132864,\n",
       " 0.026457400992512703,\n",
       " 0.009656714275479317,\n",
       " 0.030217286199331284,\n",
       " 0.052803970873355865,\n",
       " -0.07535988092422485,\n",
       " 0.009897174313664436,\n",
       " 0.029836837202310562,\n",
       " 0.017555566504597664,\n",
       " 0.023091990500688553,\n",
       " 0.0019339261343702674,\n",
       " 0.0014001254457980394,\n",
       " -0.04717599228024483,\n",
       " -0.011194380931556225,\n",
       " -0.11420133709907532,\n",
       " -0.019812004640698433,\n",
       " 0.04026623070240021,\n",
       " 0.0021929889917373657,\n",
       " -0.07979222387075424,\n",
       " -0.02538231387734413,\n",
       " 0.09448292851448059,\n",
       " -0.02898111194372177,\n",
       " -0.14500252902507782,\n",
       " 0.23097743093967438,\n",
       " 0.027731100097298622,\n",
       " 0.032111480832099915,\n",
       " 0.031064996495842934,\n",
       " 0.04283281788229942,\n",
       " 0.06423777341842651,\n",
       " 0.03216314688324928,\n",
       " -0.00487674493342638,\n",
       " 0.055699415504932404,\n",
       " -0.03753236308693886,\n",
       " -0.0215055663138628,\n",
       " -0.028342649340629578,\n",
       " -0.028846941888332367,\n",
       " 0.03835311904549599,\n",
       " -0.01746867224574089,\n",
       " 0.05248536914587021,\n",
       " -0.07487605512142181,\n",
       " -0.03125976398587227,\n",
       " 0.021841533482074738,\n",
       " -0.03989564999938011,\n",
       " -0.008587109856307507,\n",
       " 0.026956573128700256,\n",
       " -0.04849550500512123,\n",
       " 0.011469874531030655,\n",
       " 0.029618263244628906,\n",
       " -0.020572170615196228,\n",
       " 0.013103901408612728,\n",
       " 0.028833406046032906,\n",
       " -3.194200554190157e-33,\n",
       " 0.0647820383310318,\n",
       " -0.018130239099264145,\n",
       " 0.051789943128824234,\n",
       " 0.12198273092508316,\n",
       " 0.028780145570635796,\n",
       " 0.0087220324203372,\n",
       " -0.07052115350961685,\n",
       " -0.01690724864602089,\n",
       " 0.040739696472883224,\n",
       " 0.042116180062294006,\n",
       " 0.02544722706079483,\n",
       " 0.03574619069695473,\n",
       " -0.04914474114775658,\n",
       " 0.002129100728780031,\n",
       " -0.015546616166830063,\n",
       " 0.05073058605194092,\n",
       " -0.048185259103775024,\n",
       " 0.03588063269853592,\n",
       " -0.004067067988216877,\n",
       " 0.10172475874423981,\n",
       " -0.05597001686692238,\n",
       " -0.010680987499654293,\n",
       " 0.011235800571739674,\n",
       " 0.09068652987480164,\n",
       " 0.004234495107084513,\n",
       " 0.035138655453920364,\n",
       " -0.009702835232019424,\n",
       " -0.09386523813009262,\n",
       " 0.09285551309585571,\n",
       " 0.00800494384020567,\n",
       " -0.007705416064709425,\n",
       " -0.052086714655160904,\n",
       " -0.012587959878146648,\n",
       " 0.0032668698113411665,\n",
       " 0.0060135237872600555,\n",
       " 0.007581581827253103,\n",
       " 0.010517198592424393,\n",
       " -0.08634552359580994,\n",
       " -0.06987876445055008,\n",
       " -0.0025338700506836176,\n",
       " -0.09097661077976227,\n",
       " 0.04688737168908119,\n",
       " 0.05207647755742073,\n",
       " 0.007193892262876034,\n",
       " 0.010903597809374332,\n",
       " -0.005229538772255182,\n",
       " 0.013937323354184628,\n",
       " 0.02196837216615677,\n",
       " 0.03420856222510338,\n",
       " 0.060224637389183044,\n",
       " 0.00011661044845823199,\n",
       " 0.014731992967426777,\n",
       " -0.07008922845125198,\n",
       " 0.02849903516471386,\n",
       " -0.027601642534136772,\n",
       " 0.010768351145088673,\n",
       " 0.03483092412352562,\n",
       " -0.022487878799438477,\n",
       " 0.00976911373436451,\n",
       " 0.07722778618335724,\n",
       " 0.021588344126939774,\n",
       " 0.11495622247457504,\n",
       " -0.06800113618373871,\n",
       " 0.023761043325066566,\n",
       " -0.015983911231160164,\n",
       " -0.01782696507871151,\n",
       " 0.06439494341611862,\n",
       " 0.03202573582530022,\n",
       " 0.05027022957801819,\n",
       " -0.005913649220019579,\n",
       " -0.03370799124240875,\n",
       " 0.017840316519141197,\n",
       " 0.01657339744269848,\n",
       " 0.06329654157161713,\n",
       " 0.03467720001935959,\n",
       " 0.04647345840930939,\n",
       " 0.09790614992380142,\n",
       " -0.006635494064539671,\n",
       " 0.02520708367228508,\n",
       " -0.0779883861541748,\n",
       " 0.01692640222609043,\n",
       " -0.0009457881096750498,\n",
       " 0.02247185818850994,\n",
       " -0.038253240287303925,\n",
       " 0.09570475667715073,\n",
       " -0.00535071175545454,\n",
       " 0.010469038039445877,\n",
       " -0.11524058878421783,\n",
       " -0.013262532651424408,\n",
       " -0.010709351859986782,\n",
       " -0.08311721682548523,\n",
       " 0.07327357679605484,\n",
       " 0.049392201006412506,\n",
       " -0.008994361385703087,\n",
       " -0.09584556519985199,\n",
       " 3.366149296434549e-33,\n",
       " 0.12493181973695755,\n",
       " 0.019349709153175354,\n",
       " -0.0582258477807045,\n",
       " -0.03598824888467789,\n",
       " -0.050746746361255646,\n",
       " -0.04566233605146408,\n",
       " -0.08260342478752136,\n",
       " 0.14819477498531342,\n",
       " -0.08842117339372635,\n",
       " 0.06027441471815109,\n",
       " 0.05103025957942009,\n",
       " 0.010303089395165443,\n",
       " 0.14121423661708832,\n",
       " 0.030813878402113914,\n",
       " 0.06103307381272316,\n",
       " -0.05285125970840454,\n",
       " 0.13664892315864563,\n",
       " 0.009189915843307972,\n",
       " -0.017325272783637047,\n",
       " -0.012848668731749058,\n",
       " -0.00799528043717146,\n",
       " -0.05098002031445503,\n",
       " -0.052350591868162155,\n",
       " 0.007593057118356228,\n",
       " -0.015166228637099266,\n",
       " 0.016960326582193375,\n",
       " 0.021270541474223137,\n",
       " 0.02055799402296543,\n",
       " -0.1200280711054802,\n",
       " 0.014461806043982506,\n",
       " 0.02675984986126423,\n",
       " 0.025330591946840286,\n",
       " -0.0427546426653862,\n",
       " 0.006768474821001291,\n",
       " -0.01445858832448721,\n",
       " 0.045261986553668976,\n",
       " -0.09147657454013824,\n",
       " -0.019439177587628365,\n",
       " -0.017833461984992027,\n",
       " -0.05491012707352638,\n",
       " -0.052641063928604126,\n",
       " -0.010459036566317081,\n",
       " -0.05201602354645729,\n",
       " 0.020892051979899406,\n",
       " -0.07997025549411774,\n",
       " -0.012111312709748745,\n",
       " -0.05773141607642174,\n",
       " 0.02317824214696884,\n",
       " -0.00803161971271038,\n",
       " -0.025989310815930367,\n",
       " -0.07995670288801193,\n",
       " -0.02072887495160103,\n",
       " 0.048817772418260574,\n",
       " -0.02038920484483242,\n",
       " -0.049176573753356934,\n",
       " 0.01415967382490635,\n",
       " -0.06362210959196091,\n",
       " -0.007807392161339521,\n",
       " 0.016431482508778572,\n",
       " -0.02568255178630352,\n",
       " 0.01338108442723751,\n",
       " 0.026248762384057045,\n",
       " 0.009978335350751877,\n",
       " 0.06322894990444183,\n",
       " 0.0026721502654254436,\n",
       " -0.006582724861800671,\n",
       " 0.016632026061415672,\n",
       " 0.03236645832657814,\n",
       " 0.03794251009821892,\n",
       " -0.036376021802425385,\n",
       " -0.006910946220159531,\n",
       " 0.00015967455692589283,\n",
       " -0.001633585779927671,\n",
       " -0.02727823331952095,\n",
       " -0.028038015589118004,\n",
       " 0.04968152567744255,\n",
       " -0.028867164626717567,\n",
       " -0.002418051240965724,\n",
       " 0.014774874784052372,\n",
       " 0.009764568880200386,\n",
       " 0.005797559395432472,\n",
       " 0.013486078940331936,\n",
       " 0.005567895248532295,\n",
       " 0.0372270792722702,\n",
       " 0.007232493255287409,\n",
       " 0.04015621170401573,\n",
       " 0.08150321245193481,\n",
       " 0.07199164479970932,\n",
       " -0.01305615995079279,\n",
       " -0.04288202524185181,\n",
       " -0.011011214926838875,\n",
       " 0.004897830542176962,\n",
       " -0.009229752235114574,\n",
       " 0.03519146889448166,\n",
       " -0.05103498697280884,\n",
       " -1.5714373802211412e-08,\n",
       " -0.08862444013357162,\n",
       " 0.0239093154668808,\n",
       " -0.01623874343931675,\n",
       " 0.03170047700405121,\n",
       " 0.027284175157546997,\n",
       " 0.05246879905462265,\n",
       " -0.04707096517086029,\n",
       " -0.058847445994615555,\n",
       " -0.0632082149386406,\n",
       " 0.04088853672146797,\n",
       " 0.049827940762043,\n",
       " 0.10655166208744049,\n",
       " -0.07450233399868011,\n",
       " -0.012495458126068115,\n",
       " 0.018370643258094788,\n",
       " 0.039474066346883774,\n",
       " -0.024797869846224785,\n",
       " 0.01451625395566225,\n",
       " -0.03706921264529228,\n",
       " 0.020015696063637733,\n",
       " -4.8594301915727556e-05,\n",
       " 0.00986657477915287,\n",
       " 0.024838784709572792,\n",
       " -0.05245809629559517,\n",
       " 0.029314136132597923,\n",
       " -0.08719196915626526,\n",
       " -0.014499745331704617,\n",
       " 0.026019057258963585,\n",
       " -0.018746383488178253,\n",
       " -0.07620513439178467,\n",
       " 0.035043250769376755,\n",
       " 0.10363949090242386,\n",
       " -0.02805054932832718,\n",
       " 0.012718234211206436,\n",
       " -0.07632549107074738,\n",
       " -0.018652433529496193,\n",
       " 0.02497669868171215,\n",
       " 0.08144541829824448,\n",
       " 0.06875890493392944,\n",
       " -0.0640566349029541,\n",
       " -0.08389392495155334,\n",
       " 0.061362382024526596,\n",
       " -0.033545587211847305,\n",
       " -0.10615341365337372,\n",
       " -0.04008050262928009,\n",
       " 0.03253019228577614,\n",
       " 0.07662486284971237,\n",
       " -0.07301613688468933,\n",
       " 0.0003375994274392724,\n",
       " -0.04087162762880325,\n",
       " -0.0757884681224823,\n",
       " 0.027527686208486557,\n",
       " 0.07462546974420547,\n",
       " 0.01771729253232479,\n",
       " 0.09121839702129364,\n",
       " 0.11022018641233444,\n",
       " 0.0005698270397260785,\n",
       " 0.05146332085132599,\n",
       " -0.014551276341080666,\n",
       " 0.03323199599981308,\n",
       " 0.023792244493961334,\n",
       " -0.022889798507094383,\n",
       " 0.03893755376338959,\n",
       " 0.030206795781850815]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = embedding.embed_query(\"Hello world\")\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a3855b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector length: 384\n"
     ]
    }
   ],
   "source": [
    "print( \"Vector length:\", len(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea8733bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2d255c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "34b6c5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone \n",
    "print(\"Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6f2bc2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone \n",
    "pinecone_api_key = PINECONE_API_KEY\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a334c3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.pinecone.Pinecone at 0x236b96bb6a0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a330344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec \n",
    "\n",
    "index_name = \"presi-bot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name = index_name,\n",
    "        dimension=384,  # Dimension of the embeddings\n",
    "        metric= \"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "677f7af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=texts_chunk,\n",
    "    embedding=embedding,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9951e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Existing index\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "# Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bbe50e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more data to the existing pinecone index\n",
    "dswith = Document(\n",
    "    page_content=\"Intellipaat is a youtube channel that provides tutorials on various topics.\",\n",
    "    metadata={\"source\": \"Youtube\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8842cbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8a74a4ab-ccfd-49dd-864e-444b8f786b75']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docsearch.add_documents(documents=[dswith])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cbec528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9c54ec6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='2495761c-fd14-4f30-ad08-dcaf21171e05', metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='generative AI. Far from being just another application field, AI \\nagents are a burgeoning domain that amplifies the potential of gen-\\nerative AI. They hold the promise of enhancing every application'),\n",
       " Document(id='b4eff945-47d8-42a5-86a5-4727d970849b', metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='generative AI. Far from being just another application field, AI \\nagents are a burgeoning domain that amplifies the potential of gen-\\nerative AI. They hold the promise of enhancing every application'),\n",
       " Document(id='126b4ecc-ab66-4361-a6ac-ba6958ef5354', metadata={'source': 'data\\\\Generative AI.pdf'}, page_content='generative AI. Far from being just another application field, AI \\nagents are a burgeoning domain that amplifies the potential of gen-\\nerative AI. They hold the promise of enhancing every application')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Generative AI?\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1aa75522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505634ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "743f3298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8d6fac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an Edcational assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "146b32ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(chatModel, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8afaf0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI refers to technology that uses machine learning models to generate new content, such as text, images, or music, by learning patterns from existing data. It holds the potential to enhance various applications by creating new and innovative outputs. \n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is Generative AI?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd040e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM stands for Large Language Model, which is a type of artificial intelligence designed to understand and generate human-like text by learning from large amounts of natural language data. They scale up without specific training for individual tasks, demonstrating adaptability by combining and extrapolating learned behaviors.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is LLM?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3643f7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The E attendance requirements specify that a student must have a minimum attendance of 75% in all courses in each semester or academic term. Exceptions can be made for approved leave of absence, such as participating in competitions or experiencing medical emergencies, where relaxation may be granted. Additionally, these requirements must adhere to any government regulatory body prescriptions for specific programs.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"what is the E ATTENDANCE REQUIREMENTS?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
